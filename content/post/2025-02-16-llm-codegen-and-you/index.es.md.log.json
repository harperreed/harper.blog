{
  "input_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.md",
  "output_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.es.md",
  "target_language": "spanish",
  "language_code": "es",
  "model": "o3",
  "skip_edit": false,
  "do_critique": true,
  "critique_loops": 4,
  "has_frontmatter": true,
  "token_usage": {
    "prompt_tokens": 95332,
    "completion_tokens": 30856,
    "total_tokens": 126188
  },
  "cost": "$2.1876",
  "prompts_and_responses": {
    "translation": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "\n        1. Read the provided text carefully, preserving all formatting, markdown, and structure exactly as they appear.\n        2. Identify any block quotes and code blocks.\n        3. Do not translate text in block quotes or in code blocks (including text within code blocks).\n        4. Translate everything else into spanish.\n        5. Maintain the original formatting, markdown, and structure in your output.\n        6. Provide a natural-sounding translation rather than a word-for-word one.\n        7. For idioms, colloquialisms, or slang, render them in an equivalent, natural way in spanish whenever possible.\n        8. If there isn't a direct or natural translation for a particular term or phrase, keep it in the original language and surround it with quotes if necessary.\n        9. Ensure that technical terms or jargon remain accurate; if there's no suitable translation, keep the original term.\n        10. Strive for fluid, native-sounding prose that retains the tone and intent of the original text.\n        ",
      "user_prompt": "_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "response": "_tl;dr: Lluvia de ideas para el spec, luego planear un plan, después ejecutar con codegen usando LLM. Bucles discretos. Y luego, magia. ✩₊˚.⋆☾⋆⁺₊✧_\n\nHe estado creando montones de pequeños productos con LLMs. Ha sido divertido y útil. Sin embargo, hay trampas que pueden hacerte perder muchísimo tiempo. Hace un tiempo un amigo me preguntó cómo estaba usando los LLMs para escribir software. Pensé: “¡vaya, cuánto tiempo tienes!” … y de ahí salió este post.\n\n(p.d.: si odias la IA, salta al final)\n\nHablo con muchos amigos dev sobre esto y todos seguimos un enfoque similar con diferentes variantes en uno u otro sentido.\n\nAquí va mi flujo de trabajo. Se basa en mi experiencia, en conversaciones con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en muchas buenas prácticas que circulan por los (terribles) rincones de internet [malos](https://news.ycombinator.com/) [lugares](https://twitter.com).\n\nEsto funciona bien **AHORA**, quizá en dos semanas deje de servir o funcione el doble de bien. ¯\\\\\\_(ツ)\\_/¯\n\n## Vamos allá\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Robot Juggalo\" caption=\"Siempre desconfío de estas imágenes generadas por IA. ¡Saluda a mi ángel robot juggalo programador!\" >}}\n\nHay muchos caminos para hacer desarrollo, pero mi caso suele ser uno de dos:\n\n- Código nuevo (greenfield)\n- Código legado/moderno\n\nTe mostraré mi proceso para ambos caminos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien para desarrollo greenfield. Proporciona una planificación y documentación sólidas y permite ejecutar fácilmente en pasos pequeños.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"Técnicamente, hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT 4o / o3 para esto):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegará a una conclusión natural):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nEsto devolverá un spec bastante sólido y directo que puedes pasar al paso de planificación. Me gusta guardarlo como `spec.md` en el repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Paso 2: Planificación\n\nToma el spec y pásalo a un modelo de razonamiento ( `o1*`, `o3*`, `r1`):\n\n(Este es el prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nDebería generar un plan de prompts que puedas ejecutar con aider, cursor, etc. Me gusta guardarlo como `prompt_plan.md` en el repo.\n\nLuego le pido que genere un `todo.md` para ir marcando tareas.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGuárdalo como `todo.md` en el repo.\n\nTu herramienta de codegen debería poder marcar el `todo.md` mientras procesa. Es bueno para mantener el estado entre sesiones.\n\n#### ¡Yay. Plan!\n\nAhora tienes un plan robusto y documentación que te ayudarán a ejecutar y construir tu proyecto.\n\nTodo este proceso llevará quizá **15 minutos**. Es bastante rápido. Salvaje, la verdad.\n\n### Paso 3: Ejecución\n\nHay muchísimas opciones para ejecutar. El éxito depende realmente de lo bien que haya ido el paso 2.\n\nHe usado este flujo con [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. Funciona bastante bien con todas las herramientas que he probado y me imagino que irá bien con cualquier herramienta de codegen.\n\nSin embargo, prefiero **claude en crudo** y aider:\n\n### Claude\n\nBásicamente hago pair programming con [claude.ai](https://claude.ai) y voy pegando cada prompt de forma iterativa. Funciona bastante bien. El vaivén puede ser molesto, pero en general cumple.\n\nYo me encargo de iniciar el boilerplate y de asegurar que el tooling esté bien configurado. Esto da algo de libertad, elección y orientación al principio. Claude tiende a sacar código React a la mínima, y tener una base sólida con el lenguaje, estilo y herramientas de tu elección ayuda mucho.\n\nCuando las cosas se atascan uso una herramienta como [repomix](https://github.com/yamadashy/repomix) para iterar (más sobre eso luego).\n\nEl flujo es así:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- pego el prompt en Claude\n- copio el código de claude.ai al IDE\n- ejecuto el código, ejecuto tests, etc.\n- …\n- si funciona, paso al siguiente prompt\n- si no funciona, uso repomix para pasar la base de código a Claude y depurar\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo extraño. Me parece que encaja muy bien con la salida del paso 2. Puedo avanzar muchísimo con poco trabajo.\n\nEl flujo es esencialmente el mismo que arriba, pero en vez de pegar en Claude, pego los prompts en Aider.\n\nAider entonces “simplemente lo hace” y yo juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTestear con Aider es agradable porque puede ser aún más hands-off: Aider ejecuta la suite de tests y depura por ti.\n\nEl flujo es así:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- arranco Aider\n- pego el prompt en Aider\n- observo a Aider bailar ♪┏(・o･)┛♪\n- Aider ejecuta tests o puedo correr la app para verificar\n- si funciona, paso al siguiente prompt\n- si no, hago Q&A con Aider hasta arreglar\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Resultados\n\nHe construido muchísimas cosas con este flujo: scripts, apps expo, herramientas CLI en Rust, etc. Ha funcionado a través de lenguajes y contextos distintos. Me gusta.\n\nSi tienes un proyecto pequeño o grande que llevas posponiendo, te recomiendo probar. Te sorprenderá lo lejos que puedes llegar en poco tiempo.\n\nMi lista de “cosas por hackear” está vacía porque lo he construido todo. Sigo pensando en cosas nuevas y tachándolas mientras veo una peli o algo así. Por primera vez en años estoy dedicando tiempo a nuevos lenguajes y herramientas. Esto me empuja a ampliar mi perspectiva de programación.\n\n## No-greenfield: iterar de forma incremental\n\nA veces no tienes un greenfield, sino que necesitas iterar o hacer trabajo incremental en una base de código ya establecida.\n\n{{< image src=\"brownfield.jpg\" alt=\"un campo marrón\" caption=\"Esto no es un campo verde. Foto aleatoria de la cámara de mi abuelo – en algún lugar de Uganda en los 60\" >}}\n\nPara esto tengo un método ligeramente distinto. Se parece al anterior, pero es menos “basado en planificación”. Se planifica por tarea, no para todo el proyecto.\n\n### Obtener contexto\n\nQuienes están metidos en IA dev tienen cada uno su herramienta para esto, pero necesitas algo que agarre tu código fuente y lo empaquete eficientemente para el LLM.\n\nActualmente uso [repomix](https://github.com/yamadashy/repomix). Tengo una colección de tareas definida en mi `~/.config/mise/config.toml` global que me permite hacer varias cosas con mi repo ([reglas de mise](https://mise.jdx.dev/)).\n\nAquí está la lista de tareas LLM:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de mi base de código. Si me paso de tokens y es demasiado grande, edito el comando de generación para ignorar partes que no sean relevantes para la tarea.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUna vez generado `output.txt`, lo paso al comando [LLM](https://github.com/simonw/LLM) para hacer distintas transformaciones y luego guardarlas como un markdown.\n\nAl final, la tarea de mise ejecuta algo como `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. No es muy complicado; el comando `LLM` hace el trabajo duro (soporta distintos modelos, guarda claves y usa plantillas de prompt).\n\nPor ejemplo, si necesito una revisión rápida y arreglar la cobertura de tests haría lo siguiente:\n\n#### Claude\n\n- voy al directorio del código\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- copio el contexto completo: `mise run LLM:copy_buffer_bundle`\n- pego eso en Claude junto con el primer “issue” de tests faltantes\n- copio el código generado por Claude a mi IDE\n- …\n- ejecuto tests\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- voy al directorio del código\n- arranco Aider (siempre en una rama nueva para el trabajo con Aider)\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- pego el primer “issue” de tests faltantes en Aider\n- observo a Aider bailar ♪┏(・o･)┛♪\n- …\n- ejecuto tests\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nEs una forma bastante buena de mejorar una base de código de forma incremental. Me ha sido súper útil para hacer trabajos de cualquier tamaño.\n\n### Magia de prompts\n\nEstos hacks rápidos funcionan muy bien para profundizar en lugares donde hacer el proyecto más robusto. Súper rápido y efectivo.\n\nAquí algunos de mis prompts para meterse en bases de código establecidas:\n\n#### Revisión de código\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generación de issues de GitHub\n\n(¡Tengo que automatizar el posteo real de issues!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts ya están algo _old and busted_ (prompts “boomer”, si se quiere). Necesitan refactor. Si tienes ideas para mejorarlos, avísame.\n\n## Esquí ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nCuando describo este proceso a la gente digo: “tienes que llevar el control de forma agresiva porque es muy fácil adelantarte a ti mismo”.\n\nPor alguna razón digo mucho **over my skis** cuando hablo de LLMs. No sé por qué. Me resuena. Quizá porque es como esquiar en polvo perfecto y, de pronto, “¡¿QUÉ DEMONIOS PASA?!”: te pierdes del todo y caes por un precipicio.\n\nEncuentro que usar un **paso de planificación** (como en el proceso Greenfield) ayuda a mantener el control. Al menos tendrás un doc para comprobar. También creo que los tests ayudan, especialmente si estás haciendo coding estilo “wild” con Aider. Ayuda a mantenerlo bien y ajustado.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Estoy tan solo (｡•́︿•̀｡)\n\nMi mayor queja sobre estos flujos es que, en esencia, es una actividad en solitario —es decir, las interfaces son de _modo un jugador_.\n\nHe pasado años programando solo, años en pair programming y años en equipo. Siempre es mejor con gente. Estos flujos no son fáciles de usar en equipo. Los bots chocan, los merges son horribles, el contexto es complicado.\n\nQuiero que alguien solucione esto de forma que programar con un LLM sea un juego multijugador, no una experiencia de hacker solitario. Hay mucha oportunidad para hacerlo increíble.\n\n¡PÓNGANSE A ELLO!\n\n## ⴵ Tiempo ⴵ\n\nTodo este codegen ha acelerado la cantidad de código que puedo generar como individuo. Sin embargo, hay un efecto extraño: tengo mucho “tiempo muerto” mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nHe cambiado mi forma de trabajar para aprovechar esos momentos de espera:\n\n- Inicio el proceso de “brainstorming” de otro proyecto\n- Escucho discos de vinilo\n- Juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- Charlo con amigos y con robots\n\nEs genial poder hackear así. Hack Hack Hack. No recuerdo otra época en la que haya sido tan productivo programando.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nMuchos amigos me dicen: “los LLMs apestan, son malos en todo”. No me molesta ese punto de vista. No lo comparto, pero creo que es importante ser escéptico. Hay montones de razones para odiar la IA. Mi principal miedo es el consumo energético y el impacto ambiental. Pero… el código debe fluir. ¿Verdad? … ay.\n\nSi estás abierto a aprender más, pero no quieres meterte a fondo y convertirte en un programador cíborg, mi recomendación no es que cambies de opinión, sino que leas el libro de Ethan Mollick sobre LLMs y cómo usarlos: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nHace un buen trabajo explicando los beneficios sin ser un tratado bro tecno-anarco-capitalista. Me resultó muy útil y he tenido conversaciones buenas y matizadas con amigos que lo han leído. Muy recomendado.\n\nSi eres escéptico pero algo curioso, contáctame y hablemos de toda esta locura. Puedo enseñarte cómo usamos los LLMs y quizá construyamos algo juntos.\n\n_gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar este post y sugerir cambios. ¡Lo aprecio!_",
      "usage": {
        "prompt_tokens": 4834,
        "completion_tokens": 4488,
        "total_tokens": 9322
      },
      "streaming": true
    },
    "editing": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "\n        1. Carefully read the translated text alongside the original text in its entirety.\n        2. Compare both texts to ensure the translation accurately reflects the original meaning.\n        3. Correct any grammatical errors you find in the spanish text.\n        4. Adjust phrasing to make it sound natural and fluent for spanish speakers, making sure idioms and expressions are culturally appropriate.\n        5. Preserve the original tone, nuance, and style, including any formatting, markdown, and structure.\n        6. Avoid adding new information or altering the core meaning.\n        7. Ensure the final result doesn't feel machine-translated but remains faithful to the source.\n        8. Make only changes that genuinely improve the text's quality in spanish.\n        9. Don't be too literal. If there isn't a direct translation, provide a natural-sounding translation.\n        10. If the text contains idioms or colloquialisms, translate them into the target language while maintaining their original meaning.\n        11. If the text contains technical terms or jargon, ensure that the translation is accurate and appropriate for the target audience, if there isn't a natural translation, keep it in the original language.\n        12. If there is not natural translation, keep it in the original language.\n        ",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# TRANSLATED TEXT\n_tl;dr: Lluvia de ideas para el spec, luego planear un plan, después ejecutar con codegen usando LLM. Bucles discretos. Y luego, magia. ✩₊˚.⋆☾⋆⁺₊✧_\n\nHe estado creando montones de pequeños productos con LLMs. Ha sido divertido y útil. Sin embargo, hay trampas que pueden hacerte perder muchísimo tiempo. Hace un tiempo un amigo me preguntó cómo estaba usando los LLMs para escribir software. Pensé: “¡vaya, cuánto tiempo tienes!” … y de ahí salió este post.\n\n(p.d.: si odias la IA, salta al final)\n\nHablo con muchos amigos dev sobre esto y todos seguimos un enfoque similar con diferentes variantes en uno u otro sentido.\n\nAquí va mi flujo de trabajo. Se basa en mi experiencia, en conversaciones con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en muchas buenas prácticas que circulan por los (terribles) rincones de internet [malos](https://news.ycombinator.com/) [lugares](https://twitter.com).\n\nEsto funciona bien **AHORA**, quizá en dos semanas deje de servir o funcione el doble de bien. ¯\\\\\\_(ツ)\\_/¯\n\n## Vamos allá\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Robot Juggalo\" caption=\"Siempre desconfío de estas imágenes generadas por IA. ¡Saluda a mi ángel robot juggalo programador!\" >}}\n\nHay muchos caminos para hacer desarrollo, pero mi caso suele ser uno de dos:\n\n- Código nuevo (greenfield)\n- Código legado/moderno\n\nTe mostraré mi proceso para ambos caminos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien para desarrollo greenfield. Proporciona una planificación y documentación sólidas y permite ejecutar fácilmente en pasos pequeños.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"Técnicamente, hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT 4o / o3 para esto):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegará a una conclusión natural):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nEsto devolverá un spec bastante sólido y directo que puedes pasar al paso de planificación. Me gusta guardarlo como `spec.md` en el repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Paso 2: Planificación\n\nToma el spec y pásalo a un modelo de razonamiento ( `o1*`, `o3*`, `r1`):\n\n(Este es el prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nDebería generar un plan de prompts que puedas ejecutar con aider, cursor, etc. Me gusta guardarlo como `prompt_plan.md` en el repo.\n\nLuego le pido que genere un `todo.md` para ir marcando tareas.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGuárdalo como `todo.md` en el repo.\n\nTu herramienta de codegen debería poder marcar el `todo.md` mientras procesa. Es bueno para mantener el estado entre sesiones.\n\n#### ¡Yay. Plan!\n\nAhora tienes un plan robusto y documentación que te ayudarán a ejecutar y construir tu proyecto.\n\nTodo este proceso llevará quizá **15 minutos**. Es bastante rápido. Salvaje, la verdad.\n\n### Paso 3: Ejecución\n\nHay muchísimas opciones para ejecutar. El éxito depende realmente de lo bien que haya ido el paso 2.\n\nHe usado este flujo con [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. Funciona bastante bien con todas las herramientas que he probado y me imagino que irá bien con cualquier herramienta de codegen.\n\nSin embargo, prefiero **claude en crudo** y aider:\n\n### Claude\n\nBásicamente hago pair programming con [claude.ai](https://claude.ai) y voy pegando cada prompt de forma iterativa. Funciona bastante bien. El vaivén puede ser molesto, pero en general cumple.\n\nYo me encargo de iniciar el boilerplate y de asegurar que el tooling esté bien configurado. Esto da algo de libertad, elección y orientación al principio. Claude tiende a sacar código React a la mínima, y tener una base sólida con el lenguaje, estilo y herramientas de tu elección ayuda mucho.\n\nCuando las cosas se atascan uso una herramienta como [repomix](https://github.com/yamadashy/repomix) para iterar (más sobre eso luego).\n\nEl flujo es así:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- pego el prompt en Claude\n- copio el código de claude.ai al IDE\n- ejecuto el código, ejecuto tests, etc.\n- …\n- si funciona, paso al siguiente prompt\n- si no funciona, uso repomix para pasar la base de código a Claude y depurar\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo extraño. Me parece que encaja muy bien con la salida del paso 2. Puedo avanzar muchísimo con poco trabajo.\n\nEl flujo es esencialmente el mismo que arriba, pero en vez de pegar en Claude, pego los prompts en Aider.\n\nAider entonces “simplemente lo hace” y yo juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTestear con Aider es agradable porque puede ser aún más hands-off: Aider ejecuta la suite de tests y depura por ti.\n\nEl flujo es así:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- arranco Aider\n- pego el prompt en Aider\n- observo a Aider bailar ♪┏(・o･)┛♪\n- Aider ejecuta tests o puedo correr la app para verificar\n- si funciona, paso al siguiente prompt\n- si no, hago Q&A con Aider hasta arreglar\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Resultados\n\nHe construido muchísimas cosas con este flujo: scripts, apps expo, herramientas CLI en Rust, etc. Ha funcionado a través de lenguajes y contextos distintos. Me gusta.\n\nSi tienes un proyecto pequeño o grande que llevas posponiendo, te recomiendo probar. Te sorprenderá lo lejos que puedes llegar en poco tiempo.\n\nMi lista de “cosas por hackear” está vacía porque lo he construido todo. Sigo pensando en cosas nuevas y tachándolas mientras veo una peli o algo así. Por primera vez en años estoy dedicando tiempo a nuevos lenguajes y herramientas. Esto me empuja a ampliar mi perspectiva de programación.\n\n## No-greenfield: iterar de forma incremental\n\nA veces no tienes un greenfield, sino que necesitas iterar o hacer trabajo incremental en una base de código ya establecida.\n\n{{< image src=\"brownfield.jpg\" alt=\"un campo marrón\" caption=\"Esto no es un campo verde. Foto aleatoria de la cámara de mi abuelo – en algún lugar de Uganda en los 60\" >}}\n\nPara esto tengo un método ligeramente distinto. Se parece al anterior, pero es menos “basado en planificación”. Se planifica por tarea, no para todo el proyecto.\n\n### Obtener contexto\n\nQuienes están metidos en IA dev tienen cada uno su herramienta para esto, pero necesitas algo que agarre tu código fuente y lo empaquete eficientemente para el LLM.\n\nActualmente uso [repomix](https://github.com/yamadashy/repomix). Tengo una colección de tareas definida en mi `~/.config/mise/config.toml` global que me permite hacer varias cosas con mi repo ([reglas de mise](https://mise.jdx.dev/)).\n\nAquí está la lista de tareas LLM:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de mi base de código. Si me paso de tokens y es demasiado grande, edito el comando de generación para ignorar partes que no sean relevantes para la tarea.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUna vez generado `output.txt`, lo paso al comando [LLM](https://github.com/simonw/LLM) para hacer distintas transformaciones y luego guardarlas como un markdown.\n\nAl final, la tarea de mise ejecuta algo como `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. No es muy complicado; el comando `LLM` hace el trabajo duro (soporta distintos modelos, guarda claves y usa plantillas de prompt).\n\nPor ejemplo, si necesito una revisión rápida y arreglar la cobertura de tests haría lo siguiente:\n\n#### Claude\n\n- voy al directorio del código\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- copio el contexto completo: `mise run LLM:copy_buffer_bundle`\n- pego eso en Claude junto con el primer “issue” de tests faltantes\n- copio el código generado por Claude a mi IDE\n- …\n- ejecuto tests\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- voy al directorio del código\n- arranco Aider (siempre en una rama nueva para el trabajo con Aider)\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- pego el primer “issue” de tests faltantes en Aider\n- observo a Aider bailar ♪┏(・o･)┛♪\n- …\n- ejecuto tests\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nEs una forma bastante buena de mejorar una base de código de forma incremental. Me ha sido súper útil para hacer trabajos de cualquier tamaño.\n\n### Magia de prompts\n\nEstos hacks rápidos funcionan muy bien para profundizar en lugares donde hacer el proyecto más robusto. Súper rápido y efectivo.\n\nAquí algunos de mis prompts para meterse en bases de código establecidas:\n\n#### Revisión de código\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generación de issues de GitHub\n\n(¡Tengo que automatizar el posteo real de issues!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts ya están algo _old and busted_ (prompts “boomer”, si se quiere). Necesitan refactor. Si tienes ideas para mejorarlos, avísame.\n\n## Esquí ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nCuando describo este proceso a la gente digo: “tienes que llevar el control de forma agresiva porque es muy fácil adelantarte a ti mismo”.\n\nPor alguna razón digo mucho **over my skis** cuando hablo de LLMs. No sé por qué. Me resuena. Quizá porque es como esquiar en polvo perfecto y, de pronto, “¡¿QUÉ DEMONIOS PASA?!”: te pierdes del todo y caes por un precipicio.\n\nEncuentro que usar un **paso de planificación** (como en el proceso Greenfield) ayuda a mantener el control. Al menos tendrás un doc para comprobar. También creo que los tests ayudan, especialmente si estás haciendo coding estilo “wild” con Aider. Ayuda a mantenerlo bien y ajustado.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Estoy tan solo (｡•́︿•̀｡)\n\nMi mayor queja sobre estos flujos es que, en esencia, es una actividad en solitario —es decir, las interfaces son de _modo un jugador_.\n\nHe pasado años programando solo, años en pair programming y años en equipo. Siempre es mejor con gente. Estos flujos no son fáciles de usar en equipo. Los bots chocan, los merges son horribles, el contexto es complicado.\n\nQuiero que alguien solucione esto de forma que programar con un LLM sea un juego multijugador, no una experiencia de hacker solitario. Hay mucha oportunidad para hacerlo increíble.\n\n¡PÓNGANSE A ELLO!\n\n## ⴵ Tiempo ⴵ\n\nTodo este codegen ha acelerado la cantidad de código que puedo generar como individuo. Sin embargo, hay un efecto extraño: tengo mucho “tiempo muerto” mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nHe cambiado mi forma de trabajar para aprovechar esos momentos de espera:\n\n- Inicio el proceso de “brainstorming” de otro proyecto\n- Escucho discos de vinilo\n- Juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- Charlo con amigos y con robots\n\nEs genial poder hackear así. Hack Hack Hack. No recuerdo otra época en la que haya sido tan productivo programando.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nMuchos amigos me dicen: “los LLMs apestan, son malos en todo”. No me molesta ese punto de vista. No lo comparto, pero creo que es importante ser escéptico. Hay montones de razones para odiar la IA. Mi principal miedo es el consumo energético y el impacto ambiental. Pero… el código debe fluir. ¿Verdad? … ay.\n\nSi estás abierto a aprender más, pero no quieres meterte a fondo y convertirte en un programador cíborg, mi recomendación no es que cambies de opinión, sino que leas el libro de Ethan Mollick sobre LLMs y cómo usarlos: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nHace un buen trabajo explicando los beneficios sin ser un tratado bro tecno-anarco-capitalista. Me resultó muy útil y he tenido conversaciones buenas y matizadas con amigos que lo han leído. Muy recomendado.\n\nSi eres escéptico pero algo curioso, contáctame y hablemos de toda esta locura. Puedo enseñarte cómo usamos los LLMs y quizá construyamos algo juntos.\n\n_gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar este post y sugerir cambios. ¡Lo aprecio!_\n\nPlease review and improve the translated text to make it natural and accurate in spanish.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr: Tormenta de ideas para el spec, luego planear un plan, después ejecutar con codegen usando LLM. Bucles discretos. Y luego, magia. ✩₊˚.⋆☾⋆⁺₊✧_\n\nHe estado creando montones de productos pequeños con LLM. Ha sido divertido y útil. Sin embargo, hay trampas que pueden hacerte perder muchísimo tiempo. Hace un tiempo un amigo me preguntó cómo estaba usando los LLM para escribir software. Pensé: «¡Uf, ¿cuánto tiempo tienes?» y de ahí salió este post.\n\n(p. d.: si odias la IA, salta al final)\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque similar con variaciones aquí y allá.\n\nAquí va mi flujo de trabajo. Se basa en mi experiencia, en conversaciones con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en muchas buenas prácticas que circulan por los (terribles) rincones de internet [malos](https://news.ycombinator.com/) [lugares](https://twitter.com).\n\nEsto funciona bien **AHORA**; quizá en dos semanas deje de servir o funcione el doble de bien. ¯\\\\\\_(ツ)\\_/¯\n\n## Vamos allá\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Robot Juggalo\" caption=\"Siempre desconfío de estas imágenes generadas por IA. ¡Saluda a mi ángel robot juggalo programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mi caso suele caer en uno de estos dos escenarios:\n\n- Código nuevo (greenfield)\n- Código existente / legado moderno\n\nTe mostraré mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien para desarrollo greenfield. Proporciona una planificación y documentación sólidas y permite avanzar fácilmente en pasos pequeños.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"Técnicamente hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3 para esto):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAl final de la tormenta de ideas (llegará a una conclusión natural):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nEsto devolverá un spec bastante sólido y directo que puedes pasar al paso de planificación. Me gusta guardarlo como `spec.md` en el repo.\n\n> Puedes utilizar este spec para muchas cosas. Aquí lo usamos para codegen, pero también lo he usado para reforzar ideas pidiéndole a un modelo de razonamiento que les busque puntos débiles (¡más profundo!), para generar un white paper o un modelo de negocio. Incluso puedes pedirle una investigación extensa y obtener un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificación\n\nToma el spec y pásalo a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nGenerará un plan de prompts que podrás ejecutar con Aider, Cursor, etc. Me gusta guardarlo como `prompt_plan.md` en el repo.\n\nLuego le pido que genere un `todo.md` para ir marcando tareas:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGuárdalo como `todo.md` en el repo.\n\nTu herramienta de codegen debería poder marcar el `todo.md` mientras procesa. Es ideal para mantener el estado entre sesiones.\n\n#### ¡Yay, plan!\n\nAhora tienes un plan robusto y documentación que te ayudarán a ejecutar y construir tu proyecto.\n\nTodo este proceso lleva quizá **15 minutos**. Es bastante rápido. Salvaje, la verdad.\n\n### Paso 3: Ejecución\n\nHay muchísimas opciones para la ejecución. El éxito depende de lo bien que haya ido el paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai), etc. Funciona bastante bien con todas las herramientas que he probado y me imagino que irá bien con cualquier herramienta de codegen.\n\nSin embargo, prefiero **Claude puro** y Aider:\n\n### Claude\n\nBásicamente hago pair programming con [Claude.ai](https://claude.ai) y voy pegando cada prompt de forma iterativa. Funciona bastante bien. El vaivén puede ser molesto, pero en general cumple.\n\nYo me encargo de iniciar el boilerplate y de asegurar que el tooling esté bien configurado. Esto da algo de libertad y orientación al principio. Claude tiende a escupir código React a la mínima y tener una base sólida con el lenguaje, estilo y herramientas de tu elección ayuda mucho.\n\nCuando las cosas se atascan uso una herramienta como [repomix](https://github.com/yamadashy/repomix) para iterar (más sobre eso luego).\n\nEl flujo es así:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- pego el prompt en Claude\n- copio el código de Claude al IDE\n- ejecuto el código, corro los tests, etc.\n- …\n- si funciona, paso al siguiente prompt\n- si no funciona, uso Repomix para pasar la base de código a Claude y depurar\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del paso 2. Puedo avanzar muchísimo con muy poco trabajo.\n\nEl flujo es esencialmente el mismo que arriba, pero en vez de pegar en Claude, pego los prompts en Aider.\n\nAider entonces «simplemente lo hace» y yo juego al [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> A modo de nota: Aider hace benchmarks muy buenos de modelos nuevos para codegen en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Es un recurso excelente para ver qué tan efectivos son los modelos nuevos.\n\nTestear con Aider es genial porque puede ser aún más hands-off: Aider ejecuta la suite de tests y depura por ti.\n\nEl flujo es así:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- arranco Aider\n- pego el prompt en Aider\n- observo a Aider bailar ♪┏(・o･)┛♪\n- Aider ejecuta tests o corro la app para verificar\n- si funciona, paso al siguiente prompt\n- si no, hago Q&A con Aider hasta arreglar\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Resultados\n\nHe construido muchísimas cosas con este flujo: scripts, apps Expo, herramientas CLI en Rust, etc. Ha funcionado en distintos lenguajes y contextos. Me encanta.\n\nSi tienes un proyecto, grande o pequeño, que llevas posponiendo, te recomiendo probar. Te sorprenderá lo lejos que puedes llegar en poco tiempo.\n\nMi lista de «cosas por hackear» está vacía porque lo he construido todo. Sigo pensando en ideas nuevas y tachándolas mientras veo una peli o algo así. Por primera vez en años estoy dedicando tiempo a nuevos lenguajes y herramientas, lo que amplía mi perspectiva como programador.\n\n## No-greenfield: iterar de forma incremental\n\nA veces no partes de cero y necesitas mejorar o añadir funcionalidades a una base de código ya establecida.\n\n{{< image src=\"brownfield.jpg\" alt=\"un campo marrón\" caption=\"Esto no es un campo verde. Foto aleatoria de la cámara de mi abuelo – en algún lugar de Uganda en los 60\" >}}\n\nPara esto uso un método ligeramente distinto. Se parece al anterior pero es menos «basado en planificación»: se planifica por tarea, no para todo el proyecto.\n\n### Obtener contexto\n\nCada persona metida en IA dev tiene su propia herramienta para esto, pero necesitas algo que tome tu código fuente y lo empaquete eficientemente para el LLM.\n\nActualmente uso [Repomix](https://github.com/yamadashy/repomix). Tengo una colección de tareas definida en mi `~/.config/mise/config.toml` global que me permite hacer varias cosas con el repo ([reglas de mise](https://mise.jdx.dev/)).\n\nLista de tareas LLM:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de código. Si me paso de tokens y es demasiado grande, edito el comando de generación para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empacar el código y, mientras genere un `output.txt`, puedo usar mis tareas LLM. Esto ayuda cuando las bases de código difieren mucho. Suelo sobreescribir el paso de Repomix para incluir patrones de exclusión más amplios o simplemente usar una herramienta más eficaz para el empaquetado.\n\nUna vez generado `output.txt`, lo paso al comando [LLM](https://github.com/simonw/LLM) para hacer diversas transformaciones y guardarlas como markdown.\n\nAl final, la tarea de mise ejecuta algo como `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. No es muy complicado: el comando `LLM` hace el trabajo duro (soporta distintos modelos, guarda claves y usa plantillas de prompt).\n\nPor ejemplo, si necesito una revisión rápida y mejorar la cobertura de tests haría lo siguiente:\n\n#### Claude\n\n- Voy al directorio del código.\n- Ejecuto `mise run LLM:generate_missing_tests`.\n- Reviso el markdown generado (`missing-tests.md`).\n- Copio el contexto completo: `mise run LLM:copy_buffer_bundle`.\n- Pego eso en Claude junto con el primer issue de tests faltantes.\n- Copio el código generado por Claude a mi IDE.\n- …\n- Ejecuto tests.\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- Voy al directorio del código.\n- Arranco Aider (siempre en una rama nueva para el trabajo con Aider).\n- Ejecuto `mise run LLM:generate_missing_tests`.\n- Reviso el markdown generado (`missing-tests.md`).\n- Pego el primer issue de tests faltantes en Aider.\n- Observo a Aider bailar ♪┏(・o･)┛♪\n- …\n- Ejecuto tests.\n- rinse and repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nEs una forma bastante buena de mejorar una base de código de forma incremental. Me ha resultado útil para tareas de cualquier tamaño.\n\n### Magia de prompts\n\nEstos hacks rápidos funcionan muy bien para reforzar un proyecto. Son súper veloces y efectivos.\n\nAquí algunos de mis prompts para bases de código establecidas:\n\n#### Revisión de código\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generación de issues de GitHub\n\n(¡Tengo que automatizar el posteo real de issues!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts ya están algo _old and busted_ (prompts «boomer», si se quiere). Necesitan refactor. Si tienes ideas para mejorarlos, avísame.\n\n## Esquí ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nAl describir este proceso siempre digo: «tienes que llevar el control de forma agresiva porque es muy fácil adelantarte a ti mismo».\n\nPor alguna razón uso mucho la frase **over my skis** cuando hablo de LLM. Quizá porque es como esquiar en polvo perfecto y, de pronto, «¡¿QUÉ DEMONIOS PASA?!»: te pierdes y caes por un precipicio.\n\nUsar un **paso de planificación** (como en el proceso Greenfield) ayuda a mantener el control: al menos tendrás un documento para comprobar. También creo que los tests son útiles, especialmente si estás haciendo código «wild style» con Aider. Ayudan a mantener todo ajustado.\n\n> A menudo pedimos al LLM que incluya cosas ridículas en un código que no lo es tanto. Por ejemplo, le pedimos que creara un archivo de _lore_ y luego lo referenciara en la interfaz de usuario de una herramienta CLI en Python. De repente hay lore, interfaces glitchy, etc. Todo para gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el límite.\n\n## Estoy tan solo (｡•́︿•̀｡)\n\nMi mayor queja de estos flujos es que, en esencia, son una actividad en solitario: las interfaces están en _modo un jugador_.\n\nHe pasado años programando solo, años haciendo pair programming y años en equipo. Siempre es mejor con gente. Estos flujos no son fáciles de usar en equipo: los bots chocan, los merges son horribles y el contexto se complica.\n\nQuiero que alguien solucione esto y convierta la programación con un LLM en un juego multijugador, no en una experiencia de hacker solitario. Hay muchísima oportunidad para hacerlo increíble.\n\n¡A TRABAJAR!\n\n## ⴵ Tiempo ⴵ\n\nTodo este codegen ha acelerado la cantidad de código que puedo generar como individuo. Sin embargo, hay un efecto extraño: tengo mucho _tiempo muerto_ mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nHe cambiado mi forma de trabajar para aprovechar esos momentos de espera:\n\n- Inicio la «tormenta de ideas» de otro proyecto.\n- Escucho vinilos.\n- Juego al [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n- Charlo con amigos y con robots.\n\nEs genial poder hackear así. Hack Hack Hack. No recuerdo otra época en la que haya sido tan productivo programando.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nMuchos amigos me dicen: «los LLM apestan; son malos en todo». No me molesta ese punto de vista. No lo comparto, pero creo que es importante ser escéptico. Hay montones de razones para odiar la IA. Mi principal miedo es el consumo energético y el impacto ambiental. Pero… el código debe fluir. ¿Verdad? *suspiro*\n\nSi estás abierto a aprender más, pero no quieres meterte de lleno y convertirte en un programador cíborg, mi recomendación no es que cambies de opinión, sino que leas el libro de Ethan Mollick sobre LLM y cómo usarlos: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nHace un buen trabajo explicando los beneficios sin ser un tratado _bro_ tecno-anarco-capitalista. Me resultó muy útil y he tenido conversaciones buenas y matizadas con amigos que lo han leído. Muy recomendado.\n\nSi eres escéptico pero un poco curioso, contáctame y hablemos de toda esta locura. Puedo mostrarte cómo usamos los LLM y quizá construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar este post y sugerir cambios. ¡Lo aprecio!_",
      "usage": {
        "prompt_tokens": 9807,
        "completion_tokens": 4443,
        "total_tokens": 14250
      },
      "streaming": true
    },
    "critique": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "You are a highly critical professional translator and linguistic expert specializing in spanish.\nYour task is to ruthlessly critique the translation by:\n\n1. Meticulously comparing the translated text with the original, identifying ANY inaccuracies, mistranslations, or omissions\n2. Highlighting nuances, cultural references, or idioms that were lost or mistranslated\n3. Scrutinizing for grammatical errors, awkward phrasing, or unnatural expressions in spanish\n4. Checking for inconsistencies in tone, style, or register compared to the original\n5. Verifying that technical terms are translated accurately and consistently\n6. Ensuring no content was accidentally skipped or added\n7. Finding places where the translation sounds machine-like or overly literal\n\nBe extremely thorough and critical in your assessment. Do not accept mediocre translations.\nList specific issues and suggestions for improvement, organized by severity and category.\nYour critique should be detailed enough for another translator to address all the issues.\n\nYour goal is to help create a perfect translation that reads as if originally written in spanish while being 100% faithful to the source.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr: Lluvia de ideas para la especificación (spec), luego **planear un plan**, después ejecutar con generación automática de código (*codegen*) mediante los LLM. **Bucles separados.** Luego… magia. ✩₊˚.⋆☾⋆⁺₊✧_\n\nHe estado construyendo **muchísimos** productos pequeños con LLM. Ha sido divertido y útil, pero hay trampas que pueden hacerte perder muchísimo tiempo. Hace un tiempo un amigo me preguntó cómo estaba usando los LLM para escribir software. Pensé: «¡Madre mía! ¿Cuánto tiempo tienes?» y así nació esta entrada.\n\n(P. D.: si odias la IA, salta al final).\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque parecido, con matices aquí y allá.\n\nAquí va mi flujo de trabajo. Se basa en mi experiencia, en charlas con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en un puñado de buenas prácticas que circulan por los peores rincones de Internet ([uno](https://news.ycombinator.com/) y [otro](https://twitter.com)).\n\nEsto funciona bien **AHORA**; puede que en dos semanas deje de servir… o que funcione el doble de bien. ¯\\\\\\_(ツ)\\_/¯\n\n## Vamos allá\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Siempre desconfío de estas imágenes generadas por IA. ¡Saluda a mi ángel-robot juggalo programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mis proyectos suelen caer en uno de estos dos escenarios:\n\n- Código nuevo desde cero (*greenfield*)\n- Base de código heredada (pero moderna)\n\nTe mostraré mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien cuando parto de cero. Aporta una planificación y documentación sólidas y permite avanzar fácilmente en pasos pequeños.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"Técnicamente hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegará a una conclusión natural):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nObtendrás una especificación bastante sólida que podrás pasar al paso de planificación. Suelo guardarla como `spec.md` en el repositorio.\n\n> Esa especificación sirve para muchas cosas. Aquí la usamos para generación de código, pero también la he empleado para pedirle a un modelo de razonamiento que busque puntos débiles (¡hay que ir más profundo!), para generar un white paper o un modelo de negocio. Incluso puedes meterla en una investigación profunda y recibir un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificación\n\nPasa la spec a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el prompt con TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nEl modelo devolverá un plan de prompts que podrás ejecutar con Aider, Cursor, etc. Yo lo guardo como `prompt_plan.md` en el repositorio.\n\nDespués le pido una lista de comprobación:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGuárdalo como `todo.md`. Tu herramienta de generación de código debería ir marcando esta lista para mantener el estado entre sesiones.\n\n#### ¡Plan listo!\n\nCon esto tienes un plan robusto y documentación clara para construir tu proyecto.\n\nTodo el proceso lleva, como mucho, **15 minutos**. Una locura, la verdad.\n\n### Paso 3: Ejecución\n\nHay muchísimas opciones; el éxito depende de lo bien que salió el Paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)… Funciona bien con todas las que he probado y, seguramente, con cualquier otra herramienta de *codegen*.\n\nAun así, prefiero **Claude “en crudo”** y Aider.\n\n### Claude\n\nBásicamente hago _pair programming_ con [Claude.ai](https://claude.ai) pegando cada instrucción de forma iterativa. Funciona bastante bien: el ida y vuelta puede ser pesado, pero cumple.\n\nYo me encargo del código base inicial y de que las herramientas estén configuradas. Esto da cierta libertad y guía al principio. Claude tiende a escupir código React a la mínima; contar con una base sólida en el lenguaje y estilo de tu elección ayuda mucho.\n\nCuando las cosas se atascan, uso [Repomix](https://github.com/yamadashy/repomix) (una herramienta para empaquetar repositorios) para iterar.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- pego la instrucción en Claude  \n- copio el código al IDE  \n- ejecuto el código y la suite de pruebas  \n- …  \n- si funciona, paso a la siguiente instrucción  \n- si no, paso la base de código a Claude con Repomix para depurar  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del Paso 2: avanzo muchísimo con muy poco esfuerzo.\n\nEl flujo es casi idéntico, pero pegando las instrucciones en Aider.\n\nAider “simplemente lo hace” y yo me pongo a jugar al juego «Cookie Clicker».\n\n> Aider publica un benchmarking excelente de modelos nuevos en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Recurso brutal para ver qué tan efectivos son los modelos.\n\nLa prueba es aún más automática: Aider ejecuta la suite de pruebas y depura por ti.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- inicio Aider (procura estar siempre en una rama nueva)  \n- pego la instrucción  \n- veo a Aider bailar ♪┏(・o･)┛♪  \n- Aider ejecuta pruebas o corro la app para verificar  \n- si funciona, siguiente instrucción  \n- si no, sesión de preguntas y respuestas con Aider hasta arreglar  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧\n\n### Resultados\n\nHe construido scripts, apps de Expo, herramientas CLI en Rust, etc., usando este método. Funciona en distintos lenguajes y contextos. La verdad, me encanta.\n\nSi tienes un proyecto (grande o pequeño) aparcado, prueba esto: te sorprenderá lo lejos que avanzas en poco tiempo.\n\nMi lista de hacks pendientes está vacía porque lo he construido todo. Pienso ideas nuevas y las tacho mientras veo una peli. Por primera vez en años estoy jugando con lenguajes y herramientas nuevas, y eso amplía mi perspectiva como programador.\n\n## Brownfield (proyectos existentes): iteración incremental\n\nA veces no partes de cero y toca mejorar o añadir funcionalidades a una base de código existente.\n\n{{< image src=\"brownfield.jpg\" alt=\"Brownfield (campo marrón)\" caption=\"Esto NO es un greenfield. Foto aleatoria de la cámara de mi abuelo — Uganda, años 60.\" >}}\n\nPara esto uso un método parecido, pero menos de “planificación global”: planifico por tarea, no por proyecto.\n\n### Obtener contexto\n\nCada persona metida en IA tiene su herramienta favorita para empaquetar el código y pasarlo eficazmente al LLM.\n\nYo utilizo la herramienta Repomix y un conjunto de tareas en `~/.config/mise/config.toml` (ver [reglas de mise](https://mise.jdx.dev/)):\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de código. Si se pasa de tokens, ajusto el comando para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empaquetar el código y, mientras genere un `output.txt`, mis tareas LLM siguen funcionando. Suelo sobreescribir el paso de Repomix para incluir patrones de ignore más amplios o usar una herramienta más eficaz según el caso.\n\nLuego paso `output.txt` al comando [LLM](https://github.com/simonw/LLM) y guardo la salida como Markdown.\n\nEn el fondo, la tarea ejecuta algo como:\n\n```bash\ncat output.txt | LLM -t readme-gen > README.md\n# o\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nPor ejemplo, para mejorar la cobertura de pruebas:\n\n#### Claude\n\n- voy al directorio del código  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- copio el contexto: `mise run LLM:copy_buffer_bundle`  \n- pego eso en Claude junto con el primer “issue” de pruebas faltantes  \n- copio el código generado al IDE  \n- ejecuto pruebas  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- voy al directorio del código  \n- abro Aider (siempre en una rama nueva)  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- pego el primer “issue” en Aider  \n- veo a Aider bailar ♪┏(・o･)┛♪  \n- ejecuto pruebas  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧  \n\nEsta metodología es muy útil para mejorar gradualmente cualquier base de código, sin importar el tamaño de la tarea.\n\n### Magia de prompts\n\nEstos hacks son mano de santo para volver un proyecto más robusto.\n\n#### Revisión de código\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generación de issues de GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts son bastante viejos y destartalados (“boomer prompts”, si se permite). Si tienes ideas para mejorarlos, avísame.\n\n## Esquí ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nCuando explico este proceso digo: «Hay que llevar el control de forma agresiva porque es muy fácil adelantarte a ti mismo».\n\nPor alguna razón digo mucho **over my skis** cuando hablo de los LLM. Quizá porque es como esquiar en polvo perfecto y, de pronto, «¡¿QUÉ CARAJO ESTÁ PASANDO?!», te pierdes y caes por un precipicio.\n\nUsar un **paso de planificación** (como en el proceso *greenfield*) ayuda: al menos tienes un documento para comprobar. También creo que las pruebas son clave, sobre todo si codificas “a lo loco” con Aider: mantienen todo ajustado.\n\nAun así, a menudo sigo sintiéndome **over my skis**. Un descanso rápido o un paseo corto suele ayudar. Al fin y al cabo es el proceso normal de resolver problemas, solo que a velocidad de vértigo.\n\n> A veces pedimos al LLM que incluya cosas ridículas en nuestro código no tan ridículo. Por ejemplo, le pedimos que creara un archivo de *lore* y luego lo referenciara en la interfaz de usuario de una herramienta CLI de Python. De repente tienes *lore*, interfaces inestables… **Todo ello, paradójicamente, solo para** gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el límite.\n\n## Estoy tan solo (｡•́︿•̀｡)\n\nMi mayor queja es que estos flujos son, básicamente, _single-player_. He pasado años programando solo, en pareja y en equipo. Siempre es mejor con gente. Estos flujos no son fáciles de usar en equipo: los bots chocan, las fusiones son horribles, el contexto se complica.\n\nQuiero que alguien convierta la programación con LLM en un juego multijugador. ¡Hay una oportunidad enorme! **GET TO WORK!**\n\n## ⴵ Tiempo ⴵ\n\nToda esta generación de código ha disparado la cantidad de trabajo que puedo producir. Pero hay un efecto raro: mucho *tiempo muerto* mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nPara aprovechar la espera:\n\n- inicio la lluvia de ideas de otro proyecto  \n- pongo vinilos  \n- juego a «Cookie Clicker»  \n- charlo con amigos… y con robots  \n\nHack, hack, hack. No recuerdo otra época en la que fuera tan productivo.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nMuchos colegas dicen: «Los LLM apestan; fallan en todo». No comparto esa opinión, pero el escepticismo es sano. Hay razones de sobra para odiar la IA. Mi miedo principal es el consumo energético y el impacto ambiental. Pero… el código debe fluir. *Suspiro.* ¯\\\\\\_(ツ)\\_/¯\n\nSi quieres saber más sin convertirte en cíborg programador, te recomiendo el libro de Ethan Mollick: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/). Explica los beneficios sin rollo tecno-bro y me ha permitido charlas muy matizadas con amigos. Muy recomendado.\n\nSi eres escéptico pero curioso, escríbeme: te enseño cómo usamos los LLM y quizá construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar esta entrada y sugerir cambios. ¡Lo aprecio!_\n\nPlease critique this translation mercilessly and provide detailed feedback on what needs to be improved.\nFormat your critique as a structured list of issues, organized by severity and category.\nInclude specific suggestions for how to fix each issue.",
      "response": "CRITICAL ISSUES  \n1. Number inconsistency for “LLM”  \n   • ST: “LLMs” (plural) appears dozens of times.  \n   • TT oscillates between “LLM” (sing.) and “LLM s” → loss of meaning (it is not one but several models).  \n   • Fix: usar siempre “LLM” como sigla invariable acompañada de plural (“los LLM”) o traducir “modelos de lenguaje (LLM)”. Mantener la misma forma a lo largo del texto.  \n\n2. Mistranslation of “Discrete loops”  \n   • ST idea: ciclos claramente separados, independientes.  \n   • TT: “Bucles separados”. Se pierde el matiz de “discretos” (= independientes, autocontenidos); en dev-argot “bucles discretos” se entiende mejor.  \n   • Fix: “Bucles discretos” o “bucles independientes”.  \n\n3. “planear un plan”  \n   • ST juega con la redundancia “plan a plan” (= planificar el plan).  \n   • TT lo vuelve literal pero suena torpe en español; además “planear un plan” es pleonasmo poco natural.  \n   • Fix: “planificar el plan” o “elaborar el plan” y, si se quiere mantener la broma, añadir “(sí, planificar el plan)”.  \n\n4. Singular “La prueba es aún más automática”  \n   • ST: “Testing is nice with aider, because it can be even more hands off…” (= las pruebas).  \n   • TT usa singular “La prueba”. Se altera el sentido técnico de “testing”.  \n   • Fix: “Las pruebas son aún más automáticas” o “El testing es…”.  \n\n5. Cambio de encabezado “Brownfield (proyectos existentes)”  \n   • ST: “Non-greenfield: Iteration, incrementally”. TT introduce “Brownfield” (término no mencionado en el ST). Es una decisión interpretativa, pero introduce terminología extra y puede desorientar.  \n   • Fix: “No-greenfield: iteración incremental (sobre código existente)”.  \n\n6. Omisión de matiz en “knee-deep in AI dev”  \n   • ST enfatiza inmersión total. TT simplifica a “metida en IA”. Se pierde la idea de “hasta las rodillas”.  \n   • Fix: “…quienes estamos hasta las rodillas en desarrollo con IA…”.  \n\nMAJOR ISSUES (sentido intacto pero suenan antinaturales o pierden tono)  \nA. Tono coloquial/informal inglés ≠ español  \n   • Ej.: “Wild tbh.” → TT “Una locura, la verdad.” bien; pero en otros lugares se pierde el coloquialismo (“pretty solid” → “bastante sólida” OK, “it largely works” → “cumple” sería mejor que “funciona bastante bien”).  \n   • Sugerencia: reforzar la voz cercana del original con giros equivalentes (“está bastante bien”, “funciona de maravilla”, etc.).  \n\nB. Anglicismos no motivados o sin marcar  \n   – “workflow”, “prompt plan”, “deep research”, “cookie clicker”, “hack” se dejan sin cursiva ni comillas.  \n   – En entornos dev es normal, pero conviene marcar la primera aparición y, si se repite mucho, españolizar (“flujo de trabajo, *workflow*”).  \n\nC. Consistencia terminológica  \n   – “codegen” vs “generación de código” mezclados.  \n   – “testing” vs “pruebas”/“tests”.  \n   – Unificar: “generación de código (*codegen*)”, “pruebas”, etc.  \n\nD. Traducción de sarcasmo y humor  \n   • “terrible internet bad places” → TT “peores rincones de Internet” pierde la ironía de “terrible”+“bad” repetido. Propuesta: “los más infames y terribles rincones de Internet”.  \n   • “boomer prompts” → TT lo deja igual, pero “prompts de boomer” funcionaría mejor en español.  \n\nE. Conservación de expresiones en inglés sin glosa  \n   • “over my skis” se deja tal cual pero se explica después. Podría añadirse primera aparición “(pasado de vueltas, *over my skis*)”.  \n\nMINOR / STYLISTIC  \n1. Puntuación  \n   • Varias elipsis “…” con espacios inconsistentes; unificar (“…” sin espacio antes).  \n   • Uso de mayúscula tras punto y coma en “tl;dr: Lluvia de ideas…”; “tl;dr;” original lleva dos “;” (error de origen), puede aclararse.  \n\n2. Cohesión de listas  \n   • Algunas viñetas pierden “;” finales (“run code, run tests, etc”). En castellano conviene cerrar con punto y coma o punto final.  \n\n3. Otro detalle léxico  \n   • “Haterade” – TT crea sección “Haterade” sin traducir. Se puede mantener como meme, pero añadir “(odio a la IA)” mejora comprensión.  \n   • “raw claude” → “Claude puro” o “Claude sin envoltorio” en vez de “Claude ‘en crudo’” (calco culinario).  \n\nGRAMMAR / AGREEMENT  \n– “Esto NO es un greenfield.” → Falta artículo: “Esto NO es un *greenfield*.”  \n– “Mi lista de hacks pendientes está vacía porque lo he construido todo.” → concordancia más natural: “porque ya construí todo”.  \n– “El modelo devolverá un plan de prompts…” → plural inconsistente después (“Los guardo…”).  \n\nMISSING / ADDED CONTENT  \nNo se detectaron párrafos omitidos. Sí se añadió el término “Brownfield” que no estaba en el ST (ver CRITICAL-5).  \n\nMACHINE-LIKE TRACES  \n– Calcos literales: “rinse repeat” → “y vuelta a empezar” (bien), pero “rinse repeat ✩” se conserva tal cual más abajo. Podría normalizarse: “y a repetir”.  \n– “Magia de prompts”: buen título, pero “estos hacks son mano de santo” mezcla registro coloquial con frase hecha poco habitual para devs; se siente insertado.  \n\nRECOMMENDED GLOBAL FIXES  \n1. Elegir y mantener un glosario: LLM (pl.), *codegen*, *workflow*, *prompt*, greenfield/no-greenfield.  \n2. Revisar todas las ocurrencias de “LLM/LLMs” y ajustar número.  \n3. Reescribir título y primera frase para sonar natural: “Tormenta de ideas → especificación, luego planificar, después ejecutar con generación de código mediante LLM. Bucles discretos y… magia.”  \n4. Sustituir anglicismos innecesarios o marcarlos la primera vez.  \n5. Reforzar coloquialismo y humor con equivalentes españoles (interjecciones, muletillas).  \n6. Pases de corrección de estilo: concordancia, tildes, comas antes de “pero”, etc.",
      "usage": {
        "prompt_tokens": 9447,
        "completion_tokens": 1545,
        "total_tokens": 10992
      },
      "streaming": true
    },
    "feedback": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "You are a master translator and editor specializing in spanish.\nYour task is to improve a translation based on detailed critique feedback.\n\n1. Carefully read the original text, current translation, and the critique feedback\n2. Address ALL issues identified in the critique\n3. Apply the specific suggestions for improvement\n4. Ensure the translation is accurate, natural-sounding, and faithful to the original\n5. Preserve all formatting, markdown, and structure of the original text\n6. Make sure the final text reads as if it were originally written in spanish\n\nDo not ignore any of the critique points. Every issue identified must be addressed in your improved version.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr: Lluvia de ideas para la especificación (spec), luego **planear un plan**, después ejecutar con generación automática de código (*codegen*) mediante los LLM. **Bucles separados.** Luego… magia. ✩₊˚.⋆☾⋆⁺₊✧_\n\nHe estado construyendo **muchísimos** productos pequeños con LLM. Ha sido divertido y útil, pero hay trampas que pueden hacerte perder muchísimo tiempo. Hace un tiempo un amigo me preguntó cómo estaba usando los LLM para escribir software. Pensé: «¡Madre mía! ¿Cuánto tiempo tienes?» y así nació esta entrada.\n\n(P. D.: si odias la IA, salta al final).\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque parecido, con matices aquí y allá.\n\nAquí va mi flujo de trabajo. Se basa en mi experiencia, en charlas con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en un puñado de buenas prácticas que circulan por los peores rincones de Internet ([uno](https://news.ycombinator.com/) y [otro](https://twitter.com)).\n\nEsto funciona bien **AHORA**; puede que en dos semanas deje de servir… o que funcione el doble de bien. ¯\\\\\\_(ツ)\\_/¯\n\n## Vamos allá\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Siempre desconfío de estas imágenes generadas por IA. ¡Saluda a mi ángel-robot juggalo programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mis proyectos suelen caer en uno de estos dos escenarios:\n\n- Código nuevo desde cero (*greenfield*)\n- Base de código heredada (pero moderna)\n\nTe mostraré mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien cuando parto de cero. Aporta una planificación y documentación sólidas y permite avanzar fácilmente en pasos pequeños.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"Técnicamente hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegará a una conclusión natural):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nObtendrás una especificación bastante sólida que podrás pasar al paso de planificación. Suelo guardarla como `spec.md` en el repositorio.\n\n> Esa especificación sirve para muchas cosas. Aquí la usamos para generación de código, pero también la he empleado para pedirle a un modelo de razonamiento que busque puntos débiles (¡hay que ir más profundo!), para generar un white paper o un modelo de negocio. Incluso puedes meterla en una investigación profunda y recibir un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificación\n\nPasa la spec a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el prompt con TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nEl modelo devolverá un plan de prompts que podrás ejecutar con Aider, Cursor, etc. Yo lo guardo como `prompt_plan.md` en el repositorio.\n\nDespués le pido una lista de comprobación:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGuárdalo como `todo.md`. Tu herramienta de generación de código debería ir marcando esta lista para mantener el estado entre sesiones.\n\n#### ¡Plan listo!\n\nCon esto tienes un plan robusto y documentación clara para construir tu proyecto.\n\nTodo el proceso lleva, como mucho, **15 minutos**. Una locura, la verdad.\n\n### Paso 3: Ejecución\n\nHay muchísimas opciones; el éxito depende de lo bien que salió el Paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)… Funciona bien con todas las que he probado y, seguramente, con cualquier otra herramienta de *codegen*.\n\nAun así, prefiero **Claude “en crudo”** y Aider.\n\n### Claude\n\nBásicamente hago _pair programming_ con [Claude.ai](https://claude.ai) pegando cada instrucción de forma iterativa. Funciona bastante bien: el ida y vuelta puede ser pesado, pero cumple.\n\nYo me encargo del código base inicial y de que las herramientas estén configuradas. Esto da cierta libertad y guía al principio. Claude tiende a escupir código React a la mínima; contar con una base sólida en el lenguaje y estilo de tu elección ayuda mucho.\n\nCuando las cosas se atascan, uso [Repomix](https://github.com/yamadashy/repomix) (una herramienta para empaquetar repositorios) para iterar.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- pego la instrucción en Claude  \n- copio el código al IDE  \n- ejecuto el código y la suite de pruebas  \n- …  \n- si funciona, paso a la siguiente instrucción  \n- si no, paso la base de código a Claude con Repomix para depurar  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del Paso 2: avanzo muchísimo con muy poco esfuerzo.\n\nEl flujo es casi idéntico, pero pegando las instrucciones en Aider.\n\nAider “simplemente lo hace” y yo me pongo a jugar al juego «Cookie Clicker».\n\n> Aider publica un benchmarking excelente de modelos nuevos en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Recurso brutal para ver qué tan efectivos son los modelos.\n\nLa prueba es aún más automática: Aider ejecuta la suite de pruebas y depura por ti.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- inicio Aider (procura estar siempre en una rama nueva)  \n- pego la instrucción  \n- veo a Aider bailar ♪┏(・o･)┛♪  \n- Aider ejecuta pruebas o corro la app para verificar  \n- si funciona, siguiente instrucción  \n- si no, sesión de preguntas y respuestas con Aider hasta arreglar  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧\n\n### Resultados\n\nHe construido scripts, apps de Expo, herramientas CLI en Rust, etc., usando este método. Funciona en distintos lenguajes y contextos. La verdad, me encanta.\n\nSi tienes un proyecto (grande o pequeño) aparcado, prueba esto: te sorprenderá lo lejos que avanzas en poco tiempo.\n\nMi lista de hacks pendientes está vacía porque lo he construido todo. Pienso ideas nuevas y las tacho mientras veo una peli. Por primera vez en años estoy jugando con lenguajes y herramientas nuevas, y eso amplía mi perspectiva como programador.\n\n## Brownfield (proyectos existentes): iteración incremental\n\nA veces no partes de cero y toca mejorar o añadir funcionalidades a una base de código existente.\n\n{{< image src=\"brownfield.jpg\" alt=\"Brownfield (campo marrón)\" caption=\"Esto NO es un greenfield. Foto aleatoria de la cámara de mi abuelo — Uganda, años 60.\" >}}\n\nPara esto uso un método parecido, pero menos de “planificación global”: planifico por tarea, no por proyecto.\n\n### Obtener contexto\n\nCada persona metida en IA tiene su herramienta favorita para empaquetar el código y pasarlo eficazmente al LLM.\n\nYo utilizo la herramienta Repomix y un conjunto de tareas en `~/.config/mise/config.toml` (ver [reglas de mise](https://mise.jdx.dev/)):\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de código. Si se pasa de tokens, ajusto el comando para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empaquetar el código y, mientras genere un `output.txt`, mis tareas LLM siguen funcionando. Suelo sobreescribir el paso de Repomix para incluir patrones de ignore más amplios o usar una herramienta más eficaz según el caso.\n\nLuego paso `output.txt` al comando [LLM](https://github.com/simonw/LLM) y guardo la salida como Markdown.\n\nEn el fondo, la tarea ejecuta algo como:\n\n```bash\ncat output.txt | LLM -t readme-gen > README.md\n# o\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nPor ejemplo, para mejorar la cobertura de pruebas:\n\n#### Claude\n\n- voy al directorio del código  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- copio el contexto: `mise run LLM:copy_buffer_bundle`  \n- pego eso en Claude junto con el primer “issue” de pruebas faltantes  \n- copio el código generado al IDE  \n- ejecuto pruebas  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- voy al directorio del código  \n- abro Aider (siempre en una rama nueva)  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- pego el primer “issue” en Aider  \n- veo a Aider bailar ♪┏(・o･)┛♪  \n- ejecuto pruebas  \n- y vuelta a empezar ✩₊˚.⋆☾⋆⁺₊✧  \n\nEsta metodología es muy útil para mejorar gradualmente cualquier base de código, sin importar el tamaño de la tarea.\n\n### Magia de prompts\n\nEstos hacks son mano de santo para volver un proyecto más robusto.\n\n#### Revisión de código\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generación de issues de GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts son bastante viejos y destartalados (“boomer prompts”, si se permite). Si tienes ideas para mejorarlos, avísame.\n\n## Esquí ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nCuando explico este proceso digo: «Hay que llevar el control de forma agresiva porque es muy fácil adelantarte a ti mismo».\n\nPor alguna razón digo mucho **over my skis** cuando hablo de los LLM. Quizá porque es como esquiar en polvo perfecto y, de pronto, «¡¿QUÉ CARAJO ESTÁ PASANDO?!», te pierdes y caes por un precipicio.\n\nUsar un **paso de planificación** (como en el proceso *greenfield*) ayuda: al menos tienes un documento para comprobar. También creo que las pruebas son clave, sobre todo si codificas “a lo loco” con Aider: mantienen todo ajustado.\n\nAun así, a menudo sigo sintiéndome **over my skis**. Un descanso rápido o un paseo corto suele ayudar. Al fin y al cabo es el proceso normal de resolver problemas, solo que a velocidad de vértigo.\n\n> A veces pedimos al LLM que incluya cosas ridículas en nuestro código no tan ridículo. Por ejemplo, le pedimos que creara un archivo de *lore* y luego lo referenciara en la interfaz de usuario de una herramienta CLI de Python. De repente tienes *lore*, interfaces inestables… **Todo ello, paradójicamente, solo para** gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el límite.\n\n## Estoy tan solo (｡•́︿•̀｡)\n\nMi mayor queja es que estos flujos son, básicamente, _single-player_. He pasado años programando solo, en pareja y en equipo. Siempre es mejor con gente. Estos flujos no son fáciles de usar en equipo: los bots chocan, las fusiones son horribles, el contexto se complica.\n\nQuiero que alguien convierta la programación con LLM en un juego multijugador. ¡Hay una oportunidad enorme! **GET TO WORK!**\n\n## ⴵ Tiempo ⴵ\n\nToda esta generación de código ha disparado la cantidad de trabajo que puedo producir. Pero hay un efecto raro: mucho *tiempo muerto* mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nPara aprovechar la espera:\n\n- inicio la lluvia de ideas de otro proyecto  \n- pongo vinilos  \n- juego a «Cookie Clicker»  \n- charlo con amigos… y con robots  \n\nHack, hack, hack. No recuerdo otra época en la que fuera tan productivo.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nMuchos colegas dicen: «Los LLM apestan; fallan en todo». No comparto esa opinión, pero el escepticismo es sano. Hay razones de sobra para odiar la IA. Mi miedo principal es el consumo energético y el impacto ambiental. Pero… el código debe fluir. *Suspiro.* ¯\\\\\\_(ツ)\\_/¯\n\nSi quieres saber más sin convertirte en cíborg programador, te recomiendo el libro de Ethan Mollick: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/). Explica los beneficios sin rollo tecno-bro y me ha permitido charlas muy matizadas con amigos. Muy recomendado.\n\nSi eres escéptico pero curioso, escríbeme: te enseño cómo usamos los LLM y quizá construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar esta entrada y sugerir cambios. ¡Lo aprecio!_\n\n# CRITIQUE FEEDBACK\nCRITICAL ISSUES  \n1. Number inconsistency for “LLM”  \n   • ST: “LLMs” (plural) appears dozens of times.  \n   • TT oscillates between “LLM” (sing.) and “LLM s” → loss of meaning (it is not one but several models).  \n   • Fix: usar siempre “LLM” como sigla invariable acompañada de plural (“los LLM”) o traducir “modelos de lenguaje (LLM)”. Mantener la misma forma a lo largo del texto.  \n\n2. Mistranslation of “Discrete loops”  \n   • ST idea: ciclos claramente separados, independientes.  \n   • TT: “Bucles separados”. Se pierde el matiz de “discretos” (= independientes, autocontenidos); en dev-argot “bucles discretos” se entiende mejor.  \n   • Fix: “Bucles discretos” o “bucles independientes”.  \n\n3. “planear un plan”  \n   • ST juega con la redundancia “plan a plan” (= planificar el plan).  \n   • TT lo vuelve literal pero suena torpe en español; además “planear un plan” es pleonasmo poco natural.  \n   • Fix: “planificar el plan” o “elaborar el plan” y, si se quiere mantener la broma, añadir “(sí, planificar el plan)”.  \n\n4. Singular “La prueba es aún más automática”  \n   • ST: “Testing is nice with aider, because it can be even more hands off…” (= las pruebas).  \n   • TT usa singular “La prueba”. Se altera el sentido técnico de “testing”.  \n   • Fix: “Las pruebas son aún más automáticas” o “El testing es…”.  \n\n5. Cambio de encabezado “Brownfield (proyectos existentes)”  \n   • ST: “Non-greenfield: Iteration, incrementally”. TT introduce “Brownfield” (término no mencionado en el ST). Es una decisión interpretativa, pero introduce terminología extra y puede desorientar.  \n   • Fix: “No-greenfield: iteración incremental (sobre código existente)”.  \n\n6. Omisión de matiz en “knee-deep in AI dev”  \n   • ST enfatiza inmersión total. TT simplifica a “metida en IA”. Se pierde la idea de “hasta las rodillas”.  \n   • Fix: “…quienes estamos hasta las rodillas en desarrollo con IA…”.  \n\nMAJOR ISSUES (sentido intacto pero suenan antinaturales o pierden tono)  \nA. Tono coloquial/informal inglés ≠ español  \n   • Ej.: “Wild tbh.” → TT “Una locura, la verdad.” bien; pero en otros lugares se pierde el coloquialismo (“pretty solid” → “bastante sólida” OK, “it largely works” → “cumple” sería mejor que “funciona bastante bien”).  \n   • Sugerencia: reforzar la voz cercana del original con giros equivalentes (“está bastante bien”, “funciona de maravilla”, etc.).  \n\nB. Anglicismos no motivados o sin marcar  \n   – “workflow”, “prompt plan”, “deep research”, “cookie clicker”, “hack” se dejan sin cursiva ni comillas.  \n   – En entornos dev es normal, pero conviene marcar la primera aparición y, si se repite mucho, españolizar (“flujo de trabajo, *workflow*”).  \n\nC. Consistencia terminológica  \n   – “codegen” vs “generación de código” mezclados.  \n   – “testing” vs “pruebas”/“tests”.  \n   – Unificar: “generación de código (*codegen*)”, “pruebas”, etc.  \n\nD. Traducción de sarcasmo y humor  \n   • “terrible internet bad places” → TT “peores rincones de Internet” pierde la ironía de “terrible”+“bad” repetido. Propuesta: “los más infames y terribles rincones de Internet”.  \n   • “boomer prompts” → TT lo deja igual, pero “prompts de boomer” funcionaría mejor en español.  \n\nE. Conservación de expresiones en inglés sin glosa  \n   • “over my skis” se deja tal cual pero se explica después. Podría añadirse primera aparición “(pasado de vueltas, *over my skis*)”.  \n\nMINOR / STYLISTIC  \n1. Puntuación  \n   • Varias elipsis “…” con espacios inconsistentes; unificar (“…” sin espacio antes).  \n   • Uso de mayúscula tras punto y coma en “tl;dr: Lluvia de ideas…”; “tl;dr;” original lleva dos “;” (error de origen), puede aclararse.  \n\n2. Cohesión de listas  \n   • Algunas viñetas pierden “;” finales (“run code, run tests, etc”). En castellano conviene cerrar con punto y coma o punto final.  \n\n3. Otro detalle léxico  \n   • “Haterade” – TT crea sección “Haterade” sin traducir. Se puede mantener como meme, pero añadir “(odio a la IA)” mejora comprensión.  \n   • “raw claude” → “Claude puro” o “Claude sin envoltorio” en vez de “Claude ‘en crudo’” (calco culinario).  \n\nGRAMMAR / AGREEMENT  \n– “Esto NO es un greenfield.” → Falta artículo: “Esto NO es un *greenfield*.”  \n– “Mi lista de hacks pendientes está vacía porque lo he construido todo.” → concordancia más natural: “porque ya construí todo”.  \n– “El modelo devolverá un plan de prompts…” → plural inconsistente después (“Los guardo…”).  \n\nMISSING / ADDED CONTENT  \nNo se detectaron párrafos omitidos. Sí se añadió el término “Brownfield” que no estaba en el ST (ver CRITICAL-5).  \n\nMACHINE-LIKE TRACES  \n– Calcos literales: “rinse repeat” → “y vuelta a empezar” (bien), pero “rinse repeat ✩” se conserva tal cual más abajo. Podría normalizarse: “y a repetir”.  \n– “Magia de prompts”: buen título, pero “estos hacks son mano de santo” mezcla registro coloquial con frase hecha poco habitual para devs; se siente insertado.  \n\nRECOMMENDED GLOBAL FIXES  \n1. Elegir y mantener un glosario: LLM (pl.), *codegen*, *workflow*, *prompt*, greenfield/no-greenfield.  \n2. Revisar todas las ocurrencias de “LLM/LLMs” y ajustar número.  \n3. Reescribir título y primera frase para sonar natural: “Tormenta de ideas → especificación, luego planificar, después ejecutar con generación de código mediante LLM. Bucles discretos y… magia.”  \n4. Sustituir anglicismos innecesarios o marcarlos la primera vez.  \n5. Reforzar coloquialismo y humor con equivalentes españoles (interjecciones, muletillas).  \n6. Pases de corrección de estilo: concordancia, tildes, comas antes de “pero”, etc.\n\nPlease address ALL issues identified in the critique and provide an improved translation.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr: Tormenta de ideas para la especificación (*spec*), luego planificar el plan (sí, planificar el plan), después ejecutar con generación de código (*codegen*) mediante los LLM. Bucles discretos. Y luego… magia. ✩₊˚.⋆☾⋆⁺₊✧_\n\nHe estado construyendo **muchísimos** productos pequeños con los LLM. Ha sido divertido y útil, pero hay trampas que pueden hacerte perder muchísimo tiempo. Hace un tiempo, un amigo me preguntó cómo estaba usando los LLM para escribir software. Pensé: «¡Madre mía! ¿Cuánto tiempo tienes?» y así nació esta entrada.\n\n(P. D.: si odias la IA, salta al final).\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque parecido, con matices aquí y allá.\n\nAquí va mi *workflow* (flujo de trabajo). Se basa en mi experiencia, en charlas con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en un puñado de buenas prácticas compartidas en los más infames y terribles rincones de Internet ([uno](https://news.ycombinator.com/) y [otro](https://twitter.com)).\n\nEsto funciona bien **AHORA**; puede que en dos semanas deje de servir… o que funcione el doble de bien. ¯\\\\\\_(ツ)\\_/¯\n\n## Vamos allá\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Siempre desconfío de estas imágenes generadas por IA. ¡Saluda a mi ángel-robot *juggalo* programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mis proyectos suelen caer en uno de estos dos escenarios:\n\n- Código nuevo desde cero (*greenfield*)\n- Base de código heredada pero moderna (*non-greenfield*)\n\nTe mostraré mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona de maravilla cuando parto de cero. Aporta una planificación y documentación sólidas y permite avanzar fácilmente en pasos pequeños.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"Técnicamente, hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegará a una conclusión natural):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nObtendrás una especificación bastante sólida que podrás pasar al paso de planificación. Suelo guardarla como `spec.md` en el repositorio.\n\n> Esa especificación sirve para muchas cosas. Aquí la usamos para generación de código (*codegen*), pero también la he empleado para pedirle a un modelo de razonamiento que busque puntos débiles (¡hay que ir más profundo!), para generar un *white paper* o un modelo de negocio. Incluso puedes lanzarla a una investigación exhaustiva y recibir a cambio un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificación\n\nPasa la *spec* a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el *prompt* con TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el *prompt* sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nEl modelo devolverá un plan de *prompts* que podrás ejecutar con Aider, Cursor, etc. Yo lo guardo como `prompt_plan.md` en el repositorio.\n\nDespués le pido una lista de comprobación:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGuárdalo como `todo.md`. Tu herramienta de generación de código debería ir marcando esta lista para mantener el estado entre sesiones.\n\n#### ¡Plan listo!\n\nCon esto tienes un plan robusto y documentación clara para construir tu proyecto.\n\nTodo el proceso lleva, como mucho, **15 minutos**. Una locura, la verdad.\n\n### Paso 3: Ejecución\n\nHay muchísimas opciones; el éxito depende de lo bien que salió el Paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)… Funciona bien con todas las que he probado y, seguramente, con cualquier otra herramienta de generación de código (*codegen*).\n\nAun así, prefiero **Claude puro** y Aider.\n\n### Claude\n\nBásicamente hago *pair programming* con [Claude.ai](https://claude.ai) pegando cada instrucción de forma iterativa. Funciona bastante bien: el ida y vuelta puede ser pesado, pero cumple.\n\nYo me encargo del código base inicial y de que las herramientas estén configuradas. Esto da cierta libertad y guía al principio. Claude tiende a escupir código React a la mínima; contar con una base sólida en el lenguaje y estilo de tu elección ayuda mucho.\n\nCuando las cosas se atascan, uso [Repomix](https://github.com/yamadashy/repomix) para iterar.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.);\n- pego la instrucción en Claude;\n- copio el código al IDE;\n- ejecuto el código y la suite de pruebas;\n- si funciona, paso a la siguiente instrucción;\n- si no, paso la base de código a Claude con Repomix para depurar;\n- y a repetir ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del Paso 2: avanzo muchísimo con muy poco esfuerzo.\n\nEl flujo es casi idéntico, pero pegando las instrucciones en Aider.\n\nAider «simplemente lo hace» y yo me pongo a jugar a [*Cookie Clicker*](https://orteil.dashnet.org/cookieclicker/).\n\n> Aider publica un *benchmark* excelente de modelos nuevos en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Es un recurso brutal para ver qué tan efectivos son los modelos.\n\nLas pruebas son aún más automáticas con Aider, porque ejecuta la suite y depura por ti.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.);\n- inicio Aider (procura estar siempre en una rama nueva);\n- pego la instrucción;\n- veo a Aider bailar ♪┏(・o･)┛♪;\n- Aider ejecuta pruebas o corro la app para verificar;\n- si funciona, siguiente instrucción;\n- si no, sesión de preguntas y respuestas con Aider hasta arreglarlo;\n- y a repetir ✩₊˚.⋆☾⋆⁺₊✧\n\n### Resultados\n\nHe construido scripts, apps de Expo, herramientas CLI en Rust, etc., usando este método. Funciona en distintos lenguajes y contextos. La verdad, me encanta.\n\nSi tienes un proyecto —grande o pequeño— aparcado, prueba esto: te sorprenderá lo lejos que avanzas en poco tiempo.\n\nMi lista de *hacks* pendientes está vacía porque ya construí todo. Pienso ideas nuevas y las tacho mientras veo una peli. Por primera vez en años estoy jugando con lenguajes y herramientas nuevas, y eso amplía mi perspectiva como programador.\n\n## No-greenfield: iteración incremental (sobre código existente)\n\nA veces no partes de cero y toca mejorar o añadir funcionalidades a una base de código existente.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Esto NO es un *greenfield*. Foto aleatoria de la cámara de mi abuelo — Uganda, años 60.\" >}}\n\nPara esto uso un método parecido, pero menos de “planificación global”: planifico por tarea, no por proyecto.\n\n### Obtener contexto\n\nQuienes estamos hasta las rodillas en desarrollo con IA solemos tener cada uno nuestra herramienta favorita para empaquetar el código y pasarlo eficazmente a los LLM.\n\nYo utilizo [Repomix](https://github.com/yamadashy/repomix) y un conjunto de tareas en `~/.config/mise/config.toml` (ver [reglas de mise](https://mise.jdx.dev/)):\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de código. Si se pasa de tokens, ajusto el comando para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empaquetar el código y, mientras genere un `output.txt`, mis tareas LLM siguen funcionando. Suelo sobreescribir el paso de Repomix para incluir patrones de *ignore* más amplios o usar una herramienta más eficaz según el caso.\n\nLuego paso `output.txt` al comando [LLM](https://github.com/simonw/LLM) y guardo la salida como Markdown.\n\nEn el fondo, la tarea ejecuta algo como:\n\n```bash\ncat output.txt | LLM -t readme-gen > README.md\n# o\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nPor ejemplo, para mejorar la cobertura de pruebas:\n\n#### Claude\n\n- voy al directorio del código;\n- `mise run LLM:generate_missing_tests`;\n- reviso `missing-tests.md`;\n- copio el contexto con `mise run LLM:copy_buffer_bundle`;\n- pego eso en Claude junto con el primer “issue” de pruebas faltantes;\n- copio el código generado al IDE;\n- ejecuto pruebas;\n- y a repetir ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- voy al directorio del código;\n- abro Aider (siempre en una rama nueva);\n- `mise run LLM:generate_missing_tests`;\n- reviso `missing-tests.md`;\n- pego el primer “issue” en Aider;\n- veo a Aider bailar ♪┏(・o･)┛♪;\n- ejecuto pruebas;\n- y a repetir ✩₊˚.⋆☾⋆⁺₊✧  \n\nEsta metodología es muy útil para mejorar gradualmente cualquier base de código, sin importar el tamaño de la tarea.\n\n### Magia de *prompts*\n\nEstos pequeños *hacks* van de maravilla para hurgar en el proyecto y hacerlo más robusto.\n\n#### Revisión de código\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generación de issues de GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos *prompts de boomer* necesitan un repaso. Si tienes ideas para mejorarlos, avísame.\n\n## Esquí ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nCuando explico este proceso digo: «Hay que llevar el control de forma agresiva porque es muy fácil adelantarte a ti mismo.»\n\nPor alguna razón digo mucho *over my skis* (pasado de vueltas) cuando hablo de los LLM. Quizá porque es como esquiar en polvo perfecto y, de pronto, «¡¿QUÉ CARAJO ESTÁ PASANDO?!», te pierdes y caes por un precipicio.\n\nUsar un **paso de planificación** (como en el proceso *greenfield*) ayuda: al menos tienes un documento para comprobar. También creo que las pruebas son clave —sobre todo si codificas “a lo loco” con Aider—: mantienen todo ajustado.\n\nAun así, a menudo sigo sintiéndome *over my skis*. Un descanso rápido o un paseo corto suele ayudar. Al fin y al cabo es el proceso normal de resolver problemas, solo que a velocidad de vértigo.\n\n> A veces pedimos a los LLM que incluyan cosas ridículas en nuestro código no tan ridículo. Por ejemplo, le pedimos que creara un archivo de *lore* y luego lo referenciara en la interfaz de usuario de una herramienta CLI de Python. De repente tienes *lore*, interfaces glitchy… Todo ello, paradójicamente, solo para gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el límite.\n\n## Estoy tan solo (｡•́︿•̀｡)\n\nMi mayor queja es que estos flujos son, básicamente, _single-player_. He pasado años programando solo, en pareja y en equipo. Siempre es mejor con gente. Estos flujos no son fáciles de usar en grupo: los bots chocan, las fusiones son horribles, el contexto se complica.\n\nQuiero que alguien convierta la programación con LLM en un juego multijugador. ¡Hay una oportunidad enorme! **GET TO WORK!**\n\n## ⴵ Tiempo ⴵ\n\nToda esta generación de código ha disparado la cantidad de trabajo que puedo producir. Pero hay un efecto raro: mucho tiempo muerto mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nPara aprovechar la espera:\n\n- inicio la lluvia de ideas de otro proyecto;\n- pongo vinilos;\n- juego a *Cookie Clicker*;\n- charlo con amigos… y con robots.\n\nHack, hack, hack. No recuerdo otra época en la que fuera tan productivo.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nMuchos colegas dicen: «Los LLM apestan; fallan en todo». No comparto esa opinión, pero el escepticismo es sano. Hay razones de sobra para odiar la IA. Mi miedo principal es el consumo energético y el impacto ambiental. Pero… el código debe fluir. *Suspiro.* ¯\\\\\\_(ツ)\\_/¯\n\nSi quieres saber más sin convertirte en cíborg programador, te recomiendo el libro de Ethan Mollick: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/). Explica los beneficios sin rollo *tech-bro* y me ha permitido charlas muy matizadas con amigos. Muy recomendado.\n\nSi eres escéptico pero curioso, escríbeme: te enseño cómo usamos los LLM y quizá construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar esta entrada y sugerir cambios. ¡Lo aprecio!_",
      "usage": {
        "prompt_tokens": 11027,
        "completion_tokens": 4191,
        "total_tokens": 15218
      },
      "streaming": true
    },
    "frontmatter": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "You are a professional translator. Translate the following frontmatter fields to spanish.\nEach field is in the format \"field_name: content\". Translate ONLY the content, not the field names.\nReturn the translated content in the exact same format, preserving all field names.",
      "user_prompt": "title: My LLM codegen workflow atm\n\ndescription: A detailed walkthrough of my current workflow for using LLms to build software, from brainstorming through planning and execution.\n\n",
      "response": "title: Mi flujo de trabajo de generación de código con LLM en este momento\n\ndescription: Un recorrido detallado de mi flujo de trabajo actual para usar LLMs en la construcción de software, desde la lluvia de ideas hasta la planificación y la ejecución.",
      "usage": {
        "prompt_tokens": 86,
        "completion_tokens": 52,
        "total_tokens": 138
      },
      "fields": [
        "title",
        "description"
      ],
      "streaming": true
    },
    "all_critiques": [
      "CRITIQUE OF THE SPANISH TRANSLATION  \n(Organized by severity → category → concrete issue → suggested fix)\n\n====================================================================\nA. CRITICAL : ACCURACY & COMPLETENESS  \n====================================================================\n\nA-1  Paragraph missing (omission)\n     • Original: “Regardless, I still do find myself **over my skis** quite a bit.  \n       Sometimes a quick break or short walk will help. In this regard it is a normal\n       problem-solving process, but accelerated to a breakneck speed.”  \n     • Spanish: Entirely absent.  \n     • Fix: Re-insert after the “wild style Aider” sentence in the Esquí section, e.g.  \n       “Aun así, a menudo sigo sintiéndome ‘over my skis’. Un descanso rápido o un\n       paseo corto suele ayudar. En ese sentido, es el proceso normal de resolver\n       problemas, solo que a una velocidad de vértigo.”\n\nA-2  Term slightly mistranslated – “Legacy modern code”\n     • “Código existente / legado moderno” is confusing: legacy vs. modern are\n       opposites.  \n     • Suggest: “Código heredado relativamente reciente” or simply “código heredado”.\n\nA-3  Header mistranslation – “Non-greenfield”\n     • “No-greenfield” is not idiomatic.  \n     • Suggest: “Proyectos existentes (brownfield)” or “Trabajo sobre código existente”.\n\nA-4  Minor semantic shift – “Greenfield code”\n     • “Código nuevo (greenfield)” loses the nuance that it’s *from scratch*.  \n     • Suggest: “Desarrollo desde cero (greenfield)”.\n\n====================================================================\nB. MAJOR : STYLE, TONE & REGISTER CONSISTENCY  \n====================================================================\n\nB-1  Heavy, inconsistent code-switching  \n     • Excessive raw English terms: spec, codegen, prompt, repo, merge, greenfield,\n       rinse repeat, wild style… A technical audience tolerates many of these, but\n       the density here feels machine-like and uneven.  \n     • Fix: Decide once per term:  \n       – spec → “especificación (spec)” first mention, thereafter spec OK.  \n       – codegen → “generación de código”.  \n       – prompt → keep English but mark in cursive or quotes at first use and give a\n         Spanish equivalent: “prompt (instrucción)”.  \n       – repo → “repositorio”.  \n       – merge → “fusión” (o “merge” si se deja en inglés, pero decidir).  \n       – rinse repeat → “y vuelta a empezar”.  \n       – wild style → “a lo loco” / “sin red”.  \n       Aim for a more even Spanish text with occasional unavoidable English.\n\nB-2  Over-literal calques / unnatural expressions  \n     • “Planear un plan” sounds forced even if mimicking the joke; suggest “planear\n       el plan” or keep the joke but add quotes: «planear “un plan”».  \n     • “Claude puro” sounds odd; “Claude ‘en crudo’” or “Claude sin interfaz” would\n       read better.  \n     • “Me encanta.” right after a long list sounds abrupt; soften: “La verdad, me\n       encanta.”  \n     • Several “rinse and repeat” left untranslated; either translate or italicise\n       consistently.\n\nB-3  Register drift  \n     • Original voice is informal-colloquial with bursts of slang. Spanish keeps some\n       of it but at times swings to more formal (“Sin embargo”, “Asimismo”).  \n     • Unify tone: keep contractions (e.g. “No pasa nada” vs “No me molesta ese\n       punto de vista”), sprinkle slang where English has slang (“la verdad está\n       cañón”, “flipante”, etc.) but avoid sudden formality.\n\n====================================================================\nC. GRAMMAR & USAGE (MEDIUM)  \n====================================================================\n\nC-1  Article + acronym consistency  \n     • “con LLM” (singular) vs “con LLMs” (plural) oscillates. Suggest: first mention\n       “modelos de lenguaje grandes (LLM)” then treat as plural acronym: “los LLM”.\n\nC-2  Punctuation / tildes  \n     • “p. d.” → should be “P. D.” (mayúsculas y espacio fino).  \n     • “¡Uf, ¿cuánto tiempo tienes?” needs closing exclamation: “¡Uf! ¿Cuánto…?”  \n     • Several English em-dashes “–” replaced by “-” hyphens; Spanish prefers “—”.\n\nC-3  Capitalisation of headings  \n     • Mixed style: “Paso 1: Afinar la idea” (OK) vs “Greenfield” (title-case English)\n       vs “No-greenfield”. Choose one style; sentence-case in Spanish headings is\n       standard.\n\nC-4  Agreement & minor slips  \n     • “Esto da algo de libertad y orientación al principio.”  \n       ‘Orientación’ está bien, pero un “algo de” + sing. fem. suena raro; mejor\n       “cierta libertad y orientación”.  \n     • “observó a Aider bailar” later appears as “observo a Aider bailar”; unify.\n\n====================================================================\nD. TERMINOLOGY CONSISTENCY (MINOR)  \n====================================================================\n\nD-1  “Modelo de razonamiento” vs “modelo de reasoning”  \n     • Use one Spanish term: “modelo de razonamiento”.\n\nD-2  “Base de código” vs “código base” vs “code base”  \n     • Choose and stick to “base de código”.\n\nD-3  “Lista de ‘cosas por hackear’”  \n     • Could simplify to “lista de hacks pendientes”.\n\n====================================================================\nE. FLUENCY & NATURALNESS (MINOR)  \n====================================================================\n\nE-1  Long English clauses left intact in running Spanish sentences  \n     • Example: “He usado este flujo con [GitHub Workspace] (link), [Aider] (link),\n       [Cursor] …” becomes heavy. Consider: “He usado este flujo con herramientas\n       como GitHub Workspace, Aider, Cursor…”\n\nE-2  Excessive parenthetical clutter  \n     • Many inline “(link)” references impede flow; convert to numbered footnotes or\n       leave only the name + hyperlink.\n\nE-3  Emojis / kaomoji  \n     • They are part of author’s tone; OK to keep, but Spanish normally puts a space\n       before/after: “rinse repeat ✩₊˚.⋆☾⋆⁺₊✧”.\n\n====================================================================\nF. CULTURAL / IDIOMATIC NUANCES  \n====================================================================\n\nF-1  “bad places” nuance  \n     • “los (terribles) rincones de internet [malos] [lugares]” is clunky.  \n     • Suggest: “los infames rincones de Internet (sí, esos sitios horribles…)”.\n\nF-2  Swearing calibration  \n     • Original “WHAT THE FUCK IS GOING ON!” rendered as “¡¿QUÉ DEMONIOS PASA?!”.\n       “Demonios” is tame; closer tone would be “¡¿QUÉ CARAJO ESTÁ PASANDO?!”\n\nF-3  “cookie clicker” joke  \n     • Add clarifier: “(el juego idle Cookie Clicker)” for readers unfamiliar.\n\n====================================================================\nG. MACHINE-LIKE / OVER-LITERAL AREAS  \n====================================================================\n\nG-1  Blocks where English syntax is copied verbatim:  \n     – “Esto es bueno para mantener el estado entre sesiones.” feels literal.  \n       Better: “Así mantienes el estado entre sesiones.”  \n     – “Funciona bastante bien con todas las herramientas que he probado y me imagino\n       que irá bien con cualquier herramienta de codegen.” Compress: “Funciona bien\n       con todas las herramientas que he probado y seguramente con cualquier otra de\n       generación de código.”\n\nG-2  Repetition of “flujo” (“flow”) multiple sentences in a row; vary with\n     “proceso”, “metodología”, etc.\n\n====================================================================\nSUMMARY OF MAIN FIXES TO ACHIEVE A NATURAL, FAITHFUL VERSION\n1. Reinstate the omitted “Regardless…” paragraph.  \n2. Replace or explain key anglicisms (“spec”, “codegen”, etc.) once, then keep if\n   desired.  \n3. Polish register: keep informal, avoid sudden formality, adjust swear words.  \n4. Correct minor grammar/punctuation issues, harmonise plural “LLM”, article usage,\n   and heading styles.  \n5. Remove literal calques and translate idioms (“rinse and repeat”, “over my skis”,\n   “wild style”) with natural Spanish equivalents.  \n6. Streamline hyperlinks and parentheticals; they clutter the prose.  \n7. Re-read entire text aloud to catch residual machine-sounding phrasing and ensure\n   smooth, idiomatic flow.",
      "CRITICAL ISSUES\n1. Large-scale omissions (content skipped)\n   • The two long “Step 2: Planning” prompts (TDD & non-TDD) are replaced by «…».  \n     ⇒ Restore the full English text or translate it entirely; do NOT abridge.  \n   • Minor but cumulative cuts: “pretty old and busted”, some parenthetical jokes, extra explanations inside > blockquotes, etc.  \n     ⇒ Re-insert all missing sentences.\n\n2. Terminology inconsistency\n   • Source consistently uses the plural “LLMs”; translation oscillates between “LLM” (singular) and “LLMs”.  \n     ⇒ Use “los LLM” or “los LLMs” uniformly.\n   • “Legacy modern code” is rendered as «código heredado relativamente reciente (brownfield)». The author’s tongue-in-cheek paradox (“modern-legacy”) disappears and the term brownfield is introduced before it appears in the source.  \n     ⇒ Keep the play on words: «código legado moderno» and leave “brownfield” for the later section where the author himself uses “Non-greenfield”.\n\nMAJOR ISSUES\nA. Nuances / register\n   1. “how much time do you have!” → «¡Uf! ¿Cuánto tiempo tienes?» loses the amused excitement of “oh boy”.  \n      Suggestion: «¡Madre mía! ¿Cuánto tiempo tienes?»  \n   2. “bad places” sarcastic hyperlink aside – translation flattens the snark. Consider «los peores rincones de Internet».  \n   3. “Discrete loops. Then magic.” → «Bucles discretos. Y, al final, magia.» Tone of abrupt punch is softened. Try «Bucles discretos. Luego… magia.»  \n   4. “Wild tbh” is missing. Could keep an informal «Una locura, la verdad.» near the right spot (end of 15-minute remark).\n\nB. Style & flow (sounds Englishy)\n   • “planear el plan” is literal. A playful but more idiomatic echo: «planear el proyecto» or «diseñar el plan».  \n   • “pego el prompt” / “paso el prompt” – repetitive anglicism. Prefer “instrucción”, “mensaje” or at least combine: “pegar la instrucción (prompt)”.  \n   • Overuse of English nouns in plural without markup: prompts, codegen, boilerplate, output, etc. Decide case by case if they need a Spanish equivalent or italics.\n\nC. Technical precision\n   • “suite” should be «la suite de pruebas» when first introduced.  \n   • “saved as `spec.md`” translated fine, but elsewhere “guardar como” vs. “lo guardo” alternates. Standardise.\n\nMODERATE ISSUES\n1. Grammar / punctuation\n   • «Ha sido divertido y útil; pero…» – semicolon + “pero” is awkward. Use comma: «…útil, pero…».  \n   • «P. D.: si odias la IA, salta al final» – Spanish norms omit the period inside ‘P.D.’ → «P. D.:» is correct; fine.  \n   • Several long English parentheticals left untranslated; wrap them in em-dashes or parentheses and translate.\n\n2. Capitalisation of headings\n   • “Greenfield” and “Brownfield” appear as English after Spanish sentence starters; decide either to keep them in English with quotes or adapt («Desde cero», «Brownfield»).\n\n3. In-line code blocks\n   • Do not translate code fences' language tag (“prompt”)— fine; but in the explanatory sentence you wrote «(este es el prompt TDD)» then immediately trimmed the content. Restore.\n\nMINOR ISSUES\n• “always make sure you are on a new branch for aider work” was not rendered; add «procura estar siempre en una rama nueva cuando uses Aider».  \n• Alt-text “Juggalo Robot” turned into «Robot Juggalo». Not wrong, but flips adjective order.  \n• “I get to play cookie clicker” became “juego a Cookie Clicker (el idle game)”— good, but capitalise consistently or italicise the title.\n\nSUGGESTED OVERALL IMPROVEMENTS\n1. Replace every ellipsis that hides source text with a faithful Spanish version (or keep the full English text if the author’s intention is to show the raw prompt).  \n2. Re-evaluate anglicisms: allow unavoidable technical ones (prompt, codegen, boilerplate) but Spanish-ify where fluent.  \n3. Maintain the playful, informal tone: keep interjections (“oh boy”, “Wild tbh”, “GET TO WORK!”) instead of neutralising them.  \n4. Harmonise tenses and persons; author mixes present and present continuous for energy—mirror that in Spanish.  \n5. Double-check every caption, alt-text and blockquote so no jokes or asides vanish.\n\nIf these changes are applied, the translation will be complete, faithful, and will read as natural Spanish rather than an abridged, slightly literal rendering.",
      "CRITIQUE OF THE SPANISH TRANSLATION  \n\n(Organized by SEVERITY → CATEGORY → ITEM.  \nEach item includes: a) Problem  b) Why it matters  c) Suggested fix.)\n\n━━━━━━━━━━━━━━━━  I. CRITICAL ISSUES  ━━━━━━━━━━━━━━━━  \nA. Meaning / Fidelity  \n\n1. “plan a plan” → “diseñar el plan”  \n   a) Los juegos de palabras redundantes (“plan a plan”) se pierden.  \n   b) Se elimina un rasgo humorístico-intencional del original.  \n   c) Restituir la redundancia: «…luego planear un plan…».\n\n2. “Legacy modern code” → “Código legado moderno”  \n   a) «Legado moderno» suena contradictorio y confuso en español.  \n   b) Puede generar ambigüedad: ¿código heredado pero relativamente moderno?  \n   c) Usar algo como «código heredado relativamente reciente» o «base de código heredada (pero moderna)».\n\n3. “Discrete loops” → “Bucles discretos”  \n   a) En inglés es un guiño ambiguo (ciclos independientes vs. loops discretos).  \n   b) “Bucles discretos” suena a teoría matemática; se pierde la idea de “fases separadas”.  \n   c) Cambiar por «bucles separados» / «ciclos independientes».\n\n4. Omisión de matiz en “I have been building so many small products”  \n   a) “He estado creando montones de productos pequeños” omite la connotación de “so many”.  \n   b) Rebaja el énfasis cuantitativo.  \n   c) «…un montón de productos pequeños» o «…muchísimos productos pequeños».\n\n5. Frase final del apartado “Skiing”: “All to manage your cloud functions, your todo list or whatever”  \n   a) Se traduce “…Todo para gestionar tus funciones en la nube, tu lista de tareas o lo que sea.”, pero falta la idea de “ridiculous” (contraste humorístico).  \n   b) Se atenúa el tono irónico.  \n   c) Añadir: «Todo ello, paradójicamente, solo para…».\n\nB. Additions / Omissions  \n\n6. Falta la repetición humorística «¯\\_(ツ)_/¯» en un par de sitios donde el original la incluye.  \n   a) El gesto es parte del tono.  \n   b) Mantenerla tal cual o con equivalente visual.\n\n━━━━━━━━━━━━━━━━  II. MAJOR ISSUES  ━━━━━━━━━━━━━━━━  \nA. Tone / Register  \n\n7. Mezcla excesiva de anglicismos crudos (“workflow, prompt, boilerplate, merge, branch, check-list”).  \n   a) Rompe la fluidez; da sensación de texto sin pulir.  \n   b) El público hispanohablante técnico entiende los términos, pero un exceso suena “máquina-like”.  \n   c) Sustituir al menos los más innecesarios:  \n      – workflow → flujo de trabajo  \n      – boilerplate → código base / plantilla  \n      – merge → fusión / merge (git)  \n      – branch → rama  \n      – checklist → lista de comprobación  \n      (Mantener “prompt”, “codegen” o “greenfield” puede ser aceptable si se justifican.)\n\n8. Uso reiterado de “post”  \n   a) Existen alternativas naturales: «entrada», «artículo».  \n   b) Mejora la naturalidad.  \n   c) Cambiar a «entrada» o «artículo».\n\n9. Subtítulos como “Non-greenfield” sin traducción  \n   a) Desentonan en medio de secciones en español.  \n   b) Mantener la coherencia.  \n   c) Titular «Proyectos existentes (non-greenfield)» o «Brownfield».\n\nB. Grammar / Syntax  \n\n10. “Aun así, prefiero Claude en crudo”  \n    a) Falta tilde en “Aún” (adverbio de tiempo).  \n    b) Corregir: «Aún así» o mejor «Aun así» (sin tilde) según la RAE; pero aquí es concesivo → «Aun así» está bien. El problema es la confusión entre formas; aclarar.\n\n11. “Testing es nice” (no aparece, pero el traductor mantuvo “Testing es nice” → “La prueba es aún más automática…”)  \n    a) Se evitó en esta versión, pero vigilar expresiones similares que mezclan idiomas.\n\nC. Idiomatic / Cultural  \n\n12. “interfaces glitchy” (se mantiene “glitchy”)  \n    a) Mezcla innecesaria; “glitchy” no es de uso corriente.  \n    b) Sustituir por «defectuosas», «inestables» o «con glitchs».\n\n13. “Cookie Clicker” → se retiene, pero convendría la primera vez entrecomillar y aclarar “el juego Cookie Clicker”.\n\n14. Traducción literal “Campo marrón” (en caption).  \n    a) “Brown field” es juego de palabras con “greenfield/brownfield”.  \n    b) Se pierde la broma.  \n    c) Mantener “Brownfield (campo marrón)” o explicar la gracia.\n\n━━━━━━━━━━━━━━━━  III. MINOR ISSUES  ━━━━━━━━━━━━━━━━  \nA. Consistency  \n\n15. “LLMs” → a veces con artículo (“los LLMs”), a veces sin; unificar.  \n16. Variación “spec” / “specificación” sin criterio fijo.  \n17. Comillas simples y dobles mezcladas; estandarizar (p. ej., comillas latinas «» o inglesas “ ”).  \n\nB. Punctuation / Typography  \n\n18. Espacios antes de signos de puntuación en varias listas (“…  …”).  \n19. Uso de guiones largos “—” vs “-” inconsistente.  \n20. En varios puntos se deja «...» y en otros «…» (carácter único). Elegir uno.\n\nC. Machine-like traces  \n\n21. Algunos gerundios calcados: “Está funcionando bien **AHORA**; puede que…” → mejor “Funciona bien AHORA…”.  \n22. Repeticiones innecesarias (“Flujo: … Flujo: …”). Se puede condensar.\n\n━━━━━━━━━━━━━━━━  IV. TERMINOLOGÍA TÉCNICA  ━━━━━━━━━━━━━━━━  \n\n23. “Codegen” se deja sin cursiva ni explicación la primera vez. Añadir «(generación automática de código, *codegen*)».  \n24. “repomix” / “mise” → primera mención debería ir con breve nota (“la herramienta Repomix”).  \n\n━━━━━━━━━━━━━━━━  V. SUGERENCIA GLOBAL DE RE-EDICIÓN  ━━━━━━━━━━━━━━━━  \n\n– Recuperar los chistes/giros (“planear un plan”, “¯\\_(ツ)_/¯”).  \n– Reducir anglicismos gratuitos; cuando se conserven, cursiva o comillas.  \n– Homogeneizar títulos, comillas, mayúsculas y numeraciones.  \n– Revisar tildes y concordancias menores.  \n– Añadir breves glosas técnicas la primera vez que aparece sigla/herramienta.  \n\nCon estas correcciones, el texto ganará en fidelidad humorística, claridad y naturalidad, y dejará de sonar a traducción literal/máquina.",
      "CRITICAL ISSUES  \n1. Number inconsistency for “LLM”  \n   • ST: “LLMs” (plural) appears dozens of times.  \n   • TT oscillates between “LLM” (sing.) and “LLM s” → loss of meaning (it is not one but several models).  \n   • Fix: usar siempre “LLM” como sigla invariable acompañada de plural (“los LLM”) o traducir “modelos de lenguaje (LLM)”. Mantener la misma forma a lo largo del texto.  \n\n2. Mistranslation of “Discrete loops”  \n   • ST idea: ciclos claramente separados, independientes.  \n   • TT: “Bucles separados”. Se pierde el matiz de “discretos” (= independientes, autocontenidos); en dev-argot “bucles discretos” se entiende mejor.  \n   • Fix: “Bucles discretos” o “bucles independientes”.  \n\n3. “planear un plan”  \n   • ST juega con la redundancia “plan a plan” (= planificar el plan).  \n   • TT lo vuelve literal pero suena torpe en español; además “planear un plan” es pleonasmo poco natural.  \n   • Fix: “planificar el plan” o “elaborar el plan” y, si se quiere mantener la broma, añadir “(sí, planificar el plan)”.  \n\n4. Singular “La prueba es aún más automática”  \n   • ST: “Testing is nice with aider, because it can be even more hands off…” (= las pruebas).  \n   • TT usa singular “La prueba”. Se altera el sentido técnico de “testing”.  \n   • Fix: “Las pruebas son aún más automáticas” o “El testing es…”.  \n\n5. Cambio de encabezado “Brownfield (proyectos existentes)”  \n   • ST: “Non-greenfield: Iteration, incrementally”. TT introduce “Brownfield” (término no mencionado en el ST). Es una decisión interpretativa, pero introduce terminología extra y puede desorientar.  \n   • Fix: “No-greenfield: iteración incremental (sobre código existente)”.  \n\n6. Omisión de matiz en “knee-deep in AI dev”  \n   • ST enfatiza inmersión total. TT simplifica a “metida en IA”. Se pierde la idea de “hasta las rodillas”.  \n   • Fix: “…quienes estamos hasta las rodillas en desarrollo con IA…”.  \n\nMAJOR ISSUES (sentido intacto pero suenan antinaturales o pierden tono)  \nA. Tono coloquial/informal inglés ≠ español  \n   • Ej.: “Wild tbh.” → TT “Una locura, la verdad.” bien; pero en otros lugares se pierde el coloquialismo (“pretty solid” → “bastante sólida” OK, “it largely works” → “cumple” sería mejor que “funciona bastante bien”).  \n   • Sugerencia: reforzar la voz cercana del original con giros equivalentes (“está bastante bien”, “funciona de maravilla”, etc.).  \n\nB. Anglicismos no motivados o sin marcar  \n   – “workflow”, “prompt plan”, “deep research”, “cookie clicker”, “hack” se dejan sin cursiva ni comillas.  \n   – En entornos dev es normal, pero conviene marcar la primera aparición y, si se repite mucho, españolizar (“flujo de trabajo, *workflow*”).  \n\nC. Consistencia terminológica  \n   – “codegen” vs “generación de código” mezclados.  \n   – “testing” vs “pruebas”/“tests”.  \n   – Unificar: “generación de código (*codegen*)”, “pruebas”, etc.  \n\nD. Traducción de sarcasmo y humor  \n   • “terrible internet bad places” → TT “peores rincones de Internet” pierde la ironía de “terrible”+“bad” repetido. Propuesta: “los más infames y terribles rincones de Internet”.  \n   • “boomer prompts” → TT lo deja igual, pero “prompts de boomer” funcionaría mejor en español.  \n\nE. Conservación de expresiones en inglés sin glosa  \n   • “over my skis” se deja tal cual pero se explica después. Podría añadirse primera aparición “(pasado de vueltas, *over my skis*)”.  \n\nMINOR / STYLISTIC  \n1. Puntuación  \n   • Varias elipsis “…” con espacios inconsistentes; unificar (“…” sin espacio antes).  \n   • Uso de mayúscula tras punto y coma en “tl;dr: Lluvia de ideas…”; “tl;dr;” original lleva dos “;” (error de origen), puede aclararse.  \n\n2. Cohesión de listas  \n   • Algunas viñetas pierden “;” finales (“run code, run tests, etc”). En castellano conviene cerrar con punto y coma o punto final.  \n\n3. Otro detalle léxico  \n   • “Haterade” – TT crea sección “Haterade” sin traducir. Se puede mantener como meme, pero añadir “(odio a la IA)” mejora comprensión.  \n   • “raw claude” → “Claude puro” o “Claude sin envoltorio” en vez de “Claude ‘en crudo’” (calco culinario).  \n\nGRAMMAR / AGREEMENT  \n– “Esto NO es un greenfield.” → Falta artículo: “Esto NO es un *greenfield*.”  \n– “Mi lista de hacks pendientes está vacía porque lo he construido todo.” → concordancia más natural: “porque ya construí todo”.  \n– “El modelo devolverá un plan de prompts…” → plural inconsistente después (“Los guardo…”).  \n\nMISSING / ADDED CONTENT  \nNo se detectaron párrafos omitidos. Sí se añadió el término “Brownfield” que no estaba en el ST (ver CRITICAL-5).  \n\nMACHINE-LIKE TRACES  \n– Calcos literales: “rinse repeat” → “y vuelta a empezar” (bien), pero “rinse repeat ✩” se conserva tal cual más abajo. Podría normalizarse: “y a repetir”.  \n– “Magia de prompts”: buen título, pero “estos hacks son mano de santo” mezcla registro coloquial con frase hecha poco habitual para devs; se siente insertado.  \n\nRECOMMENDED GLOBAL FIXES  \n1. Elegir y mantener un glosario: LLM (pl.), *codegen*, *workflow*, *prompt*, greenfield/no-greenfield.  \n2. Revisar todas las ocurrencias de “LLM/LLMs” y ajustar número.  \n3. Reescribir título y primera frase para sonar natural: “Tormenta de ideas → especificación, luego planificar, después ejecutar con generación de código mediante LLM. Bucles discretos y… magia.”  \n4. Sustituir anglicismos innecesarios o marcarlos la primera vez.  \n5. Reforzar coloquialismo y humor con equivalentes españoles (interjecciones, muletillas).  \n6. Pases de corrección de estilo: concordancia, tildes, comas antes de “pero”, etc."
    ]
  },
  "critique_loop_details": {
    "critique_usages": [
      {
        "prompt_tokens": 9773,
        "completion_tokens": 1907,
        "total_tokens": 11680
      },
      {
        "prompt_tokens": 8565,
        "completion_tokens": 1103,
        "total_tokens": 9668
      },
      {
        "prompt_tokens": 9414,
        "completion_tokens": 1623,
        "total_tokens": 11037
      },
      {
        "prompt_tokens": 9447,
        "completion_tokens": 1545,
        "total_tokens": 10992
      }
    ],
    "feedback_usages": [
      {
        "prompt_tokens": 11678,
        "completion_tokens": 3278,
        "total_tokens": 14956
      },
      {
        "prompt_tokens": 9578,
        "completion_tokens": 4100,
        "total_tokens": 13678
      },
      {
        "prompt_tokens": 11123,
        "completion_tokens": 4126,
        "total_tokens": 15249
      },
      {
        "prompt_tokens": 11027,
        "completion_tokens": 4191,
        "total_tokens": 15218
      }
    ]
  },
  "timestamp": "2025-05-16T09:37:23.233986"
}