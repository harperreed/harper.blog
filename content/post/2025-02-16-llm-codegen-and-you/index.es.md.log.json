{
  "input_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.md",
  "output_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.es.md",
  "target_language": "spanish",
  "language_code": "es",
  "model": "o3",
  "skip_edit": false,
  "do_critique": true,
  "critique_loops": 4,
  "has_frontmatter": true,
  "token_usage": {
    "prompt_tokens": 95332,
    "completion_tokens": 30856,
    "total_tokens": 126188
  },
  "cost": "$2.1876",
  "prompts_and_responses": {
    "translation": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "\n        1. Read the provided text carefully, preserving all formatting, markdown, and structure exactly as they appear.\n        2. Identify any block quotes and code blocks.\n        3. Do not translate text in block quotes or in code blocks (including text within code blocks).\n        4. Translate everything else into spanish.\n        5. Maintain the original formatting, markdown, and structure in your output.\n        6. Provide a natural-sounding translation rather than a word-for-word one.\n        7. For idioms, colloquialisms, or slang, render them in an equivalent, natural way in spanish whenever possible.\n        8. If there isn't a direct or natural translation for a particular term or phrase, keep it in the original language and surround it with quotes if necessary.\n        9. Ensure that technical terms or jargon remain accurate; if there's no suitable translation, keep the original term.\n        10. Strive for fluid, native-sounding prose that retains the tone and intent of the original text.\n        ",
      "user_prompt": "_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "response": "_tl;dr: Lluvia de ideas para el spec, luego planear un plan, despu√©s ejecutar con codegen usando LLM. Bucles discretos. Y luego, magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nHe estado creando montones de peque√±os productos con LLMs. Ha sido divertido y √∫til. Sin embargo, hay trampas que pueden hacerte perder much√≠simo tiempo. Hace un tiempo un amigo me pregunt√≥ c√≥mo estaba usando los LLMs para escribir software. Pens√©: ‚Äú¬°vaya, cu√°nto tiempo tienes!‚Äù ‚Ä¶ y de ah√≠ sali√≥ este post.\n\n(p.d.: si odias la IA, salta al final)\n\nHablo con muchos amigos dev sobre esto y todos seguimos un enfoque similar con diferentes variantes en uno u otro sentido.\n\nAqu√≠ va mi flujo de trabajo. Se basa en mi experiencia, en conversaciones con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en muchas buenas pr√°cticas que circulan por los (terribles) rincones de internet [malos](https://news.ycombinator.com/) [lugares](https://twitter.com).\n\nEsto funciona bien **AHORA**, quiz√° en dos semanas deje de servir o funcione el doble de bien. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Vamos all√°\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Robot Juggalo\" caption=\"Siempre desconf√≠o de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel robot juggalo programador!\" >}}\n\nHay muchos caminos para hacer desarrollo, pero mi caso suele ser uno de dos:\n\n- C√≥digo nuevo (greenfield)\n- C√≥digo legado/moderno\n\nTe mostrar√© mi proceso para ambos caminos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien para desarrollo greenfield. Proporciona una planificaci√≥n y documentaci√≥n s√≥lidas y permite ejecutar f√°cilmente en pasos peque√±os.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"T√©cnicamente, hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT 4o / o3 para esto):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegar√° a una conclusi√≥n natural):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nEsto devolver√° un spec bastante s√≥lido y directo que puedes pasar al paso de planificaci√≥n. Me gusta guardarlo como `spec.md` en el repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Paso 2: Planificaci√≥n\n\nToma el spec y p√°salo a un modelo de razonamiento ( `o1*`, `o3*`, `r1`):\n\n(Este es el prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nDeber√≠a generar un plan de prompts que puedas ejecutar con aider, cursor, etc. Me gusta guardarlo como `prompt_plan.md` en el repo.\n\nLuego le pido que genere un `todo.md` para ir marcando tareas.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGu√°rdalo como `todo.md` en el repo.\n\nTu herramienta de codegen deber√≠a poder marcar el `todo.md` mientras procesa. Es bueno para mantener el estado entre sesiones.\n\n#### ¬°Yay. Plan!\n\nAhora tienes un plan robusto y documentaci√≥n que te ayudar√°n a ejecutar y construir tu proyecto.\n\nTodo este proceso llevar√° quiz√° **15 minutos**. Es bastante r√°pido. Salvaje, la verdad.\n\n### Paso 3: Ejecuci√≥n\n\nHay much√≠simas opciones para ejecutar. El √©xito depende realmente de lo bien que haya ido el paso 2.\n\nHe usado este flujo con [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. Funciona bastante bien con todas las herramientas que he probado y me imagino que ir√° bien con cualquier herramienta de codegen.\n\nSin embargo, prefiero **claude en crudo** y aider:\n\n### Claude\n\nB√°sicamente hago pair programming con [claude.ai](https://claude.ai) y voy pegando cada prompt de forma iterativa. Funciona bastante bien. El vaiv√©n puede ser molesto, pero en general cumple.\n\nYo me encargo de iniciar el boilerplate y de asegurar que el tooling est√© bien configurado. Esto da algo de libertad, elecci√≥n y orientaci√≥n al principio. Claude tiende a sacar c√≥digo React a la m√≠nima, y tener una base s√≥lida con el lenguaje, estilo y herramientas de tu elecci√≥n ayuda mucho.\n\nCuando las cosas se atascan uso una herramienta como [repomix](https://github.com/yamadashy/repomix) para iterar (m√°s sobre eso luego).\n\nEl flujo es as√≠:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- pego el prompt en Claude\n- copio el c√≥digo de claude.ai al IDE\n- ejecuto el c√≥digo, ejecuto tests, etc.\n- ‚Ä¶\n- si funciona, paso al siguiente prompt\n- si no funciona, uso repomix para pasar la base de c√≥digo a Claude y depurar\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo extra√±o. Me parece que encaja muy bien con la salida del paso 2. Puedo avanzar much√≠simo con poco trabajo.\n\nEl flujo es esencialmente el mismo que arriba, pero en vez de pegar en Claude, pego los prompts en Aider.\n\nAider entonces ‚Äúsimplemente lo hace‚Äù y yo juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTestear con Aider es agradable porque puede ser a√∫n m√°s hands-off: Aider ejecuta la suite de tests y depura por ti.\n\nEl flujo es as√≠:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- arranco Aider\n- pego el prompt en Aider\n- observo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- Aider ejecuta tests o puedo correr la app para verificar\n- si funciona, paso al siguiente prompt\n- si no, hago Q&A con Aider hasta arreglar\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Resultados\n\nHe construido much√≠simas cosas con este flujo: scripts, apps expo, herramientas CLI en Rust, etc. Ha funcionado a trav√©s de lenguajes y contextos distintos. Me gusta.\n\nSi tienes un proyecto peque√±o o grande que llevas posponiendo, te recomiendo probar. Te sorprender√° lo lejos que puedes llegar en poco tiempo.\n\nMi lista de ‚Äúcosas por hackear‚Äù est√° vac√≠a porque lo he construido todo. Sigo pensando en cosas nuevas y tach√°ndolas mientras veo una peli o algo as√≠. Por primera vez en a√±os estoy dedicando tiempo a nuevos lenguajes y herramientas. Esto me empuja a ampliar mi perspectiva de programaci√≥n.\n\n## No-greenfield: iterar de forma incremental\n\nA veces no tienes un greenfield, sino que necesitas iterar o hacer trabajo incremental en una base de c√≥digo ya establecida.\n\n{{< image src=\"brownfield.jpg\" alt=\"un campo marr√≥n\" caption=\"Esto no es un campo verde. Foto aleatoria de la c√°mara de mi abuelo ‚Äì en alg√∫n lugar de Uganda en los 60\" >}}\n\nPara esto tengo un m√©todo ligeramente distinto. Se parece al anterior, pero es menos ‚Äúbasado en planificaci√≥n‚Äù. Se planifica por tarea, no para todo el proyecto.\n\n### Obtener contexto\n\nQuienes est√°n metidos en IA dev tienen cada uno su herramienta para esto, pero necesitas algo que agarre tu c√≥digo fuente y lo empaquete eficientemente para el LLM.\n\nActualmente uso [repomix](https://github.com/yamadashy/repomix). Tengo una colecci√≥n de tareas definida en mi `~/.config/mise/config.toml` global que me permite hacer varias cosas con mi repo ([reglas de mise](https://mise.jdx.dev/)).\n\nAqu√≠ est√° la lista de tareas LLM:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de mi base de c√≥digo. Si me paso de tokens y es demasiado grande, edito el comando de generaci√≥n para ignorar partes que no sean relevantes para la tarea.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUna vez generado `output.txt`, lo paso al comando [LLM](https://github.com/simonw/LLM) para hacer distintas transformaciones y luego guardarlas como un markdown.\n\nAl final, la tarea de mise ejecuta algo como `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. No es muy complicado; el comando `LLM` hace el trabajo duro (soporta distintos modelos, guarda claves y usa plantillas de prompt).\n\nPor ejemplo, si necesito una revisi√≥n r√°pida y arreglar la cobertura de tests har√≠a lo siguiente:\n\n#### Claude\n\n- voy al directorio del c√≥digo\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- copio el contexto completo: `mise run LLM:copy_buffer_bundle`\n- pego eso en Claude junto con el primer ‚Äúissue‚Äù de tests faltantes\n- copio el c√≥digo generado por Claude a mi IDE\n- ‚Ä¶\n- ejecuto tests\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- voy al directorio del c√≥digo\n- arranco Aider (siempre en una rama nueva para el trabajo con Aider)\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- pego el primer ‚Äúissue‚Äù de tests faltantes en Aider\n- observo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ‚Ä¶\n- ejecuto tests\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nEs una forma bastante buena de mejorar una base de c√≥digo de forma incremental. Me ha sido s√∫per √∫til para hacer trabajos de cualquier tama√±o.\n\n### Magia de prompts\n\nEstos hacks r√°pidos funcionan muy bien para profundizar en lugares donde hacer el proyecto m√°s robusto. S√∫per r√°pido y efectivo.\n\nAqu√≠ algunos de mis prompts para meterse en bases de c√≥digo establecidas:\n\n#### Revisi√≥n de c√≥digo\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generaci√≥n de issues de GitHub\n\n(¬°Tengo que automatizar el posteo real de issues!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts ya est√°n algo _old and busted_ (prompts ‚Äúboomer‚Äù, si se quiere). Necesitan refactor. Si tienes ideas para mejorarlos, av√≠same.\n\n## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nCuando describo este proceso a la gente digo: ‚Äútienes que llevar el control de forma agresiva porque es muy f√°cil adelantarte a ti mismo‚Äù.\n\nPor alguna raz√≥n digo mucho **over my skis** cuando hablo de LLMs. No s√© por qu√©. Me resuena. Quiz√° porque es como esquiar en polvo perfecto y, de pronto, ‚Äú¬°¬øQU√â DEMONIOS PASA?!‚Äù: te pierdes del todo y caes por un precipicio.\n\nEncuentro que usar un **paso de planificaci√≥n** (como en el proceso Greenfield) ayuda a mantener el control. Al menos tendr√°s un doc para comprobar. Tambi√©n creo que los tests ayudan, especialmente si est√°s haciendo coding estilo ‚Äúwild‚Äù con Aider. Ayuda a mantenerlo bien y ajustado.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Estoy tan solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMi mayor queja sobre estos flujos es que, en esencia, es una actividad en solitario ‚Äîes decir, las interfaces son de _modo un jugador_.\n\nHe pasado a√±os programando solo, a√±os en pair programming y a√±os en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en equipo. Los bots chocan, los merges son horribles, el contexto es complicado.\n\nQuiero que alguien solucione esto de forma que programar con un LLM sea un juego multijugador, no una experiencia de hacker solitario. Hay mucha oportunidad para hacerlo incre√≠ble.\n\n¬°P√ìNGANSE A ELLO!\n\n## ‚¥µ Tiempo ‚¥µ\n\nTodo este codegen ha acelerado la cantidad de c√≥digo que puedo generar como individuo. Sin embargo, hay un efecto extra√±o: tengo mucho ‚Äútiempo muerto‚Äù mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nHe cambiado mi forma de trabajar para aprovechar esos momentos de espera:\n\n- Inicio el proceso de ‚Äúbrainstorming‚Äù de otro proyecto\n- Escucho discos de vinilo\n- Juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- Charlo con amigos y con robots\n\nEs genial poder hackear as√≠. Hack Hack Hack. No recuerdo otra √©poca en la que haya sido tan productivo programando.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nMuchos amigos me dicen: ‚Äúlos LLMs apestan, son malos en todo‚Äù. No me molesta ese punto de vista. No lo comparto, pero creo que es importante ser esc√©ptico. Hay montones de razones para odiar la IA. Mi principal miedo es el consumo energ√©tico y el impacto ambiental. Pero‚Ä¶ el c√≥digo debe fluir. ¬øVerdad? ‚Ä¶ ay.\n\nSi est√°s abierto a aprender m√°s, pero no quieres meterte a fondo y convertirte en un programador c√≠borg, mi recomendaci√≥n no es que cambies de opini√≥n, sino que leas el libro de Ethan Mollick sobre LLMs y c√≥mo usarlos: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nHace un buen trabajo explicando los beneficios sin ser un tratado bro tecno-anarco-capitalista. Me result√≥ muy √∫til y he tenido conversaciones buenas y matizadas con amigos que lo han le√≠do. Muy recomendado.\n\nSi eres esc√©ptico pero algo curioso, cont√°ctame y hablemos de toda esta locura. Puedo ense√±arte c√≥mo usamos los LLMs y quiz√° construyamos algo juntos.\n\n_gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar este post y sugerir cambios. ¬°Lo aprecio!_",
      "usage": {
        "prompt_tokens": 4834,
        "completion_tokens": 4488,
        "total_tokens": 9322
      },
      "streaming": true
    },
    "editing": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "\n        1. Carefully read the translated text alongside the original text in its entirety.\n        2. Compare both texts to ensure the translation accurately reflects the original meaning.\n        3. Correct any grammatical errors you find in the spanish text.\n        4. Adjust phrasing to make it sound natural and fluent for spanish speakers, making sure idioms and expressions are culturally appropriate.\n        5. Preserve the original tone, nuance, and style, including any formatting, markdown, and structure.\n        6. Avoid adding new information or altering the core meaning.\n        7. Ensure the final result doesn't feel machine-translated but remains faithful to the source.\n        8. Make only changes that genuinely improve the text's quality in spanish.\n        9. Don't be too literal. If there isn't a direct translation, provide a natural-sounding translation.\n        10. If the text contains idioms or colloquialisms, translate them into the target language while maintaining their original meaning.\n        11. If the text contains technical terms or jargon, ensure that the translation is accurate and appropriate for the target audience, if there isn't a natural translation, keep it in the original language.\n        12. If there is not natural translation, keep it in the original language.\n        ",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# TRANSLATED TEXT\n_tl;dr: Lluvia de ideas para el spec, luego planear un plan, despu√©s ejecutar con codegen usando LLM. Bucles discretos. Y luego, magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nHe estado creando montones de peque√±os productos con LLMs. Ha sido divertido y √∫til. Sin embargo, hay trampas que pueden hacerte perder much√≠simo tiempo. Hace un tiempo un amigo me pregunt√≥ c√≥mo estaba usando los LLMs para escribir software. Pens√©: ‚Äú¬°vaya, cu√°nto tiempo tienes!‚Äù ‚Ä¶ y de ah√≠ sali√≥ este post.\n\n(p.d.: si odias la IA, salta al final)\n\nHablo con muchos amigos dev sobre esto y todos seguimos un enfoque similar con diferentes variantes en uno u otro sentido.\n\nAqu√≠ va mi flujo de trabajo. Se basa en mi experiencia, en conversaciones con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en muchas buenas pr√°cticas que circulan por los (terribles) rincones de internet [malos](https://news.ycombinator.com/) [lugares](https://twitter.com).\n\nEsto funciona bien **AHORA**, quiz√° en dos semanas deje de servir o funcione el doble de bien. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Vamos all√°\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Robot Juggalo\" caption=\"Siempre desconf√≠o de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel robot juggalo programador!\" >}}\n\nHay muchos caminos para hacer desarrollo, pero mi caso suele ser uno de dos:\n\n- C√≥digo nuevo (greenfield)\n- C√≥digo legado/moderno\n\nTe mostrar√© mi proceso para ambos caminos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien para desarrollo greenfield. Proporciona una planificaci√≥n y documentaci√≥n s√≥lidas y permite ejecutar f√°cilmente en pasos peque√±os.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"T√©cnicamente, hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT 4o / o3 para esto):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegar√° a una conclusi√≥n natural):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nEsto devolver√° un spec bastante s√≥lido y directo que puedes pasar al paso de planificaci√≥n. Me gusta guardarlo como `spec.md` en el repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Paso 2: Planificaci√≥n\n\nToma el spec y p√°salo a un modelo de razonamiento ( `o1*`, `o3*`, `r1`):\n\n(Este es el prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nDeber√≠a generar un plan de prompts que puedas ejecutar con aider, cursor, etc. Me gusta guardarlo como `prompt_plan.md` en el repo.\n\nLuego le pido que genere un `todo.md` para ir marcando tareas.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGu√°rdalo como `todo.md` en el repo.\n\nTu herramienta de codegen deber√≠a poder marcar el `todo.md` mientras procesa. Es bueno para mantener el estado entre sesiones.\n\n#### ¬°Yay. Plan!\n\nAhora tienes un plan robusto y documentaci√≥n que te ayudar√°n a ejecutar y construir tu proyecto.\n\nTodo este proceso llevar√° quiz√° **15 minutos**. Es bastante r√°pido. Salvaje, la verdad.\n\n### Paso 3: Ejecuci√≥n\n\nHay much√≠simas opciones para ejecutar. El √©xito depende realmente de lo bien que haya ido el paso 2.\n\nHe usado este flujo con [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. Funciona bastante bien con todas las herramientas que he probado y me imagino que ir√° bien con cualquier herramienta de codegen.\n\nSin embargo, prefiero **claude en crudo** y aider:\n\n### Claude\n\nB√°sicamente hago pair programming con [claude.ai](https://claude.ai) y voy pegando cada prompt de forma iterativa. Funciona bastante bien. El vaiv√©n puede ser molesto, pero en general cumple.\n\nYo me encargo de iniciar el boilerplate y de asegurar que el tooling est√© bien configurado. Esto da algo de libertad, elecci√≥n y orientaci√≥n al principio. Claude tiende a sacar c√≥digo React a la m√≠nima, y tener una base s√≥lida con el lenguaje, estilo y herramientas de tu elecci√≥n ayuda mucho.\n\nCuando las cosas se atascan uso una herramienta como [repomix](https://github.com/yamadashy/repomix) para iterar (m√°s sobre eso luego).\n\nEl flujo es as√≠:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- pego el prompt en Claude\n- copio el c√≥digo de claude.ai al IDE\n- ejecuto el c√≥digo, ejecuto tests, etc.\n- ‚Ä¶\n- si funciona, paso al siguiente prompt\n- si no funciona, uso repomix para pasar la base de c√≥digo a Claude y depurar\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo extra√±o. Me parece que encaja muy bien con la salida del paso 2. Puedo avanzar much√≠simo con poco trabajo.\n\nEl flujo es esencialmente el mismo que arriba, pero en vez de pegar en Claude, pego los prompts en Aider.\n\nAider entonces ‚Äúsimplemente lo hace‚Äù y yo juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTestear con Aider es agradable porque puede ser a√∫n m√°s hands-off: Aider ejecuta la suite de tests y depura por ti.\n\nEl flujo es as√≠:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- arranco Aider\n- pego el prompt en Aider\n- observo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- Aider ejecuta tests o puedo correr la app para verificar\n- si funciona, paso al siguiente prompt\n- si no, hago Q&A con Aider hasta arreglar\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Resultados\n\nHe construido much√≠simas cosas con este flujo: scripts, apps expo, herramientas CLI en Rust, etc. Ha funcionado a trav√©s de lenguajes y contextos distintos. Me gusta.\n\nSi tienes un proyecto peque√±o o grande que llevas posponiendo, te recomiendo probar. Te sorprender√° lo lejos que puedes llegar en poco tiempo.\n\nMi lista de ‚Äúcosas por hackear‚Äù est√° vac√≠a porque lo he construido todo. Sigo pensando en cosas nuevas y tach√°ndolas mientras veo una peli o algo as√≠. Por primera vez en a√±os estoy dedicando tiempo a nuevos lenguajes y herramientas. Esto me empuja a ampliar mi perspectiva de programaci√≥n.\n\n## No-greenfield: iterar de forma incremental\n\nA veces no tienes un greenfield, sino que necesitas iterar o hacer trabajo incremental en una base de c√≥digo ya establecida.\n\n{{< image src=\"brownfield.jpg\" alt=\"un campo marr√≥n\" caption=\"Esto no es un campo verde. Foto aleatoria de la c√°mara de mi abuelo ‚Äì en alg√∫n lugar de Uganda en los 60\" >}}\n\nPara esto tengo un m√©todo ligeramente distinto. Se parece al anterior, pero es menos ‚Äúbasado en planificaci√≥n‚Äù. Se planifica por tarea, no para todo el proyecto.\n\n### Obtener contexto\n\nQuienes est√°n metidos en IA dev tienen cada uno su herramienta para esto, pero necesitas algo que agarre tu c√≥digo fuente y lo empaquete eficientemente para el LLM.\n\nActualmente uso [repomix](https://github.com/yamadashy/repomix). Tengo una colecci√≥n de tareas definida en mi `~/.config/mise/config.toml` global que me permite hacer varias cosas con mi repo ([reglas de mise](https://mise.jdx.dev/)).\n\nAqu√≠ est√° la lista de tareas LLM:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de mi base de c√≥digo. Si me paso de tokens y es demasiado grande, edito el comando de generaci√≥n para ignorar partes que no sean relevantes para la tarea.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUna vez generado `output.txt`, lo paso al comando [LLM](https://github.com/simonw/LLM) para hacer distintas transformaciones y luego guardarlas como un markdown.\n\nAl final, la tarea de mise ejecuta algo como `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. No es muy complicado; el comando `LLM` hace el trabajo duro (soporta distintos modelos, guarda claves y usa plantillas de prompt).\n\nPor ejemplo, si necesito una revisi√≥n r√°pida y arreglar la cobertura de tests har√≠a lo siguiente:\n\n#### Claude\n\n- voy al directorio del c√≥digo\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- copio el contexto completo: `mise run LLM:copy_buffer_bundle`\n- pego eso en Claude junto con el primer ‚Äúissue‚Äù de tests faltantes\n- copio el c√≥digo generado por Claude a mi IDE\n- ‚Ä¶\n- ejecuto tests\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- voy al directorio del c√≥digo\n- arranco Aider (siempre en una rama nueva para el trabajo con Aider)\n- ejecuto `mise run LLM:generate_missing_tests`\n- reviso el markdown generado (`missing-tests.md`)\n- pego el primer ‚Äúissue‚Äù de tests faltantes en Aider\n- observo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ‚Ä¶\n- ejecuto tests\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nEs una forma bastante buena de mejorar una base de c√≥digo de forma incremental. Me ha sido s√∫per √∫til para hacer trabajos de cualquier tama√±o.\n\n### Magia de prompts\n\nEstos hacks r√°pidos funcionan muy bien para profundizar en lugares donde hacer el proyecto m√°s robusto. S√∫per r√°pido y efectivo.\n\nAqu√≠ algunos de mis prompts para meterse en bases de c√≥digo establecidas:\n\n#### Revisi√≥n de c√≥digo\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generaci√≥n de issues de GitHub\n\n(¬°Tengo que automatizar el posteo real de issues!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts ya est√°n algo _old and busted_ (prompts ‚Äúboomer‚Äù, si se quiere). Necesitan refactor. Si tienes ideas para mejorarlos, av√≠same.\n\n## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nCuando describo este proceso a la gente digo: ‚Äútienes que llevar el control de forma agresiva porque es muy f√°cil adelantarte a ti mismo‚Äù.\n\nPor alguna raz√≥n digo mucho **over my skis** cuando hablo de LLMs. No s√© por qu√©. Me resuena. Quiz√° porque es como esquiar en polvo perfecto y, de pronto, ‚Äú¬°¬øQU√â DEMONIOS PASA?!‚Äù: te pierdes del todo y caes por un precipicio.\n\nEncuentro que usar un **paso de planificaci√≥n** (como en el proceso Greenfield) ayuda a mantener el control. Al menos tendr√°s un doc para comprobar. Tambi√©n creo que los tests ayudan, especialmente si est√°s haciendo coding estilo ‚Äúwild‚Äù con Aider. Ayuda a mantenerlo bien y ajustado.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Estoy tan solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMi mayor queja sobre estos flujos es que, en esencia, es una actividad en solitario ‚Äîes decir, las interfaces son de _modo un jugador_.\n\nHe pasado a√±os programando solo, a√±os en pair programming y a√±os en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en equipo. Los bots chocan, los merges son horribles, el contexto es complicado.\n\nQuiero que alguien solucione esto de forma que programar con un LLM sea un juego multijugador, no una experiencia de hacker solitario. Hay mucha oportunidad para hacerlo incre√≠ble.\n\n¬°P√ìNGANSE A ELLO!\n\n## ‚¥µ Tiempo ‚¥µ\n\nTodo este codegen ha acelerado la cantidad de c√≥digo que puedo generar como individuo. Sin embargo, hay un efecto extra√±o: tengo mucho ‚Äútiempo muerto‚Äù mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nHe cambiado mi forma de trabajar para aprovechar esos momentos de espera:\n\n- Inicio el proceso de ‚Äúbrainstorming‚Äù de otro proyecto\n- Escucho discos de vinilo\n- Juego al [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- Charlo con amigos y con robots\n\nEs genial poder hackear as√≠. Hack Hack Hack. No recuerdo otra √©poca en la que haya sido tan productivo programando.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nMuchos amigos me dicen: ‚Äúlos LLMs apestan, son malos en todo‚Äù. No me molesta ese punto de vista. No lo comparto, pero creo que es importante ser esc√©ptico. Hay montones de razones para odiar la IA. Mi principal miedo es el consumo energ√©tico y el impacto ambiental. Pero‚Ä¶ el c√≥digo debe fluir. ¬øVerdad? ‚Ä¶ ay.\n\nSi est√°s abierto a aprender m√°s, pero no quieres meterte a fondo y convertirte en un programador c√≠borg, mi recomendaci√≥n no es que cambies de opini√≥n, sino que leas el libro de Ethan Mollick sobre LLMs y c√≥mo usarlos: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nHace un buen trabajo explicando los beneficios sin ser un tratado bro tecno-anarco-capitalista. Me result√≥ muy √∫til y he tenido conversaciones buenas y matizadas con amigos que lo han le√≠do. Muy recomendado.\n\nSi eres esc√©ptico pero algo curioso, cont√°ctame y hablemos de toda esta locura. Puedo ense√±arte c√≥mo usamos los LLMs y quiz√° construyamos algo juntos.\n\n_gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar este post y sugerir cambios. ¬°Lo aprecio!_\n\nPlease review and improve the translated text to make it natural and accurate in spanish.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr: Tormenta de ideas para el spec, luego planear un plan, despu√©s ejecutar con codegen usando LLM. Bucles discretos. Y luego, magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nHe estado creando montones de productos peque√±os con LLM. Ha sido divertido y √∫til. Sin embargo, hay trampas que pueden hacerte perder much√≠simo tiempo. Hace un tiempo un amigo me pregunt√≥ c√≥mo estaba usando los LLM para escribir software. Pens√©: ¬´¬°Uf, ¬øcu√°nto tiempo tienes?¬ª y de ah√≠ sali√≥ este post.\n\n(p. d.: si odias la IA, salta al final)\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque similar con variaciones aqu√≠ y all√°.\n\nAqu√≠ va mi flujo de trabajo. Se basa en mi experiencia, en conversaciones con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en muchas buenas pr√°cticas que circulan por los (terribles) rincones de internet [malos](https://news.ycombinator.com/) [lugares](https://twitter.com).\n\nEsto funciona bien **AHORA**; quiz√° en dos semanas deje de servir o funcione el doble de bien. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Vamos all√°\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Robot Juggalo\" caption=\"Siempre desconf√≠o de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel robot juggalo programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mi caso suele caer en uno de estos dos escenarios:\n\n- C√≥digo nuevo (greenfield)\n- C√≥digo existente / legado moderno\n\nTe mostrar√© mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien para desarrollo greenfield. Proporciona una planificaci√≥n y documentaci√≥n s√≥lidas y permite avanzar f√°cilmente en pasos peque√±os.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"T√©cnicamente hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3 para esto):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAl final de la tormenta de ideas (llegar√° a una conclusi√≥n natural):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nEsto devolver√° un spec bastante s√≥lido y directo que puedes pasar al paso de planificaci√≥n. Me gusta guardarlo como `spec.md` en el repo.\n\n> Puedes utilizar este spec para muchas cosas. Aqu√≠ lo usamos para codegen, pero tambi√©n lo he usado para reforzar ideas pidi√©ndole a un modelo de razonamiento que les busque puntos d√©biles (¬°m√°s profundo!), para generar un white paper o un modelo de negocio. Incluso puedes pedirle una investigaci√≥n extensa y obtener un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificaci√≥n\n\nToma el spec y p√°salo a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nGenerar√° un plan de prompts que podr√°s ejecutar con Aider, Cursor, etc. Me gusta guardarlo como `prompt_plan.md` en el repo.\n\nLuego le pido que genere un `todo.md` para ir marcando tareas:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGu√°rdalo como `todo.md` en el repo.\n\nTu herramienta de codegen deber√≠a poder marcar el `todo.md` mientras procesa. Es ideal para mantener el estado entre sesiones.\n\n#### ¬°Yay, plan!\n\nAhora tienes un plan robusto y documentaci√≥n que te ayudar√°n a ejecutar y construir tu proyecto.\n\nTodo este proceso lleva quiz√° **15 minutos**. Es bastante r√°pido. Salvaje, la verdad.\n\n### Paso 3: Ejecuci√≥n\n\nHay much√≠simas opciones para la ejecuci√≥n. El √©xito depende de lo bien que haya ido el paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai), etc. Funciona bastante bien con todas las herramientas que he probado y me imagino que ir√° bien con cualquier herramienta de codegen.\n\nSin embargo, prefiero **Claude puro** y Aider:\n\n### Claude\n\nB√°sicamente hago pair programming con [Claude.ai](https://claude.ai) y voy pegando cada prompt de forma iterativa. Funciona bastante bien. El vaiv√©n puede ser molesto, pero en general cumple.\n\nYo me encargo de iniciar el boilerplate y de asegurar que el tooling est√© bien configurado. Esto da algo de libertad y orientaci√≥n al principio. Claude tiende a escupir c√≥digo React a la m√≠nima y tener una base s√≥lida con el lenguaje, estilo y herramientas de tu elecci√≥n ayuda mucho.\n\nCuando las cosas se atascan uso una herramienta como [repomix](https://github.com/yamadashy/repomix) para iterar (m√°s sobre eso luego).\n\nEl flujo es as√≠:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- pego el prompt en Claude\n- copio el c√≥digo de Claude al IDE\n- ejecuto el c√≥digo, corro los tests, etc.\n- ‚Ä¶\n- si funciona, paso al siguiente prompt\n- si no funciona, uso Repomix para pasar la base de c√≥digo a Claude y depurar\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del paso 2. Puedo avanzar much√≠simo con muy poco trabajo.\n\nEl flujo es esencialmente el mismo que arriba, pero en vez de pegar en Claude, pego los prompts en Aider.\n\nAider entonces ¬´simplemente lo hace¬ª y yo juego al [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> A modo de nota: Aider hace benchmarks muy buenos de modelos nuevos para codegen en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Es un recurso excelente para ver qu√© tan efectivos son los modelos nuevos.\n\nTestear con Aider es genial porque puede ser a√∫n m√°s hands-off: Aider ejecuta la suite de tests y depura por ti.\n\nEl flujo es as√≠:\n\n- preparo el repo (boilerplate, `uv init`, `cargo init`, etc.)\n- arranco Aider\n- pego el prompt en Aider\n- observo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- Aider ejecuta tests o corro la app para verificar\n- si funciona, paso al siguiente prompt\n- si no, hago Q&A con Aider hasta arreglar\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Resultados\n\nHe construido much√≠simas cosas con este flujo: scripts, apps Expo, herramientas CLI en Rust, etc. Ha funcionado en distintos lenguajes y contextos. Me encanta.\n\nSi tienes un proyecto, grande o peque√±o, que llevas posponiendo, te recomiendo probar. Te sorprender√° lo lejos que puedes llegar en poco tiempo.\n\nMi lista de ¬´cosas por hackear¬ª est√° vac√≠a porque lo he construido todo. Sigo pensando en ideas nuevas y tach√°ndolas mientras veo una peli o algo as√≠. Por primera vez en a√±os estoy dedicando tiempo a nuevos lenguajes y herramientas, lo que ampl√≠a mi perspectiva como programador.\n\n## No-greenfield: iterar de forma incremental\n\nA veces no partes de cero y necesitas mejorar o a√±adir funcionalidades a una base de c√≥digo ya establecida.\n\n{{< image src=\"brownfield.jpg\" alt=\"un campo marr√≥n\" caption=\"Esto no es un campo verde. Foto aleatoria de la c√°mara de mi abuelo ‚Äì en alg√∫n lugar de Uganda en los 60\" >}}\n\nPara esto uso un m√©todo ligeramente distinto. Se parece al anterior pero es menos ¬´basado en planificaci√≥n¬ª: se planifica por tarea, no para todo el proyecto.\n\n### Obtener contexto\n\nCada persona metida en IA dev tiene su propia herramienta para esto, pero necesitas algo que tome tu c√≥digo fuente y lo empaquete eficientemente para el LLM.\n\nActualmente uso [Repomix](https://github.com/yamadashy/repomix). Tengo una colecci√≥n de tareas definida en mi `~/.config/mise/config.toml` global que me permite hacer varias cosas con el repo ([reglas de mise](https://mise.jdx.dev/)).\n\nLista de tareas LLM:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de c√≥digo. Si me paso de tokens y es demasiado grande, edito el comando de generaci√≥n para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empacar el c√≥digo y, mientras genere un `output.txt`, puedo usar mis tareas LLM. Esto ayuda cuando las bases de c√≥digo difieren mucho. Suelo sobreescribir el paso de Repomix para incluir patrones de exclusi√≥n m√°s amplios o simplemente usar una herramienta m√°s eficaz para el empaquetado.\n\nUna vez generado `output.txt`, lo paso al comando [LLM](https://github.com/simonw/LLM) para hacer diversas transformaciones y guardarlas como markdown.\n\nAl final, la tarea de mise ejecuta algo como `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. No es muy complicado: el comando `LLM` hace el trabajo duro (soporta distintos modelos, guarda claves y usa plantillas de prompt).\n\nPor ejemplo, si necesito una revisi√≥n r√°pida y mejorar la cobertura de tests har√≠a lo siguiente:\n\n#### Claude\n\n- Voy al directorio del c√≥digo.\n- Ejecuto `mise run LLM:generate_missing_tests`.\n- Reviso el markdown generado (`missing-tests.md`).\n- Copio el contexto completo: `mise run LLM:copy_buffer_bundle`.\n- Pego eso en Claude junto con el primer issue de tests faltantes.\n- Copio el c√≥digo generado por Claude a mi IDE.\n- ‚Ä¶\n- Ejecuto tests.\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- Voy al directorio del c√≥digo.\n- Arranco Aider (siempre en una rama nueva para el trabajo con Aider).\n- Ejecuto `mise run LLM:generate_missing_tests`.\n- Reviso el markdown generado (`missing-tests.md`).\n- Pego el primer issue de tests faltantes en Aider.\n- Observo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ‚Ä¶\n- Ejecuto tests.\n- rinse and repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nEs una forma bastante buena de mejorar una base de c√≥digo de forma incremental. Me ha resultado √∫til para tareas de cualquier tama√±o.\n\n### Magia de prompts\n\nEstos hacks r√°pidos funcionan muy bien para reforzar un proyecto. Son s√∫per veloces y efectivos.\n\nAqu√≠ algunos de mis prompts para bases de c√≥digo establecidas:\n\n#### Revisi√≥n de c√≥digo\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generaci√≥n de issues de GitHub\n\n(¬°Tengo que automatizar el posteo real de issues!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts ya est√°n algo _old and busted_ (prompts ¬´boomer¬ª, si se quiere). Necesitan refactor. Si tienes ideas para mejorarlos, av√≠same.\n\n## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nAl describir este proceso siempre digo: ¬´tienes que llevar el control de forma agresiva porque es muy f√°cil adelantarte a ti mismo¬ª.\n\nPor alguna raz√≥n uso mucho la frase **over my skis** cuando hablo de LLM. Quiz√° porque es como esquiar en polvo perfecto y, de pronto, ¬´¬°¬øQU√â DEMONIOS PASA?!¬ª: te pierdes y caes por un precipicio.\n\nUsar un **paso de planificaci√≥n** (como en el proceso Greenfield) ayuda a mantener el control: al menos tendr√°s un documento para comprobar. Tambi√©n creo que los tests son √∫tiles, especialmente si est√°s haciendo c√≥digo ¬´wild style¬ª con Aider. Ayudan a mantener todo ajustado.\n\n> A menudo pedimos al LLM que incluya cosas rid√≠culas en un c√≥digo que no lo es tanto. Por ejemplo, le pedimos que creara un archivo de _lore_ y luego lo referenciara en la interfaz de usuario de una herramienta CLI en Python. De repente hay lore, interfaces glitchy, etc. Todo para gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el l√≠mite.\n\n## Estoy tan solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMi mayor queja de estos flujos es que, en esencia, son una actividad en solitario: las interfaces est√°n en _modo un jugador_.\n\nHe pasado a√±os programando solo, a√±os haciendo pair programming y a√±os en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en equipo: los bots chocan, los merges son horribles y el contexto se complica.\n\nQuiero que alguien solucione esto y convierta la programaci√≥n con un LLM en un juego multijugador, no en una experiencia de hacker solitario. Hay much√≠sima oportunidad para hacerlo incre√≠ble.\n\n¬°A TRABAJAR!\n\n## ‚¥µ Tiempo ‚¥µ\n\nTodo este codegen ha acelerado la cantidad de c√≥digo que puedo generar como individuo. Sin embargo, hay un efecto extra√±o: tengo mucho _tiempo muerto_ mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nHe cambiado mi forma de trabajar para aprovechar esos momentos de espera:\n\n- Inicio la ¬´tormenta de ideas¬ª de otro proyecto.\n- Escucho vinilos.\n- Juego al [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n- Charlo con amigos y con robots.\n\nEs genial poder hackear as√≠. Hack Hack Hack. No recuerdo otra √©poca en la que haya sido tan productivo programando.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nMuchos amigos me dicen: ¬´los LLM apestan; son malos en todo¬ª. No me molesta ese punto de vista. No lo comparto, pero creo que es importante ser esc√©ptico. Hay montones de razones para odiar la IA. Mi principal miedo es el consumo energ√©tico y el impacto ambiental. Pero‚Ä¶ el c√≥digo debe fluir. ¬øVerdad? *suspiro*\n\nSi est√°s abierto a aprender m√°s, pero no quieres meterte de lleno y convertirte en un programador c√≠borg, mi recomendaci√≥n no es que cambies de opini√≥n, sino que leas el libro de Ethan Mollick sobre LLM y c√≥mo usarlos: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nHace un buen trabajo explicando los beneficios sin ser un tratado _bro_ tecno-anarco-capitalista. Me result√≥ muy √∫til y he tenido conversaciones buenas y matizadas con amigos que lo han le√≠do. Muy recomendado.\n\nSi eres esc√©ptico pero un poco curioso, cont√°ctame y hablemos de toda esta locura. Puedo mostrarte c√≥mo usamos los LLM y quiz√° construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar este post y sugerir cambios. ¬°Lo aprecio!_",
      "usage": {
        "prompt_tokens": 9807,
        "completion_tokens": 4443,
        "total_tokens": 14250
      },
      "streaming": true
    },
    "critique": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "You are a highly critical professional translator and linguistic expert specializing in spanish.\nYour task is to ruthlessly critique the translation by:\n\n1. Meticulously comparing the translated text with the original, identifying ANY inaccuracies, mistranslations, or omissions\n2. Highlighting nuances, cultural references, or idioms that were lost or mistranslated\n3. Scrutinizing for grammatical errors, awkward phrasing, or unnatural expressions in spanish\n4. Checking for inconsistencies in tone, style, or register compared to the original\n5. Verifying that technical terms are translated accurately and consistently\n6. Ensuring no content was accidentally skipped or added\n7. Finding places where the translation sounds machine-like or overly literal\n\nBe extremely thorough and critical in your assessment. Do not accept mediocre translations.\nList specific issues and suggestions for improvement, organized by severity and category.\nYour critique should be detailed enough for another translator to address all the issues.\n\nYour goal is to help create a perfect translation that reads as if originally written in spanish while being 100% faithful to the source.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr: Lluvia de ideas para la especificaci√≥n (spec), luego **planear un plan**, despu√©s ejecutar con generaci√≥n autom√°tica de c√≥digo (*codegen*) mediante los LLM. **Bucles separados.** Luego‚Ä¶ magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nHe estado construyendo **much√≠simos** productos peque√±os con LLM. Ha sido divertido y √∫til, pero hay trampas que pueden hacerte perder much√≠simo tiempo. Hace un tiempo un amigo me pregunt√≥ c√≥mo estaba usando los LLM para escribir software. Pens√©: ¬´¬°Madre m√≠a! ¬øCu√°nto tiempo tienes?¬ª y as√≠ naci√≥ esta entrada.\n\n(P. D.: si odias la IA, salta al final).\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque parecido, con matices aqu√≠ y all√°.\n\nAqu√≠ va mi flujo de trabajo. Se basa en mi experiencia, en charlas con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en un pu√±ado de buenas pr√°cticas que circulan por los peores rincones de Internet ([uno](https://news.ycombinator.com/) y [otro](https://twitter.com)).\n\nEsto funciona bien **AHORA**; puede que en dos semanas deje de servir‚Ä¶ o que funcione el doble de bien. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Vamos all√°\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Siempre desconf√≠o de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel-robot juggalo programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mis proyectos suelen caer en uno de estos dos escenarios:\n\n- C√≥digo nuevo desde cero (*greenfield*)\n- Base de c√≥digo heredada (pero moderna)\n\nTe mostrar√© mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien cuando parto de cero. Aporta una planificaci√≥n y documentaci√≥n s√≥lidas y permite avanzar f√°cilmente en pasos peque√±os.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"T√©cnicamente hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegar√° a una conclusi√≥n natural):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nObtendr√°s una especificaci√≥n bastante s√≥lida que podr√°s pasar al paso de planificaci√≥n. Suelo guardarla como `spec.md` en el repositorio.\n\n> Esa especificaci√≥n sirve para muchas cosas. Aqu√≠ la usamos para generaci√≥n de c√≥digo, pero tambi√©n la he empleado para pedirle a un modelo de razonamiento que busque puntos d√©biles (¬°hay que ir m√°s profundo!), para generar un white paper o un modelo de negocio. Incluso puedes meterla en una investigaci√≥n profunda y recibir un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificaci√≥n\n\nPasa la spec a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el prompt con TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nEl modelo devolver√° un plan de prompts que podr√°s ejecutar con Aider, Cursor, etc. Yo lo guardo como `prompt_plan.md` en el repositorio.\n\nDespu√©s le pido una lista de comprobaci√≥n:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGu√°rdalo como `todo.md`. Tu herramienta de generaci√≥n de c√≥digo deber√≠a ir marcando esta lista para mantener el estado entre sesiones.\n\n#### ¬°Plan listo!\n\nCon esto tienes un plan robusto y documentaci√≥n clara para construir tu proyecto.\n\nTodo el proceso lleva, como mucho, **15 minutos**. Una locura, la verdad.\n\n### Paso 3: Ejecuci√≥n\n\nHay much√≠simas opciones; el √©xito depende de lo bien que sali√≥ el Paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)‚Ä¶ Funciona bien con todas las que he probado y, seguramente, con cualquier otra herramienta de *codegen*.\n\nAun as√≠, prefiero **Claude ‚Äúen crudo‚Äù** y Aider.\n\n### Claude\n\nB√°sicamente hago _pair programming_ con [Claude.ai](https://claude.ai) pegando cada instrucci√≥n de forma iterativa. Funciona bastante bien: el ida y vuelta puede ser pesado, pero cumple.\n\nYo me encargo del c√≥digo base inicial y de que las herramientas est√©n configuradas. Esto da cierta libertad y gu√≠a al principio. Claude tiende a escupir c√≥digo React a la m√≠nima; contar con una base s√≥lida en el lenguaje y estilo de tu elecci√≥n ayuda mucho.\n\nCuando las cosas se atascan, uso [Repomix](https://github.com/yamadashy/repomix) (una herramienta para empaquetar repositorios) para iterar.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- pego la instrucci√≥n en Claude  \n- copio el c√≥digo al IDE  \n- ejecuto el c√≥digo y la suite de pruebas  \n- ‚Ä¶  \n- si funciona, paso a la siguiente instrucci√≥n  \n- si no, paso la base de c√≥digo a Claude con Repomix para depurar  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del Paso 2: avanzo much√≠simo con muy poco esfuerzo.\n\nEl flujo es casi id√©ntico, pero pegando las instrucciones en Aider.\n\nAider ‚Äúsimplemente lo hace‚Äù y yo me pongo a jugar al juego ¬´Cookie Clicker¬ª.\n\n> Aider publica un benchmarking excelente de modelos nuevos en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Recurso brutal para ver qu√© tan efectivos son los modelos.\n\nLa prueba es a√∫n m√°s autom√°tica: Aider ejecuta la suite de pruebas y depura por ti.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- inicio Aider (procura estar siempre en una rama nueva)  \n- pego la instrucci√≥n  \n- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™  \n- Aider ejecuta pruebas o corro la app para verificar  \n- si funciona, siguiente instrucci√≥n  \n- si no, sesi√≥n de preguntas y respuestas con Aider hasta arreglar  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Resultados\n\nHe construido scripts, apps de Expo, herramientas CLI en Rust, etc., usando este m√©todo. Funciona en distintos lenguajes y contextos. La verdad, me encanta.\n\nSi tienes un proyecto (grande o peque√±o) aparcado, prueba esto: te sorprender√° lo lejos que avanzas en poco tiempo.\n\nMi lista de hacks pendientes est√° vac√≠a porque lo he construido todo. Pienso ideas nuevas y las tacho mientras veo una peli. Por primera vez en a√±os estoy jugando con lenguajes y herramientas nuevas, y eso ampl√≠a mi perspectiva como programador.\n\n## Brownfield (proyectos existentes): iteraci√≥n incremental\n\nA veces no partes de cero y toca mejorar o a√±adir funcionalidades a una base de c√≥digo existente.\n\n{{< image src=\"brownfield.jpg\" alt=\"Brownfield (campo marr√≥n)\" caption=\"Esto NO es un greenfield. Foto aleatoria de la c√°mara de mi abuelo ‚Äî Uganda, a√±os 60.\" >}}\n\nPara esto uso un m√©todo parecido, pero menos de ‚Äúplanificaci√≥n global‚Äù: planifico por tarea, no por proyecto.\n\n### Obtener contexto\n\nCada persona metida en IA tiene su herramienta favorita para empaquetar el c√≥digo y pasarlo eficazmente al LLM.\n\nYo utilizo la herramienta Repomix y un conjunto de tareas en `~/.config/mise/config.toml` (ver [reglas de mise](https://mise.jdx.dev/)):\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de c√≥digo. Si se pasa de tokens, ajusto el comando para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empaquetar el c√≥digo y, mientras genere un `output.txt`, mis tareas LLM siguen funcionando. Suelo sobreescribir el paso de Repomix para incluir patrones de ignore m√°s amplios o usar una herramienta m√°s eficaz seg√∫n el caso.\n\nLuego paso `output.txt` al comando [LLM](https://github.com/simonw/LLM) y guardo la salida como Markdown.\n\nEn el fondo, la tarea ejecuta algo como:\n\n```bash\ncat output.txt | LLM -t readme-gen > README.md\n# o\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nPor ejemplo, para mejorar la cobertura de pruebas:\n\n#### Claude\n\n- voy al directorio del c√≥digo  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- copio el contexto: `mise run LLM:copy_buffer_bundle`  \n- pego eso en Claude junto con el primer ‚Äúissue‚Äù de pruebas faltantes  \n- copio el c√≥digo generado al IDE  \n- ejecuto pruebas  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  \n\n#### Aider\n\n- voy al directorio del c√≥digo  \n- abro Aider (siempre en una rama nueva)  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- pego el primer ‚Äúissue‚Äù en Aider  \n- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™  \n- ejecuto pruebas  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  \n\nEsta metodolog√≠a es muy √∫til para mejorar gradualmente cualquier base de c√≥digo, sin importar el tama√±o de la tarea.\n\n### Magia de prompts\n\nEstos hacks son mano de santo para volver un proyecto m√°s robusto.\n\n#### Revisi√≥n de c√≥digo\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generaci√≥n de issues de GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts son bastante viejos y destartalados (‚Äúboomer prompts‚Äù, si se permite). Si tienes ideas para mejorarlos, av√≠same.\n\n## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nCuando explico este proceso digo: ¬´Hay que llevar el control de forma agresiva porque es muy f√°cil adelantarte a ti mismo¬ª.\n\nPor alguna raz√≥n digo mucho **over my skis** cuando hablo de los LLM. Quiz√° porque es como esquiar en polvo perfecto y, de pronto, ¬´¬°¬øQU√â CARAJO EST√Å PASANDO?!¬ª, te pierdes y caes por un precipicio.\n\nUsar un **paso de planificaci√≥n** (como en el proceso *greenfield*) ayuda: al menos tienes un documento para comprobar. Tambi√©n creo que las pruebas son clave, sobre todo si codificas ‚Äúa lo loco‚Äù con Aider: mantienen todo ajustado.\n\nAun as√≠, a menudo sigo sinti√©ndome **over my skis**. Un descanso r√°pido o un paseo corto suele ayudar. Al fin y al cabo es el proceso normal de resolver problemas, solo que a velocidad de v√©rtigo.\n\n> A veces pedimos al LLM que incluya cosas rid√≠culas en nuestro c√≥digo no tan rid√≠culo. Por ejemplo, le pedimos que creara un archivo de *lore* y luego lo referenciara en la interfaz de usuario de una herramienta CLI de Python. De repente tienes *lore*, interfaces inestables‚Ä¶ **Todo ello, parad√≥jicamente, solo para** gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el l√≠mite.\n\n## Estoy tan solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMi mayor queja es que estos flujos son, b√°sicamente, _single-player_. He pasado a√±os programando solo, en pareja y en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en equipo: los bots chocan, las fusiones son horribles, el contexto se complica.\n\nQuiero que alguien convierta la programaci√≥n con LLM en un juego multijugador. ¬°Hay una oportunidad enorme! **GET TO WORK!**\n\n## ‚¥µ Tiempo ‚¥µ\n\nToda esta generaci√≥n de c√≥digo ha disparado la cantidad de trabajo que puedo producir. Pero hay un efecto raro: mucho *tiempo muerto* mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nPara aprovechar la espera:\n\n- inicio la lluvia de ideas de otro proyecto  \n- pongo vinilos  \n- juego a ¬´Cookie Clicker¬ª  \n- charlo con amigos‚Ä¶ y con robots  \n\nHack, hack, hack. No recuerdo otra √©poca en la que fuera tan productivo.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nMuchos colegas dicen: ¬´Los LLM apestan; fallan en todo¬ª. No comparto esa opini√≥n, pero el escepticismo es sano. Hay razones de sobra para odiar la IA. Mi miedo principal es el consumo energ√©tico y el impacto ambiental. Pero‚Ä¶ el c√≥digo debe fluir. *Suspiro.* ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\nSi quieres saber m√°s sin convertirte en c√≠borg programador, te recomiendo el libro de Ethan Mollick: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/). Explica los beneficios sin rollo tecno-bro y me ha permitido charlas muy matizadas con amigos. Muy recomendado.\n\nSi eres esc√©ptico pero curioso, escr√≠beme: te ense√±o c√≥mo usamos los LLM y quiz√° construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar esta entrada y sugerir cambios. ¬°Lo aprecio!_\n\nPlease critique this translation mercilessly and provide detailed feedback on what needs to be improved.\nFormat your critique as a structured list of issues, organized by severity and category.\nInclude specific suggestions for how to fix each issue.",
      "response": "CRITICAL ISSUES  \n1. Number inconsistency for ‚ÄúLLM‚Äù  \n   ‚Ä¢ ST: ‚ÄúLLMs‚Äù (plural) appears dozens of times.  \n   ‚Ä¢ TT oscillates between ‚ÄúLLM‚Äù (sing.) and ‚ÄúLLM s‚Äù ‚Üí loss of meaning (it is not one but several models).  \n   ‚Ä¢ Fix: usar siempre ‚ÄúLLM‚Äù como sigla invariable acompa√±ada de plural (‚Äúlos LLM‚Äù) o traducir ‚Äúmodelos de lenguaje (LLM)‚Äù. Mantener la misma forma a lo largo del texto.  \n\n2. Mistranslation of ‚ÄúDiscrete loops‚Äù  \n   ‚Ä¢ ST idea: ciclos claramente separados, independientes.  \n   ‚Ä¢ TT: ‚ÄúBucles separados‚Äù. Se pierde el matiz de ‚Äúdiscretos‚Äù (= independientes, autocontenidos); en dev-argot ‚Äúbucles discretos‚Äù se entiende mejor.  \n   ‚Ä¢ Fix: ‚ÄúBucles discretos‚Äù o ‚Äúbucles independientes‚Äù.  \n\n3. ‚Äúplanear un plan‚Äù  \n   ‚Ä¢ ST juega con la redundancia ‚Äúplan a plan‚Äù (= planificar el plan).  \n   ‚Ä¢ TT lo vuelve literal pero suena torpe en espa√±ol; adem√°s ‚Äúplanear un plan‚Äù es pleonasmo poco natural.  \n   ‚Ä¢ Fix: ‚Äúplanificar el plan‚Äù o ‚Äúelaborar el plan‚Äù y, si se quiere mantener la broma, a√±adir ‚Äú(s√≠, planificar el plan)‚Äù.  \n\n4. Singular ‚ÄúLa prueba es a√∫n m√°s autom√°tica‚Äù  \n   ‚Ä¢ ST: ‚ÄúTesting is nice with aider, because it can be even more hands off‚Ä¶‚Äù (= las pruebas).  \n   ‚Ä¢ TT usa singular ‚ÄúLa prueba‚Äù. Se altera el sentido t√©cnico de ‚Äútesting‚Äù.  \n   ‚Ä¢ Fix: ‚ÄúLas pruebas son a√∫n m√°s autom√°ticas‚Äù o ‚ÄúEl testing es‚Ä¶‚Äù.  \n\n5. Cambio de encabezado ‚ÄúBrownfield (proyectos existentes)‚Äù  \n   ‚Ä¢ ST: ‚ÄúNon-greenfield: Iteration, incrementally‚Äù. TT introduce ‚ÄúBrownfield‚Äù (t√©rmino no mencionado en el ST). Es una decisi√≥n interpretativa, pero introduce terminolog√≠a extra y puede desorientar.  \n   ‚Ä¢ Fix: ‚ÄúNo-greenfield: iteraci√≥n incremental (sobre c√≥digo existente)‚Äù.  \n\n6. Omisi√≥n de matiz en ‚Äúknee-deep in AI dev‚Äù  \n   ‚Ä¢ ST enfatiza inmersi√≥n total. TT simplifica a ‚Äúmetida en IA‚Äù. Se pierde la idea de ‚Äúhasta las rodillas‚Äù.  \n   ‚Ä¢ Fix: ‚Äú‚Ä¶quienes estamos hasta las rodillas en desarrollo con IA‚Ä¶‚Äù.  \n\nMAJOR ISSUES (sentido intacto pero suenan antinaturales o pierden tono)  \nA. Tono coloquial/informal ingl√©s ‚â† espa√±ol  \n   ‚Ä¢ Ej.: ‚ÄúWild tbh.‚Äù ‚Üí TT ‚ÄúUna locura, la verdad.‚Äù bien; pero en otros lugares se pierde el coloquialismo (‚Äúpretty solid‚Äù ‚Üí ‚Äúbastante s√≥lida‚Äù OK, ‚Äúit largely works‚Äù ‚Üí ‚Äúcumple‚Äù ser√≠a mejor que ‚Äúfunciona bastante bien‚Äù).  \n   ‚Ä¢ Sugerencia: reforzar la voz cercana del original con giros equivalentes (‚Äúest√° bastante bien‚Äù, ‚Äúfunciona de maravilla‚Äù, etc.).  \n\nB. Anglicismos no motivados o sin marcar  \n   ‚Äì ‚Äúworkflow‚Äù, ‚Äúprompt plan‚Äù, ‚Äúdeep research‚Äù, ‚Äúcookie clicker‚Äù, ‚Äúhack‚Äù se dejan sin cursiva ni comillas.  \n   ‚Äì En entornos dev es normal, pero conviene marcar la primera aparici√≥n y, si se repite mucho, espa√±olizar (‚Äúflujo de trabajo, *workflow*‚Äù).  \n\nC. Consistencia terminol√≥gica  \n   ‚Äì ‚Äúcodegen‚Äù vs ‚Äúgeneraci√≥n de c√≥digo‚Äù mezclados.  \n   ‚Äì ‚Äútesting‚Äù vs ‚Äúpruebas‚Äù/‚Äútests‚Äù.  \n   ‚Äì Unificar: ‚Äúgeneraci√≥n de c√≥digo (*codegen*)‚Äù, ‚Äúpruebas‚Äù, etc.  \n\nD. Traducci√≥n de sarcasmo y humor  \n   ‚Ä¢ ‚Äúterrible internet bad places‚Äù ‚Üí TT ‚Äúpeores rincones de Internet‚Äù pierde la iron√≠a de ‚Äúterrible‚Äù+‚Äúbad‚Äù repetido. Propuesta: ‚Äúlos m√°s infames y terribles rincones de Internet‚Äù.  \n   ‚Ä¢ ‚Äúboomer prompts‚Äù ‚Üí TT lo deja igual, pero ‚Äúprompts de boomer‚Äù funcionar√≠a mejor en espa√±ol.  \n\nE. Conservaci√≥n de expresiones en ingl√©s sin glosa  \n   ‚Ä¢ ‚Äúover my skis‚Äù se deja tal cual pero se explica despu√©s. Podr√≠a a√±adirse primera aparici√≥n ‚Äú(pasado de vueltas, *over my skis*)‚Äù.  \n\nMINOR / STYLISTIC  \n1. Puntuaci√≥n  \n   ‚Ä¢ Varias elipsis ‚Äú‚Ä¶‚Äù con espacios inconsistentes; unificar (‚Äú‚Ä¶‚Äù sin espacio antes).  \n   ‚Ä¢ Uso de may√∫scula tras punto y coma en ‚Äútl;dr: Lluvia de ideas‚Ä¶‚Äù; ‚Äútl;dr;‚Äù original lleva dos ‚Äú;‚Äù (error de origen), puede aclararse.  \n\n2. Cohesi√≥n de listas  \n   ‚Ä¢ Algunas vi√±etas pierden ‚Äú;‚Äù finales (‚Äúrun code, run tests, etc‚Äù). En castellano conviene cerrar con punto y coma o punto final.  \n\n3. Otro detalle l√©xico  \n   ‚Ä¢ ‚ÄúHaterade‚Äù ‚Äì TT crea secci√≥n ‚ÄúHaterade‚Äù sin traducir. Se puede mantener como meme, pero a√±adir ‚Äú(odio a la IA)‚Äù mejora comprensi√≥n.  \n   ‚Ä¢ ‚Äúraw claude‚Äù ‚Üí ‚ÄúClaude puro‚Äù o ‚ÄúClaude sin envoltorio‚Äù en vez de ‚ÄúClaude ‚Äòen crudo‚Äô‚Äù (calco culinario).  \n\nGRAMMAR / AGREEMENT  \n‚Äì ‚ÄúEsto NO es un greenfield.‚Äù ‚Üí Falta art√≠culo: ‚ÄúEsto NO es un *greenfield*.‚Äù  \n‚Äì ‚ÄúMi lista de hacks pendientes est√° vac√≠a porque lo he construido todo.‚Äù ‚Üí concordancia m√°s natural: ‚Äúporque ya constru√≠ todo‚Äù.  \n‚Äì ‚ÄúEl modelo devolver√° un plan de prompts‚Ä¶‚Äù ‚Üí plural inconsistente despu√©s (‚ÄúLos guardo‚Ä¶‚Äù).  \n\nMISSING / ADDED CONTENT  \nNo se detectaron p√°rrafos omitidos. S√≠ se a√±adi√≥ el t√©rmino ‚ÄúBrownfield‚Äù que no estaba en el ST (ver CRITICAL-5).  \n\nMACHINE-LIKE TRACES  \n‚Äì Calcos literales: ‚Äúrinse repeat‚Äù ‚Üí ‚Äúy vuelta a empezar‚Äù (bien), pero ‚Äúrinse repeat ‚ú©‚Äù se conserva tal cual m√°s abajo. Podr√≠a normalizarse: ‚Äúy a repetir‚Äù.  \n‚Äì ‚ÄúMagia de prompts‚Äù: buen t√≠tulo, pero ‚Äúestos hacks son mano de santo‚Äù mezcla registro coloquial con frase hecha poco habitual para devs; se siente insertado.  \n\nRECOMMENDED GLOBAL FIXES  \n1. Elegir y mantener un glosario: LLM (pl.), *codegen*, *workflow*, *prompt*, greenfield/no-greenfield.  \n2. Revisar todas las ocurrencias de ‚ÄúLLM/LLMs‚Äù y ajustar n√∫mero.  \n3. Reescribir t√≠tulo y primera frase para sonar natural: ‚ÄúTormenta de ideas ‚Üí especificaci√≥n, luego planificar, despu√©s ejecutar con generaci√≥n de c√≥digo mediante LLM. Bucles discretos y‚Ä¶ magia.‚Äù  \n4. Sustituir anglicismos innecesarios o marcarlos la primera vez.  \n5. Reforzar coloquialismo y humor con equivalentes espa√±oles (interjecciones, muletillas).  \n6. Pases de correcci√≥n de estilo: concordancia, tildes, comas antes de ‚Äúpero‚Äù, etc.",
      "usage": {
        "prompt_tokens": 9447,
        "completion_tokens": 1545,
        "total_tokens": 10992
      },
      "streaming": true
    },
    "feedback": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "You are a master translator and editor specializing in spanish.\nYour task is to improve a translation based on detailed critique feedback.\n\n1. Carefully read the original text, current translation, and the critique feedback\n2. Address ALL issues identified in the critique\n3. Apply the specific suggestions for improvement\n4. Ensure the translation is accurate, natural-sounding, and faithful to the original\n5. Preserve all formatting, markdown, and structure of the original text\n6. Make sure the final text reads as if it were originally written in spanish\n\nDo not ignore any of the critique points. Every issue identified must be addressed in your improved version.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr: Lluvia de ideas para la especificaci√≥n (spec), luego **planear un plan**, despu√©s ejecutar con generaci√≥n autom√°tica de c√≥digo (*codegen*) mediante los LLM. **Bucles separados.** Luego‚Ä¶ magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nHe estado construyendo **much√≠simos** productos peque√±os con LLM. Ha sido divertido y √∫til, pero hay trampas que pueden hacerte perder much√≠simo tiempo. Hace un tiempo un amigo me pregunt√≥ c√≥mo estaba usando los LLM para escribir software. Pens√©: ¬´¬°Madre m√≠a! ¬øCu√°nto tiempo tienes?¬ª y as√≠ naci√≥ esta entrada.\n\n(P. D.: si odias la IA, salta al final).\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque parecido, con matices aqu√≠ y all√°.\n\nAqu√≠ va mi flujo de trabajo. Se basa en mi experiencia, en charlas con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en un pu√±ado de buenas pr√°cticas que circulan por los peores rincones de Internet ([uno](https://news.ycombinator.com/) y [otro](https://twitter.com)).\n\nEsto funciona bien **AHORA**; puede que en dos semanas deje de servir‚Ä¶ o que funcione el doble de bien. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Vamos all√°\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Siempre desconf√≠o de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel-robot juggalo programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mis proyectos suelen caer en uno de estos dos escenarios:\n\n- C√≥digo nuevo desde cero (*greenfield*)\n- Base de c√≥digo heredada (pero moderna)\n\nTe mostrar√© mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona bien cuando parto de cero. Aporta una planificaci√≥n y documentaci√≥n s√≥lidas y permite avanzar f√°cilmente en pasos peque√±os.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"T√©cnicamente hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegar√° a una conclusi√≥n natural):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nObtendr√°s una especificaci√≥n bastante s√≥lida que podr√°s pasar al paso de planificaci√≥n. Suelo guardarla como `spec.md` en el repositorio.\n\n> Esa especificaci√≥n sirve para muchas cosas. Aqu√≠ la usamos para generaci√≥n de c√≥digo, pero tambi√©n la he empleado para pedirle a un modelo de razonamiento que busque puntos d√©biles (¬°hay que ir m√°s profundo!), para generar un white paper o un modelo de negocio. Incluso puedes meterla en una investigaci√≥n profunda y recibir un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificaci√≥n\n\nPasa la spec a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el prompt con TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el prompt sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nEl modelo devolver√° un plan de prompts que podr√°s ejecutar con Aider, Cursor, etc. Yo lo guardo como `prompt_plan.md` en el repositorio.\n\nDespu√©s le pido una lista de comprobaci√≥n:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGu√°rdalo como `todo.md`. Tu herramienta de generaci√≥n de c√≥digo deber√≠a ir marcando esta lista para mantener el estado entre sesiones.\n\n#### ¬°Plan listo!\n\nCon esto tienes un plan robusto y documentaci√≥n clara para construir tu proyecto.\n\nTodo el proceso lleva, como mucho, **15 minutos**. Una locura, la verdad.\n\n### Paso 3: Ejecuci√≥n\n\nHay much√≠simas opciones; el √©xito depende de lo bien que sali√≥ el Paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)‚Ä¶ Funciona bien con todas las que he probado y, seguramente, con cualquier otra herramienta de *codegen*.\n\nAun as√≠, prefiero **Claude ‚Äúen crudo‚Äù** y Aider.\n\n### Claude\n\nB√°sicamente hago _pair programming_ con [Claude.ai](https://claude.ai) pegando cada instrucci√≥n de forma iterativa. Funciona bastante bien: el ida y vuelta puede ser pesado, pero cumple.\n\nYo me encargo del c√≥digo base inicial y de que las herramientas est√©n configuradas. Esto da cierta libertad y gu√≠a al principio. Claude tiende a escupir c√≥digo React a la m√≠nima; contar con una base s√≥lida en el lenguaje y estilo de tu elecci√≥n ayuda mucho.\n\nCuando las cosas se atascan, uso [Repomix](https://github.com/yamadashy/repomix) (una herramienta para empaquetar repositorios) para iterar.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- pego la instrucci√≥n en Claude  \n- copio el c√≥digo al IDE  \n- ejecuto el c√≥digo y la suite de pruebas  \n- ‚Ä¶  \n- si funciona, paso a la siguiente instrucci√≥n  \n- si no, paso la base de c√≥digo a Claude con Repomix para depurar  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del Paso 2: avanzo much√≠simo con muy poco esfuerzo.\n\nEl flujo es casi id√©ntico, pero pegando las instrucciones en Aider.\n\nAider ‚Äúsimplemente lo hace‚Äù y yo me pongo a jugar al juego ¬´Cookie Clicker¬ª.\n\n> Aider publica un benchmarking excelente de modelos nuevos en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Recurso brutal para ver qu√© tan efectivos son los modelos.\n\nLa prueba es a√∫n m√°s autom√°tica: Aider ejecuta la suite de pruebas y depura por ti.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.)  \n- inicio Aider (procura estar siempre en una rama nueva)  \n- pego la instrucci√≥n  \n- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™  \n- Aider ejecuta pruebas o corro la app para verificar  \n- si funciona, siguiente instrucci√≥n  \n- si no, sesi√≥n de preguntas y respuestas con Aider hasta arreglar  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Resultados\n\nHe construido scripts, apps de Expo, herramientas CLI en Rust, etc., usando este m√©todo. Funciona en distintos lenguajes y contextos. La verdad, me encanta.\n\nSi tienes un proyecto (grande o peque√±o) aparcado, prueba esto: te sorprender√° lo lejos que avanzas en poco tiempo.\n\nMi lista de hacks pendientes est√° vac√≠a porque lo he construido todo. Pienso ideas nuevas y las tacho mientras veo una peli. Por primera vez en a√±os estoy jugando con lenguajes y herramientas nuevas, y eso ampl√≠a mi perspectiva como programador.\n\n## Brownfield (proyectos existentes): iteraci√≥n incremental\n\nA veces no partes de cero y toca mejorar o a√±adir funcionalidades a una base de c√≥digo existente.\n\n{{< image src=\"brownfield.jpg\" alt=\"Brownfield (campo marr√≥n)\" caption=\"Esto NO es un greenfield. Foto aleatoria de la c√°mara de mi abuelo ‚Äî Uganda, a√±os 60.\" >}}\n\nPara esto uso un m√©todo parecido, pero menos de ‚Äúplanificaci√≥n global‚Äù: planifico por tarea, no por proyecto.\n\n### Obtener contexto\n\nCada persona metida en IA tiene su herramienta favorita para empaquetar el c√≥digo y pasarlo eficazmente al LLM.\n\nYo utilizo la herramienta Repomix y un conjunto de tareas en `~/.config/mise/config.toml` (ver [reglas de mise](https://mise.jdx.dev/)):\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de c√≥digo. Si se pasa de tokens, ajusto el comando para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empaquetar el c√≥digo y, mientras genere un `output.txt`, mis tareas LLM siguen funcionando. Suelo sobreescribir el paso de Repomix para incluir patrones de ignore m√°s amplios o usar una herramienta m√°s eficaz seg√∫n el caso.\n\nLuego paso `output.txt` al comando [LLM](https://github.com/simonw/LLM) y guardo la salida como Markdown.\n\nEn el fondo, la tarea ejecuta algo como:\n\n```bash\ncat output.txt | LLM -t readme-gen > README.md\n# o\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nPor ejemplo, para mejorar la cobertura de pruebas:\n\n#### Claude\n\n- voy al directorio del c√≥digo  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- copio el contexto: `mise run LLM:copy_buffer_bundle`  \n- pego eso en Claude junto con el primer ‚Äúissue‚Äù de pruebas faltantes  \n- copio el c√≥digo generado al IDE  \n- ejecuto pruebas  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  \n\n#### Aider\n\n- voy al directorio del c√≥digo  \n- abro Aider (siempre en una rama nueva)  \n- `mise run LLM:generate_missing_tests`  \n- reviso `missing-tests.md`  \n- pego el primer ‚Äúissue‚Äù en Aider  \n- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™  \n- ejecuto pruebas  \n- y vuelta a empezar ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  \n\nEsta metodolog√≠a es muy √∫til para mejorar gradualmente cualquier base de c√≥digo, sin importar el tama√±o de la tarea.\n\n### Magia de prompts\n\nEstos hacks son mano de santo para volver un proyecto m√°s robusto.\n\n#### Revisi√≥n de c√≥digo\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generaci√≥n de issues de GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos prompts son bastante viejos y destartalados (‚Äúboomer prompts‚Äù, si se permite). Si tienes ideas para mejorarlos, av√≠same.\n\n## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nCuando explico este proceso digo: ¬´Hay que llevar el control de forma agresiva porque es muy f√°cil adelantarte a ti mismo¬ª.\n\nPor alguna raz√≥n digo mucho **over my skis** cuando hablo de los LLM. Quiz√° porque es como esquiar en polvo perfecto y, de pronto, ¬´¬°¬øQU√â CARAJO EST√Å PASANDO?!¬ª, te pierdes y caes por un precipicio.\n\nUsar un **paso de planificaci√≥n** (como en el proceso *greenfield*) ayuda: al menos tienes un documento para comprobar. Tambi√©n creo que las pruebas son clave, sobre todo si codificas ‚Äúa lo loco‚Äù con Aider: mantienen todo ajustado.\n\nAun as√≠, a menudo sigo sinti√©ndome **over my skis**. Un descanso r√°pido o un paseo corto suele ayudar. Al fin y al cabo es el proceso normal de resolver problemas, solo que a velocidad de v√©rtigo.\n\n> A veces pedimos al LLM que incluya cosas rid√≠culas en nuestro c√≥digo no tan rid√≠culo. Por ejemplo, le pedimos que creara un archivo de *lore* y luego lo referenciara en la interfaz de usuario de una herramienta CLI de Python. De repente tienes *lore*, interfaces inestables‚Ä¶ **Todo ello, parad√≥jicamente, solo para** gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el l√≠mite.\n\n## Estoy tan solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMi mayor queja es que estos flujos son, b√°sicamente, _single-player_. He pasado a√±os programando solo, en pareja y en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en equipo: los bots chocan, las fusiones son horribles, el contexto se complica.\n\nQuiero que alguien convierta la programaci√≥n con LLM en un juego multijugador. ¬°Hay una oportunidad enorme! **GET TO WORK!**\n\n## ‚¥µ Tiempo ‚¥µ\n\nToda esta generaci√≥n de c√≥digo ha disparado la cantidad de trabajo que puedo producir. Pero hay un efecto raro: mucho *tiempo muerto* mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Imprimiendo\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nPara aprovechar la espera:\n\n- inicio la lluvia de ideas de otro proyecto  \n- pongo vinilos  \n- juego a ¬´Cookie Clicker¬ª  \n- charlo con amigos‚Ä¶ y con robots  \n\nHack, hack, hack. No recuerdo otra √©poca en la que fuera tan productivo.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nMuchos colegas dicen: ¬´Los LLM apestan; fallan en todo¬ª. No comparto esa opini√≥n, pero el escepticismo es sano. Hay razones de sobra para odiar la IA. Mi miedo principal es el consumo energ√©tico y el impacto ambiental. Pero‚Ä¶ el c√≥digo debe fluir. *Suspiro.* ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\nSi quieres saber m√°s sin convertirte en c√≠borg programador, te recomiendo el libro de Ethan Mollick: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/). Explica los beneficios sin rollo tecno-bro y me ha permitido charlas muy matizadas con amigos. Muy recomendado.\n\nSi eres esc√©ptico pero curioso, escr√≠beme: te ense√±o c√≥mo usamos los LLM y quiz√° construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar esta entrada y sugerir cambios. ¬°Lo aprecio!_\n\n# CRITIQUE FEEDBACK\nCRITICAL ISSUES  \n1. Number inconsistency for ‚ÄúLLM‚Äù  \n   ‚Ä¢ ST: ‚ÄúLLMs‚Äù (plural) appears dozens of times.  \n   ‚Ä¢ TT oscillates between ‚ÄúLLM‚Äù (sing.) and ‚ÄúLLM s‚Äù ‚Üí loss of meaning (it is not one but several models).  \n   ‚Ä¢ Fix: usar siempre ‚ÄúLLM‚Äù como sigla invariable acompa√±ada de plural (‚Äúlos LLM‚Äù) o traducir ‚Äúmodelos de lenguaje (LLM)‚Äù. Mantener la misma forma a lo largo del texto.  \n\n2. Mistranslation of ‚ÄúDiscrete loops‚Äù  \n   ‚Ä¢ ST idea: ciclos claramente separados, independientes.  \n   ‚Ä¢ TT: ‚ÄúBucles separados‚Äù. Se pierde el matiz de ‚Äúdiscretos‚Äù (= independientes, autocontenidos); en dev-argot ‚Äúbucles discretos‚Äù se entiende mejor.  \n   ‚Ä¢ Fix: ‚ÄúBucles discretos‚Äù o ‚Äúbucles independientes‚Äù.  \n\n3. ‚Äúplanear un plan‚Äù  \n   ‚Ä¢ ST juega con la redundancia ‚Äúplan a plan‚Äù (= planificar el plan).  \n   ‚Ä¢ TT lo vuelve literal pero suena torpe en espa√±ol; adem√°s ‚Äúplanear un plan‚Äù es pleonasmo poco natural.  \n   ‚Ä¢ Fix: ‚Äúplanificar el plan‚Äù o ‚Äúelaborar el plan‚Äù y, si se quiere mantener la broma, a√±adir ‚Äú(s√≠, planificar el plan)‚Äù.  \n\n4. Singular ‚ÄúLa prueba es a√∫n m√°s autom√°tica‚Äù  \n   ‚Ä¢ ST: ‚ÄúTesting is nice with aider, because it can be even more hands off‚Ä¶‚Äù (= las pruebas).  \n   ‚Ä¢ TT usa singular ‚ÄúLa prueba‚Äù. Se altera el sentido t√©cnico de ‚Äútesting‚Äù.  \n   ‚Ä¢ Fix: ‚ÄúLas pruebas son a√∫n m√°s autom√°ticas‚Äù o ‚ÄúEl testing es‚Ä¶‚Äù.  \n\n5. Cambio de encabezado ‚ÄúBrownfield (proyectos existentes)‚Äù  \n   ‚Ä¢ ST: ‚ÄúNon-greenfield: Iteration, incrementally‚Äù. TT introduce ‚ÄúBrownfield‚Äù (t√©rmino no mencionado en el ST). Es una decisi√≥n interpretativa, pero introduce terminolog√≠a extra y puede desorientar.  \n   ‚Ä¢ Fix: ‚ÄúNo-greenfield: iteraci√≥n incremental (sobre c√≥digo existente)‚Äù.  \n\n6. Omisi√≥n de matiz en ‚Äúknee-deep in AI dev‚Äù  \n   ‚Ä¢ ST enfatiza inmersi√≥n total. TT simplifica a ‚Äúmetida en IA‚Äù. Se pierde la idea de ‚Äúhasta las rodillas‚Äù.  \n   ‚Ä¢ Fix: ‚Äú‚Ä¶quienes estamos hasta las rodillas en desarrollo con IA‚Ä¶‚Äù.  \n\nMAJOR ISSUES (sentido intacto pero suenan antinaturales o pierden tono)  \nA. Tono coloquial/informal ingl√©s ‚â† espa√±ol  \n   ‚Ä¢ Ej.: ‚ÄúWild tbh.‚Äù ‚Üí TT ‚ÄúUna locura, la verdad.‚Äù bien; pero en otros lugares se pierde el coloquialismo (‚Äúpretty solid‚Äù ‚Üí ‚Äúbastante s√≥lida‚Äù OK, ‚Äúit largely works‚Äù ‚Üí ‚Äúcumple‚Äù ser√≠a mejor que ‚Äúfunciona bastante bien‚Äù).  \n   ‚Ä¢ Sugerencia: reforzar la voz cercana del original con giros equivalentes (‚Äúest√° bastante bien‚Äù, ‚Äúfunciona de maravilla‚Äù, etc.).  \n\nB. Anglicismos no motivados o sin marcar  \n   ‚Äì ‚Äúworkflow‚Äù, ‚Äúprompt plan‚Äù, ‚Äúdeep research‚Äù, ‚Äúcookie clicker‚Äù, ‚Äúhack‚Äù se dejan sin cursiva ni comillas.  \n   ‚Äì En entornos dev es normal, pero conviene marcar la primera aparici√≥n y, si se repite mucho, espa√±olizar (‚Äúflujo de trabajo, *workflow*‚Äù).  \n\nC. Consistencia terminol√≥gica  \n   ‚Äì ‚Äúcodegen‚Äù vs ‚Äúgeneraci√≥n de c√≥digo‚Äù mezclados.  \n   ‚Äì ‚Äútesting‚Äù vs ‚Äúpruebas‚Äù/‚Äútests‚Äù.  \n   ‚Äì Unificar: ‚Äúgeneraci√≥n de c√≥digo (*codegen*)‚Äù, ‚Äúpruebas‚Äù, etc.  \n\nD. Traducci√≥n de sarcasmo y humor  \n   ‚Ä¢ ‚Äúterrible internet bad places‚Äù ‚Üí TT ‚Äúpeores rincones de Internet‚Äù pierde la iron√≠a de ‚Äúterrible‚Äù+‚Äúbad‚Äù repetido. Propuesta: ‚Äúlos m√°s infames y terribles rincones de Internet‚Äù.  \n   ‚Ä¢ ‚Äúboomer prompts‚Äù ‚Üí TT lo deja igual, pero ‚Äúprompts de boomer‚Äù funcionar√≠a mejor en espa√±ol.  \n\nE. Conservaci√≥n de expresiones en ingl√©s sin glosa  \n   ‚Ä¢ ‚Äúover my skis‚Äù se deja tal cual pero se explica despu√©s. Podr√≠a a√±adirse primera aparici√≥n ‚Äú(pasado de vueltas, *over my skis*)‚Äù.  \n\nMINOR / STYLISTIC  \n1. Puntuaci√≥n  \n   ‚Ä¢ Varias elipsis ‚Äú‚Ä¶‚Äù con espacios inconsistentes; unificar (‚Äú‚Ä¶‚Äù sin espacio antes).  \n   ‚Ä¢ Uso de may√∫scula tras punto y coma en ‚Äútl;dr: Lluvia de ideas‚Ä¶‚Äù; ‚Äútl;dr;‚Äù original lleva dos ‚Äú;‚Äù (error de origen), puede aclararse.  \n\n2. Cohesi√≥n de listas  \n   ‚Ä¢ Algunas vi√±etas pierden ‚Äú;‚Äù finales (‚Äúrun code, run tests, etc‚Äù). En castellano conviene cerrar con punto y coma o punto final.  \n\n3. Otro detalle l√©xico  \n   ‚Ä¢ ‚ÄúHaterade‚Äù ‚Äì TT crea secci√≥n ‚ÄúHaterade‚Äù sin traducir. Se puede mantener como meme, pero a√±adir ‚Äú(odio a la IA)‚Äù mejora comprensi√≥n.  \n   ‚Ä¢ ‚Äúraw claude‚Äù ‚Üí ‚ÄúClaude puro‚Äù o ‚ÄúClaude sin envoltorio‚Äù en vez de ‚ÄúClaude ‚Äòen crudo‚Äô‚Äù (calco culinario).  \n\nGRAMMAR / AGREEMENT  \n‚Äì ‚ÄúEsto NO es un greenfield.‚Äù ‚Üí Falta art√≠culo: ‚ÄúEsto NO es un *greenfield*.‚Äù  \n‚Äì ‚ÄúMi lista de hacks pendientes est√° vac√≠a porque lo he construido todo.‚Äù ‚Üí concordancia m√°s natural: ‚Äúporque ya constru√≠ todo‚Äù.  \n‚Äì ‚ÄúEl modelo devolver√° un plan de prompts‚Ä¶‚Äù ‚Üí plural inconsistente despu√©s (‚ÄúLos guardo‚Ä¶‚Äù).  \n\nMISSING / ADDED CONTENT  \nNo se detectaron p√°rrafos omitidos. S√≠ se a√±adi√≥ el t√©rmino ‚ÄúBrownfield‚Äù que no estaba en el ST (ver CRITICAL-5).  \n\nMACHINE-LIKE TRACES  \n‚Äì Calcos literales: ‚Äúrinse repeat‚Äù ‚Üí ‚Äúy vuelta a empezar‚Äù (bien), pero ‚Äúrinse repeat ‚ú©‚Äù se conserva tal cual m√°s abajo. Podr√≠a normalizarse: ‚Äúy a repetir‚Äù.  \n‚Äì ‚ÄúMagia de prompts‚Äù: buen t√≠tulo, pero ‚Äúestos hacks son mano de santo‚Äù mezcla registro coloquial con frase hecha poco habitual para devs; se siente insertado.  \n\nRECOMMENDED GLOBAL FIXES  \n1. Elegir y mantener un glosario: LLM (pl.), *codegen*, *workflow*, *prompt*, greenfield/no-greenfield.  \n2. Revisar todas las ocurrencias de ‚ÄúLLM/LLMs‚Äù y ajustar n√∫mero.  \n3. Reescribir t√≠tulo y primera frase para sonar natural: ‚ÄúTormenta de ideas ‚Üí especificaci√≥n, luego planificar, despu√©s ejecutar con generaci√≥n de c√≥digo mediante LLM. Bucles discretos y‚Ä¶ magia.‚Äù  \n4. Sustituir anglicismos innecesarios o marcarlos la primera vez.  \n5. Reforzar coloquialismo y humor con equivalentes espa√±oles (interjecciones, muletillas).  \n6. Pases de correcci√≥n de estilo: concordancia, tildes, comas antes de ‚Äúpero‚Äù, etc.\n\nPlease address ALL issues identified in the critique and provide an improved translation.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr: Tormenta de ideas para la especificaci√≥n (*spec*), luego planificar el plan (s√≠, planificar el plan), despu√©s ejecutar con generaci√≥n de c√≥digo (*codegen*) mediante los LLM. Bucles discretos. Y luego‚Ä¶ magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nHe estado construyendo **much√≠simos** productos peque√±os con los LLM. Ha sido divertido y √∫til, pero hay trampas que pueden hacerte perder much√≠simo tiempo. Hace un tiempo, un amigo me pregunt√≥ c√≥mo estaba usando los LLM para escribir software. Pens√©: ¬´¬°Madre m√≠a! ¬øCu√°nto tiempo tienes?¬ª y as√≠ naci√≥ esta entrada.\n\n(P. D.: si odias la IA, salta al final).\n\nHablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque parecido, con matices aqu√≠ y all√°.\n\nAqu√≠ va mi *workflow* (flujo de trabajo). Se basa en mi experiencia, en charlas con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en un pu√±ado de buenas pr√°cticas compartidas en los m√°s infames y terribles rincones de Internet ([uno](https://news.ycombinator.com/) y [otro](https://twitter.com)).\n\nEsto funciona bien **AHORA**; puede que en dos semanas deje de servir‚Ä¶ o que funcione el doble de bien. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Vamos all√°\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Siempre desconf√≠o de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel-robot *juggalo* programador!\" >}}\n\nHay muchos caminos para desarrollar, pero mis proyectos suelen caer en uno de estos dos escenarios:\n\n- C√≥digo nuevo desde cero (*greenfield*)\n- Base de c√≥digo heredada pero moderna (*non-greenfield*)\n\nTe mostrar√© mi proceso para ambos.\n\n## Greenfield\n\nEl siguiente proceso me funciona de maravilla cuando parto de cero. Aporta una planificaci√≥n y documentaci√≥n s√≥lidas y permite avanzar f√°cilmente en pasos peque√±os.\n\n{{< image src=\"greenfield.jpg\" alt=\"Campo verde\" caption=\"T√©cnicamente, hay un campo verde a la derecha. Leica Q, 14/5/2016\" >}}\n\n### Paso 1: Afinar la idea\n\nUsa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAl final de la lluvia de ideas (llegar√° a una conclusi√≥n natural):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nObtendr√°s una especificaci√≥n bastante s√≥lida que podr√°s pasar al paso de planificaci√≥n. Suelo guardarla como `spec.md` en el repositorio.\n\n> Esa especificaci√≥n sirve para muchas cosas. Aqu√≠ la usamos para generaci√≥n de c√≥digo (*codegen*), pero tambi√©n la he empleado para pedirle a un modelo de razonamiento que busque puntos d√©biles (¬°hay que ir m√°s profundo!), para generar un *white paper* o un modelo de negocio. Incluso puedes lanzarla a una investigaci√≥n exhaustiva y recibir a cambio un documento de apoyo de 10 000 palabras.\n\n### Paso 2: Planificaci√≥n\n\nPasa la *spec* a un modelo de razonamiento (`o1*`, `o3*`, `r1`):\n\n(Este es el *prompt* con TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Este es el *prompt* sin TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nEl modelo devolver√° un plan de *prompts* que podr√°s ejecutar con Aider, Cursor, etc. Yo lo guardo como `prompt_plan.md` en el repositorio.\n\nDespu√©s le pido una lista de comprobaci√≥n:\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nGu√°rdalo como `todo.md`. Tu herramienta de generaci√≥n de c√≥digo deber√≠a ir marcando esta lista para mantener el estado entre sesiones.\n\n#### ¬°Plan listo!\n\nCon esto tienes un plan robusto y documentaci√≥n clara para construir tu proyecto.\n\nTodo el proceso lleva, como mucho, **15 minutos**. Una locura, la verdad.\n\n### Paso 3: Ejecuci√≥n\n\nHay much√≠simas opciones; el √©xito depende de lo bien que sali√≥ el Paso 2.\n\nHe usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)‚Ä¶ Funciona bien con todas las que he probado y, seguramente, con cualquier otra herramienta de generaci√≥n de c√≥digo (*codegen*).\n\nAun as√≠, prefiero **Claude puro** y Aider.\n\n### Claude\n\nB√°sicamente hago *pair programming* con [Claude.ai](https://claude.ai) pegando cada instrucci√≥n de forma iterativa. Funciona bastante bien: el ida y vuelta puede ser pesado, pero cumple.\n\nYo me encargo del c√≥digo base inicial y de que las herramientas est√©n configuradas. Esto da cierta libertad y gu√≠a al principio. Claude tiende a escupir c√≥digo React a la m√≠nima; contar con una base s√≥lida en el lenguaje y estilo de tu elecci√≥n ayuda mucho.\n\nCuando las cosas se atascan, uso [Repomix](https://github.com/yamadashy/repomix) para iterar.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.);\n- pego la instrucci√≥n en Claude;\n- copio el c√≥digo al IDE;\n- ejecuto el c√≥digo y la suite de pruebas;\n- si funciona, paso a la siguiente instrucci√≥n;\n- si no, paso la base de c√≥digo a Claude con Repomix para depurar;\n- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del Paso 2: avanzo much√≠simo con muy poco esfuerzo.\n\nEl flujo es casi id√©ntico, pero pegando las instrucciones en Aider.\n\nAider ¬´simplemente lo hace¬ª y yo me pongo a jugar a [*Cookie Clicker*](https://orteil.dashnet.org/cookieclicker/).\n\n> Aider publica un *benchmark* excelente de modelos nuevos en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Es un recurso brutal para ver qu√© tan efectivos son los modelos.\n\nLas pruebas son a√∫n m√°s autom√°ticas con Aider, porque ejecuta la suite y depura por ti.\n\nFlujo de trabajo:\n\n- preparo el repositorio (`uv init`, `cargo init`, etc.);\n- inicio Aider (procura estar siempre en una rama nueva);\n- pego la instrucci√≥n;\n- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™;\n- Aider ejecuta pruebas o corro la app para verificar;\n- si funciona, siguiente instrucci√≥n;\n- si no, sesi√≥n de preguntas y respuestas con Aider hasta arreglarlo;\n- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Resultados\n\nHe construido scripts, apps de Expo, herramientas CLI en Rust, etc., usando este m√©todo. Funciona en distintos lenguajes y contextos. La verdad, me encanta.\n\nSi tienes un proyecto ‚Äîgrande o peque√±o‚Äî aparcado, prueba esto: te sorprender√° lo lejos que avanzas en poco tiempo.\n\nMi lista de *hacks* pendientes est√° vac√≠a porque ya constru√≠ todo. Pienso ideas nuevas y las tacho mientras veo una peli. Por primera vez en a√±os estoy jugando con lenguajes y herramientas nuevas, y eso ampl√≠a mi perspectiva como programador.\n\n## No-greenfield: iteraci√≥n incremental (sobre c√≥digo existente)\n\nA veces no partes de cero y toca mejorar o a√±adir funcionalidades a una base de c√≥digo existente.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Esto NO es un *greenfield*. Foto aleatoria de la c√°mara de mi abuelo ‚Äî Uganda, a√±os 60.\" >}}\n\nPara esto uso un m√©todo parecido, pero menos de ‚Äúplanificaci√≥n global‚Äù: planifico por tarea, no por proyecto.\n\n### Obtener contexto\n\nQuienes estamos hasta las rodillas en desarrollo con IA solemos tener cada uno nuestra herramienta favorita para empaquetar el c√≥digo y pasarlo eficazmente a los LLM.\n\nYo utilizo [Repomix](https://github.com/yamadashy/repomix) y un conjunto de tareas en `~/.config/mise/config.toml` (ver [reglas de mise](https://mise.jdx.dev/)):\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nGenero un `output.txt` con el contexto de la base de c√≥digo. Si se pasa de tokens, ajusto el comando para ignorar partes irrelevantes.\n\n> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empaquetar el c√≥digo y, mientras genere un `output.txt`, mis tareas LLM siguen funcionando. Suelo sobreescribir el paso de Repomix para incluir patrones de *ignore* m√°s amplios o usar una herramienta m√°s eficaz seg√∫n el caso.\n\nLuego paso `output.txt` al comando [LLM](https://github.com/simonw/LLM) y guardo la salida como Markdown.\n\nEn el fondo, la tarea ejecuta algo como:\n\n```bash\ncat output.txt | LLM -t readme-gen > README.md\n# o\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nPor ejemplo, para mejorar la cobertura de pruebas:\n\n#### Claude\n\n- voy al directorio del c√≥digo;\n- `mise run LLM:generate_missing_tests`;\n- reviso `missing-tests.md`;\n- copio el contexto con `mise run LLM:copy_buffer_bundle`;\n- pego eso en Claude junto con el primer ‚Äúissue‚Äù de pruebas faltantes;\n- copio el c√≥digo generado al IDE;\n- ejecuto pruebas;\n- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  \n\n#### Aider\n\n- voy al directorio del c√≥digo;\n- abro Aider (siempre en una rama nueva);\n- `mise run LLM:generate_missing_tests`;\n- reviso `missing-tests.md`;\n- pego el primer ‚Äúissue‚Äù en Aider;\n- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™;\n- ejecuto pruebas;\n- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  \n\nEsta metodolog√≠a es muy √∫til para mejorar gradualmente cualquier base de c√≥digo, sin importar el tama√±o de la tarea.\n\n### Magia de *prompts*\n\nEstos peque√±os *hacks* van de maravilla para hurgar en el proyecto y hacerlo m√°s robusto.\n\n#### Revisi√≥n de c√≥digo\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Generaci√≥n de issues de GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests faltantes\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nEstos *prompts de boomer* necesitan un repaso. Si tienes ideas para mejorarlos, av√≠same.\n\n## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nCuando explico este proceso digo: ¬´Hay que llevar el control de forma agresiva porque es muy f√°cil adelantarte a ti mismo.¬ª\n\nPor alguna raz√≥n digo mucho *over my skis* (pasado de vueltas) cuando hablo de los LLM. Quiz√° porque es como esquiar en polvo perfecto y, de pronto, ¬´¬°¬øQU√â CARAJO EST√Å PASANDO?!¬ª, te pierdes y caes por un precipicio.\n\nUsar un **paso de planificaci√≥n** (como en el proceso *greenfield*) ayuda: al menos tienes un documento para comprobar. Tambi√©n creo que las pruebas son clave ‚Äîsobre todo si codificas ‚Äúa lo loco‚Äù con Aider‚Äî: mantienen todo ajustado.\n\nAun as√≠, a menudo sigo sinti√©ndome *over my skis*. Un descanso r√°pido o un paseo corto suele ayudar. Al fin y al cabo es el proceso normal de resolver problemas, solo que a velocidad de v√©rtigo.\n\n> A veces pedimos a los LLM que incluyan cosas rid√≠culas en nuestro c√≥digo no tan rid√≠culo. Por ejemplo, le pedimos que creara un archivo de *lore* y luego lo referenciara en la interfaz de usuario de una herramienta CLI de Python. De repente tienes *lore*, interfaces glitchy‚Ä¶ Todo ello, parad√≥jicamente, solo para gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el l√≠mite.\n\n## Estoy tan solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMi mayor queja es que estos flujos son, b√°sicamente, _single-player_. He pasado a√±os programando solo, en pareja y en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en grupo: los bots chocan, las fusiones son horribles, el contexto se complica.\n\nQuiero que alguien convierta la programaci√≥n con LLM en un juego multijugador. ¬°Hay una oportunidad enorme! **GET TO WORK!**\n\n## ‚¥µ Tiempo ‚¥µ\n\nToda esta generaci√≥n de c√≥digo ha disparado la cantidad de trabajo que puedo producir. Pero hay un efecto raro: mucho tiempo muerto mientras el LLM quema tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Lo recuerdo como si fuera ayer\" >}}\n\nPara aprovechar la espera:\n\n- inicio la lluvia de ideas de otro proyecto;\n- pongo vinilos;\n- juego a *Cookie Clicker*;\n- charlo con amigos‚Ä¶ y con robots.\n\nHack, hack, hack. No recuerdo otra √©poca en la que fuera tan productivo.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nMuchos colegas dicen: ¬´Los LLM apestan; fallan en todo¬ª. No comparto esa opini√≥n, pero el escepticismo es sano. Hay razones de sobra para odiar la IA. Mi miedo principal es el consumo energ√©tico y el impacto ambiental. Pero‚Ä¶ el c√≥digo debe fluir. *Suspiro.* ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\nSi quieres saber m√°s sin convertirte en c√≠borg programador, te recomiendo el libro de Ethan Mollick: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/). Explica los beneficios sin rollo *tech-bro* y me ha permitido charlas muy matizadas con amigos. Muy recomendado.\n\nSi eres esc√©ptico pero curioso, escr√≠beme: te ense√±o c√≥mo usamos los LLM y quiz√° construyamos algo juntos.\n\n_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar esta entrada y sugerir cambios. ¬°Lo aprecio!_",
      "usage": {
        "prompt_tokens": 11027,
        "completion_tokens": 4191,
        "total_tokens": 15218
      },
      "streaming": true
    },
    "frontmatter": {
      "model": "o3",
      "target_language": "spanish",
      "system_prompt": "You are a professional translator. Translate the following frontmatter fields to spanish.\nEach field is in the format \"field_name: content\". Translate ONLY the content, not the field names.\nReturn the translated content in the exact same format, preserving all field names.",
      "user_prompt": "title: My LLM codegen workflow atm\n\ndescription: A detailed walkthrough of my current workflow for using LLms to build software, from brainstorming through planning and execution.\n\n",
      "response": "title: Mi flujo de trabajo de generaci√≥n de c√≥digo con LLM en este momento\n\ndescription: Un recorrido detallado de mi flujo de trabajo actual para usar LLMs en la construcci√≥n de software, desde la lluvia de ideas hasta la planificaci√≥n y la ejecuci√≥n.",
      "usage": {
        "prompt_tokens": 86,
        "completion_tokens": 52,
        "total_tokens": 138
      },
      "fields": [
        "title",
        "description"
      ],
      "streaming": true
    },
    "all_critiques": [
      "CRITIQUE OF THE SPANISH TRANSLATION  \n(Organized by severity ‚Üí category ‚Üí concrete issue ‚Üí suggested fix)\n\n====================================================================\nA. CRITICAL : ACCURACY & COMPLETENESS  \n====================================================================\n\nA-1  Paragraph missing (omission)\n     ‚Ä¢ Original: ‚ÄúRegardless, I still do find myself **over my skis** quite a bit.  \n       Sometimes a quick break or short walk will help. In this regard it is a normal\n       problem-solving process, but accelerated to a breakneck speed.‚Äù  \n     ‚Ä¢ Spanish: Entirely absent.  \n     ‚Ä¢ Fix: Re-insert after the ‚Äúwild style Aider‚Äù sentence in the Esqu√≠ section, e.g.  \n       ‚ÄúAun as√≠, a menudo sigo sinti√©ndome ‚Äòover my skis‚Äô. Un descanso r√°pido o un\n       paseo corto suele ayudar. En ese sentido, es el proceso normal de resolver\n       problemas, solo que a una velocidad de v√©rtigo.‚Äù\n\nA-2  Term slightly mistranslated ‚Äì ‚ÄúLegacy modern code‚Äù\n     ‚Ä¢ ‚ÄúC√≥digo existente / legado moderno‚Äù is confusing: legacy vs. modern are\n       opposites.  \n     ‚Ä¢ Suggest: ‚ÄúC√≥digo heredado relativamente reciente‚Äù or simply ‚Äúc√≥digo heredado‚Äù.\n\nA-3  Header mistranslation ‚Äì ‚ÄúNon-greenfield‚Äù\n     ‚Ä¢ ‚ÄúNo-greenfield‚Äù is not idiomatic.  \n     ‚Ä¢ Suggest: ‚ÄúProyectos existentes (brownfield)‚Äù or ‚ÄúTrabajo sobre c√≥digo existente‚Äù.\n\nA-4  Minor semantic shift ‚Äì ‚ÄúGreenfield code‚Äù\n     ‚Ä¢ ‚ÄúC√≥digo nuevo (greenfield)‚Äù loses the nuance that it‚Äôs *from scratch*.  \n     ‚Ä¢ Suggest: ‚ÄúDesarrollo desde cero (greenfield)‚Äù.\n\n====================================================================\nB. MAJOR : STYLE, TONE & REGISTER CONSISTENCY  \n====================================================================\n\nB-1  Heavy, inconsistent code-switching  \n     ‚Ä¢ Excessive raw English terms: spec, codegen, prompt, repo, merge, greenfield,\n       rinse repeat, wild style‚Ä¶ A technical audience tolerates many of these, but\n       the density here feels machine-like and uneven.  \n     ‚Ä¢ Fix: Decide once per term:  \n       ‚Äì spec ‚Üí ‚Äúespecificaci√≥n (spec)‚Äù first mention, thereafter spec OK.  \n       ‚Äì codegen ‚Üí ‚Äúgeneraci√≥n de c√≥digo‚Äù.  \n       ‚Äì prompt ‚Üí keep English but mark in cursive or quotes at first use and give a\n         Spanish equivalent: ‚Äúprompt (instrucci√≥n)‚Äù.  \n       ‚Äì repo ‚Üí ‚Äúrepositorio‚Äù.  \n       ‚Äì merge ‚Üí ‚Äúfusi√≥n‚Äù (o ‚Äúmerge‚Äù si se deja en ingl√©s, pero decidir).  \n       ‚Äì rinse repeat ‚Üí ‚Äúy vuelta a empezar‚Äù.  \n       ‚Äì wild style ‚Üí ‚Äúa lo loco‚Äù / ‚Äúsin red‚Äù.  \n       Aim for a more even Spanish text with occasional unavoidable English.\n\nB-2  Over-literal calques / unnatural expressions  \n     ‚Ä¢ ‚ÄúPlanear un plan‚Äù sounds forced even if mimicking the joke; suggest ‚Äúplanear\n       el plan‚Äù or keep the joke but add quotes: ¬´planear ‚Äúun plan‚Äù¬ª.  \n     ‚Ä¢ ‚ÄúClaude puro‚Äù sounds odd; ‚ÄúClaude ‚Äòen crudo‚Äô‚Äù or ‚ÄúClaude sin interfaz‚Äù would\n       read better.  \n     ‚Ä¢ ‚ÄúMe encanta.‚Äù right after a long list sounds abrupt; soften: ‚ÄúLa verdad, me\n       encanta.‚Äù  \n     ‚Ä¢ Several ‚Äúrinse and repeat‚Äù left untranslated; either translate or italicise\n       consistently.\n\nB-3  Register drift  \n     ‚Ä¢ Original voice is informal-colloquial with bursts of slang. Spanish keeps some\n       of it but at times swings to more formal (‚ÄúSin embargo‚Äù, ‚ÄúAsimismo‚Äù).  \n     ‚Ä¢ Unify tone: keep contractions (e.g. ‚ÄúNo pasa nada‚Äù vs ‚ÄúNo me molesta ese\n       punto de vista‚Äù), sprinkle slang where English has slang (‚Äúla verdad est√°\n       ca√±√≥n‚Äù, ‚Äúflipante‚Äù, etc.) but avoid sudden formality.\n\n====================================================================\nC. GRAMMAR & USAGE (MEDIUM)  \n====================================================================\n\nC-1  Article + acronym consistency  \n     ‚Ä¢ ‚Äúcon LLM‚Äù (singular) vs ‚Äúcon LLMs‚Äù (plural) oscillates. Suggest: first mention\n       ‚Äúmodelos de lenguaje grandes (LLM)‚Äù then treat as plural acronym: ‚Äúlos LLM‚Äù.\n\nC-2  Punctuation / tildes  \n     ‚Ä¢ ‚Äúp. d.‚Äù ‚Üí should be ‚ÄúP. D.‚Äù (may√∫sculas y espacio fino).  \n     ‚Ä¢ ‚Äú¬°Uf, ¬øcu√°nto tiempo tienes?‚Äù needs closing exclamation: ‚Äú¬°Uf! ¬øCu√°nto‚Ä¶?‚Äù  \n     ‚Ä¢ Several English em-dashes ‚Äú‚Äì‚Äù replaced by ‚Äú-‚Äù hyphens; Spanish prefers ‚Äú‚Äî‚Äù.\n\nC-3  Capitalisation of headings  \n     ‚Ä¢ Mixed style: ‚ÄúPaso 1: Afinar la idea‚Äù (OK) vs ‚ÄúGreenfield‚Äù (title-case English)\n       vs ‚ÄúNo-greenfield‚Äù. Choose one style; sentence-case in Spanish headings is\n       standard.\n\nC-4  Agreement & minor slips  \n     ‚Ä¢ ‚ÄúEsto da algo de libertad y orientaci√≥n al principio.‚Äù  \n       ‚ÄòOrientaci√≥n‚Äô est√° bien, pero un ‚Äúalgo de‚Äù + sing. fem. suena raro; mejor\n       ‚Äúcierta libertad y orientaci√≥n‚Äù.  \n     ‚Ä¢ ‚Äúobserv√≥ a Aider bailar‚Äù later appears as ‚Äúobservo a Aider bailar‚Äù; unify.\n\n====================================================================\nD. TERMINOLOGY CONSISTENCY (MINOR)  \n====================================================================\n\nD-1  ‚ÄúModelo de razonamiento‚Äù vs ‚Äúmodelo de reasoning‚Äù  \n     ‚Ä¢ Use one Spanish term: ‚Äúmodelo de razonamiento‚Äù.\n\nD-2  ‚ÄúBase de c√≥digo‚Äù vs ‚Äúc√≥digo base‚Äù vs ‚Äúcode base‚Äù  \n     ‚Ä¢ Choose and stick to ‚Äúbase de c√≥digo‚Äù.\n\nD-3  ‚ÄúLista de ‚Äòcosas por hackear‚Äô‚Äù  \n     ‚Ä¢ Could simplify to ‚Äúlista de hacks pendientes‚Äù.\n\n====================================================================\nE. FLUENCY & NATURALNESS (MINOR)  \n====================================================================\n\nE-1  Long English clauses left intact in running Spanish sentences  \n     ‚Ä¢ Example: ‚ÄúHe usado este flujo con [GitHub Workspace] (link), [Aider] (link),\n       [Cursor] ‚Ä¶‚Äù becomes heavy. Consider: ‚ÄúHe usado este flujo con herramientas\n       como GitHub Workspace, Aider, Cursor‚Ä¶‚Äù\n\nE-2  Excessive parenthetical clutter  \n     ‚Ä¢ Many inline ‚Äú(link)‚Äù references impede flow; convert to numbered footnotes or\n       leave only the name + hyperlink.\n\nE-3  Emojis / kaomoji  \n     ‚Ä¢ They are part of author‚Äôs tone; OK to keep, but Spanish normally puts a space\n       before/after: ‚Äúrinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß‚Äù.\n\n====================================================================\nF. CULTURAL / IDIOMATIC NUANCES  \n====================================================================\n\nF-1  ‚Äúbad places‚Äù nuance  \n     ‚Ä¢ ‚Äúlos (terribles) rincones de internet [malos] [lugares]‚Äù is clunky.  \n     ‚Ä¢ Suggest: ‚Äúlos infames rincones de Internet (s√≠, esos sitios horribles‚Ä¶)‚Äù.\n\nF-2  Swearing calibration  \n     ‚Ä¢ Original ‚ÄúWHAT THE FUCK IS GOING ON!‚Äù rendered as ‚Äú¬°¬øQU√â DEMONIOS PASA?!‚Äù.\n       ‚ÄúDemonios‚Äù is tame; closer tone would be ‚Äú¬°¬øQU√â CARAJO EST√Å PASANDO?!‚Äù\n\nF-3  ‚Äúcookie clicker‚Äù joke  \n     ‚Ä¢ Add clarifier: ‚Äú(el juego idle Cookie Clicker)‚Äù for readers unfamiliar.\n\n====================================================================\nG. MACHINE-LIKE / OVER-LITERAL AREAS  \n====================================================================\n\nG-1  Blocks where English syntax is copied verbatim:  \n     ‚Äì ‚ÄúEsto es bueno para mantener el estado entre sesiones.‚Äù feels literal.  \n       Better: ‚ÄúAs√≠ mantienes el estado entre sesiones.‚Äù  \n     ‚Äì ‚ÄúFunciona bastante bien con todas las herramientas que he probado y me imagino\n       que ir√° bien con cualquier herramienta de codegen.‚Äù Compress: ‚ÄúFunciona bien\n       con todas las herramientas que he probado y seguramente con cualquier otra de\n       generaci√≥n de c√≥digo.‚Äù\n\nG-2  Repetition of ‚Äúflujo‚Äù (‚Äúflow‚Äù) multiple sentences in a row; vary with\n     ‚Äúproceso‚Äù, ‚Äúmetodolog√≠a‚Äù, etc.\n\n====================================================================\nSUMMARY OF MAIN FIXES TO ACHIEVE A NATURAL, FAITHFUL VERSION\n1. Reinstate the omitted ‚ÄúRegardless‚Ä¶‚Äù paragraph.  \n2. Replace or explain key anglicisms (‚Äúspec‚Äù, ‚Äúcodegen‚Äù, etc.) once, then keep if\n   desired.  \n3. Polish register: keep informal, avoid sudden formality, adjust swear words.  \n4. Correct minor grammar/punctuation issues, harmonise plural ‚ÄúLLM‚Äù, article usage,\n   and heading styles.  \n5. Remove literal calques and translate idioms (‚Äúrinse and repeat‚Äù, ‚Äúover my skis‚Äù,\n   ‚Äúwild style‚Äù) with natural Spanish equivalents.  \n6. Streamline hyperlinks and parentheticals; they clutter the prose.  \n7. Re-read entire text aloud to catch residual machine-sounding phrasing and ensure\n   smooth, idiomatic flow.",
      "CRITICAL ISSUES\n1. Large-scale omissions (content skipped)\n   ‚Ä¢ The two long ‚ÄúStep 2: Planning‚Äù prompts (TDD & non-TDD) are replaced by ¬´‚Ä¶¬ª.  \n     ‚áí Restore the full English text or translate it entirely; do NOT abridge.  \n   ‚Ä¢ Minor but cumulative cuts: ‚Äúpretty old and busted‚Äù, some parenthetical jokes, extra explanations inside > blockquotes, etc.  \n     ‚áí Re-insert all missing sentences.\n\n2. Terminology inconsistency\n   ‚Ä¢ Source consistently uses the plural ‚ÄúLLMs‚Äù; translation oscillates between ‚ÄúLLM‚Äù (singular) and ‚ÄúLLMs‚Äù.  \n     ‚áí Use ‚Äúlos LLM‚Äù or ‚Äúlos LLMs‚Äù uniformly.\n   ‚Ä¢ ‚ÄúLegacy modern code‚Äù is rendered as ¬´c√≥digo heredado relativamente reciente (brownfield)¬ª. The author‚Äôs tongue-in-cheek paradox (‚Äúmodern-legacy‚Äù) disappears and the term brownfield is introduced before it appears in the source.  \n     ‚áí Keep the play on words: ¬´c√≥digo legado moderno¬ª and leave ‚Äúbrownfield‚Äù for the later section where the author himself uses ‚ÄúNon-greenfield‚Äù.\n\nMAJOR ISSUES\nA. Nuances / register\n   1. ‚Äúhow much time do you have!‚Äù ‚Üí ¬´¬°Uf! ¬øCu√°nto tiempo tienes?¬ª loses the amused excitement of ‚Äúoh boy‚Äù.  \n      Suggestion: ¬´¬°Madre m√≠a! ¬øCu√°nto tiempo tienes?¬ª  \n   2. ‚Äúbad places‚Äù sarcastic hyperlink aside ‚Äì translation flattens the snark. Consider ¬´los peores rincones de Internet¬ª.  \n   3. ‚ÄúDiscrete loops. Then magic.‚Äù ‚Üí ¬´Bucles discretos. Y, al final, magia.¬ª Tone of abrupt punch is softened. Try ¬´Bucles discretos. Luego‚Ä¶ magia.¬ª  \n   4. ‚ÄúWild tbh‚Äù is missing. Could keep an informal ¬´Una locura, la verdad.¬ª near the right spot (end of 15-minute remark).\n\nB. Style & flow (sounds Englishy)\n   ‚Ä¢ ‚Äúplanear el plan‚Äù is literal. A playful but more idiomatic echo: ¬´planear el proyecto¬ª or ¬´dise√±ar el plan¬ª.  \n   ‚Ä¢ ‚Äúpego el prompt‚Äù / ‚Äúpaso el prompt‚Äù ‚Äì repetitive anglicism. Prefer ‚Äúinstrucci√≥n‚Äù, ‚Äúmensaje‚Äù or at least combine: ‚Äúpegar la instrucci√≥n (prompt)‚Äù.  \n   ‚Ä¢ Overuse of English nouns in plural without markup: prompts, codegen, boilerplate, output, etc. Decide case by case if they need a Spanish equivalent or italics.\n\nC. Technical precision\n   ‚Ä¢ ‚Äúsuite‚Äù should be ¬´la suite de pruebas¬ª when first introduced.  \n   ‚Ä¢ ‚Äúsaved as `spec.md`‚Äù translated fine, but elsewhere ‚Äúguardar como‚Äù vs. ‚Äúlo guardo‚Äù alternates. Standardise.\n\nMODERATE ISSUES\n1. Grammar / punctuation\n   ‚Ä¢ ¬´Ha sido divertido y √∫til; pero‚Ä¶¬ª ‚Äì semicolon + ‚Äúpero‚Äù is awkward. Use comma: ¬´‚Ä¶√∫til, pero‚Ä¶¬ª.  \n   ‚Ä¢ ¬´P. D.: si odias la IA, salta al final¬ª ‚Äì Spanish norms omit the period inside ‚ÄòP.D.‚Äô ‚Üí ¬´P. D.:¬ª is correct; fine.  \n   ‚Ä¢ Several long English parentheticals left untranslated; wrap them in em-dashes or parentheses and translate.\n\n2. Capitalisation of headings\n   ‚Ä¢ ‚ÄúGreenfield‚Äù and ‚ÄúBrownfield‚Äù appear as English after Spanish sentence starters; decide either to keep them in English with quotes or adapt (¬´Desde cero¬ª, ¬´Brownfield¬ª).\n\n3. In-line code blocks\n   ‚Ä¢ Do not translate code fences' language tag (‚Äúprompt‚Äù)‚Äî fine; but in the explanatory sentence you wrote ¬´(este es el prompt TDD)¬ª then immediately trimmed the content. Restore.\n\nMINOR ISSUES\n‚Ä¢ ‚Äúalways make sure you are on a new branch for aider work‚Äù was not rendered; add ¬´procura estar siempre en una rama nueva cuando uses Aider¬ª.  \n‚Ä¢ Alt-text ‚ÄúJuggalo Robot‚Äù turned into ¬´Robot Juggalo¬ª. Not wrong, but flips adjective order.  \n‚Ä¢ ‚ÄúI get to play cookie clicker‚Äù became ‚Äújuego a Cookie Clicker (el idle game)‚Äù‚Äî good, but capitalise consistently or italicise the title.\n\nSUGGESTED OVERALL IMPROVEMENTS\n1. Replace every ellipsis that hides source text with a faithful Spanish version (or keep the full English text if the author‚Äôs intention is to show the raw prompt).  \n2. Re-evaluate anglicisms: allow unavoidable technical ones (prompt, codegen, boilerplate) but Spanish-ify where fluent.  \n3. Maintain the playful, informal tone: keep interjections (‚Äúoh boy‚Äù, ‚ÄúWild tbh‚Äù, ‚ÄúGET TO WORK!‚Äù) instead of neutralising them.  \n4. Harmonise tenses and persons; author mixes present and present continuous for energy‚Äîmirror that in Spanish.  \n5. Double-check every caption, alt-text and blockquote so no jokes or asides vanish.\n\nIf these changes are applied, the translation will be complete, faithful, and will read as natural Spanish rather than an abridged, slightly literal rendering.",
      "CRITIQUE OF THE SPANISH TRANSLATION  \n\n(Organized by SEVERITY ‚Üí CATEGORY ‚Üí ITEM.  \nEach item includes: a) Problem  b) Why it matters  c) Suggested fix.)\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  I. CRITICAL ISSUES  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  \nA. Meaning / Fidelity  \n\n1. ‚Äúplan a plan‚Äù ‚Üí ‚Äúdise√±ar el plan‚Äù  \n   a) Los juegos de palabras redundantes (‚Äúplan a plan‚Äù) se pierden.  \n   b) Se elimina un rasgo humor√≠stico-intencional del original.  \n   c) Restituir la redundancia: ¬´‚Ä¶luego planear un plan‚Ä¶¬ª.\n\n2. ‚ÄúLegacy modern code‚Äù ‚Üí ‚ÄúC√≥digo legado moderno‚Äù  \n   a) ¬´Legado moderno¬ª suena contradictorio y confuso en espa√±ol.  \n   b) Puede generar ambig√ºedad: ¬øc√≥digo heredado pero relativamente moderno?  \n   c) Usar algo como ¬´c√≥digo heredado relativamente reciente¬ª o ¬´base de c√≥digo heredada (pero moderna)¬ª.\n\n3. ‚ÄúDiscrete loops‚Äù ‚Üí ‚ÄúBucles discretos‚Äù  \n   a) En ingl√©s es un gui√±o ambiguo (ciclos independientes vs. loops discretos).  \n   b) ‚ÄúBucles discretos‚Äù suena a teor√≠a matem√°tica; se pierde la idea de ‚Äúfases separadas‚Äù.  \n   c) Cambiar por ¬´bucles separados¬ª / ¬´ciclos independientes¬ª.\n\n4. Omisi√≥n de matiz en ‚ÄúI have been building so many small products‚Äù  \n   a) ‚ÄúHe estado creando montones de productos peque√±os‚Äù omite la connotaci√≥n de ‚Äúso many‚Äù.  \n   b) Rebaja el √©nfasis cuantitativo.  \n   c) ¬´‚Ä¶un mont√≥n de productos peque√±os¬ª o ¬´‚Ä¶much√≠simos productos peque√±os¬ª.\n\n5. Frase final del apartado ‚ÄúSkiing‚Äù: ‚ÄúAll to manage your cloud functions, your todo list or whatever‚Äù  \n   a) Se traduce ‚Äú‚Ä¶Todo para gestionar tus funciones en la nube, tu lista de tareas o lo que sea.‚Äù, pero falta la idea de ‚Äúridiculous‚Äù (contraste humor√≠stico).  \n   b) Se aten√∫a el tono ir√≥nico.  \n   c) A√±adir: ¬´Todo ello, parad√≥jicamente, solo para‚Ä¶¬ª.\n\nB. Additions / Omissions  \n\n6. Falta la repetici√≥n humor√≠stica ¬´¬Ø\\_(„ÉÑ)_/¬Ø¬ª en un par de sitios donde el original la incluye.  \n   a) El gesto es parte del tono.  \n   b) Mantenerla tal cual o con equivalente visual.\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  II. MAJOR ISSUES  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  \nA. Tone / Register  \n\n7. Mezcla excesiva de anglicismos crudos (‚Äúworkflow, prompt, boilerplate, merge, branch, check-list‚Äù).  \n   a) Rompe la fluidez; da sensaci√≥n de texto sin pulir.  \n   b) El p√∫blico hispanohablante t√©cnico entiende los t√©rminos, pero un exceso suena ‚Äúm√°quina-like‚Äù.  \n   c) Sustituir al menos los m√°s innecesarios:  \n      ‚Äì workflow ‚Üí flujo de trabajo  \n      ‚Äì boilerplate ‚Üí c√≥digo base / plantilla  \n      ‚Äì merge ‚Üí fusi√≥n / merge (git)  \n      ‚Äì branch ‚Üí rama  \n      ‚Äì checklist ‚Üí lista de comprobaci√≥n  \n      (Mantener ‚Äúprompt‚Äù, ‚Äúcodegen‚Äù o ‚Äúgreenfield‚Äù puede ser aceptable si se justifican.)\n\n8. Uso reiterado de ‚Äúpost‚Äù  \n   a) Existen alternativas naturales: ¬´entrada¬ª, ¬´art√≠culo¬ª.  \n   b) Mejora la naturalidad.  \n   c) Cambiar a ¬´entrada¬ª o ¬´art√≠culo¬ª.\n\n9. Subt√≠tulos como ‚ÄúNon-greenfield‚Äù sin traducci√≥n  \n   a) Desentonan en medio de secciones en espa√±ol.  \n   b) Mantener la coherencia.  \n   c) Titular ¬´Proyectos existentes (non-greenfield)¬ª o ¬´Brownfield¬ª.\n\nB. Grammar / Syntax  \n\n10. ‚ÄúAun as√≠, prefiero Claude en crudo‚Äù  \n    a) Falta tilde en ‚ÄúA√∫n‚Äù (adverbio de tiempo).  \n    b) Corregir: ¬´A√∫n as√≠¬ª o mejor ¬´Aun as√≠¬ª (sin tilde) seg√∫n la RAE; pero aqu√≠ es concesivo ‚Üí ¬´Aun as√≠¬ª est√° bien. El problema es la confusi√≥n entre formas; aclarar.\n\n11. ‚ÄúTesting es nice‚Äù (no aparece, pero el traductor mantuvo ‚ÄúTesting es nice‚Äù ‚Üí ‚ÄúLa prueba es a√∫n m√°s autom√°tica‚Ä¶‚Äù)  \n    a) Se evit√≥ en esta versi√≥n, pero vigilar expresiones similares que mezclan idiomas.\n\nC. Idiomatic / Cultural  \n\n12. ‚Äúinterfaces glitchy‚Äù (se mantiene ‚Äúglitchy‚Äù)  \n    a) Mezcla innecesaria; ‚Äúglitchy‚Äù no es de uso corriente.  \n    b) Sustituir por ¬´defectuosas¬ª, ¬´inestables¬ª o ¬´con glitchs¬ª.\n\n13. ‚ÄúCookie Clicker‚Äù ‚Üí se retiene, pero convendr√≠a la primera vez entrecomillar y aclarar ‚Äúel juego Cookie Clicker‚Äù.\n\n14. Traducci√≥n literal ‚ÄúCampo marr√≥n‚Äù (en caption).  \n    a) ‚ÄúBrown field‚Äù es juego de palabras con ‚Äúgreenfield/brownfield‚Äù.  \n    b) Se pierde la broma.  \n    c) Mantener ‚ÄúBrownfield (campo marr√≥n)‚Äù o explicar la gracia.\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  III. MINOR ISSUES  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  \nA. Consistency  \n\n15. ‚ÄúLLMs‚Äù ‚Üí a veces con art√≠culo (‚Äúlos LLMs‚Äù), a veces sin; unificar.  \n16. Variaci√≥n ‚Äúspec‚Äù / ‚Äúspecificaci√≥n‚Äù sin criterio fijo.  \n17. Comillas simples y dobles mezcladas; estandarizar (p. ej., comillas latinas ¬´¬ª o inglesas ‚Äú ‚Äù).  \n\nB. Punctuation / Typography  \n\n18. Espacios antes de signos de puntuaci√≥n en varias listas (‚Äú‚Ä¶  ‚Ä¶‚Äù).  \n19. Uso de guiones largos ‚Äú‚Äî‚Äù vs ‚Äú-‚Äù inconsistente.  \n20. En varios puntos se deja ¬´...¬ª y en otros ¬´‚Ä¶¬ª (car√°cter √∫nico). Elegir uno.\n\nC. Machine-like traces  \n\n21. Algunos gerundios calcados: ‚ÄúEst√° funcionando bien **AHORA**; puede que‚Ä¶‚Äù ‚Üí mejor ‚ÄúFunciona bien AHORA‚Ä¶‚Äù.  \n22. Repeticiones innecesarias (‚ÄúFlujo: ‚Ä¶ Flujo: ‚Ä¶‚Äù). Se puede condensar.\n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  IV. TERMINOLOG√çA T√âCNICA  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  \n\n23. ‚ÄúCodegen‚Äù se deja sin cursiva ni explicaci√≥n la primera vez. A√±adir ¬´(generaci√≥n autom√°tica de c√≥digo, *codegen*)¬ª.  \n24. ‚Äúrepomix‚Äù / ‚Äúmise‚Äù ‚Üí primera menci√≥n deber√≠a ir con breve nota (‚Äúla herramienta Repomix‚Äù).  \n\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  V. SUGERENCIA GLOBAL DE RE-EDICI√ìN  ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ  \n\n‚Äì Recuperar los chistes/giros (‚Äúplanear un plan‚Äù, ‚Äú¬Ø\\_(„ÉÑ)_/¬Ø‚Äù).  \n‚Äì Reducir anglicismos gratuitos; cuando se conserven, cursiva o comillas.  \n‚Äì Homogeneizar t√≠tulos, comillas, may√∫sculas y numeraciones.  \n‚Äì Revisar tildes y concordancias menores.  \n‚Äì A√±adir breves glosas t√©cnicas la primera vez que aparece sigla/herramienta.  \n\nCon estas correcciones, el texto ganar√° en fidelidad humor√≠stica, claridad y naturalidad, y dejar√° de sonar a traducci√≥n literal/m√°quina.",
      "CRITICAL ISSUES  \n1. Number inconsistency for ‚ÄúLLM‚Äù  \n   ‚Ä¢ ST: ‚ÄúLLMs‚Äù (plural) appears dozens of times.  \n   ‚Ä¢ TT oscillates between ‚ÄúLLM‚Äù (sing.) and ‚ÄúLLM s‚Äù ‚Üí loss of meaning (it is not one but several models).  \n   ‚Ä¢ Fix: usar siempre ‚ÄúLLM‚Äù como sigla invariable acompa√±ada de plural (‚Äúlos LLM‚Äù) o traducir ‚Äúmodelos de lenguaje (LLM)‚Äù. Mantener la misma forma a lo largo del texto.  \n\n2. Mistranslation of ‚ÄúDiscrete loops‚Äù  \n   ‚Ä¢ ST idea: ciclos claramente separados, independientes.  \n   ‚Ä¢ TT: ‚ÄúBucles separados‚Äù. Se pierde el matiz de ‚Äúdiscretos‚Äù (= independientes, autocontenidos); en dev-argot ‚Äúbucles discretos‚Äù se entiende mejor.  \n   ‚Ä¢ Fix: ‚ÄúBucles discretos‚Äù o ‚Äúbucles independientes‚Äù.  \n\n3. ‚Äúplanear un plan‚Äù  \n   ‚Ä¢ ST juega con la redundancia ‚Äúplan a plan‚Äù (= planificar el plan).  \n   ‚Ä¢ TT lo vuelve literal pero suena torpe en espa√±ol; adem√°s ‚Äúplanear un plan‚Äù es pleonasmo poco natural.  \n   ‚Ä¢ Fix: ‚Äúplanificar el plan‚Äù o ‚Äúelaborar el plan‚Äù y, si se quiere mantener la broma, a√±adir ‚Äú(s√≠, planificar el plan)‚Äù.  \n\n4. Singular ‚ÄúLa prueba es a√∫n m√°s autom√°tica‚Äù  \n   ‚Ä¢ ST: ‚ÄúTesting is nice with aider, because it can be even more hands off‚Ä¶‚Äù (= las pruebas).  \n   ‚Ä¢ TT usa singular ‚ÄúLa prueba‚Äù. Se altera el sentido t√©cnico de ‚Äútesting‚Äù.  \n   ‚Ä¢ Fix: ‚ÄúLas pruebas son a√∫n m√°s autom√°ticas‚Äù o ‚ÄúEl testing es‚Ä¶‚Äù.  \n\n5. Cambio de encabezado ‚ÄúBrownfield (proyectos existentes)‚Äù  \n   ‚Ä¢ ST: ‚ÄúNon-greenfield: Iteration, incrementally‚Äù. TT introduce ‚ÄúBrownfield‚Äù (t√©rmino no mencionado en el ST). Es una decisi√≥n interpretativa, pero introduce terminolog√≠a extra y puede desorientar.  \n   ‚Ä¢ Fix: ‚ÄúNo-greenfield: iteraci√≥n incremental (sobre c√≥digo existente)‚Äù.  \n\n6. Omisi√≥n de matiz en ‚Äúknee-deep in AI dev‚Äù  \n   ‚Ä¢ ST enfatiza inmersi√≥n total. TT simplifica a ‚Äúmetida en IA‚Äù. Se pierde la idea de ‚Äúhasta las rodillas‚Äù.  \n   ‚Ä¢ Fix: ‚Äú‚Ä¶quienes estamos hasta las rodillas en desarrollo con IA‚Ä¶‚Äù.  \n\nMAJOR ISSUES (sentido intacto pero suenan antinaturales o pierden tono)  \nA. Tono coloquial/informal ingl√©s ‚â† espa√±ol  \n   ‚Ä¢ Ej.: ‚ÄúWild tbh.‚Äù ‚Üí TT ‚ÄúUna locura, la verdad.‚Äù bien; pero en otros lugares se pierde el coloquialismo (‚Äúpretty solid‚Äù ‚Üí ‚Äúbastante s√≥lida‚Äù OK, ‚Äúit largely works‚Äù ‚Üí ‚Äúcumple‚Äù ser√≠a mejor que ‚Äúfunciona bastante bien‚Äù).  \n   ‚Ä¢ Sugerencia: reforzar la voz cercana del original con giros equivalentes (‚Äúest√° bastante bien‚Äù, ‚Äúfunciona de maravilla‚Äù, etc.).  \n\nB. Anglicismos no motivados o sin marcar  \n   ‚Äì ‚Äúworkflow‚Äù, ‚Äúprompt plan‚Äù, ‚Äúdeep research‚Äù, ‚Äúcookie clicker‚Äù, ‚Äúhack‚Äù se dejan sin cursiva ni comillas.  \n   ‚Äì En entornos dev es normal, pero conviene marcar la primera aparici√≥n y, si se repite mucho, espa√±olizar (‚Äúflujo de trabajo, *workflow*‚Äù).  \n\nC. Consistencia terminol√≥gica  \n   ‚Äì ‚Äúcodegen‚Äù vs ‚Äúgeneraci√≥n de c√≥digo‚Äù mezclados.  \n   ‚Äì ‚Äútesting‚Äù vs ‚Äúpruebas‚Äù/‚Äútests‚Äù.  \n   ‚Äì Unificar: ‚Äúgeneraci√≥n de c√≥digo (*codegen*)‚Äù, ‚Äúpruebas‚Äù, etc.  \n\nD. Traducci√≥n de sarcasmo y humor  \n   ‚Ä¢ ‚Äúterrible internet bad places‚Äù ‚Üí TT ‚Äúpeores rincones de Internet‚Äù pierde la iron√≠a de ‚Äúterrible‚Äù+‚Äúbad‚Äù repetido. Propuesta: ‚Äúlos m√°s infames y terribles rincones de Internet‚Äù.  \n   ‚Ä¢ ‚Äúboomer prompts‚Äù ‚Üí TT lo deja igual, pero ‚Äúprompts de boomer‚Äù funcionar√≠a mejor en espa√±ol.  \n\nE. Conservaci√≥n de expresiones en ingl√©s sin glosa  \n   ‚Ä¢ ‚Äúover my skis‚Äù se deja tal cual pero se explica despu√©s. Podr√≠a a√±adirse primera aparici√≥n ‚Äú(pasado de vueltas, *over my skis*)‚Äù.  \n\nMINOR / STYLISTIC  \n1. Puntuaci√≥n  \n   ‚Ä¢ Varias elipsis ‚Äú‚Ä¶‚Äù con espacios inconsistentes; unificar (‚Äú‚Ä¶‚Äù sin espacio antes).  \n   ‚Ä¢ Uso de may√∫scula tras punto y coma en ‚Äútl;dr: Lluvia de ideas‚Ä¶‚Äù; ‚Äútl;dr;‚Äù original lleva dos ‚Äú;‚Äù (error de origen), puede aclararse.  \n\n2. Cohesi√≥n de listas  \n   ‚Ä¢ Algunas vi√±etas pierden ‚Äú;‚Äù finales (‚Äúrun code, run tests, etc‚Äù). En castellano conviene cerrar con punto y coma o punto final.  \n\n3. Otro detalle l√©xico  \n   ‚Ä¢ ‚ÄúHaterade‚Äù ‚Äì TT crea secci√≥n ‚ÄúHaterade‚Äù sin traducir. Se puede mantener como meme, pero a√±adir ‚Äú(odio a la IA)‚Äù mejora comprensi√≥n.  \n   ‚Ä¢ ‚Äúraw claude‚Äù ‚Üí ‚ÄúClaude puro‚Äù o ‚ÄúClaude sin envoltorio‚Äù en vez de ‚ÄúClaude ‚Äòen crudo‚Äô‚Äù (calco culinario).  \n\nGRAMMAR / AGREEMENT  \n‚Äì ‚ÄúEsto NO es un greenfield.‚Äù ‚Üí Falta art√≠culo: ‚ÄúEsto NO es un *greenfield*.‚Äù  \n‚Äì ‚ÄúMi lista de hacks pendientes est√° vac√≠a porque lo he construido todo.‚Äù ‚Üí concordancia m√°s natural: ‚Äúporque ya constru√≠ todo‚Äù.  \n‚Äì ‚ÄúEl modelo devolver√° un plan de prompts‚Ä¶‚Äù ‚Üí plural inconsistente despu√©s (‚ÄúLos guardo‚Ä¶‚Äù).  \n\nMISSING / ADDED CONTENT  \nNo se detectaron p√°rrafos omitidos. S√≠ se a√±adi√≥ el t√©rmino ‚ÄúBrownfield‚Äù que no estaba en el ST (ver CRITICAL-5).  \n\nMACHINE-LIKE TRACES  \n‚Äì Calcos literales: ‚Äúrinse repeat‚Äù ‚Üí ‚Äúy vuelta a empezar‚Äù (bien), pero ‚Äúrinse repeat ‚ú©‚Äù se conserva tal cual m√°s abajo. Podr√≠a normalizarse: ‚Äúy a repetir‚Äù.  \n‚Äì ‚ÄúMagia de prompts‚Äù: buen t√≠tulo, pero ‚Äúestos hacks son mano de santo‚Äù mezcla registro coloquial con frase hecha poco habitual para devs; se siente insertado.  \n\nRECOMMENDED GLOBAL FIXES  \n1. Elegir y mantener un glosario: LLM (pl.), *codegen*, *workflow*, *prompt*, greenfield/no-greenfield.  \n2. Revisar todas las ocurrencias de ‚ÄúLLM/LLMs‚Äù y ajustar n√∫mero.  \n3. Reescribir t√≠tulo y primera frase para sonar natural: ‚ÄúTormenta de ideas ‚Üí especificaci√≥n, luego planificar, despu√©s ejecutar con generaci√≥n de c√≥digo mediante LLM. Bucles discretos y‚Ä¶ magia.‚Äù  \n4. Sustituir anglicismos innecesarios o marcarlos la primera vez.  \n5. Reforzar coloquialismo y humor con equivalentes espa√±oles (interjecciones, muletillas).  \n6. Pases de correcci√≥n de estilo: concordancia, tildes, comas antes de ‚Äúpero‚Äù, etc."
    ]
  },
  "critique_loop_details": {
    "critique_usages": [
      {
        "prompt_tokens": 9773,
        "completion_tokens": 1907,
        "total_tokens": 11680
      },
      {
        "prompt_tokens": 8565,
        "completion_tokens": 1103,
        "total_tokens": 9668
      },
      {
        "prompt_tokens": 9414,
        "completion_tokens": 1623,
        "total_tokens": 11037
      },
      {
        "prompt_tokens": 9447,
        "completion_tokens": 1545,
        "total_tokens": 10992
      }
    ],
    "feedback_usages": [
      {
        "prompt_tokens": 11678,
        "completion_tokens": 3278,
        "total_tokens": 14956
      },
      {
        "prompt_tokens": 9578,
        "completion_tokens": 4100,
        "total_tokens": 13678
      },
      {
        "prompt_tokens": 11123,
        "completion_tokens": 4126,
        "total_tokens": 15249
      },
      {
        "prompt_tokens": 11027,
        "completion_tokens": 4191,
        "total_tokens": 15218
      }
    ]
  },
  "timestamp": "2025-05-16T09:37:23.233986"
}