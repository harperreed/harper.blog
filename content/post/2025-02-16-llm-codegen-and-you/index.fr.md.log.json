{
  "input_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.md",
  "output_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.fr.md",
  "target_language": "french",
  "language_code": "fr",
  "model": "o3",
  "skip_edit": false,
  "do_critique": true,
  "critique_loops": 4,
  "has_frontmatter": true,
  "token_usage": {
    "prompt_tokens": 98118,
    "completion_tokens": 33923,
    "total_tokens": 132041
  },
  "cost": "$2.3381",
  "prompts_and_responses": {
    "translation": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "\n        1. Read the provided text carefully, preserving all formatting, markdown, and structure exactly as they appear.\n        2. Identify any block quotes and code blocks.\n        3. Do not translate text in block quotes or in code blocks (including text within code blocks).\n        4. Translate everything else into french.\n        5. Maintain the original formatting, markdown, and structure in your output.\n        6. Provide a natural-sounding translation rather than a word-for-word one.\n        7. For idioms, colloquialisms, or slang, render them in an equivalent, natural way in french whenever possible.\n        8. If there isn't a direct or natural translation for a particular term or phrase, keep it in the original language and surround it with quotes if necessary.\n        9. Ensure that technical terms or jargon remain accurate; if there's no suitable translation, keep the original term.\n        10. Strive for fluid, native-sounding prose that retains the tone and intent of the original text.\n        ",
      "user_prompt": "_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "response": "_tl;dr : Élaborer un spec, puis planifier le plan, puis exécuter grâce au codegen LLM. Boucles discrètes. Et ensuite, la magie. ✩₊˚.⋆☾⋆⁺₊✧_\n\nJe construis depuis un moment plein de petits produits à l’aide des LLM. C’est à la fois amusant et utile. Mais il existe de nombreux pièges qui peuvent faire perdre un temps fou. Il y a quelque temps, un ami m’a demandé comment j’utilisais les LLM pour écrire du code. Je me suis dit : « Ohlala… tu as combien de temps ? » — d’où ce billet.\n\n(p.s. si tu détestes l’IA, va directement à la fin)\n\nJe discute souvent de tout ça avec des potes dev, et nous suivons tous à peu près la même méthode, avec quelques ajustements par-ci par-là.\n\nVoici donc mon workflow. Il s’appuie sur mon expérience perso, des échanges avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glanées dans les recoins parfois douteux d’Internet : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nÇa marche super bien **MAINTENANT**, peut-être plus du tout dans deux semaines… ou deux fois mieux. ¯\\\\\\_(ツ)\\_/¯\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images générées par IA un peu louches. Voici donc mon ange robot codeur juggalo !\" >}}\n\nIl existe plein de façons de développer, mais je me retrouve généralement dans l’un de ces deux cas :\n\n- Code neuf (greenfield)\n- Code existant relativement moderne\n\nJe vais te montrer mon process pour les deux.\n\n## Code neuf\n\nVoici le process que j’utilise pour un développement greenfield. Il fournit un cadre solide de planification et de documentation, et permet d’avancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert à droite. Leica Q, 14/05/2016\" >}}\n\n### Étape 1 : Affiner l’idée\n\nUtilise un LLM conversationnel pour peaufiner l’idée (j’emploie ChatGPT 4o / o3) :\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nÀ la fin du brainstorming (tu sentiras quand c’est fini) :\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nOn obtient alors un spec assez propre qu’on peut passer à l’étape de planification. Je le sauvegarde en général sous `spec.md` dans le repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Étape 2 : Planification\n\nPrends le spec et envoie-le à un modèle de raisonnement digne de ce nom (`o1*`, `o3*`, `r1`) :\n\n(Prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Prompt non-TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe modèle doit te sortir un « prompt plan » que tu pourras exécuter avec aider, cursor, etc. Je le sauvegarde en général sous `prompt_plan.md`.\n\nEnsuite, je lui demande de générer un `todo.md` à cocher :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nÀ mettre à la racine du repo.\n\nTon outil de codegen doit pouvoir cocher les cases du `todo.md` au fil de la session : pratique pour garder l’état.\n\n#### Hourra, un plan !\n\nTu as maintenant un plan solide et de la doc pour piloter ton projet.\n\nL’ensemble de la phase 1+2 prend **15 minutes** max. C’est fou.\n\n### Étape 3 : Exécution\n\nIl existe énormément d’outils pour cette phase. Leur réussite dépend surtout de la qualité de l’étape 2.\n\nJ’ai testé ce workflow avec [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai)… Ça marche partout.\n\nPerso je préfère **claude brut** + aider.\n\n### Claude\n\nJe fais du pair-programming sur [claude.ai](https://claude.ai) : je balance chaque prompt à la suite. Ça tourne pas mal. Les aller-retour peuvent être un peu lourds, mais globalement ça le fait.\n\nJe m’occupe du boilerplate et du setup outillage. Ça donne plus de liberté et évite que Claude ne balance d’office du React. Une bonne base claire (langage, style, tooling) aide beaucoup.\n\nQuand ça coince, j’utilise [repomix](https://github.com/yamadashy/repomix) pour passer tout le code à Claude et déboguer.\n\nWorkflow :\n\n- initialiser le repo (boilerplate, `uv init`, `cargo init`, etc.)\n- coller le prompt dans Claude\n- copier-coller le code généré dans l’IDE\n- lancer le code, les tests, etc.\n- …\n- si ça marche : prompt suivant\n- sinon : repomix + Claude pour débug\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu chelou. Ça s’imbrique bien avec la sortie de l’étape 2 et on va très loin sans effort.\n\nMême logique que ci-dessus, sauf qu’on colle les prompts dans aider.\n\nAider « fait le taf » et moi je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nGrâce aux tests, aider peut être encore plus « mains libres » : il exécute la suite et débogue tout seul.\n\nWorkflow :\n\n- initialiser le repo\n- lancer aider\n- coller le prompt\n- regarder aider danser ♪┏(・o･)┛♪\n- aider lance les tests / on vérifie l’app\n- si OK : prompt suivant\n- sinon : Q&A avec aider\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Résultats\n\nJ’ai sorti une quantité folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Franchement efficace.\n\nSi tu repousses un projet (petit ou gros), teste donc : tu seras surpris de la vitesse à laquelle ça avance.\n\nMa todo « hack » est vide, j’ai tout fait. Je découvre de nouveaux langages et outils, ça élargit vraiment mon horizon dev.\n\n## Pas de greenfield : itération incrémentale\n\nParfois, pas de page blanche : il faut enrichir un code existant.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n’est pas un champ vert. Photo au hasard venant de l’appareil de mon grand-père – quelque part en Ouganda dans les années 60\" >}}\n\nDans ce cas, méthode un peu différente : moins de plan global, plus de planification à la tâche.\n\n### Obtenir le contexte\n\nChacun a son outil fétiche pour empaqueter le code et l’injecter au LLM. Moi j’utilise [repomix](https://github.com/yamadashy/repomix) via une collection de tâches définies dans `~/.config/mise/config.toml` (voir [mise rules](https://mise.jdx.dev/)).\n\nVoici la liste de tâches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe génère un `output.txt` qui contient le contexte. Si c’est trop gros pour les tokens, j’exclus les parties inutiles.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUne fois `output.txt` prêt, je le passe à la commande [LLM](https://github.com/simonw/LLM) pour différentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn vrai, la tâche mise lance : `cat output.txt | LLM -t readme-gen > README.md` ou `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. Simple : `LLM` gère modèles, clés, templates.\n\nExemple : si je veux améliorer la couverture de tests :\n\n#### Claude\n\n- se placer dans le dossier du code\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- copier le bundle : `mise run LLM:copy_buffer_bundle`\n- coller dans Claude + premier « issue »\n- copier le code généré dans l’IDE\n- …\n- lancer tests\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- se placer dans le dossier\n- lancer aider (toujours sur une nouvelle branche)\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- coller le premier « issue » dans aider\n- regarder aider danser ♪┏(・o･)┛♪\n- …\n- lancer tests\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nSuper efficace pour améliorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j’emploie sur du code existant :\n\n#### Revue de code\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Génération d’issues GitHub\n\n(je dois encore automatiser le post des issues !)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent à dater (« boomer prompts »). Si tu as des idées pour les améliorer, fais signe !\n\n## Ski Ⓐᨒ↟ 𖠰ᨒ↟ 𖠰\n\nQuand j’explique ce process, je dis : « il faut suivre agressivement ce qui se passe, sinon tu te fais vite dépasser ».\n\nJe parle tout le temps d’être **« over my skis »** avec les LLM — tu skies dans de la poudre parfaite, puis soudain : « MAIS QU’EST-CE QUI SE PASSE ! » et tu finis dans le ravin.\n\nLa **phase de planification** (cf. Greenfield) aide à garder le contrôle : tu as au moins un doc de référence. Les tests aussi, surtout avec aider en mode freestyle : ça reste propre et serré.\n\nMalgré tout, je me retrouve souvent **over my skis**. Parfois, une pause ou une petite marche suffit. Au fond, c’est la résolution de problème habituelle, mais à vitesse supersonique.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Je suis si seul (｡•́︿•̀｡)\n\nMon principal reproche : tout ça reste majoritairement **solo** — des interfaces « single player ».\n\nJ’ai codé des années tout seul, en pair, en équipe. C’est toujours meilleur à plusieurs. Là, les bots se cognent, les merges sont moches, le contexte est compliqué.\n\nJ’aimerais vraiment qu’on résolve ça et qu’on rende le dev avec LLM **multijoueur**. Pas juste une expérience de hacker solitaire. Il y a un monde à construire là-dessus.\n\nAU BOULOT !\n\n## ⴵ Temps ⴵ\n\nLe codegen a explosé la quantité de code qu’une seule personne peut produire. Effet secondaire bizarre : beaucoup de « temps mort » pendant que le LLM calcule.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m’en souviens comme si c’était hier\" >}}\n\nJ’ai donc modifié ma façon de travailler :\n\n- je lance le brainstorming d’un autre projet\n- j’écoute des vinyles\n- je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)\n- je discute avec des amis (et des robots)\n\nC’est génial de hacker comme ça. Hack Hack Hack. Je ne me souviens pas avoir jamais été aussi productif.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nBeaucoup de mes potes disent : « les LLM c’est nul, ça rate tout ». Je respecte cette vision, même si je ne la partage pas. Il y a de vraies raisons de se méfier de l’IA. Ma peur numéro 1 : la conso électrique et l’impact environnemental. Mais… le code doit couler. Right… *soupir*.\n\nSi tu es curieux sans vouloir devenir un « cyborg programmer », lis le bouquin d’Ethan Mollick : [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC’est une bonne intro, sans le ton bro techno-libertarien. J’ai eu plein de discussions nuancées avec des amis après l’avoir lu. Recommandé.\n\nSi tu es sceptique mais intrigué, ping moi : on peut en discuter et peut-être construire un truc ensemble.\n\n_merci à [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d’avoir relu ce billet et suggéré des modifs. Je vous en suis reconnaissant._",
      "usage": {
        "prompt_tokens": 4834,
        "completion_tokens": 4298,
        "total_tokens": 9132
      },
      "streaming": true
    },
    "editing": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "\n        1. Carefully read the translated text alongside the original text in its entirety.\n        2. Compare both texts to ensure the translation accurately reflects the original meaning.\n        3. Correct any grammatical errors you find in the french text.\n        4. Adjust phrasing to make it sound natural and fluent for french speakers, making sure idioms and expressions are culturally appropriate.\n        5. Preserve the original tone, nuance, and style, including any formatting, markdown, and structure.\n        6. Avoid adding new information or altering the core meaning.\n        7. Ensure the final result doesn't feel machine-translated but remains faithful to the source.\n        8. Make only changes that genuinely improve the text's quality in french.\n        9. Don't be too literal. If there isn't a direct translation, provide a natural-sounding translation.\n        10. If the text contains idioms or colloquialisms, translate them into the target language while maintaining their original meaning.\n        11. If the text contains technical terms or jargon, ensure that the translation is accurate and appropriate for the target audience, if there isn't a natural translation, keep it in the original language.\n        12. If there is not natural translation, keep it in the original language.\n        ",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# TRANSLATED TEXT\n_tl;dr : Élaborer un spec, puis planifier le plan, puis exécuter grâce au codegen LLM. Boucles discrètes. Et ensuite, la magie. ✩₊˚.⋆☾⋆⁺₊✧_\n\nJe construis depuis un moment plein de petits produits à l’aide des LLM. C’est à la fois amusant et utile. Mais il existe de nombreux pièges qui peuvent faire perdre un temps fou. Il y a quelque temps, un ami m’a demandé comment j’utilisais les LLM pour écrire du code. Je me suis dit : « Ohlala… tu as combien de temps ? » — d’où ce billet.\n\n(p.s. si tu détestes l’IA, va directement à la fin)\n\nJe discute souvent de tout ça avec des potes dev, et nous suivons tous à peu près la même méthode, avec quelques ajustements par-ci par-là.\n\nVoici donc mon workflow. Il s’appuie sur mon expérience perso, des échanges avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glanées dans les recoins parfois douteux d’Internet : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nÇa marche super bien **MAINTENANT**, peut-être plus du tout dans deux semaines… ou deux fois mieux. ¯\\\\\\_(ツ)\\_/¯\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images générées par IA un peu louches. Voici donc mon ange robot codeur juggalo !\" >}}\n\nIl existe plein de façons de développer, mais je me retrouve généralement dans l’un de ces deux cas :\n\n- Code neuf (greenfield)\n- Code existant relativement moderne\n\nJe vais te montrer mon process pour les deux.\n\n## Code neuf\n\nVoici le process que j’utilise pour un développement greenfield. Il fournit un cadre solide de planification et de documentation, et permet d’avancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert à droite. Leica Q, 14/05/2016\" >}}\n\n### Étape 1 : Affiner l’idée\n\nUtilise un LLM conversationnel pour peaufiner l’idée (j’emploie ChatGPT 4o / o3) :\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nÀ la fin du brainstorming (tu sentiras quand c’est fini) :\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nOn obtient alors un spec assez propre qu’on peut passer à l’étape de planification. Je le sauvegarde en général sous `spec.md` dans le repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Étape 2 : Planification\n\nPrends le spec et envoie-le à un modèle de raisonnement digne de ce nom (`o1*`, `o3*`, `r1`) :\n\n(Prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Prompt non-TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe modèle doit te sortir un « prompt plan » que tu pourras exécuter avec aider, cursor, etc. Je le sauvegarde en général sous `prompt_plan.md`.\n\nEnsuite, je lui demande de générer un `todo.md` à cocher :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nÀ mettre à la racine du repo.\n\nTon outil de codegen doit pouvoir cocher les cases du `todo.md` au fil de la session : pratique pour garder l’état.\n\n#### Hourra, un plan !\n\nTu as maintenant un plan solide et de la doc pour piloter ton projet.\n\nL’ensemble de la phase 1+2 prend **15 minutes** max. C’est fou.\n\n### Étape 3 : Exécution\n\nIl existe énormément d’outils pour cette phase. Leur réussite dépend surtout de la qualité de l’étape 2.\n\nJ’ai testé ce workflow avec [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai)… Ça marche partout.\n\nPerso je préfère **claude brut** + aider.\n\n### Claude\n\nJe fais du pair-programming sur [claude.ai](https://claude.ai) : je balance chaque prompt à la suite. Ça tourne pas mal. Les aller-retour peuvent être un peu lourds, mais globalement ça le fait.\n\nJe m’occupe du boilerplate et du setup outillage. Ça donne plus de liberté et évite que Claude ne balance d’office du React. Une bonne base claire (langage, style, tooling) aide beaucoup.\n\nQuand ça coince, j’utilise [repomix](https://github.com/yamadashy/repomix) pour passer tout le code à Claude et déboguer.\n\nWorkflow :\n\n- initialiser le repo (boilerplate, `uv init`, `cargo init`, etc.)\n- coller le prompt dans Claude\n- copier-coller le code généré dans l’IDE\n- lancer le code, les tests, etc.\n- …\n- si ça marche : prompt suivant\n- sinon : repomix + Claude pour débug\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu chelou. Ça s’imbrique bien avec la sortie de l’étape 2 et on va très loin sans effort.\n\nMême logique que ci-dessus, sauf qu’on colle les prompts dans aider.\n\nAider « fait le taf » et moi je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nGrâce aux tests, aider peut être encore plus « mains libres » : il exécute la suite et débogue tout seul.\n\nWorkflow :\n\n- initialiser le repo\n- lancer aider\n- coller le prompt\n- regarder aider danser ♪┏(・o･)┛♪\n- aider lance les tests / on vérifie l’app\n- si OK : prompt suivant\n- sinon : Q&A avec aider\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Résultats\n\nJ’ai sorti une quantité folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Franchement efficace.\n\nSi tu repousses un projet (petit ou gros), teste donc : tu seras surpris de la vitesse à laquelle ça avance.\n\nMa todo « hack » est vide, j’ai tout fait. Je découvre de nouveaux langages et outils, ça élargit vraiment mon horizon dev.\n\n## Pas de greenfield : itération incrémentale\n\nParfois, pas de page blanche : il faut enrichir un code existant.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n’est pas un champ vert. Photo au hasard venant de l’appareil de mon grand-père – quelque part en Ouganda dans les années 60\" >}}\n\nDans ce cas, méthode un peu différente : moins de plan global, plus de planification à la tâche.\n\n### Obtenir le contexte\n\nChacun a son outil fétiche pour empaqueter le code et l’injecter au LLM. Moi j’utilise [repomix](https://github.com/yamadashy/repomix) via une collection de tâches définies dans `~/.config/mise/config.toml` (voir [mise rules](https://mise.jdx.dev/)).\n\nVoici la liste de tâches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe génère un `output.txt` qui contient le contexte. Si c’est trop gros pour les tokens, j’exclus les parties inutiles.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUne fois `output.txt` prêt, je le passe à la commande [LLM](https://github.com/simonw/LLM) pour différentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn vrai, la tâche mise lance : `cat output.txt | LLM -t readme-gen > README.md` ou `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. Simple : `LLM` gère modèles, clés, templates.\n\nExemple : si je veux améliorer la couverture de tests :\n\n#### Claude\n\n- se placer dans le dossier du code\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- copier le bundle : `mise run LLM:copy_buffer_bundle`\n- coller dans Claude + premier « issue »\n- copier le code généré dans l’IDE\n- …\n- lancer tests\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- se placer dans le dossier\n- lancer aider (toujours sur une nouvelle branche)\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- coller le premier « issue » dans aider\n- regarder aider danser ♪┏(・o･)┛♪\n- …\n- lancer tests\n- rince & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nSuper efficace pour améliorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j’emploie sur du code existant :\n\n#### Revue de code\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Génération d’issues GitHub\n\n(je dois encore automatiser le post des issues !)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent à dater (« boomer prompts »). Si tu as des idées pour les améliorer, fais signe !\n\n## Ski Ⓐᨒ↟ 𖠰ᨒ↟ 𖠰\n\nQuand j’explique ce process, je dis : « il faut suivre agressivement ce qui se passe, sinon tu te fais vite dépasser ».\n\nJe parle tout le temps d’être **« over my skis »** avec les LLM — tu skies dans de la poudre parfaite, puis soudain : « MAIS QU’EST-CE QUI SE PASSE ! » et tu finis dans le ravin.\n\nLa **phase de planification** (cf. Greenfield) aide à garder le contrôle : tu as au moins un doc de référence. Les tests aussi, surtout avec aider en mode freestyle : ça reste propre et serré.\n\nMalgré tout, je me retrouve souvent **over my skis**. Parfois, une pause ou une petite marche suffit. Au fond, c’est la résolution de problème habituelle, mais à vitesse supersonique.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Je suis si seul (｡•́︿•̀｡)\n\nMon principal reproche : tout ça reste majoritairement **solo** — des interfaces « single player ».\n\nJ’ai codé des années tout seul, en pair, en équipe. C’est toujours meilleur à plusieurs. Là, les bots se cognent, les merges sont moches, le contexte est compliqué.\n\nJ’aimerais vraiment qu’on résolve ça et qu’on rende le dev avec LLM **multijoueur**. Pas juste une expérience de hacker solitaire. Il y a un monde à construire là-dessus.\n\nAU BOULOT !\n\n## ⴵ Temps ⴵ\n\nLe codegen a explosé la quantité de code qu’une seule personne peut produire. Effet secondaire bizarre : beaucoup de « temps mort » pendant que le LLM calcule.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m’en souviens comme si c’était hier\" >}}\n\nJ’ai donc modifié ma façon de travailler :\n\n- je lance le brainstorming d’un autre projet\n- j’écoute des vinyles\n- je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)\n- je discute avec des amis (et des robots)\n\nC’est génial de hacker comme ça. Hack Hack Hack. Je ne me souviens pas avoir jamais été aussi productif.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nBeaucoup de mes potes disent : « les LLM c’est nul, ça rate tout ». Je respecte cette vision, même si je ne la partage pas. Il y a de vraies raisons de se méfier de l’IA. Ma peur numéro 1 : la conso électrique et l’impact environnemental. Mais… le code doit couler. Right… *soupir*.\n\nSi tu es curieux sans vouloir devenir un « cyborg programmer », lis le bouquin d’Ethan Mollick : [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC’est une bonne intro, sans le ton bro techno-libertarien. J’ai eu plein de discussions nuancées avec des amis après l’avoir lu. Recommandé.\n\nSi tu es sceptique mais intrigué, ping moi : on peut en discuter et peut-être construire un truc ensemble.\n\n_merci à [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d’avoir relu ce billet et suggéré des modifs. Je vous en suis reconnaissant._\n\nPlease review and improve the translated text to make it natural and accurate in french.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr : Élaborer une spec, puis planifier le plan, puis exécuter grâce au codegen LLM. Boucles discrètes. Et ensuite, la magie. ✩₊˚.⋆☾⋆⁺₊✧_\n\nÇa fait un moment que je bricole plein de petits produits à l’aide des LLM. C’est à la fois amusant et utile. Mais il existe de nombreux pièges qui peuvent faire perdre un temps fou. Il y a quelque temps, un ami m’a demandé comment j’utilisais les LLM pour écrire du code. Je me suis dit : « Oh là là… tu as combien de temps ? » — d’où ce billet.\n\n(p.s. si tu détestes l’IA, file directement à la fin)\n\nJe discute souvent de tout ça avec des potes dev, et nous suivons tous à peu près la même méthode, avec quelques ajustements par-ci par-là.\n\nVoici donc mon workflow. Il s’appuie sur mon expérience perso, sur des échanges avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glanées dans les recoins parfois douteux d’Internet : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nÇa marche super bien **MAINTENANT**, peut-être plus du tout dans deux semaines… ou deux fois mieux. ¯\\\\_(ツ)_/¯\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images générées par IA un peu louches. Voici donc mon ange robot codeur juggalo !\" >}}\n\nIl existe plein de façons de développer, mais je me retrouve généralement dans l’un de ces deux cas :\n\n- Code neuf (greenfield)\n- Code existant relativement moderne\n\nJe vais te montrer mon process pour les deux.\n\n## Code neuf\n\nVoici le process que j’utilise pour un développement greenfield. Il fournit un cadre solide de planification et de documentation, et permet d’avancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert à droite. Leica Q, 14/05/2016\" >}}\n\n### Étape 1 : Affiner l’idée\n\nUtilise un LLM conversationnel pour peaufiner l’idée (j’emploie ChatGPT 4o / o3) :\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nÀ la fin du brainstorming (tu sentiras quand c’est fini) :\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nOn obtient alors une spec assez propre qu’on peut passer à l’étape de planification. Je la sauvegarde en général sous `spec.md` dans le repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Étape 2 : Planification\n\nPrends la spec et envoie-la à un modèle de raisonnement digne de ce nom (`o1*`, `o3*`, `r1`) :\n\n(Prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Prompt non-TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe modèle doit te sortir un « prompt plan » que tu pourras exécuter avec aider, cursor, etc. Je le sauvegarde en général sous `prompt_plan.md`.\n\nEnsuite, je lui demande de générer un `todo.md` à cocher :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nÀ mettre à la racine du repo.\n\nTon outil de codegen doit pouvoir cocher les cases du `todo.md` au fil de la session : pratique pour garder l’état.\n\n#### Hourra, un plan !\n\nTu as maintenant un plan solide et une doc pour piloter ton projet.\n\nL’ensemble de la phase 1+2 prend **15 minutes** maxi. C’est fou.\n\n### Étape 3 : Exécution\n\nIl existe énormément d’outils pour cette phase. Leur réussite dépend surtout de la qualité de l’étape 2.\n\nJ’ai testé ce workflow avec [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai)… Ça marche partout.\n\nPerso, je préfère **Claude brut** et aider.\n\n### Claude\n\nJe fais du pair-programming sur [claude.ai](https://claude.ai) : je balance chaque prompt à la suite. Ça tourne pas mal. Les allers-retours peuvent être un peu lourds, mais globalement ça le fait.\n\nJe m’occupe du boilerplate et du setup tooling. Ça donne plus de liberté et évite que Claude ne sorte direct du React. Une bonne base claire (langage, style, tooling) aide beaucoup.\n\nQuand ça coince, j’utilise [repomix](https://github.com/yamadashy/repomix) pour passer tout le code à Claude et déboguer.\n\nWorkflow :\n\n- initialiser le repo (boilerplate, `uv init`, `cargo init`, etc.)\n- coller le prompt dans Claude\n- copier-coller le code généré dans l’IDE\n- lancer le code, les tests, etc.\n- …\n- si ça marche : prompt suivant\n- sinon : repomix + Claude pour déboguer\n- rinse & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu chelou. Ça s’imbrique bien avec la sortie de l’étape 2 et on va très loin sans effort.\n\nMême logique que ci-dessus, sauf qu’on colle les prompts dans aider.\n\nAider « fait le taf » et moi je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nGrâce aux tests, aider peut être encore plus « mains libres » : il exécute la suite et débogue tout seul.\n\nWorkflow :\n\n- initialiser le repo\n- lancer aider\n- coller le prompt\n- regarder aider danser ♪┏(・o･)┛♪\n- aider lance les tests / on vérifie l’app\n- si OK : prompt suivant\n- sinon : Q&A avec aider\n- rinse & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Résultats\n\nJ’ai sorti une quantité folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Franchement efficace.\n\nSi tu repousses un projet (petit ou gros), teste donc : tu seras surpris de la vitesse à laquelle ça avance.\n\nMa todo « hack » est vide, j’ai tout fait. Je découvre de nouveaux langages et outils ; ça élargit vraiment mon horizon dev.\n\n## Pas de greenfield : itération incrémentale\n\nParfois, pas de page blanche : il faut enrichir un code existant.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n’est pas un champ vert. Photo au hasard venant de l’appareil de mon grand-père – quelque part en Ouganda dans les années 60\" >}}\n\nDans ce cas, méthode un peu différente : moins de plan global, plus de planification à la tâche.\n\n### Obtenir le contexte\n\nChacun a son outil fétiche pour empaqueter le code et l’injecter au LLM. Moi, j’utilise [repomix](https://github.com/yamadashy/repomix) via une collection de tâches définies dans `~/.config/mise/config.toml` (voir [mise rules](https://mise.jdx.dev/)).\n\nVoici la liste de tâches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe génère un `output.txt` qui contient le contexte. Si c’est trop gros pour les tokens, j’exclus les parties inutiles.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUne fois `output.txt` prêt, je le passe à la commande [LLM](https://github.com/simonw/LLM) pour différentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn pratique, la tâche mise lance : `cat output.txt | LLM -t readme-gen > README.md` ou `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. Simple : `LLM` gère modèles, clés et templates.\n\nExemple : si je veux améliorer la couverture de tests :\n\n#### Claude\n\n- se placer dans le dossier du code  \n- `mise run LLM:generate_missing_tests`  \n- ouvrir `missing-tests.md`  \n- copier le bundle : `mise run LLM:copy_buffer_bundle`  \n- coller dans Claude + premier « issue »  \n- copier le code généré dans l’IDE  \n- …  \n- lancer les tests  \n- rinse & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- se placer dans le dossier  \n- lancer aider (toujours sur une nouvelle branche)  \n- `mise run LLM:generate_missing_tests`  \n- ouvrir `missing-tests.md`  \n- coller le premier « issue » dans aider  \n- regarder aider danser ♪┏(・o･)┛♪  \n- …  \n- lancer les tests  \n- rinse & repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nSuper efficace pour améliorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j’emploie sur du code existant :\n\n#### Revue de code\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Génération d’issues GitHub\n\n(je dois encore automatiser le post des issues !)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent à dater (« boomer prompts »). Si tu as des idées pour les améliorer, fais-moi signe !\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nQuand j’explique ce process, je dis : « il faut suivre agressivement ce qui se passe, sinon tu te fais vite dépasser ».\n\nJe parle tout le temps d’être **« over my skis »** avec les LLM — tu skies dans de la poudre parfaite, puis soudain : « MAIS QU’EST-CE QUI SE PASSE ! » et tu finis dans le ravin.\n\nLa **phase de planification** (cf. Greenfield) aide à garder le contrôle : tu as au moins un doc de référence. Les tests aussi, surtout avec aider en mode freestyle : ça reste propre et serré.\n\nMalgré tout, je me retrouve souvent **over my skis**. Parfois, une pause ou une petite marche suffit. Au fond, c’est la résolution de problèmes habituelle, mais à vitesse supersonique.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Je suis si seul (｡•́︿•̀｡)\n\nMon principal reproche : tout ça reste majoritairement **solo** — des interfaces « single player ».\n\nJ’ai codé des années tout seul, en pair, en équipe. C’est toujours meilleur à plusieurs. Là, les bots se cognent, les merges sont moches, le contexte est compliqué.\n\nJ’aimerais vraiment qu’on résolve ça et qu’on rende le dev avec LLM **multijoueur**. Pas juste une expérience de hacker solitaire. Il y a un monde à construire là-dessus.\n\nAU BOULOT !\n\n## ⴵ Temps ⴵ\n\nLe codegen a explosé la quantité de code qu’une seule personne peut produire. Effet secondaire bizarre : beaucoup de « temps mort » pendant que le LLM calcule.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m’en souviens comme si c’était hier\" >}}\n\nJ’ai donc adapté ma façon de travailler :\n\n- je lance le brainstorming d’un autre projet  \n- j’écoute des vinyles  \n- je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)  \n- je discute avec des amis (et des robots)\n\nC’est génial de hacker comme ça. Hack ! Hack ! Hack ! Je ne me souviens pas avoir jamais été aussi productif.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nBeaucoup de mes potes disent : « les LLM c’est nul, ça rate tout ». Je respecte cette vision, même si je ne la partage pas. Il y a de vraies raisons de se méfier de l’IA. Ma peur numéro 1 : la consommation électrique et l’impact environnemental. Mais… le code doit couler. Right… *soupir*.\n\nSi tu es curieux sans vouloir devenir un « cyborg programmer », lis le bouquin d’Ethan Mollick : [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC’est une bonne intro, sans le ton bro techno-libertarien. J’ai eu plein de discussions nuancées avec des amis après l’avoir lu. Recommandé.\n\nSi tu es sceptique mais intrigué, fais-moi signe : on peut en discuter et peut-être construire un truc ensemble.\n\n_merci à [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d’avoir relu ce billet et suggéré des modifs. Je vous suis reconnaissant._",
      "usage": {
        "prompt_tokens": 9466,
        "completion_tokens": 4307,
        "total_tokens": 13773
      },
      "streaming": true
    },
    "critique": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "You are a highly critical professional translator and linguistic expert specializing in french.\nYour task is to ruthlessly critique the translation by:\n\n1. Meticulously comparing the translated text with the original, identifying ANY inaccuracies, mistranslations, or omissions\n2. Highlighting nuances, cultural references, or idioms that were lost or mistranslated\n3. Scrutinizing for grammatical errors, awkward phrasing, or unnatural expressions in french\n4. Checking for inconsistencies in tone, style, or register compared to the original\n5. Verifying that technical terms are translated accurately and consistently\n6. Ensuring no content was accidentally skipped or added\n7. Finding places where the translation sounds machine-like or overly literal\n\nBe extremely thorough and critical in your assessment. Do not accept mediocre translations.\nList specific issues and suggestions for improvement, organized by severity and category.\nYour critique should be detailed enough for another translator to address all the issues.\n\nYour goal is to help create a perfect translation that reads as if originally written in french while being 100% faithful to the source.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr : brainstorme la spec, puis fais un plan, puis exécute la génération de code (codegen) avec un LLM. Cycles bien distincts, puis magie. ✩₊˚.⋆☾⋆⁺₊✧_\n\nJe bricole depuis un moment plein de petits projets grâce aux modèles de langage (LLM). C’est amusant – et utile. Mais il y a aussi des pièges qui peuvent faire perdre un temps fou. Un jour, un ami m’a demandé comment j’utilisais les LLM pour coder. Je me suis dit : « Oh là là ! T’as combien de temps devant toi ? » – d’où ce billet.\n\n(p.s. si tu détestes l’IA, file directement à la fin)\n\nJ’en parle souvent avec des potes dev, et on suit tous à peu près la même approche, chacun avec ses petits ajustements.\n\nVoici donc mon flux de travail. Il repose sur mon expérience perso, sur des échanges avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur des bonnes pratiques dénichées dans les recoins (parfois douteux) du Net : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nÇa marche super bien **POUR L’INSTANT** ; dans deux semaines ce sera peut-être cassé… ou deux fois plus efficace. ¯\\\\_(ツ)_/¯\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images générées par IA un peu louches. Voici mon ange-robot codeur façon juggalo !\" >}}\n\nIl y a mille façons de développer, mais je tombe généralement sur l’un de ces deux cas :\n\n- projet greenfield (tout est à créer) ;\n- code existant relativement moderne (brownfield).\n\nJe vais te montrer mon processus pour les deux.\n\n## Greenfield\n\nPour un projet greenfield, ce processus marche bien : il offre un cadre solide de planification et de documentation, et permet d’avancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert à droite. Leica Q, 14/05/2016\" >}}\n\n### Étape 1 : affiner l’idée\n\nUtilise un LLM conversationnel pour peaufiner l’idée (j’emploie ChatGPT 4o / o3) :\n\n(Conserve le prompt en anglais, c’est la langue attendue par les LLM.)\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nÀ la fin du remue-méninges (tu sentiras quand c’est terminé) :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nTu obtiens alors une spec assez propre qu’on peut passer à la phase de planification. Je la sauvegarde en général sous `spec.md`.\n\n> On peut faire plein de choses avec cette spec. Ici on vise le codegen, mais je m’en sers aussi pour demander à un modèle spécialisé dans le raisonnement de trouver les failles (toujours plus loin !), pour rédiger un livre blanc (white paper) ou imaginer un business model. Tu peux même l’envoyer dans une phase de recherche poussée et récupérer un doc de 10 000 mots en retour.\n\n### Étape 2 : planification\n\nPrends la spec et envoie-la à un modèle orienté raisonnement (`o1*`, `o3*`, `r1`) :\n\n#### Prompt TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n#### Prompt non-TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe modèle te sort un plan de prompts (`prompt_plan.md`) que tu pourras exécuter avec Aider, Cursor, etc.\n\nDemande-lui ensuite un `todo.md` à cocher :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nTon outil de codegen pourra cocher le `todo.md` au fil de la session – parfait pour garder l’état.\n\n#### Youpi : un plan !\n\nTu as maintenant un plan solide et une doc pour piloter ton projet.\n\nCes deux premières étapes prennent au plus **15 minutes**. Franchement dingue.\n\n### Étape 3 : exécution\n\nIl existe une foule d’outils pour cette phase ; leur succès dépend surtout de la qualité de l’étape 2.\n\nJ’ai testé ce workflow avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [claude-engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)… Ça marche avec tous ceux que j’ai essayés.\n\nPerso, je préfère Claude en mode « raw » (brut) et Aider.\n\n### Claude\n\nJe fais du pair programming sur [Claude.ai](https://claude.ai) : je balance chaque prompt, un à un. Les allers-retours sont parfois lourds, mais ça fonctionne.\n\nJe m’occupe du boilerplate (ossature) et du setup tooling. Ça évite que Claude ne parte direct sur du React et me laisse choisir la stack.\n\nQuand ça coince, j’utilise [repomix](https://github.com/yamadashy/repomix) pour envoyer tout le code à Claude et déboguer.\n\nWorkflow :\n\n- initialiser le dépôt (`uv init`, `cargo init`, etc.) ;  \n- coller le prompt dans Claude ;  \n- copier-coller le code généré dans l’IDE ;  \n- lancer l’appli et les tests ;  \n- …  \n- si ça marche : prompt suivant ;  \n- sinon : repomix + Claude pour déboguer ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu bizarre. Il se greffe bien sur la sortie de l’étape 2 et on va très loin sans effort.\n\nMême logique que ci-dessus, sauf qu’on colle les prompts dans Aider.\n\nAider « fait le taf » et moi je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> Au passage, Aider publie d’excellents benchmarks de modèles de codegen dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/). Pratique pour voir la perf des nouveautés.\n\nGrâce aux tests, Aider peut être encore plus mains libres : il exécute la suite et débogue tout seul.\n\nWorkflow :\n\n- initialiser le dépôt ;  \n- lancer Aider ;  \n- coller le prompt ;  \n- regarder Aider danser ♪┏(・o･)┛♪ ;  \n- Aider lance les tests / ou tu lances l’appli ;  \n- si OK : prompt suivant ;  \n- sinon : Q&A avec Aider ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\n### Résultats\n\nJ’ai sorti une quantité folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Super efficace.\n\nMa todo « hack » est vide parce que j’ai tout fait. Je continue d’avoir de nouvelles idées que je décoche à la chaîne en matant un film. Pour la première fois depuis des années, je passe du temps sur de nouveaux langages et outils ; ça élargit vraiment mon horizon.\n\n## Brownfield : itération incrémentale\n\nParfois, on n’est pas en terrain vierge : il faut améliorer une base de code existante (brownfield).\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n’est pas un champ vert. Photo prise par mon grand-père – Ouganda, années 60\" >}}\n\nDans ce cas, méthode un peu différente : moins de plan global, plus de planification à la tâche.\n\n### Obtenir le contexte\n\nChacun a son outil fétiche pour empaqueter le code et l’injecter au LLM. Moi, j’utilise [repomix](https://github.com/yamadashy/repomix) via des tâches définies dans `~/.config/mise/config.toml` (voir les [règles mise](https://mise.jdx.dev/)).\n\nListe des tâches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe génère un `output.txt` qui contient tout le contexte. Si c’est trop gros pour les jetons, j’exclus les parties inutiles.\n\n> Ce qui est top avec `mise`, c’est que les tâches peuvent être redéfinies ou surchargées dans le `.mise.toml` du projet. Je peux utiliser un autre outil pour empaqueter le code ; tant qu’il produit un `output.txt`, mes tâches LLM fonctionnent. Très pratique quand les bases de code diffèrent. Je surcharge souvent l’étape `repomix` pour élargir les patterns d’ignore ou j’utilise un outil plus efficace.\n\nUne fois `output.txt` prêt, je le passe à la commande [LLM](https://github.com/simonw/LLM) pour différentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn pratique, la tâche `mise` lance :\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nou :\n\n```\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nSimple : `LLM` gère modèles, clés et templates.\n\nExemple : améliorer la couverture de tests.\n\n#### Claude\n\n- se placer dans le dossier du code ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- copier le bundle : `mise run LLM:copy_buffer_bundle` ;  \n- coller dans Claude avec la première « issue » ;  \n- copier le code généré dans l’IDE ;  \n- lancer les tests ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- se placer dans le dossier ;  \n- lancer Aider (toujours sur une nouvelle branche) ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- coller la première « issue » dans Aider ;  \n- regarder Aider danser ♪┏(・o･)┛♪ ;  \n- lancer les tests ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\nSuper efficace pour améliorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j’utilise sur du code existant :\n\n#### Revue de code\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Génération d’issues GitHub\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent à dater (« prompts de boomer »). Si tu as des idées pour les améliorer, dis-moi !\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nQuand j’explique ce procédé, je dis toujours : « Il faut suivre de près ce qui se passe, sinon tu te retrouves vite les spatules dans le vide. »\n\nJe parle souvent d’être **over my skis** avec les LLM : tu skies dans de la poudre parfaite, puis soudain « MAIS QU’EST-CE QUI SE PASSE ? » et tu bascules dans le ravin.\n\nLa **phase de planification** (cf. greenfield) aide à garder le contrôle : tu as au moins un doc de référence. Les tests aussi, surtout avec Aider en mode freestyle : ça reste propre et serré.\n\nMalgré tout, je me retrouve souvent **over my skis**. Parfois une pause ou une petite marche suffit. Au fond, c’est la résolution de problèmes habituelle, mais à vitesse supersonique.\n\n> On demande parfois au LLM d’ajouter des trucs complètement absurdes dans un code pas si absurde. Par exemple, on lui a demandé de créer un fichier de lore puis d’y faire référence dans l’interface utilisateur d’un outil CLI Python. D’un coup, il y a du lore, des interfaces glitchy, etc. Tout ça pour gérer tes fonctions cloud, ta todo list ou autre. Le ciel est la limite.\n\n## Je suis si seul (｡•́︿•̀｡)\n\nPrincipal reproche : tout ça reste majoritairement **solo** – des interfaces « single player ».\n\nJ’ai codé des années seul, en pair, en équipe. C’est toujours meilleur à plusieurs. Là, les bots se télescopent, les conflits de fusion deviennent horribles, le contexte est compliqué.\n\nJ’aimerais vraiment qu’on rende le dev avec LLM **multijoueur**, pas juste une expérience de hacker solitaire. Il y a un monde à construire là-dessus.\n\nAU BOULOT !\n\n## ⴵ Temps ⴵ\n\nLe codegen a explosé la quantité de code qu’une personne peut produire. Effet secondaire bizarre : beaucoup de temps mort pendant que le LLM brûle ses jetons.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m’en souviens comme si c’était hier\" >}}\n\nDu coup, j’ai adapté ma façon de bosser :\n\n- je démarre le brainstorming d’un autre projet ;  \n- j’écoute des disques vinyles ;  \n- je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) ;  \n- je discute avec des amis et des robots.\n\nC’est génial de hacker comme ça. Hack ! Hack ! Hack ! Je ne me souviens pas avoir été aussi productif.\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\nPas mal de potes me disent : « Les LLM, c’est de la daube. » Je respecte ce point de vue, même si je ne le partage pas. Il y a de vraies raisons de se méfier de l’IA. Ma peur numéro 1 : la conso électrique et l’impact environnemental. Mais… le code doit couler. *soupir*\n\nSi tu es curieux sans vouloir devenir un « cyborg programmer », lis le livre d’Ethan Mollick : [**Co-Intelligence : Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC’est une bonne intro, sans le ton bro techno-libertarien. J’ai eu plein de discussions nuancées avec des amis après l’avoir lu. Recommandé.\n\nSi tu es sceptique mais un peu curieux, contacte-moi et on parlera de toute cette folie. Je peux te montrer comment on utilise les LLM et, qui sait, on pourrait construire un truc ensemble.\n\n_merci à [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d’avoir relu ce billet et proposé des modifs. Je vous suis reconnaissant._\n\nPlease critique this translation mercilessly and provide detailed feedback on what needs to be improved.\nFormat your critique as a structured list of issues, organized by severity and category.\nInclude specific suggestions for how to fix each issue.",
      "response": "CRITIQUE DÉTAILLÉE DE LA TRADUCTION  \n(les numéros renvoient aux passages dans le texte français actuel)\n\n====================================================================\nI. PROBLÈMES CRITIQUES : SENS, FIDÉ­LITÉ, OMISSIONS\n--------------------------------------------------------------------\n1. Slogan d’ouverture  \n   FR : « brainstorme la spec, puis fais un plan »  \n   • Perte du clin-d’œil « plan a plan » (double emploi volontairement absurde).  \n   • Suggestion : « … puis élabore un plan de plan … ».\n\n2. Catégorie « Legacy modern code »  \n   FR : « code existant relativement moderne (brownfield) »  \n   • « Legacy modern code » est oxymorique ; employer « code existant “moderne mais déjà legacy” » ou conserver la tournure ironique pour ne pas lisser le propos.  \n   • « Brownfield » n’apparaît pas dans l’original ici ; l’introduire peut semer la confusion (l’auteur l’utilise plus tard).\n\n3. Titre « ## Brownfield : itération incrémentale »  \n   • L’original : « ## Non-greenfield: Iteration, incrementally ».  \n   • Passer de « Non-greenfield » à « Brownfield » gomme la nuance (tout projet ≠ greenfield n’est pas forcément brownfield).  \n   • Proposer « ## Non-greenfield : itérations incrémentales ».\n\n4. « Je bricole… plein de petits projets »  \n   • « I have been building so many small products » = créer/fabriquer, pas « bricoler ».  \n   • « Bricoler » sous-entend amateurisme que l’auteur ne revendique pas.  \n   • Remplacer par « Je développe / je réalise ».\n\n5. Omission de nuance – Step 3 (« I, however, prefer **raw** claude… »)  \n   • Le texte FR garde « raw », mais perd l’idée que l’auteur préfère « claude brut (sans interface) ».  \n   • Ajouter explicitement « … en mode brut (sans surcouche) ».\n\n====================================================================\nII. PROBLÈMES MAJEURS : TON, STYLE, REGISTRE\n--------------------------------------------------------------------\n6. Oscillation « tu / vous »  \n   Exemples :  \n   6a) « (p.s. si tu détestes…) » vs « Conserve le prompt… c’est la langue attendue » (impersonnel).  \n   6b) « Votre outil de codegen pourra… ».  \n   • Choisir un vouvoiement ou un tutoiement constant (le tutoiement semble privilégié).  \n   • Harmoniser dans tout le doc, y compris les listes et encadrés.\n\n7. Anglicismes crus non justifiés  \n   « brainstorme », « spec », « prompt », « codegen », « brownfield », « workflow », etc.  \n   • Tolérés dans la communauté dev mais l’original montre aussi un registre relâché ; décider d’un équilibre. Proposer :  \n     – « séance de brainstorming », « spécification », « génération de code », « flux de travail ».  \n   • Conserver les mots-clefs techniques (« prompt »…) quand ils sont intraduisibles, mais franciser le reste.\n\n8. Ton humoristique un peu lissé  \n   • « Oh boy. how much time do you have! » → « Oh là là ! » correct mais moins moqueur ; on peut ajouter « — t’as combien d’heures devant toi ? ».  \n   • « rinse repeat ✩₊˚.⋆☾⋆⁺₊✧ » rendu littéral mais la blague (« rinse and repeat ») pourrait être traduite : « et on recommence, encore et encore ✩… ».\n\n====================================================================\nIII. PROBLÈMES MOYENS : GRAMMAIRE, SYNTAXE, FLUIDITÉ\n--------------------------------------------------------------------\n9. Ponctuation et espaces insécables  \n   • En français, espace insécable avant « ; », « : », « ? », « ! » (« tl;dr : », « Merci : »…).  \n   • Ajouter insécables ou au moins espaces simples corrects.\n\n10. Inversions malhabiles  \n    « Voici donc mon flux de travail. Il repose sur mon expérience perso… »  \n    • « mon expérience perso » = registre oral ; envisager « mon expérience personnelle ».\n\n11. Faux amis / registres  \n    « Je décoche à la chaîne » (anglicisme passif de « knocking them out ») sonne étrange.  \n    • « j’enchaîne les idées », « je les réalise à la chaîne ».\n\n12. Parenthèses excessives  \n    • Plusieurs digressions pourraient être encadrées par tirets cadratins ou virgules pour alléger la lecture.\n\n====================================================================\nIV. PROBLÈMES MINEURS : TERMINOLOGIE, DÉTAILS TECHNIQUES\n--------------------------------------------------------------------\n13. « cookie clicker »  \n    • Le lien est conservé mais « Cookie Clicker » est un nom propre ; capitaliser systématiquement.\n\n14. « disques vinyles »  \n    • « j’écoute des vinyles » plus naturel pour un francophone.\n\n15. « UV init »  \n    • Vérifier si « uv » (gestionnaire Python) doit rester en minuscule.\n\n16. « repomix pour envoyer tout le code à Claude »  \n    • Ajouter une explication rapide : « repomix ‑ un empaqueteur de repo ‑… » pour le lecteur français qui ne connaît pas.\n\n====================================================================\nV. SONS « MACHINE / LITTÉRAL »\n--------------------------------------------------------------------\n17. Maintien systématique de balises « (Conserve le prompt en anglais.) »  \n    • Répétition mécanique. Une phrase unique au début de la section suffirait.\n\n18. Traductions ligne-à-ligne des listes  \n    • Certaines listes (workflow) auraient pu être reformulées pour éviter le copier-coller anglais → français (« set up le repo (boilerplate…) »).  \n    • Proposer une version fluide : « – initialise le dépôt (boilerplate, uv init, cargo init, etc.) ».\n\n====================================================================\nVI. SUGGESTIONS GÉNÉRALES DE RÉVISION\n--------------------------------------------------------------------\n1. Clarifier et uniformiser le registre (tutoiement) sur tout le document.  \n2. Franciser la plupart des termes sauf quand l’anglais est incontournable pour les devs.  \n3. Rétablir les clins d’œil et oxymores de l’original (« plan a plan », « Legacy modern code », etc.).  \n4. Réduire les anglicismes traduits littéralement (« bricoler » → « développer », « décoche » → « finalise »).  \n5. Appliquer la typographie française (espaces avant ponctuation double, guillemets français si désiré).  \n6. Regrouper les indications « prompt à laisser en anglais » pour fluidifier.  \n7. Relire en entier pour fluidité : coupes, parenthèses,/ou digressions.\n\nEn appliquant ces corrections, la traduction gagnera en naturel, en cohérence et en fidélité au ton facétieux de l’auteur tout en restant parfaitement intelligible pour un lectorat francophone de développeurs.",
      "usage": {
        "prompt_tokens": 9584,
        "completion_tokens": 1740,
        "total_tokens": 11324
      },
      "streaming": true
    },
    "feedback": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "You are a master translator and editor specializing in french.\nYour task is to improve a translation based on detailed critique feedback.\n\n1. Carefully read the original text, current translation, and the critique feedback\n2. Address ALL issues identified in the critique\n3. Apply the specific suggestions for improvement\n4. Ensure the translation is accurate, natural-sounding, and faithful to the original\n5. Preserve all formatting, markdown, and structure of the original text\n6. Make sure the final text reads as if it were originally written in french\n\nDo not ignore any of the critique points. Every issue identified must be addressed in your improved version.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr : brainstorme la spec, puis fais un plan, puis exécute la génération de code (codegen) avec un LLM. Cycles bien distincts, puis magie. ✩₊˚.⋆☾⋆⁺₊✧_\n\nJe bricole depuis un moment plein de petits projets grâce aux modèles de langage (LLM). C’est amusant – et utile. Mais il y a aussi des pièges qui peuvent faire perdre un temps fou. Un jour, un ami m’a demandé comment j’utilisais les LLM pour coder. Je me suis dit : « Oh là là ! T’as combien de temps devant toi ? » – d’où ce billet.\n\n(p.s. si tu détestes l’IA, file directement à la fin)\n\nJ’en parle souvent avec des potes dev, et on suit tous à peu près la même approche, chacun avec ses petits ajustements.\n\nVoici donc mon flux de travail. Il repose sur mon expérience perso, sur des échanges avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur des bonnes pratiques dénichées dans les recoins (parfois douteux) du Net : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nÇa marche super bien **POUR L’INSTANT** ; dans deux semaines ce sera peut-être cassé… ou deux fois plus efficace. ¯\\\\_(ツ)_/¯\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images générées par IA un peu louches. Voici mon ange-robot codeur façon juggalo !\" >}}\n\nIl y a mille façons de développer, mais je tombe généralement sur l’un de ces deux cas :\n\n- projet greenfield (tout est à créer) ;\n- code existant relativement moderne (brownfield).\n\nJe vais te montrer mon processus pour les deux.\n\n## Greenfield\n\nPour un projet greenfield, ce processus marche bien : il offre un cadre solide de planification et de documentation, et permet d’avancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert à droite. Leica Q, 14/05/2016\" >}}\n\n### Étape 1 : affiner l’idée\n\nUtilise un LLM conversationnel pour peaufiner l’idée (j’emploie ChatGPT 4o / o3) :\n\n(Conserve le prompt en anglais, c’est la langue attendue par les LLM.)\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nÀ la fin du remue-méninges (tu sentiras quand c’est terminé) :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nTu obtiens alors une spec assez propre qu’on peut passer à la phase de planification. Je la sauvegarde en général sous `spec.md`.\n\n> On peut faire plein de choses avec cette spec. Ici on vise le codegen, mais je m’en sers aussi pour demander à un modèle spécialisé dans le raisonnement de trouver les failles (toujours plus loin !), pour rédiger un livre blanc (white paper) ou imaginer un business model. Tu peux même l’envoyer dans une phase de recherche poussée et récupérer un doc de 10 000 mots en retour.\n\n### Étape 2 : planification\n\nPrends la spec et envoie-la à un modèle orienté raisonnement (`o1*`, `o3*`, `r1`) :\n\n#### Prompt TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n#### Prompt non-TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe modèle te sort un plan de prompts (`prompt_plan.md`) que tu pourras exécuter avec Aider, Cursor, etc.\n\nDemande-lui ensuite un `todo.md` à cocher :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nTon outil de codegen pourra cocher le `todo.md` au fil de la session – parfait pour garder l’état.\n\n#### Youpi : un plan !\n\nTu as maintenant un plan solide et une doc pour piloter ton projet.\n\nCes deux premières étapes prennent au plus **15 minutes**. Franchement dingue.\n\n### Étape 3 : exécution\n\nIl existe une foule d’outils pour cette phase ; leur succès dépend surtout de la qualité de l’étape 2.\n\nJ’ai testé ce workflow avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [claude-engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)… Ça marche avec tous ceux que j’ai essayés.\n\nPerso, je préfère Claude en mode « raw » (brut) et Aider.\n\n### Claude\n\nJe fais du pair programming sur [Claude.ai](https://claude.ai) : je balance chaque prompt, un à un. Les allers-retours sont parfois lourds, mais ça fonctionne.\n\nJe m’occupe du boilerplate (ossature) et du setup tooling. Ça évite que Claude ne parte direct sur du React et me laisse choisir la stack.\n\nQuand ça coince, j’utilise [repomix](https://github.com/yamadashy/repomix) pour envoyer tout le code à Claude et déboguer.\n\nWorkflow :\n\n- initialiser le dépôt (`uv init`, `cargo init`, etc.) ;  \n- coller le prompt dans Claude ;  \n- copier-coller le code généré dans l’IDE ;  \n- lancer l’appli et les tests ;  \n- …  \n- si ça marche : prompt suivant ;  \n- sinon : repomix + Claude pour déboguer ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu bizarre. Il se greffe bien sur la sortie de l’étape 2 et on va très loin sans effort.\n\nMême logique que ci-dessus, sauf qu’on colle les prompts dans Aider.\n\nAider « fait le taf » et moi je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> Au passage, Aider publie d’excellents benchmarks de modèles de codegen dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/). Pratique pour voir la perf des nouveautés.\n\nGrâce aux tests, Aider peut être encore plus mains libres : il exécute la suite et débogue tout seul.\n\nWorkflow :\n\n- initialiser le dépôt ;  \n- lancer Aider ;  \n- coller le prompt ;  \n- regarder Aider danser ♪┏(・o･)┛♪ ;  \n- Aider lance les tests / ou tu lances l’appli ;  \n- si OK : prompt suivant ;  \n- sinon : Q&A avec Aider ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\n### Résultats\n\nJ’ai sorti une quantité folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Super efficace.\n\nMa todo « hack » est vide parce que j’ai tout fait. Je continue d’avoir de nouvelles idées que je décoche à la chaîne en matant un film. Pour la première fois depuis des années, je passe du temps sur de nouveaux langages et outils ; ça élargit vraiment mon horizon.\n\n## Brownfield : itération incrémentale\n\nParfois, on n’est pas en terrain vierge : il faut améliorer une base de code existante (brownfield).\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n’est pas un champ vert. Photo prise par mon grand-père – Ouganda, années 60\" >}}\n\nDans ce cas, méthode un peu différente : moins de plan global, plus de planification à la tâche.\n\n### Obtenir le contexte\n\nChacun a son outil fétiche pour empaqueter le code et l’injecter au LLM. Moi, j’utilise [repomix](https://github.com/yamadashy/repomix) via des tâches définies dans `~/.config/mise/config.toml` (voir les [règles mise](https://mise.jdx.dev/)).\n\nListe des tâches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe génère un `output.txt` qui contient tout le contexte. Si c’est trop gros pour les jetons, j’exclus les parties inutiles.\n\n> Ce qui est top avec `mise`, c’est que les tâches peuvent être redéfinies ou surchargées dans le `.mise.toml` du projet. Je peux utiliser un autre outil pour empaqueter le code ; tant qu’il produit un `output.txt`, mes tâches LLM fonctionnent. Très pratique quand les bases de code diffèrent. Je surcharge souvent l’étape `repomix` pour élargir les patterns d’ignore ou j’utilise un outil plus efficace.\n\nUne fois `output.txt` prêt, je le passe à la commande [LLM](https://github.com/simonw/LLM) pour différentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn pratique, la tâche `mise` lance :\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nou :\n\n```\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nSimple : `LLM` gère modèles, clés et templates.\n\nExemple : améliorer la couverture de tests.\n\n#### Claude\n\n- se placer dans le dossier du code ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- copier le bundle : `mise run LLM:copy_buffer_bundle` ;  \n- coller dans Claude avec la première « issue » ;  \n- copier le code généré dans l’IDE ;  \n- lancer les tests ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- se placer dans le dossier ;  \n- lancer Aider (toujours sur une nouvelle branche) ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- coller la première « issue » dans Aider ;  \n- regarder Aider danser ♪┏(・o･)┛♪ ;  \n- lancer les tests ;  \n- on recommence ✩₊˚.⋆☾⋆⁺₊✧\n\nSuper efficace pour améliorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j’utilise sur du code existant :\n\n#### Revue de code\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Génération d’issues GitHub\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent à dater (« prompts de boomer »). Si tu as des idées pour les améliorer, dis-moi !\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nQuand j’explique ce procédé, je dis toujours : « Il faut suivre de près ce qui se passe, sinon tu te retrouves vite les spatules dans le vide. »\n\nJe parle souvent d’être **over my skis** avec les LLM : tu skies dans de la poudre parfaite, puis soudain « MAIS QU’EST-CE QUI SE PASSE ? » et tu bascules dans le ravin.\n\nLa **phase de planification** (cf. greenfield) aide à garder le contrôle : tu as au moins un doc de référence. Les tests aussi, surtout avec Aider en mode freestyle : ça reste propre et serré.\n\nMalgré tout, je me retrouve souvent **over my skis**. Parfois une pause ou une petite marche suffit. Au fond, c’est la résolution de problèmes habituelle, mais à vitesse supersonique.\n\n> On demande parfois au LLM d’ajouter des trucs complètement absurdes dans un code pas si absurde. Par exemple, on lui a demandé de créer un fichier de lore puis d’y faire référence dans l’interface utilisateur d’un outil CLI Python. D’un coup, il y a du lore, des interfaces glitchy, etc. Tout ça pour gérer tes fonctions cloud, ta todo list ou autre. Le ciel est la limite.\n\n## Je suis si seul (｡•́︿•̀｡)\n\nPrincipal reproche : tout ça reste majoritairement **solo** – des interfaces « single player ».\n\nJ’ai codé des années seul, en pair, en équipe. C’est toujours meilleur à plusieurs. Là, les bots se télescopent, les conflits de fusion deviennent horribles, le contexte est compliqué.\n\nJ’aimerais vraiment qu’on rende le dev avec LLM **multijoueur**, pas juste une expérience de hacker solitaire. Il y a un monde à construire là-dessus.\n\nAU BOULOT !\n\n## ⴵ Temps ⴵ\n\nLe codegen a explosé la quantité de code qu’une personne peut produire. Effet secondaire bizarre : beaucoup de temps mort pendant que le LLM brûle ses jetons.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m’en souviens comme si c’était hier\" >}}\n\nDu coup, j’ai adapté ma façon de bosser :\n\n- je démarre le brainstorming d’un autre projet ;  \n- j’écoute des disques vinyles ;  \n- je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) ;  \n- je discute avec des amis et des robots.\n\nC’est génial de hacker comme ça. Hack ! Hack ! Hack ! Je ne me souviens pas avoir été aussi productif.\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\nPas mal de potes me disent : « Les LLM, c’est de la daube. » Je respecte ce point de vue, même si je ne le partage pas. Il y a de vraies raisons de se méfier de l’IA. Ma peur numéro 1 : la conso électrique et l’impact environnemental. Mais… le code doit couler. *soupir*\n\nSi tu es curieux sans vouloir devenir un « cyborg programmer », lis le livre d’Ethan Mollick : [**Co-Intelligence : Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC’est une bonne intro, sans le ton bro techno-libertarien. J’ai eu plein de discussions nuancées avec des amis après l’avoir lu. Recommandé.\n\nSi tu es sceptique mais un peu curieux, contacte-moi et on parlera de toute cette folie. Je peux te montrer comment on utilise les LLM et, qui sait, on pourrait construire un truc ensemble.\n\n_merci à [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d’avoir relu ce billet et proposé des modifs. Je vous suis reconnaissant._\n\n# CRITIQUE FEEDBACK\nCRITIQUE DÉTAILLÉE DE LA TRADUCTION  \n(les numéros renvoient aux passages dans le texte français actuel)\n\n====================================================================\nI. PROBLÈMES CRITIQUES : SENS, FIDÉ­LITÉ, OMISSIONS\n--------------------------------------------------------------------\n1. Slogan d’ouverture  \n   FR : « brainstorme la spec, puis fais un plan »  \n   • Perte du clin-d’œil « plan a plan » (double emploi volontairement absurde).  \n   • Suggestion : « … puis élabore un plan de plan … ».\n\n2. Catégorie « Legacy modern code »  \n   FR : « code existant relativement moderne (brownfield) »  \n   • « Legacy modern code » est oxymorique ; employer « code existant “moderne mais déjà legacy” » ou conserver la tournure ironique pour ne pas lisser le propos.  \n   • « Brownfield » n’apparaît pas dans l’original ici ; l’introduire peut semer la confusion (l’auteur l’utilise plus tard).\n\n3. Titre « ## Brownfield : itération incrémentale »  \n   • L’original : « ## Non-greenfield: Iteration, incrementally ».  \n   • Passer de « Non-greenfield » à « Brownfield » gomme la nuance (tout projet ≠ greenfield n’est pas forcément brownfield).  \n   • Proposer « ## Non-greenfield : itérations incrémentales ».\n\n4. « Je bricole… plein de petits projets »  \n   • « I have been building so many small products » = créer/fabriquer, pas « bricoler ».  \n   • « Bricoler » sous-entend amateurisme que l’auteur ne revendique pas.  \n   • Remplacer par « Je développe / je réalise ».\n\n5. Omission de nuance – Step 3 (« I, however, prefer **raw** claude… »)  \n   • Le texte FR garde « raw », mais perd l’idée que l’auteur préfère « claude brut (sans interface) ».  \n   • Ajouter explicitement « … en mode brut (sans surcouche) ».\n\n====================================================================\nII. PROBLÈMES MAJEURS : TON, STYLE, REGISTRE\n--------------------------------------------------------------------\n6. Oscillation « tu / vous »  \n   Exemples :  \n   6a) « (p.s. si tu détestes…) » vs « Conserve le prompt… c’est la langue attendue » (impersonnel).  \n   6b) « Votre outil de codegen pourra… ».  \n   • Choisir un vouvoiement ou un tutoiement constant (le tutoiement semble privilégié).  \n   • Harmoniser dans tout le doc, y compris les listes et encadrés.\n\n7. Anglicismes crus non justifiés  \n   « brainstorme », « spec », « prompt », « codegen », « brownfield », « workflow », etc.  \n   • Tolérés dans la communauté dev mais l’original montre aussi un registre relâché ; décider d’un équilibre. Proposer :  \n     – « séance de brainstorming », « spécification », « génération de code », « flux de travail ».  \n   • Conserver les mots-clefs techniques (« prompt »…) quand ils sont intraduisibles, mais franciser le reste.\n\n8. Ton humoristique un peu lissé  \n   • « Oh boy. how much time do you have! » → « Oh là là ! » correct mais moins moqueur ; on peut ajouter « — t’as combien d’heures devant toi ? ».  \n   • « rinse repeat ✩₊˚.⋆☾⋆⁺₊✧ » rendu littéral mais la blague (« rinse and repeat ») pourrait être traduite : « et on recommence, encore et encore ✩… ».\n\n====================================================================\nIII. PROBLÈMES MOYENS : GRAMMAIRE, SYNTAXE, FLUIDITÉ\n--------------------------------------------------------------------\n9. Ponctuation et espaces insécables  \n   • En français, espace insécable avant « ; », « : », « ? », « ! » (« tl;dr : », « Merci : »…).  \n   • Ajouter insécables ou au moins espaces simples corrects.\n\n10. Inversions malhabiles  \n    « Voici donc mon flux de travail. Il repose sur mon expérience perso… »  \n    • « mon expérience perso » = registre oral ; envisager « mon expérience personnelle ».\n\n11. Faux amis / registres  \n    « Je décoche à la chaîne » (anglicisme passif de « knocking them out ») sonne étrange.  \n    • « j’enchaîne les idées », « je les réalise à la chaîne ».\n\n12. Parenthèses excessives  \n    • Plusieurs digressions pourraient être encadrées par tirets cadratins ou virgules pour alléger la lecture.\n\n====================================================================\nIV. PROBLÈMES MINEURS : TERMINOLOGIE, DÉTAILS TECHNIQUES\n--------------------------------------------------------------------\n13. « cookie clicker »  \n    • Le lien est conservé mais « Cookie Clicker » est un nom propre ; capitaliser systématiquement.\n\n14. « disques vinyles »  \n    • « j’écoute des vinyles » plus naturel pour un francophone.\n\n15. « UV init »  \n    • Vérifier si « uv » (gestionnaire Python) doit rester en minuscule.\n\n16. « repomix pour envoyer tout le code à Claude »  \n    • Ajouter une explication rapide : « repomix ‑ un empaqueteur de repo ‑… » pour le lecteur français qui ne connaît pas.\n\n====================================================================\nV. SONS « MACHINE / LITTÉRAL »\n--------------------------------------------------------------------\n17. Maintien systématique de balises « (Conserve le prompt en anglais.) »  \n    • Répétition mécanique. Une phrase unique au début de la section suffirait.\n\n18. Traductions ligne-à-ligne des listes  \n    • Certaines listes (workflow) auraient pu être reformulées pour éviter le copier-coller anglais → français (« set up le repo (boilerplate…) »).  \n    • Proposer une version fluide : « – initialise le dépôt (boilerplate, uv init, cargo init, etc.) ».\n\n====================================================================\nVI. SUGGESTIONS GÉNÉRALES DE RÉVISION\n--------------------------------------------------------------------\n1. Clarifier et uniformiser le registre (tutoiement) sur tout le document.  \n2. Franciser la plupart des termes sauf quand l’anglais est incontournable pour les devs.  \n3. Rétablir les clins d’œil et oxymores de l’original (« plan a plan », « Legacy modern code », etc.).  \n4. Réduire les anglicismes traduits littéralement (« bricoler » → « développer », « décoche » → « finalise »).  \n5. Appliquer la typographie française (espaces avant ponctuation double, guillemets français si désiré).  \n6. Regrouper les indications « prompt à laisser en anglais » pour fluidifier.  \n7. Relire en entier pour fluidité : coupes, parenthèses,/ou digressions.\n\nEn appliquant ces corrections, la traduction gagnera en naturel, en cohérence et en fidélité au ton facétieux de l’auteur tout en restant parfaitement intelligible pour un lectorat francophone de développeurs.\n\nPlease address ALL issues identified in the critique and provide an improved translation.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl ; dr : fais un brainstorming de la spécification, puis élabore un plan de plan, puis exécute avec de la génération de code par LLM. Boucles bien distinctes. Ensuite, la magie. ✩₊˚.⋆☾⋆⁺₊✧_\n\nJe développe depuis quelque temps une foule de petits produits grâce aux LLM. C’est fun — et utile. Mais il y a aussi des pièges qui font perdre un temps fou. Un jour, un ami m’a demandé comment j’utilisais les LLM pour écrire du logiciel. J’ai pensé : « Oh boy, t’as combien d’heures devant toi ? » — d’où ce billet.\n\n(p.s. si tu détestes l’IA, file direct à la fin)\n\nJ’en parle souvent avec des potes dev et on suit tous à peu près la même approche, chacun y ajoutant ses petits réglages.\n\nVoici donc mon flux de travail. Il repose sur mon expérience personnelle, sur des échanges avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glanées dans les recoins (parfois douteux) du Net : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nÇa marche super bien **MAINTENANT** ; dans deux semaines ce sera peut-être cassé… ou deux fois plus performant. ¯\\\\\\_(ツ)_/¯\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images générées par IA un peu louches. Voici mon ange-robot codeur façon juggalo !\" >}}\n\nIl existe mille manières de développer, mais je me retrouve généralement dans l’un de ces deux cas :\n\n- nouveau projet (greenfield) ;\n- code « legacy moderne » (un projet assez récent mais déjà hérité).\n\nJe vais te montrer mon processus pour les deux pistes.\n\n## Greenfield\n\nPour un projet greenfield, ce processus fonctionne bien : planification solide, docs propres et avancée par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert à droite. Leica Q, 14/05/2016\" >}}\n\n### Étape 1 : affiner l’idée\n\nUtilise un LLM conversationnel pour peaufiner l’idée (j’emploie ChatGPT 4o / o3).\n\nConserve les prompts suivants en anglais (les modèles les préfèrent ainsi).\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nQuand le brainstorming arrive à sa conclusion naturelle :\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nTu obtiens une spécification bien nette que je sauvegarde d’habitude sous `spec.md`.\n\n> On peut tirer beaucoup de choses de cette spec. Ici, on vise le codegen, mais je l’utilise aussi pour demander à un modèle de raisonnement de dénicher les failles (toujours plus profond !), pour rédiger un white paper ou imaginer un business model. Tu peux même lancer une recherche poussée et récupérer un document de 10 000 mots en retour.\n\n### Étape 2 : planification\n\nEnvoie la spec à un modèle orienté raisonnement (`o1*`, `o3*`, `r1`).\n\n#### Prompt TDD\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n#### Prompt non-TDD\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe modèle te fournit alors un plan de prompts à exécuter (je le sauvegarde en `prompt_plan.md`).\n\nDemande-lui ensuite une todo-list :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nTon outil de génération de code pourra cocher `todo.md` au fil de la session : parfait pour garder le contexte.\n\n#### Youpi, un plan !\n\nTu as désormais un plan solide et une doc prête à piloter ton projet.\n\nCes deux premières étapes prennent quoi… **15 minutes** ? C’est dingue.\n\n### Étape 3 : exécution\n\nIl existe une foule d’outils ; leur succès dépend surtout de la qualité de l’étape 2.\n\nJ’ai testé ce workflow avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude-Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)… Ils s’en sortent tous.\n\nMoi, je préfère Claude en mode brut (sans surcouche) et Aider.\n\n### Claude\n\nJe fais du pair-programming sur [Claude.ai](https://claude.ai) : je colle chaque prompt tour à tour. Les allers-retours peuvent être pénibles, mais ça fonctionne.\n\nJe gère le boilerplate et le setup tooling ; ainsi, Claude n’impose pas d’office du React et je garde la main sur la stack.\n\nQuand ça coince, j’utilise [Repomix](https://github.com/yamadashy/repomix) (un empaqueteur de dépôt) pour envoyer tout le code à Claude et déboguer.\n\nWorkflow :\n\n- initialise le dépôt (boilerplate, `uv init`, `cargo init`, etc.) ;\n- colle le prompt dans Claude ;\n- copie le code généré dans ton IDE ;\n- lance l’appli, exécute les tests ;\n- …  \n- si ça roule : prompt suivant ;  \n- sinon : repomix + Claude pour déboguer ;\n- on rince, on répète ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu étrange ; il s’imbrique bien avec la sortie de l’étape 2 et permet d’aller très loin sans effort.\n\nMême logique : on colle les prompts dans Aider.\n\nAider « fait le taf » et je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> Au passage, Aider publie d’excellents benchmarks de modèles de codegen dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/). Idéal pour jauger les nouveaux modèles.\n\nGrâce aux tests, Aider peut être encore plus mains libres : il exécute la suite et débogue tout seul.\n\nWorkflow :\n\n- initialise le dépôt ;\n- lance Aider ;\n- colle le prompt ;\n- regarde Aider danser ♪┏(・o･)┛♪ ;\n- Aider lance les tests ou tu lances l’appli pour vérifier ;\n- si OK : prompt suivant ;\n- sinon : questions/réponses avec Aider pour corriger ;\n- on rince, on répète ✩₊˚.⋆☾⋆⁺₊✧\n\n### Résultats\n\nJ’ai réalisé une quantité folle de trucs : scripts, applis Expo, CLI Rust, etc. Tout langages confondus. Ultra efficace.\n\nMa todo hack est vide parce que j’ai tout fini. Je continue d’avoir de nouvelles idées que j’enchaîne pendant un film. Pour la première fois depuis des années, je découvre de nouveaux langages et outils ; ça élargit vraiment mon horizon.\n\n## Non-greenfield : itérations incrémentales\n\nParfois, on n’est pas en terrain vierge : il faut itérer sur une base de code existante.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n’est pas un champ vert. Photo prise par mon grand-père — Ouganda, années 60\" >}}\n\nDans ce cas, méthode un peu différente : moins de plan global, plus de planification tâche par tâche.\n\n### Obtenir le contexte\n\nChacun a sa technique pour empaqueter le code et l’injecter dans le LLM. J’utilise actuellement [Repomix](https://github.com/yamadashy/repomix) via des tâches définies dans `~/.config/mise/config.toml` (voir les [règles Mise](https://mise.jdx.dev/)).\n\nVoici la liste des tâches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe génère un `output.txt` contenant tout le contexte. Si ça déborde en tokens, j’exclus les parties inutiles.\n\n> Atout de `mise` : on peut redéfinir ou surcharger ces tâches dans le `.mise.toml` du projet. Tant que ça produit un `output.txt`, mes tâches LLM tournent. Pratique quand les bases de code sont très différentes. Je surcharge souvent l’étape Repomix pour élargir les motifs d’exclusion ou utiliser un empaqueteur plus adapté.\n\nUne fois `output.txt` prêt, je le passe à la commande [LLM](https://github.com/simonw/LLM) pour diverses transformations et je sauvegarde la sortie en markdown.\n\nEn pratique :\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nou :\n\n```\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\n`LLM` gère modèles, clés et templates.\n\nExemple : améliorer rapidement la couverture de tests.\n\n#### Claude\n\n- place-toi dans le dossier du code ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvre `missing-tests.md` ;  \n- copie le bundle : `mise run LLM:copy_buffer_bundle` ;  \n- colle-le dans Claude avec la première « issue » ;  \n- copie le code généré dans ton IDE ;  \n- exécute les tests ;  \n- on rince, on répète ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- place-toi dans le dossier ;  \n- lance Aider (sur une nouvelle branche) ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvre `missing-tests.md` ;  \n- colle la première « issue » dans Aider ;  \n- regarde Aider danser ♪┏(・o･)┛♪ ;  \n- exécute les tests ;  \n- on rince, on répète ✩₊˚.⋆☾⋆⁺₊✧\n\nSuper efficace pour améliorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Vite fait, bien fait.\n\nVoici quelques prompts que j’utilise sur du code établi (à conserver en anglais) :\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### Génération d’issues GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts datent un peu (« prompts de boomer »). Si tu as des idées pour les améliorer, fais signe !\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nQuand j’explique ce procédé, je dis : « Il faut suivre de près ce qui se passe, sinon tu te retrouves vite **over your skis**. »\n\nJe parle souvent d’être ***over my skis*** avec les LLM : tu skies dans de la poudre parfaite et, soudain, « WHAT THE FUCK IS GOING ON ? » — tu pars en vrille et tu chutes.\n\nLa **phase de planification** (cf. greenfield) aide à garder le contrôle : tu as au moins un doc de référence. Les tests aussi, surtout avec Aider en mode freestyle : ça garde le code propre et serré.\n\nMalgré ça, je me retrouve encore souvent ***over my skis***. Parfois, une pause ou une petite marche suffit. Au fond, c’est le même processus de résolution de problèmes, mais à vitesse supersonique.\n\n> On demande parfois au LLM d’ajouter des trucs totalement absurdes dans un code qui ne l’est pas tant que ça. Exemple : créer un fichier de lore puis le référencer dans l’interface d’un outil CLI Python. D’un coup, il y a du lore, des interfaces glitchy, etc. Tout ça pour gérer tes fonctions cloud, ta todo list ou n’importe quoi. Le ciel est la limite.\n\n## Je suis si seul (｡•́︿•̀｡)\n\nMon principal reproche : tout ça reste principalement **solo** — le mode « single player ».\n\nJ’ai codé des années seul, en pair, en équipe ; à plusieurs, c’est toujours mieux. Là, les bots se percutent, les merges deviennent atroces, le contexte est complexe.\n\nJe veux vraiment qu’on transforme le dev avec LLM en expérience multijoueur, pas juste un trip de hacker solitaire. Il y a un boulevard à ouvrir.\n\nAU BOULOT !\n\n## ⴵ Temps ⴵ\n\nLa génération de code a multiplié la quantité de code qu’une seule personne peut produire. Effet secondaire étrange : beaucoup de « temps mort » pendant que le LLM brûle ses tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m’en souviens comme si c’était hier\" >}}\n\nJ’ai donc adapté ma façon de bosser pour combler ces attentes :\n\n- je lance le brainstorming d’un autre projet ;\n- j’écoute des vinyles ;\n- je joue à [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) ;\n- je discute avec des amis et des robots.\n\nC’est génial de hacker comme ça. Hack ! Hack ! Hack ! Je ne me souviens pas avoir été aussi productif.\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\nPas mal de potes me disent : « Les LLM, c’est naze. » Je respecte ce point de vue, même si je ne le partage pas. Il y a plein de raisons de se méfier de l’IA. Ma plus grande crainte : la conso électrique et l’impact environnemental. Mais… le code doit couler. *soupir*\n\nSi tu es curieux sans vouloir devenir un « cyborg programmer », lis le livre d’Ethan Mollick : [**Co-Intelligence : Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nBonne intro, sans le ton bro techno-libertarien. J’ai eu plein de discussions nuancées avec des amis après l’avoir lu. Recommandé.\n\nSi tu es sceptique mais un peu curieux, contacte-moi et on parlera de toute cette folie. On pourra peut-être construire un truc ensemble.\n\n_merci à [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d’avoir relu ce billet et proposé des modifs. Je vous suis reconnaissant._",
      "usage": {
        "prompt_tokens": 11208,
        "completion_tokens": 4296,
        "total_tokens": 15504
      },
      "streaming": true
    },
    "frontmatter": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "You are a professional translator. Translate the following frontmatter fields to french.\nEach field is in the format \"field_name: content\". Translate ONLY the content, not the field names.\nReturn the translated content in the exact same format, preserving all field names.",
      "user_prompt": "title: My LLM codegen workflow atm\n\ndescription: A detailed walkthrough of my current workflow for using LLms to build software, from brainstorming through planning and execution.\n\n",
      "response": "title: Mon workflow de génération de code LLM en ce moment\n\ndescription: Une présentation détaillée de mon workflow actuel pour utiliser les LLMs afin de créer des logiciels, du brainstorming à la planification et à l'exécution.",
      "usage": {
        "prompt_tokens": 86,
        "completion_tokens": 48,
        "total_tokens": 134
      },
      "fields": [
        "title",
        "description"
      ],
      "streaming": true
    },
    "all_critiques": [
      "CRITIQUE DÉTAILLÉE DE LA TRADUCTION  \n(organisée par gravité et par type de problème)\n\n──────────────────────────────────  \nI. PROBLÈMES CRITIQUES – FIDÉLITÉ & EXHAUSTIVITÉ\n──────────────────────────────────  \n1. Passages entiers non traduits (omissions)  \n   • Bloc-quote après Step 1 : « You can use this spec for a number of things… »  \n   • Bloc-quote après explication de `mise` : « One thing really nice about mise is that the tasks can be redefined… »  \n   • Bloc-quote dans section Skiing : « We will often ask the LLM to include ridiculous things… »  \n   • Dernier paragraphe avant remerciements : « If you are skeptical, but a bit curious… »  \n   ➜ Traduire ou, si l’on veut vraiment conserver l’anglais, l’annoncer explicitement (« [EN] ») ; sinon c’est perçu comme un oubli.\n\n2. Contresens / choix lexicaux trompeurs  \n   a) « Boucles discrètes » pour « Discrete loops »  \n      – En français “discret” évoque la discrétion. L’idée d’itérations séparées est mieux rendue par « boucles distinctes », « boucles successives » ou « cycles indépendants ».  \n   b) « Legacy modern code » → « Code existant relativement moderne »  \n      – L’oxymore volontaire (« legacy *modern* code ») disparaît. Proposer « code existant, mais encore assez moderne » ou « code héritage mais récent ».  \n   c) Titre initial : « Élaborer une spec » atténue la nuance de “Brainstorm spec”. Mieux : « Brainstormer la spec » ou « Brainstorm : rédiger la spec ».\n\n3. Ajouts inappropriés qui changent le sens  \n   – « C’est à la fois amusant et utile. » L’original : “It has been fun, and useful.”   OK.  \n   – Pas d’autres ajouts majeurs relevés.\n\n──────────────────────────────────  \nII. PROBLÈMES MAJEURS – TON, TERMINOLOGIE, CONSTANCE\n──────────────────────────────────  \n1. Terminologie technique / jargon  \n   • « petits produits » pour “small products” sonne commercial. Préférer « petits projets », « petits outils », « mini-applications ».  \n   • « process » employé en français (“mon process”) : anglicisme acceptable à l’oral mais alourdit la lecture. Remplacer par « processus » ou « procédé ».  \n   • « spec », « prompt plan », « workflow » : conserver éventuellement l’anglais mais indiquer la première fois (specification, plan de prompts). Veiller à la cohérence (certains termes anglais sont traduits, d’autres non).  \n   • “Boilerplate” laissé tel quel ; OK dans un contexte dev, mais une note (« code de démarrage / squelette ») améliorerait l’accessibilité.\n\n2. Cohérence du tutoiement  \n   – Le texte emploie systématiquement “tu”, c’est cohérent, mais on trouve quelques impératifs impersonnels (« Utilise », « Prends ») et un « Votre codegen… » isolé. Harmoniser.\n\n3. Registre & tonalité  \n   – L’original est très oral, truffé de “oh boy”, emojis, interjections. La traduction conserve globalement le ton, mais certains passages deviennent plus lisses (« Hourra » pour “Yay” paraît vieillot).  \n   – Expressions calquées : « rinse repeat ✩₊˚.⋆☾⋆⁺₊✧ » est gardé tel quel ; OK, mais le verbe “rinse” n’est pas francisé. On peut ajouter « (on recommence) » juste après.\n\n4. Idiomes mal rendus  \n   • “over my skis” → traduit littéralement par « over my skis » (en anglais) + explication française ‑ OK. On pourrait ajouter l’équivalent idiomatique français (« dépassé » / « largué »).  \n   • “the code must flow” pas traduit ; on pourrait intégrer « le code doit couler » comme dans l’original anglais, mais préciser la référence (“Dune”).\n\n──────────────────────────────────  \nIII. PROBLÈMES MOYENS – GRAMMAIRE & SYNTAXE\n──────────────────────────────────  \n1. Accord / orthographe  \n   • « J’ai testé ce workflow… Ça marche partout. » → “partout” = un peu vague, rien de grave.  \n   • « Perso, je préfère **Claude brut** et aider. » → manque de majuscule à “aider” si on considère le nom propre “Aider”.  \n   • Quelques virgules manquantes avant « mais » introduisant une proposition (“… marche super bien MAINTENANT, peut-être plus du tout…”).\n\n2. Ponctuation française  \n   – Espaces insécables manquantes avant « : ; ? ! » (ex. « tl;dr : », « Étape 1 : »).  \n   – Guillemets typographiques (« « » ») absents. Acceptable dans un billet de blog, mais à noter.\n\n3. Anglicismes inutiles ou redondants  \n   – “greenfield / brownfield” conservés : courant dans la tech, mais ajouter entre parenthèses « (projet from scratch) / (projet existant) » pour lecteurs non familiers.  \n   – “Cookie Clicker” laissé sans italique ou guillemets.\n\n──────────────────────────────────  \nIV. PROBLÈMES MINEURS – FLUIDITÉ & STYLE\n──────────────────────────────────  \n1. Redondances / lourdeurs  \n   • « planifier le plan » reproduit l’effet voulu, mais on peut garder “planifier un plan” pour éviter l’allitération forcée.  \n   • Répétition du mot “prompt” : éventuellement alterner avec « instruction », « commande LLM ».\n\n2. Micro-choix de registres  \n   • « chelou » très familier ; correspond au ton, mais vérifier si cohérence globale.  \n   • « boomer prompts » => on peut franciser entre guillemets : « prompts de boomer ».\n\n3. Capitalisation / cadrage des fichiers  \n   – `todo.md` -> **anglais** dans un texte francophone, mais standard ; rien à corriger.\n\n──────────────────────────────────  \nV. SUGGESTIONS DE RÉVISION\n──────────────────────────────────  \n(à adresser point par point)\n\n1. Traduire les passages manquants.\n2. Remplacer « Boucles discrètes » par « Boucles distinctes » (ou « cycles indépendants »).  \n3. Ajuster “Legacy modern code” → « code hérité mais encore moderne ».  \n4. Changer « petits produits » → « petits projets / petits outils ».  \n5. Limiter les anglicismes : “process” → “processus”, expliciter “spec”, “workflow”, etc.  \n6. Uniformiser le tutoiement (éviter “votre”).  \n7. Ajouter les espaces insécables avant « : ; ? ! » et utiliser « « » » si publication soignée.  \n8. Revoir ponctuellement le registre :  \n   – “Hourra” → “Yes !” ou “Trop bien !”  \n   – “rinse repeat” → “on recommence” (en gardant l’émoji si souhaité).  \n9. Ajouter un bref éclaircissement lors du premier emploi de greenfield/brownfield.  \n10. Relire pour éliminer les virgules manquantes et corriger quelques broutilles d’accord.\n\n──────────────────────────────────  \nCONCLUSION\n\nLa traduction restitue globalement le ton décontracté et la structure technique du billet, mais souffre de quatre faiblesses majeures :  \n\n• plusieurs paragraphes laissés en anglais,  \n• quelques contresens (« boucles discrètes », oxymore gommé),  \n• anglicismes et terminologie peu francisés,  \n• ponctuation et micro-cohérences perfectibles.  \n\nEn corrigeant ces points, le texte gagnera à la fois en fidélité, en naturel français et en professionnalisme.",
      "CRITIQUE DÉTAILLÉE DE LA TRADUCTION  \n===================================================================  \n\nLégende des niveaux de sévérité  \n• Critique : contresens, omission ou ajout susceptible de tromper le lecteur.  \n• Majeur : formulation très maladroite, français non idiomatique, registre inapproprié.  \n• Mineur : détail stylistique, choix de ponctuation, cohérence ou micro-coquille.  \n\n-------------------------------------------------------------------  \n1. Exactitude / Fidélité au contenu  \n-------------------------------------------------------------------  \n\n1-A Omissions (Critique)  \n1. Ligne manquante : « I keep thinking of new things and knocking them out while watching a movie or something. »  \n   – Absente dans « Ma todo “hack” est vide … ».  \n   → Ajouter : « Je continue pourtant d’avoir de nouvelles idées que j’expédie en regardant un film ou autre. »\n\n2. « while waiting for the LLM to finish burning its tokens »  \n   – Rendu « pendant que le LLM calcule ». Le verbe « calculate » gomme l’idée de « consume tokens ».  \n   → Proposer : « …le temps que le LLM **avale/brûle ses jetons**. »\n\n3. « Legacy modern code »  \n   – Traduit « Code hérité mais encore moderne ». Le syntagme source est déjà oxymorique ; la traduction atténue l’ironie.  \n   → Conserver l’oxymore : « code legacy (mais “moderne”) » ou expliquer : « code existant récent ».\n\n4. « non-greenfield: Iteration, incrementally »  \n   – Devenu « Pas de greenfield : itération incrémentale ». Le terme « brownfield » (sous-titre, image) disparaît du titre.  \n   → Garder la symétrie : « Brownfield : itération incrémentale ».\n\n1-B Contresens / imprécisions (Critique)  \n5. « The bots collide » → « les bots se cognent ».  \n   – « collide » renvoie plutôt à des conflits, pas à un choc physique.  \n   → « Les bots **entrent en conflit** » ou « se marchent sur les pieds ».\n\n6. « It has been fun, and useful » → « C’est à la fois fun et utile ».  \n   – « fun » peut rester anglais dans le jargon dev, mais doubler par « amusant » rendrait le propos compréhensible hors milieu tech.  \n   → « C’était amusant ― et utile. »\n\n-------------------------------------------------------------------  \n2. Ton, registre et cohérence stylistique  \n-------------------------------------------------------------------  \n\n2-A Traitement du lecteur (Majeur)  \n7. Tutoiement constant (« tu ») : cohérent mais non indiqué dans l’original (où l’adresse est neutre). Si le texte cible est destiné à un public large/ professionnel, prévoir le vouvoiement.  \n   → Décider dès l’intro et harmoniser.\n\n2-B Calques et anglicismes bruts (Majeur)  \n8. « Brainstormer la spec », « planifier un plan », « workflow », « greenfield », « prompt plan », « issue ».  \n   – Certains anglicismes sont acceptés chez les devs, mais la densité nuit à la lisibilité.  \n   → Suggestions :  \n   • « faire un brainstorming sur la spécification »  \n   • « élaborer le plan » (et conserver le jeu de mots “plan a plan” par une note ou italique)  \n   • « flux de travail (workflow) » à la 1ʳᵉ occurrence  \n   • « demande » ou « ticket » pour « issue ».\n\n9. Nom anglais + adjectif français « Claude brut » (mineur mais étrange).  \n   → « Claude “raw” » ou « Claude en mode brut ».\n\n-------------------------------------------------------------------  \n3. Naturel du français et fluidité  \n-------------------------------------------------------------------  \n\n3-A Phrases lourdes ou bancales (Majeur)  \n10. « C’est à la fois fun et utile » → voir 6.  \n11. « Je trouve toujours ces images générées par IA un peu louches. Voici donc mon ange robot codeur juggalo ! »  \n    – L’enchaînement « donc » + « mon » paraît forcé.  \n    → « …un peu louches. Voici mon ange-robot codeur façon juggalo ! »\n\n12. « Ça marche partout. » (après la liste d’outils) – Trop elliptique.  \n    → « La méthode fonctionne avec tous les outils que j’ai testés. »\n\n3-B Ponctuation & typographie (Mineur)  \n13. Espace fine insécable avant « : », « ; », « ? », « ! » manquante presque partout.  \n14. « tl;dr : » → l’espace avant deux-points n’est pas typographique ; remplacer par «  : » (espace fine).  \n15. Guillemets : mixer “ ”, « » et \" \". Harmoniser (préférer « » en français).\n\n-------------------------------------------------------------------  \n4. Terminologie technique & cohérence  \n-------------------------------------------------------------------  \n\n16. « spec » / « specification » → alterne fréquemment. Choisir « spécification » (abrégé « spec » entre parenthèses).  \n17. « todo.md » : varie entre « todo » et « todo list ».  \n18. « boilerplate » non expliqué à la 1ʳᵉ apparition. Ajouter « (code de démarrage) ».  \n\n-------------------------------------------------------------------  \n5. Register, humour & références culturelles  \n-------------------------------------------------------------------  \n\n19. Juron adouci (Mineur)  \n    – « fuck LLMs » → « c’est nul ». La vigueur est perdue.  \n    → « “Putain, les LLM c’est de la daube.” » ou équivalent plus direct pour garder le ton.\n\n20. « over my skis » maintenu en anglais. On l’explique plus loin, mais on pourrait ajouter la métaphore française (« au-delà de mes capacités »).  \n\n-------------------------------------------------------------------  \n6. Incohérences mineures / micro-coquilles  \n-------------------------------------------------------------------  \n\n21. « je balance chaque prompt à la suite » → redondant.  \n22. Accents oubliés : « Tu es sceptique, mais un peu curieux » (virgule > mais).  \n23. Majuscule inutile : « Yes ! Un plan ! » – anglais + espace avant « ! ».  \n\n-------------------------------------------------------------------  \n7. Suggestions de révision ciblées  \n-------------------------------------------------------------------  \n\n• Remplacer le titre par :  \n  _tl ; dr : faire un brainstorming de la spécification, puis élaborer un plan, puis exécuter la génération de code avec un LLM. Boucles distinctes, puis magie. ✩₊˚.⋆☾⋆⁺₊✧_  \n\n• Uniformiser « spécification (spec) », « flux de travail (workflow) », « dépôt (repo) ».  \n\n• Brownfield section :  \n  « ## Brownfield : itération incrémentale »  \n  « Parfois, on n’est pas en terrain vierge ; il faut plutôt améliorer une base de code existante. »  \n\n• Remplacer « les bots se cognent » par « les bots se chevauchent / entrent en conflit, les fusions deviennent horribles ».  \n\n• Restituer la phrase manquante sur le visionnage de films.  \n\n• Revoir la ponctuation française : espace fine insécable avant « : », « ? », « ! ».  \n\n• Ajouter une note explicative la première fois qu’un anglicisme très technique apparaît, puis conserver l’anglais ; ex. :  \n  « codegen (génération automatique de code) ».  \n\n-------------------------------------------------------------------  \nEn appliquant ces corrections — notamment la restitution de la phrase omise, la réduction des calques et l’amélioration de la ponctuation — la traduction gagnera en fidélité et en naturel tout en conservant le ton décontracté de l’original.",
      "CRITIQUE DÉTAILLÉE DE LA TRADUCTION  \n(les numéros renvoient aux passages de la traduction ; entre guillemets : T=Traduction, O=Original)\n\n──────────────────────────────────  \nI. PROBLÈMES CRITIQUES (sens, omissions, contresens)  \n──────────────────────────────────  \n\n1. Titre « tl ; dr » avec espaces  \n   • O : « tl:dr; »  \n   • T : « tl ; dr : »  \n   → Le découpage « tl ; dr » n’existe pas, la ponctuation change même le sens pour un lectorat tech.  \n   ➜ Corriger en « tl;dr » (garder les deux points derrière si l’on veut coller au français : « tl;dr : »).\n\n2. « Legacy modern code » → « Code legacy (mais “moderne”) »  \n   – Rend mal la nuance « code existant mais encore relativement moderne ».  \n   ➜ Proposer : « code existant relativement moderne » ou « code hérité encore dans un stack moderne ».\n\n3. « Discrete loops » → « Boucles distinctes »  \n   – Manque l’idée de « étapes séparées et bouclées ». On peut croire qu’il parle d’algorithmes.  \n   ➜ « boucles séparées (une par phase) » ou « cycles bien distincts ».\n\n4. « Greenfield » / « Brownfield »  \n   – T emploie tour à tour « Code neuf (greenfield) » puis « Brownfield » sans expliquer la métaphore alors qu’elle est moins connue en français.  \n   ➜ La première occurrence devrait expliciter : « projet greenfield (tout à créer) » et plus loin « projet brownfield (base existante) ». Ou conserver l’anglais mais ajouter la glose à chaque fois.\n\n5. Manque de traduction (ou glose) pour les prompts anglais  \n   – Les blocs de prompt restent intacts ; c’est souhaitable pour la ré-utilisation mais il faut avertir le lecteur francophone qu’ils sont à conserver en anglais.  \n   ➜ Ajouter juste avant chaque bloc : « (Conservez le prompt en anglais, c’est la langue attendue par les LLM) ».\n\n6. Omission mineure dans « This entire process will take maybe 15 minutes. It is pretty quick. Wild tbh. »  \n   – T : « L’ensemble de ces deux premières étapes prend 15 minutes maxi. Complètement fou. »  \n   – « tbh » (=franchement) disparu, mais on peut l’absorber. Acceptable.  \n\n──────────────────────────────────  \nII. STYLE / TON / REGISTRE (MAJEUR)  \n──────────────────────────────────  \n\n1. Oscillations « tu » / « vous » / formes neutres  \n   – Ex. « Utilise un LLM… » (tu) vs « Votre outil de codegen… ».  \n   ➜ Choisir un registre (idéalement « tu » pour coller au ton conversationnel de l’original) et uniformiser.\n\n2. Anglicismes bruts non justifiés  \n   • « faire un brainstorming », « workflow », « boilerplate », « debuguer », etc.  \n   – Certains sont inévitables dans le milieu, mais on peut adapter :  \n     « faire un remue-méninges », « flux de travail », « ossature (boilerplate) », « déboguer ».  \n   ➜ Décider d’un glossaire et s’y tenir ; à minima mettre l’équivalent français suivi de l’anglais entre parenthèses la 1ʳᵉ fois.\n\n3. Tournures trop littérales ou calquées  \n   – « Ça marche super bien MAINTENANT » : majuscules agressives, inutile en français, préférer « ... très bien POUR L’INSTANT ».  \n   – « Yes ! Un plan ! » sonne artificiel. ➜ « Yes ! On a un plan ! » ou « Youpi, on a un plan ! ».  \n\n4. Humour & exclamations  \n   – Certaines touches d’humour US sont aplaties : « wild tbh » → « Complètement fou » fonctionne, mais « I, however, prefer raw claude » → « Perso, je préfère Claude en mode “raw” » perd le clin d’œil (« raw » ironique).  \n   ➜ Ajouter des guillemets + éventuelle note : « en mode “raw” (brut) ».\n\n──────────────────────────────────  \nIII. GRAMMAIRE, TYPOGRAPHIE, FLUIDITÉ (MOYEN)  \n──────────────────────────────────  \n\n1. Ponctuation française  \n   – Doubles espaces avant les ponctuations doubles (« ; », « : », « ? ») manquent souvent ; ex. « tl ; dr : » → « tl ; dr : ».  \n   ➜ Suivre les règles françaises : espace insécable avant ; : ? !  \n\n2. Concordance des temps  \n   – « C’était amusant — et utile. » devrait être « C’est amusant – et utile. » pour garder le présent comme l’original.  \n\n3. Petites fautes  \n   – « les fusions deviennent horribles » (merge) : neutre, mais « les conflits de fusion deviennent horribles » serait plus précis.  \n   – « Je respectE cette vision » (actuellement « Je respecte » manque le e final ?)  \n\n4. Orthographe  \n   – « white paper » non italique ni guillemets ; proposer « livre blanc (white paper) ».  \n   – « vinyles » → forme correcte, mais « j’écoute des disques vinyles ».  \n\n──────────────────────────────────  \nIV. TERMINOLOGIE TECHNIQUE & COHÉRENCE (MOYEN)  \n──────────────────────────────────  \n\n1. « Spec », « prompt_plan.md », « todo.md »  \n   – T utilise « spec » sans accent ; fixer une graphie (tout en gardant le nom de fichier) : « la spec (spec.md) ».  \n\n2. « Codegen »  \n   – Parfois traduit (génération de code) parfois laissé anglais. Harmoniser (« codegen (génération de code) » à la première occurrence).  \n\n3. « Reasoning model » → « modèle de raisonnement » : ok, mais on parle aussi de « modèle spécialisé dans le raisonnement » pour éviter l’ambiguïté.  \n\n──────────────────────────────────  \nV. NUANCES & IDIOMES MANQUANTS / MAL RENDUS (MINEUR)  \n──────────────────────────────────  \n\n1. « oh boy. how much time do you have! »  \n   – T : « Oh là là… tu as combien de temps ? »  \n   – L’intonation exclamative de « how much time do you have! » (point d’exclamation) est perdue.  \n   ➜ « Oh là là ! T’as combien de temps devant toi ? ».  \n\n2. « Keep thinking of new things and knocking them out »  \n   – T : « Je continue pourtant d’avoir de nouvelles idées que j’expédie… ».  \n   – L’idée de « knocking them out (rapidement) » presque violent/performatif pourrait être « que je décoche à la chaîne ».  \n\n3. « over my skis »  \n   – La parenthèse explicative est bonne mais on peut faire ressortir l’image : « je me retrouve les spatules dans le vide ».  \n\n──────────────────────────────────  \nVI. IMPRESSIONS « MACHINE-LIKE » / LITERALITÉ (MINEUR)  \n──────────────────────────────────  \n\n1. Répétitions proches de l’anglais  \n   – « Initialiser le dépôt (boilerplate, uv init, cargo init, etc.) » : « boilerplate » laissé brut, donne un air copié-collé.  \n   – Série de verbes « lancer, lancer, lancer » à la queue-leu-leu ; peut être allégé.  \n\n2. Longues phrases coulées sans découpe  \n   – Exemple dans la partie « Obtenir le contexte » : la phrase qui commence par « Une fois le output.txt généré… » fait cinq propositions.  \n   ➜ Fractionner pour la lisibilité.  \n\n──────────────────────────────────  \nVII. RECOMMANDATIONS GÉNÉRALES  \n──────────────────────────────────  \n\n• Choisir un registre cohérent (« tu » partout ou « vous » partout).  \n• Élaborer un petit lexique en début d’article pour les termes laissés en anglais (prompt, spec, codegen, greenfield, brownfield, boilerplate, etc.) et décider lesquels traduire.  \n• Uniformiser la ponctuation française : espaces insécables, guillemets français («  »), tirets cadratins pour incises.  \n• Alléger les anglicismes inutiles et franciser les verbes quand c’est naturel (déboguer, planifier, exécuter).  \n• Ajouter des petites gloses culturelles pour les références US (« cookie clicker », « juggalo », « Haterade ») ou les garder mais avec un lien/parenthèse explicative.  \n• Relire la concordance des temps pour garder le même rythme que l’original (présent majoritairement).  \n\nEn appliquant ces corrections de sens, de registre et de fluidité, la traduction deviendra plus naturelle pour un lecteur francophone tout en restant fidèle, précise et techniquement cohérente.",
      "CRITIQUE DÉTAILLÉE DE LA TRADUCTION  \n(les numéros renvoient aux passages dans le texte français actuel)\n\n====================================================================\nI. PROBLÈMES CRITIQUES : SENS, FIDÉ­LITÉ, OMISSIONS\n--------------------------------------------------------------------\n1. Slogan d’ouverture  \n   FR : « brainstorme la spec, puis fais un plan »  \n   • Perte du clin-d’œil « plan a plan » (double emploi volontairement absurde).  \n   • Suggestion : « … puis élabore un plan de plan … ».\n\n2. Catégorie « Legacy modern code »  \n   FR : « code existant relativement moderne (brownfield) »  \n   • « Legacy modern code » est oxymorique ; employer « code existant “moderne mais déjà legacy” » ou conserver la tournure ironique pour ne pas lisser le propos.  \n   • « Brownfield » n’apparaît pas dans l’original ici ; l’introduire peut semer la confusion (l’auteur l’utilise plus tard).\n\n3. Titre « ## Brownfield : itération incrémentale »  \n   • L’original : « ## Non-greenfield: Iteration, incrementally ».  \n   • Passer de « Non-greenfield » à « Brownfield » gomme la nuance (tout projet ≠ greenfield n’est pas forcément brownfield).  \n   • Proposer « ## Non-greenfield : itérations incrémentales ».\n\n4. « Je bricole… plein de petits projets »  \n   • « I have been building so many small products » = créer/fabriquer, pas « bricoler ».  \n   • « Bricoler » sous-entend amateurisme que l’auteur ne revendique pas.  \n   • Remplacer par « Je développe / je réalise ».\n\n5. Omission de nuance – Step 3 (« I, however, prefer **raw** claude… »)  \n   • Le texte FR garde « raw », mais perd l’idée que l’auteur préfère « claude brut (sans interface) ».  \n   • Ajouter explicitement « … en mode brut (sans surcouche) ».\n\n====================================================================\nII. PROBLÈMES MAJEURS : TON, STYLE, REGISTRE\n--------------------------------------------------------------------\n6. Oscillation « tu / vous »  \n   Exemples :  \n   6a) « (p.s. si tu détestes…) » vs « Conserve le prompt… c’est la langue attendue » (impersonnel).  \n   6b) « Votre outil de codegen pourra… ».  \n   • Choisir un vouvoiement ou un tutoiement constant (le tutoiement semble privilégié).  \n   • Harmoniser dans tout le doc, y compris les listes et encadrés.\n\n7. Anglicismes crus non justifiés  \n   « brainstorme », « spec », « prompt », « codegen », « brownfield », « workflow », etc.  \n   • Tolérés dans la communauté dev mais l’original montre aussi un registre relâché ; décider d’un équilibre. Proposer :  \n     – « séance de brainstorming », « spécification », « génération de code », « flux de travail ».  \n   • Conserver les mots-clefs techniques (« prompt »…) quand ils sont intraduisibles, mais franciser le reste.\n\n8. Ton humoristique un peu lissé  \n   • « Oh boy. how much time do you have! » → « Oh là là ! » correct mais moins moqueur ; on peut ajouter « — t’as combien d’heures devant toi ? ».  \n   • « rinse repeat ✩₊˚.⋆☾⋆⁺₊✧ » rendu littéral mais la blague (« rinse and repeat ») pourrait être traduite : « et on recommence, encore et encore ✩… ».\n\n====================================================================\nIII. PROBLÈMES MOYENS : GRAMMAIRE, SYNTAXE, FLUIDITÉ\n--------------------------------------------------------------------\n9. Ponctuation et espaces insécables  \n   • En français, espace insécable avant « ; », « : », « ? », « ! » (« tl;dr : », « Merci : »…).  \n   • Ajouter insécables ou au moins espaces simples corrects.\n\n10. Inversions malhabiles  \n    « Voici donc mon flux de travail. Il repose sur mon expérience perso… »  \n    • « mon expérience perso » = registre oral ; envisager « mon expérience personnelle ».\n\n11. Faux amis / registres  \n    « Je décoche à la chaîne » (anglicisme passif de « knocking them out ») sonne étrange.  \n    • « j’enchaîne les idées », « je les réalise à la chaîne ».\n\n12. Parenthèses excessives  \n    • Plusieurs digressions pourraient être encadrées par tirets cadratins ou virgules pour alléger la lecture.\n\n====================================================================\nIV. PROBLÈMES MINEURS : TERMINOLOGIE, DÉTAILS TECHNIQUES\n--------------------------------------------------------------------\n13. « cookie clicker »  \n    • Le lien est conservé mais « Cookie Clicker » est un nom propre ; capitaliser systématiquement.\n\n14. « disques vinyles »  \n    • « j’écoute des vinyles » plus naturel pour un francophone.\n\n15. « UV init »  \n    • Vérifier si « uv » (gestionnaire Python) doit rester en minuscule.\n\n16. « repomix pour envoyer tout le code à Claude »  \n    • Ajouter une explication rapide : « repomix ‑ un empaqueteur de repo ‑… » pour le lecteur français qui ne connaît pas.\n\n====================================================================\nV. SONS « MACHINE / LITTÉRAL »\n--------------------------------------------------------------------\n17. Maintien systématique de balises « (Conserve le prompt en anglais.) »  \n    • Répétition mécanique. Une phrase unique au début de la section suffirait.\n\n18. Traductions ligne-à-ligne des listes  \n    • Certaines listes (workflow) auraient pu être reformulées pour éviter le copier-coller anglais → français (« set up le repo (boilerplate…) »).  \n    • Proposer une version fluide : « – initialise le dépôt (boilerplate, uv init, cargo init, etc.) ».\n\n====================================================================\nVI. SUGGESTIONS GÉNÉRALES DE RÉVISION\n--------------------------------------------------------------------\n1. Clarifier et uniformiser le registre (tutoiement) sur tout le document.  \n2. Franciser la plupart des termes sauf quand l’anglais est incontournable pour les devs.  \n3. Rétablir les clins d’œil et oxymores de l’original (« plan a plan », « Legacy modern code », etc.).  \n4. Réduire les anglicismes traduits littéralement (« bricoler » → « développer », « décoche » → « finalise »).  \n5. Appliquer la typographie française (espaces avant ponctuation double, guillemets français si désiré).  \n6. Regrouper les indications « prompt à laisser en anglais » pour fluidifier.  \n7. Relire en entier pour fluidité : coupes, parenthèses,/ou digressions.\n\nEn appliquant ces corrections, la traduction gagnera en naturel, en cohérence et en fidélité au ton facétieux de l’auteur tout en restant parfaitement intelligible pour un lectorat francophone de développeurs."
    ]
  },
  "critique_loop_details": {
    "critique_usages": [
      {
        "prompt_tokens": 9449,
        "completion_tokens": 1892,
        "total_tokens": 11341
      },
      {
        "prompt_tokens": 9538,
        "completion_tokens": 1917,
        "total_tokens": 11455
      },
      {
        "prompt_tokens": 9598,
        "completion_tokens": 2215,
        "total_tokens": 11813
      },
      {
        "prompt_tokens": 9584,
        "completion_tokens": 1740,
        "total_tokens": 11324
      }
    ],
    "feedback_usages": [
      {
        "prompt_tokens": 11328,
        "completion_tokens": 4354,
        "total_tokens": 15682
      },
      {
        "prompt_tokens": 11297,
        "completion_tokens": 4400,
        "total_tokens": 15697
      },
      {
        "prompt_tokens": 11730,
        "completion_tokens": 4456,
        "total_tokens": 16186
      },
      {
        "prompt_tokens": 11208,
        "completion_tokens": 4296,
        "total_tokens": 15504
      }
    ]
  },
  "timestamp": "2025-05-16T10:06:15.146433"
}