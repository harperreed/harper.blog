{
  "input_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.md",
  "output_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.fr.md",
  "target_language": "french",
  "language_code": "fr",
  "model": "o3",
  "skip_edit": false,
  "do_critique": true,
  "critique_loops": 4,
  "has_frontmatter": true,
  "token_usage": {
    "prompt_tokens": 98118,
    "completion_tokens": 33923,
    "total_tokens": 132041
  },
  "cost": "$2.3381",
  "prompts_and_responses": {
    "translation": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "\n        1. Read the provided text carefully, preserving all formatting, markdown, and structure exactly as they appear.\n        2. Identify any block quotes and code blocks.\n        3. Do not translate text in block quotes or in code blocks (including text within code blocks).\n        4. Translate everything else into french.\n        5. Maintain the original formatting, markdown, and structure in your output.\n        6. Provide a natural-sounding translation rather than a word-for-word one.\n        7. For idioms, colloquialisms, or slang, render them in an equivalent, natural way in french whenever possible.\n        8. If there isn't a direct or natural translation for a particular term or phrase, keep it in the original language and surround it with quotes if necessary.\n        9. Ensure that technical terms or jargon remain accurate; if there's no suitable translation, keep the original term.\n        10. Strive for fluid, native-sounding prose that retains the tone and intent of the original text.\n        ",
      "user_prompt": "_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "response": "_tl;dr : √âlaborer un spec, puis planifier le plan, puis ex√©cuter gr√¢ce au codegen LLM. Boucles discr√®tes. Et ensuite, la magie. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nJe construis depuis un moment plein de petits produits √† l‚Äôaide des LLM. C‚Äôest √† la fois amusant et utile. Mais il existe de nombreux pi√®ges qui peuvent faire perdre un temps fou. Il y a quelque temps, un ami m‚Äôa demand√© comment j‚Äôutilisais les LLM pour √©crire du code. Je me suis dit : ¬´ Ohlala‚Ä¶ tu as combien de temps ? ¬ª ‚Äî d‚Äôo√π ce billet.\n\n(p.s. si tu d√©testes l‚ÄôIA, va directement √† la fin)\n\nJe discute souvent de tout √ßa avec des potes dev, et nous suivons tous √† peu pr√®s la m√™me m√©thode, avec quelques ajustements par-ci par-l√†.\n\nVoici donc mon workflow. Il s‚Äôappuie sur mon exp√©rience perso, des √©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glan√©es dans les recoins parfois douteux d‚ÄôInternet : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\n√áa marche super bien **MAINTENANT**, peut-√™tre plus du tout dans deux semaines‚Ä¶ ou deux fois mieux. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images g√©n√©r√©es par IA un peu louches. Voici donc mon ange robot codeur juggalo !\" >}}\n\nIl existe plein de fa√ßons de d√©velopper, mais je me retrouve g√©n√©ralement dans l‚Äôun de ces deux cas :\n\n- Code neuf (greenfield)\n- Code existant relativement moderne\n\nJe vais te montrer mon process pour les deux.\n\n## Code neuf\n\nVoici le process que j‚Äôutilise pour un d√©veloppement greenfield. Il fournit un cadre solide de planification et de documentation, et permet d‚Äôavancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert √† droite. Leica Q, 14/05/2016\" >}}\n\n### √âtape 1 : Affiner l‚Äôid√©e\n\nUtilise un LLM conversationnel pour peaufiner l‚Äôid√©e (j‚Äôemploie ChatGPT 4o / o3) :\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\n√Ä la fin du brainstorming (tu sentiras quand c‚Äôest fini) :\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nOn obtient alors un spec assez propre qu‚Äôon peut passer √† l‚Äô√©tape de planification. Je le sauvegarde en g√©n√©ral sous `spec.md` dans le repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### √âtape 2 : Planification\n\nPrends le spec et envoie-le √† un mod√®le de raisonnement digne de ce nom (`o1*`, `o3*`, `r1`) :\n\n(Prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Prompt non-TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe mod√®le doit te sortir un ¬´ prompt plan ¬ª que tu pourras ex√©cuter avec aider, cursor, etc. Je le sauvegarde en g√©n√©ral sous `prompt_plan.md`.\n\nEnsuite, je lui demande de g√©n√©rer un `todo.md` √† cocher :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n√Ä mettre √† la racine du repo.\n\nTon outil de codegen doit pouvoir cocher les cases du `todo.md` au fil de la session : pratique pour garder l‚Äô√©tat.\n\n#### Hourra, un plan !\n\nTu as maintenant un plan solide et de la doc pour piloter ton projet.\n\nL‚Äôensemble de la phase 1+2 prend **15 minutes** max. C‚Äôest fou.\n\n### √âtape 3 : Ex√©cution\n\nIl existe √©norm√©ment d‚Äôoutils pour cette phase. Leur r√©ussite d√©pend surtout de la qualit√© de l‚Äô√©tape 2.\n\nJ‚Äôai test√© ce workflow avec [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai)‚Ä¶ √áa marche partout.\n\nPerso je pr√©f√®re **claude brut** + aider.\n\n### Claude\n\nJe fais du pair-programming sur [claude.ai](https://claude.ai) : je balance chaque prompt √† la suite. √áa tourne pas mal. Les aller-retour peuvent √™tre un peu lourds, mais globalement √ßa le fait.\n\nJe m‚Äôoccupe du boilerplate et du setup outillage. √áa donne plus de libert√© et √©vite que Claude ne balance d‚Äôoffice du React. Une bonne base claire (langage, style, tooling) aide beaucoup.\n\nQuand √ßa coince, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) pour passer tout le code √† Claude et d√©boguer.\n\nWorkflow :\n\n- initialiser le repo (boilerplate, `uv init`, `cargo init`, etc.)\n- coller le prompt dans Claude\n- copier-coller le code g√©n√©r√© dans l‚ÄôIDE\n- lancer le code, les tests, etc.\n- ‚Ä¶\n- si √ßa marche : prompt suivant\n- sinon : repomix + Claude pour d√©bug\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu chelou. √áa s‚Äôimbrique bien avec la sortie de l‚Äô√©tape 2 et on va tr√®s loin sans effort.\n\nM√™me logique que ci-dessus, sauf qu‚Äôon colle les prompts dans aider.\n\nAider ¬´ fait le taf ¬ª et moi je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nGr√¢ce aux tests, aider peut √™tre encore plus ¬´ mains libres ¬ª : il ex√©cute la suite et d√©bogue tout seul.\n\nWorkflow :\n\n- initialiser le repo\n- lancer aider\n- coller le prompt\n- regarder aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider lance les tests / on v√©rifie l‚Äôapp\n- si OK : prompt suivant\n- sinon : Q&A avec aider\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### R√©sultats\n\nJ‚Äôai sorti une quantit√© folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Franchement efficace.\n\nSi tu repousses un projet (petit ou gros), teste donc : tu seras surpris de la vitesse √† laquelle √ßa avance.\n\nMa todo ¬´ hack ¬ª est vide, j‚Äôai tout fait. Je d√©couvre de nouveaux langages et outils, √ßa √©largit vraiment mon horizon dev.\n\n## Pas de greenfield : it√©ration incr√©mentale\n\nParfois, pas de page blanche : il faut enrichir un code existant.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n‚Äôest pas un champ vert. Photo au hasard venant de l‚Äôappareil de mon grand-p√®re ‚Äì quelque part en Ouganda dans les ann√©es 60\" >}}\n\nDans ce cas, m√©thode un peu diff√©rente : moins de plan global, plus de planification √† la t√¢che.\n\n### Obtenir le contexte\n\nChacun a son outil f√©tiche pour empaqueter le code et l‚Äôinjecter au LLM. Moi j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) via une collection de t√¢ches d√©finies dans `~/.config/mise/config.toml` (voir [mise rules](https://mise.jdx.dev/)).\n\nVoici la liste de t√¢ches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe g√©n√®re un `output.txt` qui contient le contexte. Si c‚Äôest trop gros pour les tokens, j‚Äôexclus les parties inutiles.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUne fois `output.txt` pr√™t, je le passe √† la commande [LLM](https://github.com/simonw/LLM) pour diff√©rentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn vrai, la t√¢che mise lance : `cat output.txt | LLM -t readme-gen > README.md` ou `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. Simple : `LLM` g√®re mod√®les, cl√©s, templates.\n\nExemple : si je veux am√©liorer la couverture de tests :\n\n#### Claude\n\n- se placer dans le dossier du code\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- copier le bundle : `mise run LLM:copy_buffer_bundle`\n- coller dans Claude + premier ¬´ issue ¬ª\n- copier le code g√©n√©r√© dans l‚ÄôIDE\n- ‚Ä¶\n- lancer tests\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- se placer dans le dossier\n- lancer aider (toujours sur une nouvelle branche)\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- coller le premier ¬´ issue ¬ª dans aider\n- regarder aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ‚Ä¶\n- lancer tests\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nSuper efficace pour am√©liorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j‚Äôemploie sur du code existant :\n\n#### Revue de code\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### G√©n√©ration d‚Äôissues GitHub\n\n(je dois encore automatiser le post des issues !)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent √† dater (¬´ boomer prompts ¬ª). Si tu as des id√©es pour les am√©liorer, fais signe !\n\n## Ski ‚í∂·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nQuand j‚Äôexplique ce process, je dis : ¬´ il faut suivre agressivement ce qui se passe, sinon tu te fais vite d√©passer ¬ª.\n\nJe parle tout le temps d‚Äô√™tre **¬´ over my skis ¬ª** avec les LLM ‚Äî tu skies dans de la poudre parfaite, puis soudain : ¬´ MAIS QU‚ÄôEST-CE QUI SE PASSE ! ¬ª et tu finis dans le ravin.\n\nLa **phase de planification** (cf. Greenfield) aide √† garder le contr√¥le : tu as au moins un doc de r√©f√©rence. Les tests aussi, surtout avec aider en mode freestyle : √ßa reste propre et serr√©.\n\nMalgr√© tout, je me retrouve souvent **over my skis**. Parfois, une pause ou une petite marche suffit. Au fond, c‚Äôest la r√©solution de probl√®me habituelle, mais √† vitesse supersonique.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Je suis si seul (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMon principal reproche : tout √ßa reste majoritairement **solo** ‚Äî des interfaces ¬´ single player ¬ª.\n\nJ‚Äôai cod√© des ann√©es tout seul, en pair, en √©quipe. C‚Äôest toujours meilleur √† plusieurs. L√†, les bots se cognent, les merges sont moches, le contexte est compliqu√©.\n\nJ‚Äôaimerais vraiment qu‚Äôon r√©solve √ßa et qu‚Äôon rende le dev avec LLM **multijoueur**. Pas juste une exp√©rience de hacker solitaire. Il y a un monde √† construire l√†-dessus.\n\nAU BOULOT !\n\n## ‚¥µ Temps ‚¥µ\n\nLe codegen a explos√© la quantit√© de code qu‚Äôune seule personne peut produire. Effet secondaire bizarre : beaucoup de ¬´ temps mort ¬ª pendant que le LLM calcule.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m‚Äôen souviens comme si c‚Äô√©tait hier\" >}}\n\nJ‚Äôai donc modifi√© ma fa√ßon de travailler :\n\n- je lance le brainstorming d‚Äôun autre projet\n- j‚Äô√©coute des vinyles\n- je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)\n- je discute avec des amis (et des robots)\n\nC‚Äôest g√©nial de hacker comme √ßa. Hack Hack Hack. Je ne me souviens pas avoir jamais √©t√© aussi productif.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nBeaucoup de mes potes disent : ¬´ les LLM c‚Äôest nul, √ßa rate tout ¬ª. Je respecte cette vision, m√™me si je ne la partage pas. Il y a de vraies raisons de se m√©fier de l‚ÄôIA. Ma peur num√©ro 1 : la conso √©lectrique et l‚Äôimpact environnemental. Mais‚Ä¶ le code doit couler. Right‚Ä¶ *soupir*.\n\nSi tu es curieux sans vouloir devenir un ¬´ cyborg programmer ¬ª, lis le bouquin d‚ÄôEthan Mollick : [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC‚Äôest une bonne intro, sans le ton bro techno-libertarien. J‚Äôai eu plein de discussions nuanc√©es avec des amis apr√®s l‚Äôavoir lu. Recommand√©.\n\nSi tu es sceptique mais intrigu√©, ping moi : on peut en discuter et peut-√™tre construire un truc ensemble.\n\n_merci √† [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d‚Äôavoir relu ce billet et sugg√©r√© des modifs. Je vous en suis reconnaissant._",
      "usage": {
        "prompt_tokens": 4834,
        "completion_tokens": 4298,
        "total_tokens": 9132
      },
      "streaming": true
    },
    "editing": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "\n        1. Carefully read the translated text alongside the original text in its entirety.\n        2. Compare both texts to ensure the translation accurately reflects the original meaning.\n        3. Correct any grammatical errors you find in the french text.\n        4. Adjust phrasing to make it sound natural and fluent for french speakers, making sure idioms and expressions are culturally appropriate.\n        5. Preserve the original tone, nuance, and style, including any formatting, markdown, and structure.\n        6. Avoid adding new information or altering the core meaning.\n        7. Ensure the final result doesn't feel machine-translated but remains faithful to the source.\n        8. Make only changes that genuinely improve the text's quality in french.\n        9. Don't be too literal. If there isn't a direct translation, provide a natural-sounding translation.\n        10. If the text contains idioms or colloquialisms, translate them into the target language while maintaining their original meaning.\n        11. If the text contains technical terms or jargon, ensure that the translation is accurate and appropriate for the target audience, if there isn't a natural translation, keep it in the original language.\n        12. If there is not natural translation, keep it in the original language.\n        ",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# TRANSLATED TEXT\n_tl;dr : √âlaborer un spec, puis planifier le plan, puis ex√©cuter gr√¢ce au codegen LLM. Boucles discr√®tes. Et ensuite, la magie. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nJe construis depuis un moment plein de petits produits √† l‚Äôaide des LLM. C‚Äôest √† la fois amusant et utile. Mais il existe de nombreux pi√®ges qui peuvent faire perdre un temps fou. Il y a quelque temps, un ami m‚Äôa demand√© comment j‚Äôutilisais les LLM pour √©crire du code. Je me suis dit : ¬´ Ohlala‚Ä¶ tu as combien de temps ? ¬ª ‚Äî d‚Äôo√π ce billet.\n\n(p.s. si tu d√©testes l‚ÄôIA, va directement √† la fin)\n\nJe discute souvent de tout √ßa avec des potes dev, et nous suivons tous √† peu pr√®s la m√™me m√©thode, avec quelques ajustements par-ci par-l√†.\n\nVoici donc mon workflow. Il s‚Äôappuie sur mon exp√©rience perso, des √©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glan√©es dans les recoins parfois douteux d‚ÄôInternet : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\n√áa marche super bien **MAINTENANT**, peut-√™tre plus du tout dans deux semaines‚Ä¶ ou deux fois mieux. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images g√©n√©r√©es par IA un peu louches. Voici donc mon ange robot codeur juggalo !\" >}}\n\nIl existe plein de fa√ßons de d√©velopper, mais je me retrouve g√©n√©ralement dans l‚Äôun de ces deux cas :\n\n- Code neuf (greenfield)\n- Code existant relativement moderne\n\nJe vais te montrer mon process pour les deux.\n\n## Code neuf\n\nVoici le process que j‚Äôutilise pour un d√©veloppement greenfield. Il fournit un cadre solide de planification et de documentation, et permet d‚Äôavancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert √† droite. Leica Q, 14/05/2016\" >}}\n\n### √âtape 1 : Affiner l‚Äôid√©e\n\nUtilise un LLM conversationnel pour peaufiner l‚Äôid√©e (j‚Äôemploie ChatGPT 4o / o3) :\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\n√Ä la fin du brainstorming (tu sentiras quand c‚Äôest fini) :\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nOn obtient alors un spec assez propre qu‚Äôon peut passer √† l‚Äô√©tape de planification. Je le sauvegarde en g√©n√©ral sous `spec.md` dans le repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### √âtape 2 : Planification\n\nPrends le spec et envoie-le √† un mod√®le de raisonnement digne de ce nom (`o1*`, `o3*`, `r1`) :\n\n(Prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Prompt non-TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe mod√®le doit te sortir un ¬´ prompt plan ¬ª que tu pourras ex√©cuter avec aider, cursor, etc. Je le sauvegarde en g√©n√©ral sous `prompt_plan.md`.\n\nEnsuite, je lui demande de g√©n√©rer un `todo.md` √† cocher :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n√Ä mettre √† la racine du repo.\n\nTon outil de codegen doit pouvoir cocher les cases du `todo.md` au fil de la session : pratique pour garder l‚Äô√©tat.\n\n#### Hourra, un plan !\n\nTu as maintenant un plan solide et de la doc pour piloter ton projet.\n\nL‚Äôensemble de la phase 1+2 prend **15 minutes** max. C‚Äôest fou.\n\n### √âtape 3 : Ex√©cution\n\nIl existe √©norm√©ment d‚Äôoutils pour cette phase. Leur r√©ussite d√©pend surtout de la qualit√© de l‚Äô√©tape 2.\n\nJ‚Äôai test√© ce workflow avec [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai)‚Ä¶ √áa marche partout.\n\nPerso je pr√©f√®re **claude brut** + aider.\n\n### Claude\n\nJe fais du pair-programming sur [claude.ai](https://claude.ai) : je balance chaque prompt √† la suite. √áa tourne pas mal. Les aller-retour peuvent √™tre un peu lourds, mais globalement √ßa le fait.\n\nJe m‚Äôoccupe du boilerplate et du setup outillage. √áa donne plus de libert√© et √©vite que Claude ne balance d‚Äôoffice du React. Une bonne base claire (langage, style, tooling) aide beaucoup.\n\nQuand √ßa coince, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) pour passer tout le code √† Claude et d√©boguer.\n\nWorkflow :\n\n- initialiser le repo (boilerplate, `uv init`, `cargo init`, etc.)\n- coller le prompt dans Claude\n- copier-coller le code g√©n√©r√© dans l‚ÄôIDE\n- lancer le code, les tests, etc.\n- ‚Ä¶\n- si √ßa marche : prompt suivant\n- sinon : repomix + Claude pour d√©bug\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu chelou. √áa s‚Äôimbrique bien avec la sortie de l‚Äô√©tape 2 et on va tr√®s loin sans effort.\n\nM√™me logique que ci-dessus, sauf qu‚Äôon colle les prompts dans aider.\n\nAider ¬´ fait le taf ¬ª et moi je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nGr√¢ce aux tests, aider peut √™tre encore plus ¬´ mains libres ¬ª : il ex√©cute la suite et d√©bogue tout seul.\n\nWorkflow :\n\n- initialiser le repo\n- lancer aider\n- coller le prompt\n- regarder aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider lance les tests / on v√©rifie l‚Äôapp\n- si OK : prompt suivant\n- sinon : Q&A avec aider\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### R√©sultats\n\nJ‚Äôai sorti une quantit√© folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Franchement efficace.\n\nSi tu repousses un projet (petit ou gros), teste donc : tu seras surpris de la vitesse √† laquelle √ßa avance.\n\nMa todo ¬´ hack ¬ª est vide, j‚Äôai tout fait. Je d√©couvre de nouveaux langages et outils, √ßa √©largit vraiment mon horizon dev.\n\n## Pas de greenfield : it√©ration incr√©mentale\n\nParfois, pas de page blanche : il faut enrichir un code existant.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n‚Äôest pas un champ vert. Photo au hasard venant de l‚Äôappareil de mon grand-p√®re ‚Äì quelque part en Ouganda dans les ann√©es 60\" >}}\n\nDans ce cas, m√©thode un peu diff√©rente : moins de plan global, plus de planification √† la t√¢che.\n\n### Obtenir le contexte\n\nChacun a son outil f√©tiche pour empaqueter le code et l‚Äôinjecter au LLM. Moi j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) via une collection de t√¢ches d√©finies dans `~/.config/mise/config.toml` (voir [mise rules](https://mise.jdx.dev/)).\n\nVoici la liste de t√¢ches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe g√©n√®re un `output.txt` qui contient le contexte. Si c‚Äôest trop gros pour les tokens, j‚Äôexclus les parties inutiles.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUne fois `output.txt` pr√™t, je le passe √† la commande [LLM](https://github.com/simonw/LLM) pour diff√©rentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn vrai, la t√¢che mise lance : `cat output.txt | LLM -t readme-gen > README.md` ou `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. Simple : `LLM` g√®re mod√®les, cl√©s, templates.\n\nExemple : si je veux am√©liorer la couverture de tests :\n\n#### Claude\n\n- se placer dans le dossier du code\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- copier le bundle : `mise run LLM:copy_buffer_bundle`\n- coller dans Claude + premier ¬´ issue ¬ª\n- copier le code g√©n√©r√© dans l‚ÄôIDE\n- ‚Ä¶\n- lancer tests\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- se placer dans le dossier\n- lancer aider (toujours sur une nouvelle branche)\n- `mise run LLM:generate_missing_tests`\n- ouvrir `missing-tests.md`\n- coller le premier ¬´ issue ¬ª dans aider\n- regarder aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ‚Ä¶\n- lancer tests\n- rince & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nSuper efficace pour am√©liorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j‚Äôemploie sur du code existant :\n\n#### Revue de code\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### G√©n√©ration d‚Äôissues GitHub\n\n(je dois encore automatiser le post des issues !)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent √† dater (¬´ boomer prompts ¬ª). Si tu as des id√©es pour les am√©liorer, fais signe !\n\n## Ski ‚í∂·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nQuand j‚Äôexplique ce process, je dis : ¬´ il faut suivre agressivement ce qui se passe, sinon tu te fais vite d√©passer ¬ª.\n\nJe parle tout le temps d‚Äô√™tre **¬´ over my skis ¬ª** avec les LLM ‚Äî tu skies dans de la poudre parfaite, puis soudain : ¬´ MAIS QU‚ÄôEST-CE QUI SE PASSE ! ¬ª et tu finis dans le ravin.\n\nLa **phase de planification** (cf. Greenfield) aide √† garder le contr√¥le : tu as au moins un doc de r√©f√©rence. Les tests aussi, surtout avec aider en mode freestyle : √ßa reste propre et serr√©.\n\nMalgr√© tout, je me retrouve souvent **over my skis**. Parfois, une pause ou une petite marche suffit. Au fond, c‚Äôest la r√©solution de probl√®me habituelle, mais √† vitesse supersonique.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Je suis si seul (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMon principal reproche : tout √ßa reste majoritairement **solo** ‚Äî des interfaces ¬´ single player ¬ª.\n\nJ‚Äôai cod√© des ann√©es tout seul, en pair, en √©quipe. C‚Äôest toujours meilleur √† plusieurs. L√†, les bots se cognent, les merges sont moches, le contexte est compliqu√©.\n\nJ‚Äôaimerais vraiment qu‚Äôon r√©solve √ßa et qu‚Äôon rende le dev avec LLM **multijoueur**. Pas juste une exp√©rience de hacker solitaire. Il y a un monde √† construire l√†-dessus.\n\nAU BOULOT !\n\n## ‚¥µ Temps ‚¥µ\n\nLe codegen a explos√© la quantit√© de code qu‚Äôune seule personne peut produire. Effet secondaire bizarre : beaucoup de ¬´ temps mort ¬ª pendant que le LLM calcule.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m‚Äôen souviens comme si c‚Äô√©tait hier\" >}}\n\nJ‚Äôai donc modifi√© ma fa√ßon de travailler :\n\n- je lance le brainstorming d‚Äôun autre projet\n- j‚Äô√©coute des vinyles\n- je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)\n- je discute avec des amis (et des robots)\n\nC‚Äôest g√©nial de hacker comme √ßa. Hack Hack Hack. Je ne me souviens pas avoir jamais √©t√© aussi productif.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nBeaucoup de mes potes disent : ¬´ les LLM c‚Äôest nul, √ßa rate tout ¬ª. Je respecte cette vision, m√™me si je ne la partage pas. Il y a de vraies raisons de se m√©fier de l‚ÄôIA. Ma peur num√©ro 1 : la conso √©lectrique et l‚Äôimpact environnemental. Mais‚Ä¶ le code doit couler. Right‚Ä¶ *soupir*.\n\nSi tu es curieux sans vouloir devenir un ¬´ cyborg programmer ¬ª, lis le bouquin d‚ÄôEthan Mollick : [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC‚Äôest une bonne intro, sans le ton bro techno-libertarien. J‚Äôai eu plein de discussions nuanc√©es avec des amis apr√®s l‚Äôavoir lu. Recommand√©.\n\nSi tu es sceptique mais intrigu√©, ping moi : on peut en discuter et peut-√™tre construire un truc ensemble.\n\n_merci √† [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d‚Äôavoir relu ce billet et sugg√©r√© des modifs. Je vous en suis reconnaissant._\n\nPlease review and improve the translated text to make it natural and accurate in french.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr : √âlaborer une spec, puis planifier le plan, puis ex√©cuter gr√¢ce au codegen LLM. Boucles discr√®tes. Et ensuite, la magie. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\n√áa fait un moment que je bricole plein de petits produits √† l‚Äôaide des LLM. C‚Äôest √† la fois amusant et utile. Mais il existe de nombreux pi√®ges qui peuvent faire perdre un temps fou. Il y a quelque temps, un ami m‚Äôa demand√© comment j‚Äôutilisais les LLM pour √©crire du code. Je me suis dit : ¬´ Oh l√† l√†‚Ä¶ tu as combien de temps ? ¬ª ‚Äî d‚Äôo√π ce billet.\n\n(p.s. si tu d√©testes l‚ÄôIA, file directement √† la fin)\n\nJe discute souvent de tout √ßa avec des potes dev, et nous suivons tous √† peu pr√®s la m√™me m√©thode, avec quelques ajustements par-ci par-l√†.\n\nVoici donc mon workflow. Il s‚Äôappuie sur mon exp√©rience perso, sur des √©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glan√©es dans les recoins parfois douteux d‚ÄôInternet : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\n√áa marche super bien **MAINTENANT**, peut-√™tre plus du tout dans deux semaines‚Ä¶ ou deux fois mieux. ¬Ø\\\\_(„ÉÑ)_/¬Ø\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images g√©n√©r√©es par IA un peu louches. Voici donc mon ange robot codeur juggalo !\" >}}\n\nIl existe plein de fa√ßons de d√©velopper, mais je me retrouve g√©n√©ralement dans l‚Äôun de ces deux cas :\n\n- Code neuf (greenfield)\n- Code existant relativement moderne\n\nJe vais te montrer mon process pour les deux.\n\n## Code neuf\n\nVoici le process que j‚Äôutilise pour un d√©veloppement greenfield. Il fournit un cadre solide de planification et de documentation, et permet d‚Äôavancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert √† droite. Leica Q, 14/05/2016\" >}}\n\n### √âtape 1 : Affiner l‚Äôid√©e\n\nUtilise un LLM conversationnel pour peaufiner l‚Äôid√©e (j‚Äôemploie ChatGPT 4o / o3) :\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\n√Ä la fin du brainstorming (tu sentiras quand c‚Äôest fini) :\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nOn obtient alors une spec assez propre qu‚Äôon peut passer √† l‚Äô√©tape de planification. Je la sauvegarde en g√©n√©ral sous `spec.md` dans le repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### √âtape 2 : Planification\n\nPrends la spec et envoie-la √† un mod√®le de raisonnement digne de ce nom (`o1*`, `o3*`, `r1`) :\n\n(Prompt TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(Prompt non-TDD)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe mod√®le doit te sortir un ¬´ prompt plan ¬ª que tu pourras ex√©cuter avec aider, cursor, etc. Je le sauvegarde en g√©n√©ral sous `prompt_plan.md`.\n\nEnsuite, je lui demande de g√©n√©rer un `todo.md` √† cocher :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n√Ä mettre √† la racine du repo.\n\nTon outil de codegen doit pouvoir cocher les cases du `todo.md` au fil de la session : pratique pour garder l‚Äô√©tat.\n\n#### Hourra, un plan !\n\nTu as maintenant un plan solide et une doc pour piloter ton projet.\n\nL‚Äôensemble de la phase 1+2 prend **15 minutes** maxi. C‚Äôest fou.\n\n### √âtape 3 : Ex√©cution\n\nIl existe √©norm√©ment d‚Äôoutils pour cette phase. Leur r√©ussite d√©pend surtout de la qualit√© de l‚Äô√©tape 2.\n\nJ‚Äôai test√© ce workflow avec [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai)‚Ä¶ √áa marche partout.\n\nPerso, je pr√©f√®re **Claude brut** et aider.\n\n### Claude\n\nJe fais du pair-programming sur [claude.ai](https://claude.ai) : je balance chaque prompt √† la suite. √áa tourne pas mal. Les allers-retours peuvent √™tre un peu lourds, mais globalement √ßa le fait.\n\nJe m‚Äôoccupe du boilerplate et du setup tooling. √áa donne plus de libert√© et √©vite que Claude ne sorte direct du React. Une bonne base claire (langage, style, tooling) aide beaucoup.\n\nQuand √ßa coince, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) pour passer tout le code √† Claude et d√©boguer.\n\nWorkflow :\n\n- initialiser le repo (boilerplate, `uv init`, `cargo init`, etc.)\n- coller le prompt dans Claude\n- copier-coller le code g√©n√©r√© dans l‚ÄôIDE\n- lancer le code, les tests, etc.\n- ‚Ä¶\n- si √ßa marche : prompt suivant\n- sinon : repomix + Claude pour d√©boguer\n- rinse & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu chelou. √áa s‚Äôimbrique bien avec la sortie de l‚Äô√©tape 2 et on va tr√®s loin sans effort.\n\nM√™me logique que ci-dessus, sauf qu‚Äôon colle les prompts dans aider.\n\nAider ¬´ fait le taf ¬ª et moi je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nGr√¢ce aux tests, aider peut √™tre encore plus ¬´ mains libres ¬ª : il ex√©cute la suite et d√©bogue tout seul.\n\nWorkflow :\n\n- initialiser le repo\n- lancer aider\n- coller le prompt\n- regarder aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider lance les tests / on v√©rifie l‚Äôapp\n- si OK : prompt suivant\n- sinon : Q&A avec aider\n- rinse & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### R√©sultats\n\nJ‚Äôai sorti une quantit√© folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Franchement efficace.\n\nSi tu repousses un projet (petit ou gros), teste donc : tu seras surpris de la vitesse √† laquelle √ßa avance.\n\nMa todo ¬´ hack ¬ª est vide, j‚Äôai tout fait. Je d√©couvre de nouveaux langages et outils ; √ßa √©largit vraiment mon horizon dev.\n\n## Pas de greenfield : it√©ration incr√©mentale\n\nParfois, pas de page blanche : il faut enrichir un code existant.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n‚Äôest pas un champ vert. Photo au hasard venant de l‚Äôappareil de mon grand-p√®re ‚Äì quelque part en Ouganda dans les ann√©es 60\" >}}\n\nDans ce cas, m√©thode un peu diff√©rente : moins de plan global, plus de planification √† la t√¢che.\n\n### Obtenir le contexte\n\nChacun a son outil f√©tiche pour empaqueter le code et l‚Äôinjecter au LLM. Moi, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) via une collection de t√¢ches d√©finies dans `~/.config/mise/config.toml` (voir [mise rules](https://mise.jdx.dev/)).\n\nVoici la liste de t√¢ches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe g√©n√®re un `output.txt` qui contient le contexte. Si c‚Äôest trop gros pour les tokens, j‚Äôexclus les parties inutiles.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nUne fois `output.txt` pr√™t, je le passe √† la commande [LLM](https://github.com/simonw/LLM) pour diff√©rentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn pratique, la t√¢che mise lance : `cat output.txt | LLM -t readme-gen > README.md` ou `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. Simple : `LLM` g√®re mod√®les, cl√©s et templates.\n\nExemple : si je veux am√©liorer la couverture de tests :\n\n#### Claude\n\n- se placer dans le dossier du code  \n- `mise run LLM:generate_missing_tests`  \n- ouvrir `missing-tests.md`  \n- copier le bundle : `mise run LLM:copy_buffer_bundle`  \n- coller dans Claude + premier ¬´ issue ¬ª  \n- copier le code g√©n√©r√© dans l‚ÄôIDE  \n- ‚Ä¶  \n- lancer les tests  \n- rinse & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- se placer dans le dossier  \n- lancer aider (toujours sur une nouvelle branche)  \n- `mise run LLM:generate_missing_tests`  \n- ouvrir `missing-tests.md`  \n- coller le premier ¬´ issue ¬ª dans aider  \n- regarder aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™  \n- ‚Ä¶  \n- lancer les tests  \n- rinse & repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nSuper efficace pour am√©liorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j‚Äôemploie sur du code existant :\n\n#### Revue de code\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### G√©n√©ration d‚Äôissues GitHub\n\n(je dois encore automatiser le post des issues !)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent √† dater (¬´ boomer prompts ¬ª). Si tu as des id√©es pour les am√©liorer, fais-moi signe !\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nQuand j‚Äôexplique ce process, je dis : ¬´ il faut suivre agressivement ce qui se passe, sinon tu te fais vite d√©passer ¬ª.\n\nJe parle tout le temps d‚Äô√™tre **¬´ over my skis ¬ª** avec les LLM ‚Äî tu skies dans de la poudre parfaite, puis soudain : ¬´ MAIS QU‚ÄôEST-CE QUI SE PASSE ! ¬ª et tu finis dans le ravin.\n\nLa **phase de planification** (cf. Greenfield) aide √† garder le contr√¥le : tu as au moins un doc de r√©f√©rence. Les tests aussi, surtout avec aider en mode freestyle : √ßa reste propre et serr√©.\n\nMalgr√© tout, je me retrouve souvent **over my skis**. Parfois, une pause ou une petite marche suffit. Au fond, c‚Äôest la r√©solution de probl√®mes habituelle, mais √† vitesse supersonique.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## Je suis si seul (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMon principal reproche : tout √ßa reste majoritairement **solo** ‚Äî des interfaces ¬´ single player ¬ª.\n\nJ‚Äôai cod√© des ann√©es tout seul, en pair, en √©quipe. C‚Äôest toujours meilleur √† plusieurs. L√†, les bots se cognent, les merges sont moches, le contexte est compliqu√©.\n\nJ‚Äôaimerais vraiment qu‚Äôon r√©solve √ßa et qu‚Äôon rende le dev avec LLM **multijoueur**. Pas juste une exp√©rience de hacker solitaire. Il y a un monde √† construire l√†-dessus.\n\nAU BOULOT !\n\n## ‚¥µ Temps ‚¥µ\n\nLe codegen a explos√© la quantit√© de code qu‚Äôune seule personne peut produire. Effet secondaire bizarre : beaucoup de ¬´ temps mort ¬ª pendant que le LLM calcule.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m‚Äôen souviens comme si c‚Äô√©tait hier\" >}}\n\nJ‚Äôai donc adapt√© ma fa√ßon de travailler :\n\n- je lance le brainstorming d‚Äôun autre projet  \n- j‚Äô√©coute des vinyles  \n- je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)  \n- je discute avec des amis (et des robots)\n\nC‚Äôest g√©nial de hacker comme √ßa. Hack ! Hack ! Hack ! Je ne me souviens pas avoir jamais √©t√© aussi productif.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nBeaucoup de mes potes disent : ¬´ les LLM c‚Äôest nul, √ßa rate tout ¬ª. Je respecte cette vision, m√™me si je ne la partage pas. Il y a de vraies raisons de se m√©fier de l‚ÄôIA. Ma peur num√©ro 1 : la consommation √©lectrique et l‚Äôimpact environnemental. Mais‚Ä¶ le code doit couler. Right‚Ä¶ *soupir*.\n\nSi tu es curieux sans vouloir devenir un ¬´ cyborg programmer ¬ª, lis le bouquin d‚ÄôEthan Mollick : [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC‚Äôest une bonne intro, sans le ton bro techno-libertarien. J‚Äôai eu plein de discussions nuanc√©es avec des amis apr√®s l‚Äôavoir lu. Recommand√©.\n\nSi tu es sceptique mais intrigu√©, fais-moi signe : on peut en discuter et peut-√™tre construire un truc ensemble.\n\n_merci √† [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d‚Äôavoir relu ce billet et sugg√©r√© des modifs. Je vous suis reconnaissant._",
      "usage": {
        "prompt_tokens": 9466,
        "completion_tokens": 4307,
        "total_tokens": 13773
      },
      "streaming": true
    },
    "critique": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "You are a highly critical professional translator and linguistic expert specializing in french.\nYour task is to ruthlessly critique the translation by:\n\n1. Meticulously comparing the translated text with the original, identifying ANY inaccuracies, mistranslations, or omissions\n2. Highlighting nuances, cultural references, or idioms that were lost or mistranslated\n3. Scrutinizing for grammatical errors, awkward phrasing, or unnatural expressions in french\n4. Checking for inconsistencies in tone, style, or register compared to the original\n5. Verifying that technical terms are translated accurately and consistently\n6. Ensuring no content was accidentally skipped or added\n7. Finding places where the translation sounds machine-like or overly literal\n\nBe extremely thorough and critical in your assessment. Do not accept mediocre translations.\nList specific issues and suggestions for improvement, organized by severity and category.\nYour critique should be detailed enough for another translator to address all the issues.\n\nYour goal is to help create a perfect translation that reads as if originally written in french while being 100% faithful to the source.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr : brainstorme la spec, puis fais un plan, puis ex√©cute la g√©n√©ration de code (codegen) avec un LLM. Cycles bien distincts, puis magie. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nJe bricole depuis un moment plein de petits projets gr√¢ce aux mod√®les de langage (LLM). C‚Äôest amusant ‚Äì et utile. Mais il y a aussi des pi√®ges qui peuvent faire perdre un temps fou. Un jour, un ami m‚Äôa demand√© comment j‚Äôutilisais les LLM pour coder. Je me suis dit : ¬´ Oh l√† l√† ! T‚Äôas combien de temps devant toi ? ¬ª ‚Äì d‚Äôo√π ce billet.\n\n(p.s. si tu d√©testes l‚ÄôIA, file directement √† la fin)\n\nJ‚Äôen parle souvent avec des potes dev, et on suit tous √† peu pr√®s la m√™me approche, chacun avec ses petits ajustements.\n\nVoici donc mon flux de travail. Il repose sur mon exp√©rience perso, sur des √©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur des bonnes pratiques d√©nich√©es dans les recoins (parfois douteux) du Net : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\n√áa marche super bien **POUR L‚ÄôINSTANT** ; dans deux semaines ce sera peut-√™tre cass√©‚Ä¶ ou deux fois plus efficace. ¬Ø\\\\_(„ÉÑ)_/¬Ø\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images g√©n√©r√©es par IA un peu louches. Voici mon ange-robot codeur fa√ßon juggalo !\" >}}\n\nIl y a mille fa√ßons de d√©velopper, mais je tombe g√©n√©ralement sur l‚Äôun de ces deux cas :\n\n- projet greenfield (tout est √† cr√©er) ;\n- code existant relativement moderne (brownfield).\n\nJe vais te montrer mon processus pour les deux.\n\n## Greenfield\n\nPour un projet greenfield, ce processus marche bien : il offre un cadre solide de planification et de documentation, et permet d‚Äôavancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert √† droite. Leica Q, 14/05/2016\" >}}\n\n### √âtape 1 : affiner l‚Äôid√©e\n\nUtilise un LLM conversationnel pour peaufiner l‚Äôid√©e (j‚Äôemploie ChatGPT 4o / o3) :\n\n(Conserve le prompt en anglais, c‚Äôest la langue attendue par les LLM.)\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\n√Ä la fin du remue-m√©ninges (tu sentiras quand c‚Äôest termin√©) :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nTu obtiens alors une spec assez propre qu‚Äôon peut passer √† la phase de planification. Je la sauvegarde en g√©n√©ral sous `spec.md`.\n\n> On peut faire plein de choses avec cette spec. Ici on vise le codegen, mais je m‚Äôen sers aussi pour demander √† un mod√®le sp√©cialis√© dans le raisonnement de trouver les failles (toujours plus loin !), pour r√©diger un livre blanc (white paper) ou imaginer un business model. Tu peux m√™me l‚Äôenvoyer dans une phase de recherche pouss√©e et r√©cup√©rer un doc de 10 000 mots en retour.\n\n### √âtape 2 : planification\n\nPrends la spec et envoie-la √† un mod√®le orient√© raisonnement (`o1*`, `o3*`, `r1`) :\n\n#### Prompt TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n#### Prompt non-TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe mod√®le te sort un plan de prompts (`prompt_plan.md`) que tu pourras ex√©cuter avec Aider, Cursor, etc.\n\nDemande-lui ensuite un `todo.md` √† cocher :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nTon outil de codegen pourra cocher le `todo.md` au fil de la session ‚Äì parfait pour garder l‚Äô√©tat.\n\n#### Youpi : un plan !\n\nTu as maintenant un plan solide et une doc pour piloter ton projet.\n\nCes deux premi√®res √©tapes prennent au plus **15 minutes**. Franchement dingue.\n\n### √âtape 3 : ex√©cution\n\nIl existe une foule d‚Äôoutils pour cette phase ; leur succ√®s d√©pend surtout de la qualit√© de l‚Äô√©tape 2.\n\nJ‚Äôai test√© ce workflow avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [claude-engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)‚Ä¶ √áa marche avec tous ceux que j‚Äôai essay√©s.\n\nPerso, je pr√©f√®re Claude en mode ¬´ raw ¬ª (brut) et Aider.\n\n### Claude\n\nJe fais du pair programming sur [Claude.ai](https://claude.ai) : je balance chaque prompt, un √† un. Les allers-retours sont parfois lourds, mais √ßa fonctionne.\n\nJe m‚Äôoccupe du boilerplate (ossature) et du setup tooling. √áa √©vite que Claude ne parte direct sur du React et me laisse choisir la stack.\n\nQuand √ßa coince, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) pour envoyer tout le code √† Claude et d√©boguer.\n\nWorkflow :\n\n- initialiser le d√©p√¥t (`uv init`, `cargo init`, etc.) ;  \n- coller le prompt dans Claude ;  \n- copier-coller le code g√©n√©r√© dans l‚ÄôIDE ;  \n- lancer l‚Äôappli et les tests ;  \n- ‚Ä¶  \n- si √ßa marche : prompt suivant ;  \n- sinon : repomix + Claude pour d√©boguer ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu bizarre. Il se greffe bien sur la sortie de l‚Äô√©tape 2 et on va tr√®s loin sans effort.\n\nM√™me logique que ci-dessus, sauf qu‚Äôon colle les prompts dans Aider.\n\nAider ¬´ fait le taf ¬ª et moi je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> Au passage, Aider publie d‚Äôexcellents benchmarks de mod√®les de codegen dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/). Pratique pour voir la perf des nouveaut√©s.\n\nGr√¢ce aux tests, Aider peut √™tre encore plus mains libres : il ex√©cute la suite et d√©bogue tout seul.\n\nWorkflow :\n\n- initialiser le d√©p√¥t ;  \n- lancer Aider ;  \n- coller le prompt ;  \n- regarder Aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™ ;  \n- Aider lance les tests / ou tu lances l‚Äôappli ;  \n- si OK : prompt suivant ;  \n- sinon : Q&A avec Aider ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### R√©sultats\n\nJ‚Äôai sorti une quantit√© folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Super efficace.\n\nMa todo ¬´ hack ¬ª est vide parce que j‚Äôai tout fait. Je continue d‚Äôavoir de nouvelles id√©es que je d√©coche √† la cha√Æne en matant un film. Pour la premi√®re fois depuis des ann√©es, je passe du temps sur de nouveaux langages et outils ; √ßa √©largit vraiment mon horizon.\n\n## Brownfield : it√©ration incr√©mentale\n\nParfois, on n‚Äôest pas en terrain vierge : il faut am√©liorer une base de code existante (brownfield).\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n‚Äôest pas un champ vert. Photo prise par mon grand-p√®re ‚Äì Ouganda, ann√©es 60\" >}}\n\nDans ce cas, m√©thode un peu diff√©rente : moins de plan global, plus de planification √† la t√¢che.\n\n### Obtenir le contexte\n\nChacun a son outil f√©tiche pour empaqueter le code et l‚Äôinjecter au LLM. Moi, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) via des t√¢ches d√©finies dans `~/.config/mise/config.toml` (voir les [r√®gles mise](https://mise.jdx.dev/)).\n\nListe des t√¢ches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe g√©n√®re un `output.txt` qui contient tout le contexte. Si c‚Äôest trop gros pour les jetons, j‚Äôexclus les parties inutiles.\n\n> Ce qui est top avec `mise`, c‚Äôest que les t√¢ches peuvent √™tre red√©finies ou surcharg√©es dans le `.mise.toml` du projet. Je peux utiliser un autre outil pour empaqueter le code ; tant qu‚Äôil produit un `output.txt`, mes t√¢ches LLM fonctionnent. Tr√®s pratique quand les bases de code diff√®rent. Je surcharge souvent l‚Äô√©tape `repomix` pour √©largir les patterns d‚Äôignore ou j‚Äôutilise un outil plus efficace.\n\nUne fois `output.txt` pr√™t, je le passe √† la commande [LLM](https://github.com/simonw/LLM) pour diff√©rentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn pratique, la t√¢che `mise` lance :\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nou :\n\n```\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nSimple : `LLM` g√®re mod√®les, cl√©s et templates.\n\nExemple : am√©liorer la couverture de tests.\n\n#### Claude\n\n- se placer dans le dossier du code ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- copier le bundle : `mise run LLM:copy_buffer_bundle` ;  \n- coller dans Claude avec la premi√®re ¬´ issue ¬ª ;  \n- copier le code g√©n√©r√© dans l‚ÄôIDE ;  \n- lancer les tests ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- se placer dans le dossier ;  \n- lancer Aider (toujours sur une nouvelle branche) ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- coller la premi√®re ¬´ issue ¬ª dans Aider ;  \n- regarder Aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™ ;  \n- lancer les tests ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nSuper efficace pour am√©liorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j‚Äôutilise sur du code existant :\n\n#### Revue de code\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### G√©n√©ration d‚Äôissues GitHub\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent √† dater (¬´ prompts de boomer ¬ª). Si tu as des id√©es pour les am√©liorer, dis-moi !\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nQuand j‚Äôexplique ce proc√©d√©, je dis toujours : ¬´ Il faut suivre de pr√®s ce qui se passe, sinon tu te retrouves vite les spatules dans le vide. ¬ª\n\nJe parle souvent d‚Äô√™tre **over my skis** avec les LLM : tu skies dans de la poudre parfaite, puis soudain ¬´ MAIS QU‚ÄôEST-CE QUI SE PASSE ? ¬ª et tu bascules dans le ravin.\n\nLa **phase de planification** (cf. greenfield) aide √† garder le contr√¥le : tu as au moins un doc de r√©f√©rence. Les tests aussi, surtout avec Aider en mode freestyle : √ßa reste propre et serr√©.\n\nMalgr√© tout, je me retrouve souvent **over my skis**. Parfois une pause ou une petite marche suffit. Au fond, c‚Äôest la r√©solution de probl√®mes habituelle, mais √† vitesse supersonique.\n\n> On demande parfois au LLM d‚Äôajouter des trucs compl√®tement absurdes dans un code pas si absurde. Par exemple, on lui a demand√© de cr√©er un fichier de lore puis d‚Äôy faire r√©f√©rence dans l‚Äôinterface utilisateur d‚Äôun outil CLI Python. D‚Äôun coup, il y a du lore, des interfaces glitchy, etc. Tout √ßa pour g√©rer tes fonctions cloud, ta todo list ou autre. Le ciel est la limite.\n\n## Je suis si seul (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nPrincipal reproche : tout √ßa reste majoritairement **solo** ‚Äì des interfaces ¬´ single player ¬ª.\n\nJ‚Äôai cod√© des ann√©es seul, en pair, en √©quipe. C‚Äôest toujours meilleur √† plusieurs. L√†, les bots se t√©lescopent, les conflits de fusion deviennent horribles, le contexte est compliqu√©.\n\nJ‚Äôaimerais vraiment qu‚Äôon rende le dev avec LLM **multijoueur**, pas juste une exp√©rience de hacker solitaire. Il y a un monde √† construire l√†-dessus.\n\nAU BOULOT !\n\n## ‚¥µ Temps ‚¥µ\n\nLe codegen a explos√© la quantit√© de code qu‚Äôune personne peut produire. Effet secondaire bizarre : beaucoup de temps mort pendant que le LLM br√ªle ses jetons.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m‚Äôen souviens comme si c‚Äô√©tait hier\" >}}\n\nDu coup, j‚Äôai adapt√© ma fa√ßon de bosser :\n\n- je d√©marre le brainstorming d‚Äôun autre projet ;  \n- j‚Äô√©coute des disques vinyles ;  \n- je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) ;  \n- je discute avec des amis et des robots.\n\nC‚Äôest g√©nial de hacker comme √ßa. Hack ! Hack ! Hack ! Je ne me souviens pas avoir √©t√© aussi productif.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nPas mal de potes me disent : ¬´ Les LLM, c‚Äôest de la daube. ¬ª Je respecte ce point de vue, m√™me si je ne le partage pas. Il y a de vraies raisons de se m√©fier de l‚ÄôIA. Ma peur num√©ro 1 : la conso √©lectrique et l‚Äôimpact environnemental. Mais‚Ä¶ le code doit couler. *soupir*\n\nSi tu es curieux sans vouloir devenir un ¬´ cyborg programmer ¬ª, lis le livre d‚ÄôEthan Mollick : [**Co-Intelligence : Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC‚Äôest une bonne intro, sans le ton bro techno-libertarien. J‚Äôai eu plein de discussions nuanc√©es avec des amis apr√®s l‚Äôavoir lu. Recommand√©.\n\nSi tu es sceptique mais un peu curieux, contacte-moi et on parlera de toute cette folie. Je peux te montrer comment on utilise les LLM et, qui sait, on pourrait construire un truc ensemble.\n\n_merci √† [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d‚Äôavoir relu ce billet et propos√© des modifs. Je vous suis reconnaissant._\n\nPlease critique this translation mercilessly and provide detailed feedback on what needs to be improved.\nFormat your critique as a structured list of issues, organized by severity and category.\nInclude specific suggestions for how to fix each issue.",
      "response": "CRITIQUE D√âTAILL√âE DE LA TRADUCTION  \n(les num√©ros renvoient aux passages dans le texte fran√ßais actuel)\n\n====================================================================\nI. PROBL√àMES CRITIQUES : SENS, FID√â¬≠LIT√â, OMISSIONS\n--------------------------------------------------------------------\n1. Slogan d‚Äôouverture  \n   FR : ¬´ brainstorme la spec, puis fais un plan ¬ª  \n   ‚Ä¢ Perte du clin-d‚Äô≈ìil ¬´ plan a plan ¬ª (double emploi volontairement absurde).  \n   ‚Ä¢ Suggestion : ¬´ ‚Ä¶ puis √©labore un plan de plan ‚Ä¶ ¬ª.\n\n2. Cat√©gorie ¬´ Legacy modern code ¬ª  \n   FR : ¬´ code existant relativement moderne (brownfield) ¬ª  \n   ‚Ä¢ ¬´ Legacy modern code ¬ª est oxymorique ; employer ¬´ code existant ‚Äúmoderne mais d√©j√† legacy‚Äù ¬ª ou conserver la tournure ironique pour ne pas lisser le propos.  \n   ‚Ä¢ ¬´ Brownfield ¬ª n‚Äôappara√Æt pas dans l‚Äôoriginal ici ; l‚Äôintroduire peut semer la confusion (l‚Äôauteur l‚Äôutilise plus tard).\n\n3. Titre ¬´ ## Brownfield : it√©ration incr√©mentale ¬ª  \n   ‚Ä¢ L‚Äôoriginal : ¬´ ## Non-greenfield: Iteration, incrementally ¬ª.  \n   ‚Ä¢ Passer de ¬´ Non-greenfield ¬ª √† ¬´ Brownfield ¬ª gomme la nuance (tout projet ‚â† greenfield n‚Äôest pas forc√©ment brownfield).  \n   ‚Ä¢ Proposer ¬´ ## Non-greenfield : it√©rations incr√©mentales ¬ª.\n\n4. ¬´ Je bricole‚Ä¶ plein de petits projets ¬ª  \n   ‚Ä¢ ¬´ I have been building so many small products ¬ª = cr√©er/fabriquer, pas ¬´ bricoler ¬ª.  \n   ‚Ä¢ ¬´ Bricoler ¬ª sous-entend amateurisme que l‚Äôauteur ne revendique pas.  \n   ‚Ä¢ Remplacer par ¬´ Je d√©veloppe / je r√©alise ¬ª.\n\n5. Omission de nuance ‚Äì Step 3 (¬´ I, however, prefer **raw** claude‚Ä¶ ¬ª)  \n   ‚Ä¢ Le texte FR garde ¬´ raw ¬ª, mais perd l‚Äôid√©e que l‚Äôauteur pr√©f√®re ¬´ claude brut (sans interface) ¬ª.  \n   ‚Ä¢ Ajouter explicitement ¬´ ‚Ä¶ en mode brut (sans surcouche) ¬ª.\n\n====================================================================\nII. PROBL√àMES MAJEURS : TON, STYLE, REGISTRE\n--------------------------------------------------------------------\n6. Oscillation ¬´ tu / vous ¬ª  \n   Exemples :  \n   6a) ¬´ (p.s. si tu d√©testes‚Ä¶) ¬ª vs ¬´ Conserve le prompt‚Ä¶ c‚Äôest la langue attendue ¬ª (impersonnel).  \n   6b) ¬´ Votre outil de codegen pourra‚Ä¶ ¬ª.  \n   ‚Ä¢ Choisir un vouvoiement ou un tutoiement constant (le tutoiement semble privil√©gi√©).  \n   ‚Ä¢ Harmoniser dans tout le doc, y compris les listes et encadr√©s.\n\n7. Anglicismes crus non justifi√©s  \n   ¬´ brainstorme ¬ª, ¬´ spec ¬ª, ¬´ prompt ¬ª, ¬´ codegen ¬ª, ¬´ brownfield ¬ª, ¬´ workflow ¬ª, etc.  \n   ‚Ä¢ Tol√©r√©s dans la communaut√© dev mais l‚Äôoriginal montre aussi un registre rel√¢ch√© ; d√©cider d‚Äôun √©quilibre. Proposer :  \n     ‚Äì ¬´ s√©ance de brainstorming ¬ª, ¬´ sp√©cification ¬ª, ¬´ g√©n√©ration de code ¬ª, ¬´ flux de travail ¬ª.  \n   ‚Ä¢ Conserver les mots-clefs techniques (¬´ prompt ¬ª‚Ä¶) quand ils sont intraduisibles, mais franciser le reste.\n\n8. Ton humoristique un peu liss√©  \n   ‚Ä¢ ¬´ Oh boy. how much time do you have! ¬ª ‚Üí ¬´ Oh l√† l√† ! ¬ª correct mais moins moqueur ; on peut ajouter ¬´ ‚Äî t‚Äôas combien d‚Äôheures devant toi ? ¬ª.  \n   ‚Ä¢ ¬´ rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß ¬ª rendu litt√©ral mais la blague (¬´ rinse and repeat ¬ª) pourrait √™tre traduite : ¬´ et on recommence, encore et encore ‚ú©‚Ä¶ ¬ª.\n\n====================================================================\nIII. PROBL√àMES MOYENS : GRAMMAIRE, SYNTAXE, FLUIDIT√â\n--------------------------------------------------------------------\n9. Ponctuation et espaces ins√©cables  \n   ‚Ä¢ En fran√ßais, espace ins√©cable avant ¬´ ; ¬ª, ¬´ : ¬ª, ¬´ ? ¬ª, ¬´ ! ¬ª (¬´ tl;dr : ¬ª, ¬´ Merci : ¬ª‚Ä¶).  \n   ‚Ä¢ Ajouter ins√©cables ou au moins espaces simples corrects.\n\n10. Inversions malhabiles  \n    ¬´ Voici donc mon flux de travail. Il repose sur mon exp√©rience perso‚Ä¶ ¬ª  \n    ‚Ä¢ ¬´ mon exp√©rience perso ¬ª = registre oral ; envisager ¬´ mon exp√©rience personnelle ¬ª.\n\n11. Faux amis / registres  \n    ¬´ Je d√©coche √† la cha√Æne ¬ª (anglicisme passif de ¬´ knocking them out ¬ª) sonne √©trange.  \n    ‚Ä¢ ¬´ j‚Äôencha√Æne les id√©es ¬ª, ¬´ je les r√©alise √† la cha√Æne ¬ª.\n\n12. Parenth√®ses excessives  \n    ‚Ä¢ Plusieurs digressions pourraient √™tre encadr√©es par tirets cadratins ou virgules pour all√©ger la lecture.\n\n====================================================================\nIV. PROBL√àMES MINEURS : TERMINOLOGIE, D√âTAILS TECHNIQUES\n--------------------------------------------------------------------\n13. ¬´ cookie clicker ¬ª  \n    ‚Ä¢ Le lien est conserv√© mais ¬´ Cookie Clicker ¬ª est un nom propre ; capitaliser syst√©matiquement.\n\n14. ¬´ disques vinyles ¬ª  \n    ‚Ä¢ ¬´ j‚Äô√©coute des vinyles ¬ª plus naturel pour un francophone.\n\n15. ¬´ UV init ¬ª  \n    ‚Ä¢ V√©rifier si ¬´ uv ¬ª (gestionnaire Python) doit rester en minuscule.\n\n16. ¬´ repomix pour envoyer tout le code √† Claude ¬ª  \n    ‚Ä¢ Ajouter une explication rapide : ¬´ repomix ‚Äë un empaqueteur de repo ‚Äë‚Ä¶ ¬ª pour le lecteur fran√ßais qui ne conna√Æt pas.\n\n====================================================================\nV. SONS ¬´ MACHINE / LITT√âRAL ¬ª\n--------------------------------------------------------------------\n17. Maintien syst√©matique de balises ¬´ (Conserve le prompt en anglais.) ¬ª  \n    ‚Ä¢ R√©p√©tition m√©canique. Une phrase unique au d√©but de la section suffirait.\n\n18. Traductions ligne-√†-ligne des listes  \n    ‚Ä¢ Certaines listes (workflow) auraient pu √™tre reformul√©es pour √©viter le copier-coller anglais ‚Üí fran√ßais (¬´ set up le repo (boilerplate‚Ä¶) ¬ª).  \n    ‚Ä¢ Proposer une version fluide : ¬´ ‚Äì initialise le d√©p√¥t (boilerplate, uv init, cargo init, etc.) ¬ª.\n\n====================================================================\nVI. SUGGESTIONS G√âN√âRALES DE R√âVISION\n--------------------------------------------------------------------\n1. Clarifier et uniformiser le registre (tutoiement) sur tout le document.  \n2. Franciser la plupart des termes sauf quand l‚Äôanglais est incontournable pour les devs.  \n3. R√©tablir les clins d‚Äô≈ìil et oxymores de l‚Äôoriginal (¬´ plan a plan ¬ª, ¬´ Legacy modern code ¬ª, etc.).  \n4. R√©duire les anglicismes traduits litt√©ralement (¬´ bricoler ¬ª ‚Üí ¬´ d√©velopper ¬ª, ¬´ d√©coche ¬ª ‚Üí ¬´ finalise ¬ª).  \n5. Appliquer la typographie fran√ßaise (espaces avant ponctuation double, guillemets fran√ßais si d√©sir√©).  \n6. Regrouper les indications ¬´ prompt √† laisser en anglais ¬ª pour fluidifier.  \n7. Relire en entier pour fluidit√© : coupes, parenth√®ses,/ou digressions.\n\nEn appliquant ces corrections, la traduction gagnera en naturel, en coh√©rence et en fid√©lit√© au ton fac√©tieux de l‚Äôauteur tout en restant parfaitement intelligible pour un lectorat francophone de d√©veloppeurs.",
      "usage": {
        "prompt_tokens": 9584,
        "completion_tokens": 1740,
        "total_tokens": 11324
      },
      "streaming": true
    },
    "feedback": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "You are a master translator and editor specializing in french.\nYour task is to improve a translation based on detailed critique feedback.\n\n1. Carefully read the original text, current translation, and the critique feedback\n2. Address ALL issues identified in the critique\n3. Apply the specific suggestions for improvement\n4. Ensure the translation is accurate, natural-sounding, and faithful to the original\n5. Preserve all formatting, markdown, and structure of the original text\n6. Make sure the final text reads as if it were originally written in french\n\nDo not ignore any of the critique points. Every issue identified must be addressed in your improved version.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¬Ø\\\\\\_(„ÉÑ)\\_/¬Ø\n\n## Let‚Äôs go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, use repomix to pass the codebase to claude to debug\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then ‚Äújust do it‚Äù and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn‚Äôt work, Q&A with aider to fix\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don‚Äôt have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less ‚Äúplanning based.‚Äù The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test ‚Äúissue‚Äù\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test ‚Äúissue‚Äù into aider\n- watch aider dance ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™\n- ...\n- run tests\n- rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nWhen I describe this process to people I say ‚Äúyou have to aggressively keep track of what‚Äôs going on because you can easily get ahead of yourself.‚Äù\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ‚¥µ Time ‚¥µ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of ‚Äúdowntime‚Äù while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the ‚Äúbrainstorming‚Äù process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr : brainstorme la spec, puis fais un plan, puis ex√©cute la g√©n√©ration de code (codegen) avec un LLM. Cycles bien distincts, puis magie. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nJe bricole depuis un moment plein de petits projets gr√¢ce aux mod√®les de langage (LLM). C‚Äôest amusant ‚Äì et utile. Mais il y a aussi des pi√®ges qui peuvent faire perdre un temps fou. Un jour, un ami m‚Äôa demand√© comment j‚Äôutilisais les LLM pour coder. Je me suis dit : ¬´ Oh l√† l√† ! T‚Äôas combien de temps devant toi ? ¬ª ‚Äì d‚Äôo√π ce billet.\n\n(p.s. si tu d√©testes l‚ÄôIA, file directement √† la fin)\n\nJ‚Äôen parle souvent avec des potes dev, et on suit tous √† peu pr√®s la m√™me approche, chacun avec ses petits ajustements.\n\nVoici donc mon flux de travail. Il repose sur mon exp√©rience perso, sur des √©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur des bonnes pratiques d√©nich√©es dans les recoins (parfois douteux) du Net : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\n√áa marche super bien **POUR L‚ÄôINSTANT** ; dans deux semaines ce sera peut-√™tre cass√©‚Ä¶ ou deux fois plus efficace. ¬Ø\\\\_(„ÉÑ)_/¬Ø\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images g√©n√©r√©es par IA un peu louches. Voici mon ange-robot codeur fa√ßon juggalo !\" >}}\n\nIl y a mille fa√ßons de d√©velopper, mais je tombe g√©n√©ralement sur l‚Äôun de ces deux cas :\n\n- projet greenfield (tout est √† cr√©er) ;\n- code existant relativement moderne (brownfield).\n\nJe vais te montrer mon processus pour les deux.\n\n## Greenfield\n\nPour un projet greenfield, ce processus marche bien : il offre un cadre solide de planification et de documentation, et permet d‚Äôavancer par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert √† droite. Leica Q, 14/05/2016\" >}}\n\n### √âtape 1 : affiner l‚Äôid√©e\n\nUtilise un LLM conversationnel pour peaufiner l‚Äôid√©e (j‚Äôemploie ChatGPT 4o / o3) :\n\n(Conserve le prompt en anglais, c‚Äôest la langue attendue par les LLM.)\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\n√Ä la fin du remue-m√©ninges (tu sentiras quand c‚Äôest termin√©) :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nTu obtiens alors une spec assez propre qu‚Äôon peut passer √† la phase de planification. Je la sauvegarde en g√©n√©ral sous `spec.md`.\n\n> On peut faire plein de choses avec cette spec. Ici on vise le codegen, mais je m‚Äôen sers aussi pour demander √† un mod√®le sp√©cialis√© dans le raisonnement de trouver les failles (toujours plus loin !), pour r√©diger un livre blanc (white paper) ou imaginer un business model. Tu peux m√™me l‚Äôenvoyer dans une phase de recherche pouss√©e et r√©cup√©rer un doc de 10 000 mots en retour.\n\n### √âtape 2 : planification\n\nPrends la spec et envoie-la √† un mod√®le orient√© raisonnement (`o1*`, `o3*`, `r1`) :\n\n#### Prompt TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n#### Prompt non-TDD\n\n(Conserve le prompt en anglais.)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe mod√®le te sort un plan de prompts (`prompt_plan.md`) que tu pourras ex√©cuter avec Aider, Cursor, etc.\n\nDemande-lui ensuite un `todo.md` √† cocher :\n\n(Conserve le prompt en anglais.)\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nTon outil de codegen pourra cocher le `todo.md` au fil de la session ‚Äì parfait pour garder l‚Äô√©tat.\n\n#### Youpi : un plan !\n\nTu as maintenant un plan solide et une doc pour piloter ton projet.\n\nCes deux premi√®res √©tapes prennent au plus **15 minutes**. Franchement dingue.\n\n### √âtape 3 : ex√©cution\n\nIl existe une foule d‚Äôoutils pour cette phase ; leur succ√®s d√©pend surtout de la qualit√© de l‚Äô√©tape 2.\n\nJ‚Äôai test√© ce workflow avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [claude-engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)‚Ä¶ √áa marche avec tous ceux que j‚Äôai essay√©s.\n\nPerso, je pr√©f√®re Claude en mode ¬´ raw ¬ª (brut) et Aider.\n\n### Claude\n\nJe fais du pair programming sur [Claude.ai](https://claude.ai) : je balance chaque prompt, un √† un. Les allers-retours sont parfois lourds, mais √ßa fonctionne.\n\nJe m‚Äôoccupe du boilerplate (ossature) et du setup tooling. √áa √©vite que Claude ne parte direct sur du React et me laisse choisir la stack.\n\nQuand √ßa coince, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) pour envoyer tout le code √† Claude et d√©boguer.\n\nWorkflow :\n\n- initialiser le d√©p√¥t (`uv init`, `cargo init`, etc.) ;  \n- coller le prompt dans Claude ;  \n- copier-coller le code g√©n√©r√© dans l‚ÄôIDE ;  \n- lancer l‚Äôappli et les tests ;  \n- ‚Ä¶  \n- si √ßa marche : prompt suivant ;  \n- sinon : repomix + Claude pour d√©boguer ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu bizarre. Il se greffe bien sur la sortie de l‚Äô√©tape 2 et on va tr√®s loin sans effort.\n\nM√™me logique que ci-dessus, sauf qu‚Äôon colle les prompts dans Aider.\n\nAider ¬´ fait le taf ¬ª et moi je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> Au passage, Aider publie d‚Äôexcellents benchmarks de mod√®les de codegen dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/). Pratique pour voir la perf des nouveaut√©s.\n\nGr√¢ce aux tests, Aider peut √™tre encore plus mains libres : il ex√©cute la suite et d√©bogue tout seul.\n\nWorkflow :\n\n- initialiser le d√©p√¥t ;  \n- lancer Aider ;  \n- coller le prompt ;  \n- regarder Aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™ ;  \n- Aider lance les tests / ou tu lances l‚Äôappli ;  \n- si OK : prompt suivant ;  \n- sinon : Q&A avec Aider ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### R√©sultats\n\nJ‚Äôai sorti une quantit√© folle de trucs : scripts, apps Expo, CLI Rust, etc. Tous langages confondus. Super efficace.\n\nMa todo ¬´ hack ¬ª est vide parce que j‚Äôai tout fait. Je continue d‚Äôavoir de nouvelles id√©es que je d√©coche √† la cha√Æne en matant un film. Pour la premi√®re fois depuis des ann√©es, je passe du temps sur de nouveaux langages et outils ; √ßa √©largit vraiment mon horizon.\n\n## Brownfield : it√©ration incr√©mentale\n\nParfois, on n‚Äôest pas en terrain vierge : il faut am√©liorer une base de code existante (brownfield).\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n‚Äôest pas un champ vert. Photo prise par mon grand-p√®re ‚Äì Ouganda, ann√©es 60\" >}}\n\nDans ce cas, m√©thode un peu diff√©rente : moins de plan global, plus de planification √† la t√¢che.\n\n### Obtenir le contexte\n\nChacun a son outil f√©tiche pour empaqueter le code et l‚Äôinjecter au LLM. Moi, j‚Äôutilise [repomix](https://github.com/yamadashy/repomix) via des t√¢ches d√©finies dans `~/.config/mise/config.toml` (voir les [r√®gles mise](https://mise.jdx.dev/)).\n\nListe des t√¢ches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe g√©n√®re un `output.txt` qui contient tout le contexte. Si c‚Äôest trop gros pour les jetons, j‚Äôexclus les parties inutiles.\n\n> Ce qui est top avec `mise`, c‚Äôest que les t√¢ches peuvent √™tre red√©finies ou surcharg√©es dans le `.mise.toml` du projet. Je peux utiliser un autre outil pour empaqueter le code ; tant qu‚Äôil produit un `output.txt`, mes t√¢ches LLM fonctionnent. Tr√®s pratique quand les bases de code diff√®rent. Je surcharge souvent l‚Äô√©tape `repomix` pour √©largir les patterns d‚Äôignore ou j‚Äôutilise un outil plus efficace.\n\nUne fois `output.txt` pr√™t, je le passe √† la commande [LLM](https://github.com/simonw/LLM) pour diff√©rentes transformations, puis je sauvegarde la sortie en markdown.\n\nEn pratique, la t√¢che `mise` lance :\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nou :\n\n```\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nSimple : `LLM` g√®re mod√®les, cl√©s et templates.\n\nExemple : am√©liorer la couverture de tests.\n\n#### Claude\n\n- se placer dans le dossier du code ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- copier le bundle : `mise run LLM:copy_buffer_bundle` ;  \n- coller dans Claude avec la premi√®re ¬´ issue ¬ª ;  \n- copier le code g√©n√©r√© dans l‚ÄôIDE ;  \n- lancer les tests ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- se placer dans le dossier ;  \n- lancer Aider (toujours sur une nouvelle branche) ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvrir `missing-tests.md` ;  \n- coller la premi√®re ¬´ issue ¬ª dans Aider ;  \n- regarder Aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™ ;  \n- lancer les tests ;  \n- on recommence ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nSuper efficace pour am√©liorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Ultra rapides et efficaces.\n\nVoici quelques prompts que j‚Äôutilise sur du code existant :\n\n#### Revue de code\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### G√©n√©ration d‚Äôissues GitHub\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n(Conserve le prompt en anglais.)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts commencent √† dater (¬´ prompts de boomer ¬ª). Si tu as des id√©es pour les am√©liorer, dis-moi !\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nQuand j‚Äôexplique ce proc√©d√©, je dis toujours : ¬´ Il faut suivre de pr√®s ce qui se passe, sinon tu te retrouves vite les spatules dans le vide. ¬ª\n\nJe parle souvent d‚Äô√™tre **over my skis** avec les LLM : tu skies dans de la poudre parfaite, puis soudain ¬´ MAIS QU‚ÄôEST-CE QUI SE PASSE ? ¬ª et tu bascules dans le ravin.\n\nLa **phase de planification** (cf. greenfield) aide √† garder le contr√¥le : tu as au moins un doc de r√©f√©rence. Les tests aussi, surtout avec Aider en mode freestyle : √ßa reste propre et serr√©.\n\nMalgr√© tout, je me retrouve souvent **over my skis**. Parfois une pause ou une petite marche suffit. Au fond, c‚Äôest la r√©solution de probl√®mes habituelle, mais √† vitesse supersonique.\n\n> On demande parfois au LLM d‚Äôajouter des trucs compl√®tement absurdes dans un code pas si absurde. Par exemple, on lui a demand√© de cr√©er un fichier de lore puis d‚Äôy faire r√©f√©rence dans l‚Äôinterface utilisateur d‚Äôun outil CLI Python. D‚Äôun coup, il y a du lore, des interfaces glitchy, etc. Tout √ßa pour g√©rer tes fonctions cloud, ta todo list ou autre. Le ciel est la limite.\n\n## Je suis si seul (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nPrincipal reproche : tout √ßa reste majoritairement **solo** ‚Äì des interfaces ¬´ single player ¬ª.\n\nJ‚Äôai cod√© des ann√©es seul, en pair, en √©quipe. C‚Äôest toujours meilleur √† plusieurs. L√†, les bots se t√©lescopent, les conflits de fusion deviennent horribles, le contexte est compliqu√©.\n\nJ‚Äôaimerais vraiment qu‚Äôon rende le dev avec LLM **multijoueur**, pas juste une exp√©rience de hacker solitaire. Il y a un monde √† construire l√†-dessus.\n\nAU BOULOT !\n\n## ‚¥µ Temps ‚¥µ\n\nLe codegen a explos√© la quantit√© de code qu‚Äôune personne peut produire. Effet secondaire bizarre : beaucoup de temps mort pendant que le LLM br√ªle ses jetons.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m‚Äôen souviens comme si c‚Äô√©tait hier\" >}}\n\nDu coup, j‚Äôai adapt√© ma fa√ßon de bosser :\n\n- je d√©marre le brainstorming d‚Äôun autre projet ;  \n- j‚Äô√©coute des disques vinyles ;  \n- je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) ;  \n- je discute avec des amis et des robots.\n\nC‚Äôest g√©nial de hacker comme √ßa. Hack ! Hack ! Hack ! Je ne me souviens pas avoir √©t√© aussi productif.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nPas mal de potes me disent : ¬´ Les LLM, c‚Äôest de la daube. ¬ª Je respecte ce point de vue, m√™me si je ne le partage pas. Il y a de vraies raisons de se m√©fier de l‚ÄôIA. Ma peur num√©ro 1 : la conso √©lectrique et l‚Äôimpact environnemental. Mais‚Ä¶ le code doit couler. *soupir*\n\nSi tu es curieux sans vouloir devenir un ¬´ cyborg programmer ¬ª, lis le livre d‚ÄôEthan Mollick : [**Co-Intelligence : Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nC‚Äôest une bonne intro, sans le ton bro techno-libertarien. J‚Äôai eu plein de discussions nuanc√©es avec des amis apr√®s l‚Äôavoir lu. Recommand√©.\n\nSi tu es sceptique mais un peu curieux, contacte-moi et on parlera de toute cette folie. Je peux te montrer comment on utilise les LLM et, qui sait, on pourrait construire un truc ensemble.\n\n_merci √† [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d‚Äôavoir relu ce billet et propos√© des modifs. Je vous suis reconnaissant._\n\n# CRITIQUE FEEDBACK\nCRITIQUE D√âTAILL√âE DE LA TRADUCTION  \n(les num√©ros renvoient aux passages dans le texte fran√ßais actuel)\n\n====================================================================\nI. PROBL√àMES CRITIQUES : SENS, FID√â¬≠LIT√â, OMISSIONS\n--------------------------------------------------------------------\n1. Slogan d‚Äôouverture  \n   FR : ¬´ brainstorme la spec, puis fais un plan ¬ª  \n   ‚Ä¢ Perte du clin-d‚Äô≈ìil ¬´ plan a plan ¬ª (double emploi volontairement absurde).  \n   ‚Ä¢ Suggestion : ¬´ ‚Ä¶ puis √©labore un plan de plan ‚Ä¶ ¬ª.\n\n2. Cat√©gorie ¬´ Legacy modern code ¬ª  \n   FR : ¬´ code existant relativement moderne (brownfield) ¬ª  \n   ‚Ä¢ ¬´ Legacy modern code ¬ª est oxymorique ; employer ¬´ code existant ‚Äúmoderne mais d√©j√† legacy‚Äù ¬ª ou conserver la tournure ironique pour ne pas lisser le propos.  \n   ‚Ä¢ ¬´ Brownfield ¬ª n‚Äôappara√Æt pas dans l‚Äôoriginal ici ; l‚Äôintroduire peut semer la confusion (l‚Äôauteur l‚Äôutilise plus tard).\n\n3. Titre ¬´ ## Brownfield : it√©ration incr√©mentale ¬ª  \n   ‚Ä¢ L‚Äôoriginal : ¬´ ## Non-greenfield: Iteration, incrementally ¬ª.  \n   ‚Ä¢ Passer de ¬´ Non-greenfield ¬ª √† ¬´ Brownfield ¬ª gomme la nuance (tout projet ‚â† greenfield n‚Äôest pas forc√©ment brownfield).  \n   ‚Ä¢ Proposer ¬´ ## Non-greenfield : it√©rations incr√©mentales ¬ª.\n\n4. ¬´ Je bricole‚Ä¶ plein de petits projets ¬ª  \n   ‚Ä¢ ¬´ I have been building so many small products ¬ª = cr√©er/fabriquer, pas ¬´ bricoler ¬ª.  \n   ‚Ä¢ ¬´ Bricoler ¬ª sous-entend amateurisme que l‚Äôauteur ne revendique pas.  \n   ‚Ä¢ Remplacer par ¬´ Je d√©veloppe / je r√©alise ¬ª.\n\n5. Omission de nuance ‚Äì Step 3 (¬´ I, however, prefer **raw** claude‚Ä¶ ¬ª)  \n   ‚Ä¢ Le texte FR garde ¬´ raw ¬ª, mais perd l‚Äôid√©e que l‚Äôauteur pr√©f√®re ¬´ claude brut (sans interface) ¬ª.  \n   ‚Ä¢ Ajouter explicitement ¬´ ‚Ä¶ en mode brut (sans surcouche) ¬ª.\n\n====================================================================\nII. PROBL√àMES MAJEURS : TON, STYLE, REGISTRE\n--------------------------------------------------------------------\n6. Oscillation ¬´ tu / vous ¬ª  \n   Exemples :  \n   6a) ¬´ (p.s. si tu d√©testes‚Ä¶) ¬ª vs ¬´ Conserve le prompt‚Ä¶ c‚Äôest la langue attendue ¬ª (impersonnel).  \n   6b) ¬´ Votre outil de codegen pourra‚Ä¶ ¬ª.  \n   ‚Ä¢ Choisir un vouvoiement ou un tutoiement constant (le tutoiement semble privil√©gi√©).  \n   ‚Ä¢ Harmoniser dans tout le doc, y compris les listes et encadr√©s.\n\n7. Anglicismes crus non justifi√©s  \n   ¬´ brainstorme ¬ª, ¬´ spec ¬ª, ¬´ prompt ¬ª, ¬´ codegen ¬ª, ¬´ brownfield ¬ª, ¬´ workflow ¬ª, etc.  \n   ‚Ä¢ Tol√©r√©s dans la communaut√© dev mais l‚Äôoriginal montre aussi un registre rel√¢ch√© ; d√©cider d‚Äôun √©quilibre. Proposer :  \n     ‚Äì ¬´ s√©ance de brainstorming ¬ª, ¬´ sp√©cification ¬ª, ¬´ g√©n√©ration de code ¬ª, ¬´ flux de travail ¬ª.  \n   ‚Ä¢ Conserver les mots-clefs techniques (¬´ prompt ¬ª‚Ä¶) quand ils sont intraduisibles, mais franciser le reste.\n\n8. Ton humoristique un peu liss√©  \n   ‚Ä¢ ¬´ Oh boy. how much time do you have! ¬ª ‚Üí ¬´ Oh l√† l√† ! ¬ª correct mais moins moqueur ; on peut ajouter ¬´ ‚Äî t‚Äôas combien d‚Äôheures devant toi ? ¬ª.  \n   ‚Ä¢ ¬´ rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß ¬ª rendu litt√©ral mais la blague (¬´ rinse and repeat ¬ª) pourrait √™tre traduite : ¬´ et on recommence, encore et encore ‚ú©‚Ä¶ ¬ª.\n\n====================================================================\nIII. PROBL√àMES MOYENS : GRAMMAIRE, SYNTAXE, FLUIDIT√â\n--------------------------------------------------------------------\n9. Ponctuation et espaces ins√©cables  \n   ‚Ä¢ En fran√ßais, espace ins√©cable avant ¬´ ; ¬ª, ¬´ : ¬ª, ¬´ ? ¬ª, ¬´ ! ¬ª (¬´ tl;dr : ¬ª, ¬´ Merci : ¬ª‚Ä¶).  \n   ‚Ä¢ Ajouter ins√©cables ou au moins espaces simples corrects.\n\n10. Inversions malhabiles  \n    ¬´ Voici donc mon flux de travail. Il repose sur mon exp√©rience perso‚Ä¶ ¬ª  \n    ‚Ä¢ ¬´ mon exp√©rience perso ¬ª = registre oral ; envisager ¬´ mon exp√©rience personnelle ¬ª.\n\n11. Faux amis / registres  \n    ¬´ Je d√©coche √† la cha√Æne ¬ª (anglicisme passif de ¬´ knocking them out ¬ª) sonne √©trange.  \n    ‚Ä¢ ¬´ j‚Äôencha√Æne les id√©es ¬ª, ¬´ je les r√©alise √† la cha√Æne ¬ª.\n\n12. Parenth√®ses excessives  \n    ‚Ä¢ Plusieurs digressions pourraient √™tre encadr√©es par tirets cadratins ou virgules pour all√©ger la lecture.\n\n====================================================================\nIV. PROBL√àMES MINEURS : TERMINOLOGIE, D√âTAILS TECHNIQUES\n--------------------------------------------------------------------\n13. ¬´ cookie clicker ¬ª  \n    ‚Ä¢ Le lien est conserv√© mais ¬´ Cookie Clicker ¬ª est un nom propre ; capitaliser syst√©matiquement.\n\n14. ¬´ disques vinyles ¬ª  \n    ‚Ä¢ ¬´ j‚Äô√©coute des vinyles ¬ª plus naturel pour un francophone.\n\n15. ¬´ UV init ¬ª  \n    ‚Ä¢ V√©rifier si ¬´ uv ¬ª (gestionnaire Python) doit rester en minuscule.\n\n16. ¬´ repomix pour envoyer tout le code √† Claude ¬ª  \n    ‚Ä¢ Ajouter une explication rapide : ¬´ repomix ‚Äë un empaqueteur de repo ‚Äë‚Ä¶ ¬ª pour le lecteur fran√ßais qui ne conna√Æt pas.\n\n====================================================================\nV. SONS ¬´ MACHINE / LITT√âRAL ¬ª\n--------------------------------------------------------------------\n17. Maintien syst√©matique de balises ¬´ (Conserve le prompt en anglais.) ¬ª  \n    ‚Ä¢ R√©p√©tition m√©canique. Une phrase unique au d√©but de la section suffirait.\n\n18. Traductions ligne-√†-ligne des listes  \n    ‚Ä¢ Certaines listes (workflow) auraient pu √™tre reformul√©es pour √©viter le copier-coller anglais ‚Üí fran√ßais (¬´ set up le repo (boilerplate‚Ä¶) ¬ª).  \n    ‚Ä¢ Proposer une version fluide : ¬´ ‚Äì initialise le d√©p√¥t (boilerplate, uv init, cargo init, etc.) ¬ª.\n\n====================================================================\nVI. SUGGESTIONS G√âN√âRALES DE R√âVISION\n--------------------------------------------------------------------\n1. Clarifier et uniformiser le registre (tutoiement) sur tout le document.  \n2. Franciser la plupart des termes sauf quand l‚Äôanglais est incontournable pour les devs.  \n3. R√©tablir les clins d‚Äô≈ìil et oxymores de l‚Äôoriginal (¬´ plan a plan ¬ª, ¬´ Legacy modern code ¬ª, etc.).  \n4. R√©duire les anglicismes traduits litt√©ralement (¬´ bricoler ¬ª ‚Üí ¬´ d√©velopper ¬ª, ¬´ d√©coche ¬ª ‚Üí ¬´ finalise ¬ª).  \n5. Appliquer la typographie fran√ßaise (espaces avant ponctuation double, guillemets fran√ßais si d√©sir√©).  \n6. Regrouper les indications ¬´ prompt √† laisser en anglais ¬ª pour fluidifier.  \n7. Relire en entier pour fluidit√© : coupes, parenth√®ses,/ou digressions.\n\nEn appliquant ces corrections, la traduction gagnera en naturel, en coh√©rence et en fid√©lit√© au ton fac√©tieux de l‚Äôauteur tout en restant parfaitement intelligible pour un lectorat francophone de d√©veloppeurs.\n\nPlease address ALL issues identified in the critique and provide an improved translation.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl ; dr : fais un brainstorming de la sp√©cification, puis √©labore un plan de plan, puis ex√©cute avec de la g√©n√©ration de code par LLM. Boucles bien distinctes. Ensuite, la magie. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_\n\nJe d√©veloppe depuis quelque temps une foule de petits produits gr√¢ce aux LLM. C‚Äôest fun‚Ää‚Äî‚Ääet utile. Mais il y a aussi des pi√®ges qui font perdre un temps fou. Un jour, un ami m‚Äôa demand√© comment j‚Äôutilisais les LLM pour √©crire du logiciel. J‚Äôai pens√© : ¬´ Oh boy, t‚Äôas combien d‚Äôheures devant toi ? ¬ª‚Ää‚Äî‚Ääd‚Äôo√π ce billet.\n\n(p.s. si tu d√©testes l‚ÄôIA, file direct √† la fin)\n\nJ‚Äôen parle souvent avec des potes dev et on suit tous √† peu pr√®s la m√™me approche, chacun y ajoutant ses petits r√©glages.\n\nVoici donc mon flux de travail. Il repose sur mon exp√©rience personnelle, sur des √©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glan√©es dans les recoins (parfois douteux) du Net : [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\n√áa marche super bien **MAINTENANT** ; dans deux semaines ce sera peut-√™tre cass√©‚Ä¶ ou deux fois plus performant. ¬Ø\\\\\\_(„ÉÑ)_/¬Ø\n\n## Allons-y\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"Je trouve toujours ces images g√©n√©r√©es par IA un peu louches. Voici mon ange-robot codeur fa√ßon juggalo !\" >}}\n\nIl existe mille mani√®res de d√©velopper, mais je me retrouve g√©n√©ralement dans l‚Äôun de ces deux cas :\n\n- nouveau projet (greenfield) ;\n- code ¬´ legacy moderne ¬ª (un projet assez r√©cent mais d√©j√† h√©rit√©).\n\nJe vais te montrer mon processus pour les deux pistes.\n\n## Greenfield\n\nPour un projet greenfield, ce processus fonctionne bien : planification solide, docs propres et avanc√©e par petits pas.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Techniquement, il y a bien un champ vert √† droite. Leica Q, 14/05/2016\" >}}\n\n### √âtape 1 : affiner l‚Äôid√©e\n\nUtilise un LLM conversationnel pour peaufiner l‚Äôid√©e (j‚Äôemploie ChatGPT 4o / o3).\n\nConserve les prompts suivants en anglais (les mod√®les les pr√©f√®rent ainsi).\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere‚Äôs the idea:\n\n<IDEA>\n```\n\nQuand le brainstorming arrive √† sa conclusion naturelle :\n\n```prompt\nNow that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nTu obtiens une sp√©cification bien nette que je sauvegarde d‚Äôhabitude sous `spec.md`.\n\n> On peut tirer beaucoup de choses de cette spec. Ici, on vise le codegen, mais je l‚Äôutilise aussi pour demander √† un mod√®le de raisonnement de d√©nicher les failles (toujours plus profond !), pour r√©diger un white paper ou imaginer un business model. Tu peux m√™me lancer une recherche pouss√©e et r√©cup√©rer un document de 10 000 mots en retour.\n\n### √âtape 2 : planification\n\nEnvoie la spec √† un mod√®le orient√© raisonnement (`o1*`, `o3*`, `r1`).\n\n#### Prompt TDD\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n#### Prompt non-TDD\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nLe mod√®le te fournit alors un plan de prompts √† ex√©cuter (je le sauvegarde en `prompt_plan.md`).\n\nDemande-lui ensuite une todo-list :\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nTon outil de g√©n√©ration de code pourra cocher `todo.md` au fil de la session : parfait pour garder le contexte.\n\n#### Youpi, un plan !\n\nTu as d√©sormais un plan solide et une doc pr√™te √† piloter ton projet.\n\nCes deux premi√®res √©tapes prennent quoi‚Ä¶ **15 minutes** ? C‚Äôest dingue.\n\n### √âtape 3 : ex√©cution\n\nIl existe une foule d‚Äôoutils ; leur succ√®s d√©pend surtout de la qualit√© de l‚Äô√©tape 2.\n\nJ‚Äôai test√© ce workflow avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude-Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)‚Ä¶ Ils s‚Äôen sortent tous.\n\nMoi, je pr√©f√®re Claude en mode brut (sans surcouche) et Aider.\n\n### Claude\n\nJe fais du pair-programming sur [Claude.ai](https://claude.ai) : je colle chaque prompt tour √† tour. Les allers-retours peuvent √™tre p√©nibles, mais √ßa fonctionne.\n\nJe g√®re le boilerplate et le setup tooling ; ainsi, Claude n‚Äôimpose pas d‚Äôoffice du React et je garde la main sur la stack.\n\nQuand √ßa coince, j‚Äôutilise [Repomix](https://github.com/yamadashy/repomix) (un empaqueteur de d√©p√¥t) pour envoyer tout le code √† Claude et d√©boguer.\n\nWorkflow :\n\n- initialise le d√©p√¥t (boilerplate, `uv init`, `cargo init`, etc.) ;\n- colle le prompt dans Claude ;\n- copie le code g√©n√©r√© dans ton IDE ;\n- lance l‚Äôappli, ex√©cute les tests ;\n- ‚Ä¶  \n- si √ßa roule : prompt suivant ;  \n- sinon : repomix + Claude pour d√©boguer ;\n- on rince, on r√©p√®te ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### Aider\n\n[Aider](https://aider.chat/) est fun et un peu √©trange ; il s‚Äôimbrique bien avec la sortie de l‚Äô√©tape 2 et permet d‚Äôaller tr√®s loin sans effort.\n\nM√™me logique : on colle les prompts dans Aider.\n\nAider ¬´ fait le taf ¬ª et je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> Au passage, Aider publie d‚Äôexcellents benchmarks de mod√®les de codegen dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/). Id√©al pour jauger les nouveaux mod√®les.\n\nGr√¢ce aux tests, Aider peut √™tre encore plus mains libres : il ex√©cute la suite et d√©bogue tout seul.\n\nWorkflow :\n\n- initialise le d√©p√¥t ;\n- lance Aider ;\n- colle le prompt ;\n- regarde Aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™ ;\n- Aider lance les tests ou tu lances l‚Äôappli pour v√©rifier ;\n- si OK : prompt suivant ;\n- sinon : questions/r√©ponses avec Aider pour corriger ;\n- on rince, on r√©p√®te ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n### R√©sultats\n\nJ‚Äôai r√©alis√© une quantit√© folle de trucs : scripts, applis Expo, CLI Rust, etc. Tout langages confondus. Ultra efficace.\n\nMa todo hack est vide parce que j‚Äôai tout fini. Je continue d‚Äôavoir de nouvelles id√©es que j‚Äôencha√Æne pendant un film. Pour la premi√®re fois depuis des ann√©es, je d√©couvre de nouveaux langages et outils ; √ßa √©largit vraiment mon horizon.\n\n## Non-greenfield : it√©rations incr√©mentales\n\nParfois, on n‚Äôest pas en terrain vierge : il faut it√©rer sur une base de code existante.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"Ce n‚Äôest pas un champ vert. Photo prise par mon grand-p√®re ‚Äî Ouganda, ann√©es 60\" >}}\n\nDans ce cas, m√©thode un peu diff√©rente : moins de plan global, plus de planification t√¢che par t√¢che.\n\n### Obtenir le contexte\n\nChacun a sa technique pour empaqueter le code et l‚Äôinjecter dans le LLM. J‚Äôutilise actuellement [Repomix](https://github.com/yamadashy/repomix) via des t√¢ches d√©finies dans `~/.config/mise/config.toml` (voir les [r√®gles Mise](https://mise.jdx.dev/)).\n\nVoici la liste des t√¢ches LLM :\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nJe g√©n√®re un `output.txt` contenant tout le contexte. Si √ßa d√©borde en tokens, j‚Äôexclus les parties inutiles.\n\n> Atout de `mise` : on peut red√©finir ou surcharger ces t√¢ches dans le `.mise.toml` du projet. Tant que √ßa produit un `output.txt`, mes t√¢ches LLM tournent. Pratique quand les bases de code sont tr√®s diff√©rentes. Je surcharge souvent l‚Äô√©tape Repomix pour √©largir les motifs d‚Äôexclusion ou utiliser un empaqueteur plus adapt√©.\n\nUne fois `output.txt` pr√™t, je le passe √† la commande [LLM](https://github.com/simonw/LLM) pour diverses transformations et je sauvegarde la sortie en markdown.\n\nEn pratique :\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nou :\n\n```\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\n`LLM` g√®re mod√®les, cl√©s et templates.\n\nExemple : am√©liorer rapidement la couverture de tests.\n\n#### Claude\n\n- place-toi dans le dossier du code ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvre `missing-tests.md` ;  \n- copie le bundle : `mise run LLM:copy_buffer_bundle` ;  \n- colle-le dans Claude avec la premi√®re ¬´ issue ¬ª ;  \n- copie le code g√©n√©r√© dans ton IDE ;  \n- ex√©cute les tests ;  \n- on rince, on r√©p√®te ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\n#### Aider\n\n- place-toi dans le dossier ;  \n- lance Aider (sur une nouvelle branche) ;  \n- `mise run LLM:generate_missing_tests` ;  \n- ouvre `missing-tests.md` ;  \n- colle la premi√®re ¬´ issue ¬ª dans Aider ;  \n- regarde Aider danser ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™ ;  \n- ex√©cute les tests ;  \n- on rince, on r√©p√®te ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß\n\nSuper efficace pour am√©liorer progressivement une grosse base de code.\n\n### Magie des prompts\n\nCes petites astuces sont redoutables pour rendre un projet plus robuste. Vite fait, bien fait.\n\nVoici quelques prompts que j‚Äôutilise sur du code √©tabli (√† conserver en anglais) :\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### G√©n√©ration d‚Äôissues GitHub\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Tests manquants\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nCes prompts datent un peu (¬´ prompts de boomer ¬ª). Si tu as des id√©es pour les am√©liorer, fais signe !\n\n## Skiing ·®í‚Üü ñ†∞·®í‚Üü ñ†∞\n\nQuand j‚Äôexplique ce proc√©d√©, je dis : ¬´ Il faut suivre de pr√®s ce qui se passe, sinon tu te retrouves vite **over your skis**. ¬ª\n\nJe parle souvent d‚Äô√™tre ***over my skis*** avec les LLM : tu skies dans de la poudre parfaite et, soudain, ¬´ WHAT THE FUCK IS GOING ON ? ¬ª‚Ää‚Äî‚Äätu pars en vrille et tu chutes.\n\nLa **phase de planification** (cf. greenfield) aide √† garder le contr√¥le : tu as au moins un doc de r√©f√©rence. Les tests aussi, surtout avec Aider en mode freestyle : √ßa garde le code propre et serr√©.\n\nMalgr√© √ßa, je me retrouve encore souvent ***over my skis***. Parfois, une pause ou une petite marche suffit. Au fond, c‚Äôest le m√™me processus de r√©solution de probl√®mes, mais √† vitesse supersonique.\n\n> On demande parfois au LLM d‚Äôajouter des trucs totalement absurdes dans un code qui ne l‚Äôest pas tant que √ßa. Exemple : cr√©er un fichier de lore puis le r√©f√©rencer dans l‚Äôinterface d‚Äôun outil CLI Python. D‚Äôun coup, il y a du lore, des interfaces glitchy, etc. Tout √ßa pour g√©rer tes fonctions cloud, ta todo list ou n‚Äôimporte quoi. Le ciel est la limite.\n\n## Je suis si seul (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)\n\nMon principal reproche : tout √ßa reste principalement **solo**‚Ää‚Äî‚Ääle mode ¬´ single player ¬ª.\n\nJ‚Äôai cod√© des ann√©es seul, en pair, en √©quipe ; √† plusieurs, c‚Äôest toujours mieux. L√†, les bots se percutent, les merges deviennent atroces, le contexte est complexe.\n\nJe veux vraiment qu‚Äôon transforme le dev avec LLM en exp√©rience multijoueur, pas juste un trip de hacker solitaire. Il y a un boulevard √† ouvrir.\n\nAU BOULOT !\n\n## ‚¥µ Temps ‚¥µ\n\nLa g√©n√©ration de code a multipli√© la quantit√© de code qu‚Äôune seule personne peut produire. Effet secondaire √©trange : beaucoup de ¬´ temps mort ¬ª pendant que le LLM br√ªle ses tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"Je m‚Äôen souviens comme si c‚Äô√©tait hier\" >}}\n\nJ‚Äôai donc adapt√© ma fa√ßon de bosser pour combler ces attentes :\n\n- je lance le brainstorming d‚Äôun autre projet ;\n- j‚Äô√©coute des vinyles ;\n- je joue √† [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) ;\n- je discute avec des amis et des robots.\n\nC‚Äôest g√©nial de hacker comme √ßa. Hack ! Hack ! Hack ! Je ne me souviens pas avoir √©t√© aussi productif.\n\n## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ\n\nPas mal de potes me disent : ¬´ Les LLM, c‚Äôest naze. ¬ª Je respecte ce point de vue, m√™me si je ne le partage pas. Il y a plein de raisons de se m√©fier de l‚ÄôIA. Ma plus grande crainte : la conso √©lectrique et l‚Äôimpact environnemental. Mais‚Ä¶ le code doit couler. *soupir*\n\nSi tu es curieux sans vouloir devenir un ¬´ cyborg programmer ¬ª, lis le livre d‚ÄôEthan Mollick : [**Co-Intelligence : Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).\n\nBonne intro, sans le ton bro techno-libertarien. J‚Äôai eu plein de discussions nuanc√©es avec des amis apr√®s l‚Äôavoir lu. Recommand√©.\n\nSi tu es sceptique mais un peu curieux, contacte-moi et on parlera de toute cette folie. On pourra peut-√™tre construire un truc ensemble.\n\n_merci √† [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) d‚Äôavoir relu ce billet et propos√© des modifs. Je vous suis reconnaissant._",
      "usage": {
        "prompt_tokens": 11208,
        "completion_tokens": 4296,
        "total_tokens": 15504
      },
      "streaming": true
    },
    "frontmatter": {
      "model": "o3",
      "target_language": "french",
      "system_prompt": "You are a professional translator. Translate the following frontmatter fields to french.\nEach field is in the format \"field_name: content\". Translate ONLY the content, not the field names.\nReturn the translated content in the exact same format, preserving all field names.",
      "user_prompt": "title: My LLM codegen workflow atm\n\ndescription: A detailed walkthrough of my current workflow for using LLms to build software, from brainstorming through planning and execution.\n\n",
      "response": "title: Mon workflow de g√©n√©ration de code LLM en ce moment\n\ndescription: Une pr√©sentation d√©taill√©e de mon workflow actuel pour utiliser les LLMs afin de cr√©er des logiciels, du brainstorming √† la planification et √† l'ex√©cution.",
      "usage": {
        "prompt_tokens": 86,
        "completion_tokens": 48,
        "total_tokens": 134
      },
      "fields": [
        "title",
        "description"
      ],
      "streaming": true
    },
    "all_critiques": [
      "CRITIQUE D√âTAILL√âE DE LA TRADUCTION  \n(organis√©e par gravit√© et par type de probl√®me)\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nI. PROBL√àMES CRITIQUES ‚Äì FID√âLIT√â & EXHAUSTIVIT√â\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n1. Passages entiers non traduits (omissions)  \n   ‚Ä¢ Bloc-quote apr√®s Step 1 : ¬´ You can use this spec for a number of things‚Ä¶ ¬ª  \n   ‚Ä¢ Bloc-quote apr√®s explication de `mise` : ¬´ One thing really nice about mise is that the tasks can be redefined‚Ä¶ ¬ª  \n   ‚Ä¢ Bloc-quote dans section Skiing : ¬´ We will often ask the LLM to include ridiculous things‚Ä¶ ¬ª  \n   ‚Ä¢ Dernier paragraphe avant remerciements : ¬´ If you are skeptical, but a bit curious‚Ä¶ ¬ª  \n   ‚ûú Traduire ou, si l‚Äôon veut vraiment conserver l‚Äôanglais, l‚Äôannoncer explicitement (¬´ [EN] ¬ª) ; sinon c‚Äôest per√ßu comme un oubli.\n\n2. Contresens / choix lexicaux trompeurs  \n   a) ¬´ Boucles discr√®tes ¬ª pour ¬´ Discrete loops ¬ª  \n      ‚Äì En fran√ßais ‚Äúdiscret‚Äù √©voque la discr√©tion. L‚Äôid√©e d‚Äôit√©rations s√©par√©es est mieux rendue par ¬´ boucles distinctes ¬ª, ¬´ boucles successives ¬ª ou ¬´ cycles ind√©pendants ¬ª.  \n   b) ¬´ Legacy modern code ¬ª ‚Üí ¬´ Code existant relativement moderne ¬ª  \n      ‚Äì L‚Äôoxymore volontaire (¬´ legacy *modern* code ¬ª) dispara√Æt. Proposer ¬´ code existant, mais encore assez moderne ¬ª ou ¬´ code h√©ritage mais r√©cent ¬ª.  \n   c) Titre initial : ¬´ √âlaborer une spec ¬ª att√©nue la nuance de ‚ÄúBrainstorm spec‚Äù. Mieux : ¬´ Brainstormer la spec ¬ª ou ¬´ Brainstorm : r√©diger la spec ¬ª.\n\n3. Ajouts inappropri√©s qui changent le sens  \n   ‚Äì ¬´ C‚Äôest √† la fois amusant et utile. ¬ª L‚Äôoriginal : ‚ÄúIt has been fun, and useful.‚Äù   OK.  \n   ‚Äì Pas d‚Äôautres ajouts majeurs relev√©s.\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nII. PROBL√àMES MAJEURS ‚Äì TON, TERMINOLOGIE, CONSTANCE\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n1. Terminologie technique / jargon  \n   ‚Ä¢ ¬´ petits produits ¬ª pour ‚Äúsmall products‚Äù sonne commercial. Pr√©f√©rer ¬´ petits projets ¬ª, ¬´ petits outils ¬ª, ¬´ mini-applications ¬ª.  \n   ‚Ä¢ ¬´ process ¬ª employ√© en fran√ßais (‚Äúmon process‚Äù) : anglicisme acceptable √† l‚Äôoral mais alourdit la lecture. Remplacer par ¬´ processus ¬ª ou ¬´ proc√©d√© ¬ª.  \n   ‚Ä¢ ¬´ spec ¬ª, ¬´ prompt plan ¬ª, ¬´ workflow ¬ª : conserver √©ventuellement l‚Äôanglais mais indiquer la premi√®re fois (specification, plan de prompts). Veiller √† la coh√©rence (certains termes anglais sont traduits, d‚Äôautres non).  \n   ‚Ä¢ ‚ÄúBoilerplate‚Äù laiss√© tel quel ; OK dans un contexte dev, mais une note (¬´ code de d√©marrage / squelette ¬ª) am√©liorerait l‚Äôaccessibilit√©.\n\n2. Coh√©rence du tutoiement  \n   ‚Äì Le texte emploie syst√©matiquement ‚Äútu‚Äù, c‚Äôest coh√©rent, mais on trouve quelques imp√©ratifs impersonnels (¬´ Utilise ¬ª, ¬´ Prends ¬ª) et un ¬´ Votre codegen‚Ä¶ ¬ª isol√©. Harmoniser.\n\n3. Registre & tonalit√©  \n   ‚Äì L‚Äôoriginal est tr√®s oral, truff√© de ‚Äúoh boy‚Äù, emojis, interjections. La traduction conserve globalement le ton, mais certains passages deviennent plus lisses (¬´ Hourra ¬ª pour ‚ÄúYay‚Äù para√Æt vieillot).  \n   ‚Äì Expressions calqu√©es : ¬´ rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß ¬ª est gard√© tel quel ; OK, mais le verbe ‚Äúrinse‚Äù n‚Äôest pas francis√©. On peut ajouter ¬´ (on recommence) ¬ª juste apr√®s.\n\n4. Idiomes mal rendus  \n   ‚Ä¢ ‚Äúover my skis‚Äù ‚Üí traduit litt√©ralement par ¬´ over my skis ¬ª (en anglais) + explication fran√ßaise ‚Äë OK. On pourrait ajouter l‚Äô√©quivalent idiomatique fran√ßais (¬´ d√©pass√© ¬ª / ¬´ largu√© ¬ª).  \n   ‚Ä¢ ‚Äúthe code must flow‚Äù pas traduit ; on pourrait int√©grer ¬´ le code doit couler ¬ª comme dans l‚Äôoriginal anglais, mais pr√©ciser la r√©f√©rence (‚ÄúDune‚Äù).\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nIII. PROBL√àMES MOYENS ‚Äì GRAMMAIRE & SYNTAXE\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n1. Accord / orthographe  \n   ‚Ä¢ ¬´ J‚Äôai test√© ce workflow‚Ä¶ √áa marche partout. ¬ª ‚Üí ‚Äúpartout‚Äù = un peu vague, rien de grave.  \n   ‚Ä¢ ¬´ Perso, je pr√©f√®re **Claude brut** et aider. ¬ª ‚Üí manque de majuscule √† ‚Äúaider‚Äù si on consid√®re le nom propre ‚ÄúAider‚Äù.  \n   ‚Ä¢ Quelques virgules manquantes avant ¬´ mais ¬ª introduisant une proposition (‚Äú‚Ä¶ marche super bien MAINTENANT, peut-√™tre plus du tout‚Ä¶‚Äù).\n\n2. Ponctuation fran√ßaise  \n   ‚Äì Espaces ins√©cables manquantes avant ¬´ : ; ? ! ¬ª (ex. ¬´ tl;dr : ¬ª, ¬´ √âtape 1 : ¬ª).  \n   ‚Äì Guillemets typographiques (¬´ ¬´ ¬ª ¬ª) absents. Acceptable dans un billet de blog, mais √† noter.\n\n3. Anglicismes inutiles ou redondants  \n   ‚Äì ‚Äúgreenfield / brownfield‚Äù conserv√©s : courant dans la tech, mais ajouter entre parenth√®ses ¬´ (projet from scratch) / (projet existant) ¬ª pour lecteurs non familiers.  \n   ‚Äì ‚ÄúCookie Clicker‚Äù laiss√© sans italique ou guillemets.\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nIV. PROBL√àMES MINEURS ‚Äì FLUIDIT√â & STYLE\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n1. Redondances / lourdeurs  \n   ‚Ä¢ ¬´ planifier le plan ¬ª reproduit l‚Äôeffet voulu, mais on peut garder ‚Äúplanifier un plan‚Äù pour √©viter l‚Äôallit√©ration forc√©e.  \n   ‚Ä¢ R√©p√©tition du mot ‚Äúprompt‚Äù : √©ventuellement alterner avec ¬´ instruction ¬ª, ¬´ commande LLM ¬ª.\n\n2. Micro-choix de registres  \n   ‚Ä¢ ¬´ chelou ¬ª tr√®s familier ; correspond au ton, mais v√©rifier si coh√©rence globale.  \n   ‚Ä¢ ¬´ boomer prompts ¬ª => on peut franciser entre guillemets : ¬´ prompts de boomer ¬ª.\n\n3. Capitalisation / cadrage des fichiers  \n   ‚Äì `todo.md` -> **anglais** dans un texte francophone, mais standard ; rien √† corriger.\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nV. SUGGESTIONS DE R√âVISION\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n(√† adresser point par point)\n\n1. Traduire les passages manquants.\n2. Remplacer ¬´ Boucles discr√®tes ¬ª par ¬´ Boucles distinctes ¬ª (ou ¬´ cycles ind√©pendants ¬ª).  \n3. Ajuster ‚ÄúLegacy modern code‚Äù ‚Üí ¬´ code h√©rit√© mais encore moderne ¬ª.  \n4. Changer ¬´ petits produits ¬ª ‚Üí ¬´ petits projets / petits outils ¬ª.  \n5. Limiter les anglicismes : ‚Äúprocess‚Äù ‚Üí ‚Äúprocessus‚Äù, expliciter ‚Äúspec‚Äù, ‚Äúworkflow‚Äù, etc.  \n6. Uniformiser le tutoiement (√©viter ‚Äúvotre‚Äù).  \n7. Ajouter les espaces ins√©cables avant ¬´ : ; ? ! ¬ª et utiliser ¬´ ¬´ ¬ª ¬ª si publication soign√©e.  \n8. Revoir ponctuellement le registre :  \n   ‚Äì ‚ÄúHourra‚Äù ‚Üí ‚ÄúYes !‚Äù ou ‚ÄúTrop bien !‚Äù  \n   ‚Äì ‚Äúrinse repeat‚Äù ‚Üí ‚Äúon recommence‚Äù (en gardant l‚Äô√©moji si souhait√©).  \n9. Ajouter un bref √©claircissement lors du premier emploi de greenfield/brownfield.  \n10. Relire pour √©liminer les virgules manquantes et corriger quelques broutilles d‚Äôaccord.\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nCONCLUSION\n\nLa traduction restitue globalement le ton d√©contract√© et la structure technique du billet, mais souffre de quatre faiblesses majeures :  \n\n‚Ä¢ plusieurs paragraphes laiss√©s en anglais,  \n‚Ä¢ quelques contresens (¬´ boucles discr√®tes ¬ª, oxymore gomm√©),  \n‚Ä¢ anglicismes et terminologie peu francis√©s,  \n‚Ä¢ ponctuation et micro-coh√©rences perfectibles.  \n\nEn corrigeant ces points, le texte gagnera √† la fois en fid√©lit√©, en naturel fran√ßais et en professionnalisme.",
      "CRITIQUE D√âTAILL√âE DE LA TRADUCTION  \n===================================================================  \n\nL√©gende des niveaux de s√©v√©rit√©  \n‚Ä¢ Critique : contresens, omission ou ajout susceptible de tromper le lecteur.  \n‚Ä¢ Majeur : formulation tr√®s maladroite, fran√ßais non idiomatique, registre inappropri√©.  \n‚Ä¢ Mineur : d√©tail stylistique, choix de ponctuation, coh√©rence ou micro-coquille.  \n\n-------------------------------------------------------------------  \n1. Exactitude / Fid√©lit√© au contenu  \n-------------------------------------------------------------------  \n\n1-A‚ÄÇOmissions (Critique)  \n1. Ligne manquante : ¬´ I keep thinking of new things and knocking them out while watching a movie or something. ¬ª  \n   ‚Äì Absente dans ¬´ Ma todo ‚Äúhack‚Äù est vide ‚Ä¶ ¬ª.  \n   ‚Üí Ajouter : ¬´ Je continue pourtant d‚Äôavoir de nouvelles id√©es que j‚Äôexp√©die en regardant un film ou autre. ¬ª\n\n2. ¬´ while waiting for the LLM to finish burning its tokens ¬ª  \n   ‚Äì Rendu ¬´ pendant que le LLM calcule ¬ª. Le verbe ¬´ calculate ¬ª gomme l‚Äôid√©e de ¬´ consume tokens ¬ª.  \n   ‚Üí Proposer : ¬´ ‚Ä¶le temps que le LLM **avale/br√ªle ses jetons**. ¬ª\n\n3. ¬´ Legacy modern code ¬ª  \n   ‚Äì Traduit ¬´ Code h√©rit√© mais encore moderne ¬ª. Le syntagme source est d√©j√† oxymorique ; la traduction att√©nue l‚Äôironie.  \n   ‚Üí Conserver l‚Äôoxymore : ¬´ code legacy (mais ‚Äúmoderne‚Äù) ¬ª ou expliquer : ¬´ code existant r√©cent ¬ª.\n\n4. ¬´ non-greenfield: Iteration, incrementally ¬ª  \n   ‚Äì Devenu ¬´ Pas de greenfield : it√©ration incr√©mentale ¬ª. Le terme ¬´ brownfield ¬ª (sous-titre, image) dispara√Æt du titre.  \n   ‚Üí Garder la sym√©trie : ¬´ Brownfield : it√©ration incr√©mentale ¬ª.\n\n1-B‚ÄÇContresens / impr√©cisions (Critique)  \n5. ¬´ The bots collide ¬ª ‚Üí ¬´ les bots se cognent ¬ª.  \n   ‚Äì ¬´ collide ¬ª renvoie plut√¥t √† des conflits, pas √† un choc physique.  \n   ‚Üí ¬´ Les bots **entrent en conflit** ¬ª ou ¬´ se marchent sur les pieds ¬ª.\n\n6. ¬´ It has been fun, and useful ¬ª ‚Üí ¬´ C‚Äôest √† la fois fun et utile ¬ª.  \n   ‚Äì ¬´ fun ¬ª peut rester anglais dans le jargon dev, mais doubler par ¬´ amusant ¬ª rendrait le propos compr√©hensible hors milieu tech.  \n   ‚Üí ¬´ C‚Äô√©tait amusant ‚Äï et utile. ¬ª\n\n-------------------------------------------------------------------  \n2. Ton, registre et coh√©rence stylistique  \n-------------------------------------------------------------------  \n\n2-A‚ÄÇTraitement du lecteur (Majeur)  \n7. Tutoiement constant (¬´ tu ¬ª) : coh√©rent mais non indiqu√© dans l‚Äôoriginal (o√π l‚Äôadresse est neutre). Si le texte cible est destin√© √† un public large/ professionnel, pr√©voir le vouvoiement.  \n   ‚Üí D√©cider d√®s l‚Äôintro et harmoniser.\n\n2-B‚ÄÇCalques et anglicismes bruts (Majeur)  \n8. ¬´ Brainstormer la spec ¬ª, ¬´ planifier un plan ¬ª, ¬´ workflow ¬ª, ¬´ greenfield ¬ª, ¬´ prompt plan ¬ª, ¬´ issue ¬ª.  \n   ‚Äì Certains anglicismes sont accept√©s chez les devs, mais la densit√© nuit √† la lisibilit√©.  \n   ‚Üí Suggestions :  \n   ‚Ä¢ ¬´ faire un brainstorming sur la sp√©cification ¬ª  \n   ‚Ä¢ ¬´ √©laborer le plan ¬ª (et conserver le jeu de mots ‚Äúplan a plan‚Äù par une note ou italique)  \n   ‚Ä¢ ¬´ flux de travail (workflow) ¬ª √† la 1 ≥·µâ occurrence  \n   ‚Ä¢ ¬´ demande ¬ª ou ¬´ ticket ¬ª pour ¬´ issue ¬ª.\n\n9. Nom anglais + adjectif fran√ßais ¬´ Claude brut ¬ª (mineur mais √©trange).  \n   ‚Üí ¬´ Claude ‚Äúraw‚Äù ¬ª ou ¬´ Claude en mode brut ¬ª.\n\n-------------------------------------------------------------------  \n3. Naturel du fran√ßais et fluidit√©  \n-------------------------------------------------------------------  \n\n3-A‚ÄÇPhrases lourdes ou bancales (Majeur)  \n10. ¬´ C‚Äôest √† la fois fun et utile ¬ª ‚Üí voir 6.  \n11. ¬´ Je trouve toujours ces images g√©n√©r√©es par IA un peu louches. Voici donc mon ange robot codeur juggalo ! ¬ª  \n    ‚Äì L‚Äôencha√Ænement ¬´ donc ¬ª + ¬´ mon ¬ª para√Æt forc√©.  \n    ‚Üí ¬´ ‚Ä¶un peu louches. Voici mon ange-robot codeur fa√ßon juggalo ! ¬ª\n\n12. ¬´ √áa marche partout. ¬ª (apr√®s la liste d‚Äôoutils) ‚Äì Trop elliptique.  \n    ‚Üí ¬´ La m√©thode fonctionne avec tous les outils que j‚Äôai test√©s. ¬ª\n\n3-B‚ÄÇPonctuation & typographie (Mineur)  \n13. Espace fine ins√©cable avant ¬´ : ¬ª, ¬´ ; ¬ª, ¬´ ? ¬ª, ¬´ ! ¬ª manquante presque partout.  \n14. ¬´ tl;dr : ¬ª ‚Üí l‚Äôespace avant deux-points n‚Äôest pas typographique ; remplacer par ¬´  : ¬ª (espace fine).  \n15. Guillemets : mixer ‚Äú ‚Äù, ¬´ ¬ª et \" \". Harmoniser (pr√©f√©rer ¬´ ¬ª en fran√ßais).\n\n-------------------------------------------------------------------  \n4. Terminologie technique & coh√©rence  \n-------------------------------------------------------------------  \n\n16. ¬´ spec ¬ª / ¬´ specification ¬ª ‚Üí alterne fr√©quemment. Choisir ¬´ sp√©cification ¬ª (abr√©g√© ¬´ spec ¬ª entre parenth√®ses).  \n17. ¬´ todo.md ¬ª : varie entre ¬´ todo ¬ª et ¬´ todo list ¬ª.  \n18. ¬´ boilerplate ¬ª non expliqu√© √† la 1 ≥·µâ apparition. Ajouter ¬´ (code de d√©marrage) ¬ª.  \n\n-------------------------------------------------------------------  \n5. Register, humour & r√©f√©rences culturelles  \n-------------------------------------------------------------------  \n\n19. Juron adouci (Mineur)  \n    ‚Äì ¬´ fuck LLMs ¬ª ‚Üí ¬´ c‚Äôest nul ¬ª. La vigueur est perdue.  \n    ‚Üí ¬´ ‚ÄúPutain, les LLM c‚Äôest de la daube.‚Äù ¬ª ou √©quivalent plus direct pour garder le ton.\n\n20. ¬´ over my skis ¬ª maintenu en anglais. On l‚Äôexplique plus loin, mais on pourrait ajouter la m√©taphore fran√ßaise (¬´ au-del√† de mes capacit√©s ¬ª).  \n\n-------------------------------------------------------------------  \n6. Incoh√©rences mineures / micro-coquilles  \n-------------------------------------------------------------------  \n\n21. ¬´ je balance chaque prompt √† la suite ¬ª ‚Üí redondant.  \n22. Accents oubli√©s : ¬´ Tu es sceptique, mais un peu curieux ¬ª (virgule > mais).  \n23. Majuscule inutile : ¬´ Yes ! Un plan ! ¬ª ‚Äì anglais + espace avant ¬´ ! ¬ª.  \n\n-------------------------------------------------------------------  \n7. Suggestions de r√©vision cibl√©es  \n-------------------------------------------------------------------  \n\n‚Ä¢ Remplacer le titre par :  \n  _tl ; dr : faire un brainstorming de la sp√©cification, puis √©laborer un plan, puis ex√©cuter la g√©n√©ration de code avec un LLM. Boucles distinctes, puis magie. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_  \n\n‚Ä¢ Uniformiser ¬´ sp√©cification (spec) ¬ª, ¬´ flux de travail (workflow) ¬ª, ¬´ d√©p√¥t (repo) ¬ª.  \n\n‚Ä¢ Brownfield section :  \n  ¬´ ## Brownfield : it√©ration incr√©mentale ¬ª  \n  ¬´ Parfois, on n‚Äôest pas en terrain vierge ; il faut plut√¥t am√©liorer une base de code existante. ¬ª  \n\n‚Ä¢ Remplacer ¬´ les bots se cognent ¬ª par ¬´ les bots se chevauchent / entrent en conflit, les fusions deviennent horribles ¬ª.  \n\n‚Ä¢ Restituer la phrase manquante sur le visionnage de films.  \n\n‚Ä¢ Revoir la ponctuation fran√ßaise : espace fine ins√©cable avant ¬´ : ¬ª, ¬´ ? ¬ª, ¬´ ! ¬ª.  \n\n‚Ä¢ Ajouter une note explicative la premi√®re fois qu‚Äôun anglicisme tr√®s technique appara√Æt, puis conserver l‚Äôanglais ; ex. :  \n  ¬´ codegen (g√©n√©ration automatique de code) ¬ª.  \n\n-------------------------------------------------------------------  \nEn appliquant ces corrections ‚Äî notamment la restitution de la phrase omise, la r√©duction des calques et l‚Äôam√©lioration de la ponctuation ‚Äî la traduction gagnera en fid√©lit√© et en naturel tout en conservant le ton d√©contract√© de l‚Äôoriginal.",
      "CRITIQUE D√âTAILL√âE DE LA TRADUCTION  \n(les num√©ros renvoient aux passages de la traduction ; entre guillemets : T=Traduction, O=Original)\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nI. PROBL√àMES CRITIQUES (sens, omissions, contresens)  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n\n1. Titre ¬´ tl ; dr ¬ª avec espaces  \n   ‚Ä¢ O : ¬´ tl:dr; ¬ª  \n   ‚Ä¢ T : ¬´ tl ; dr : ¬ª  \n   ‚Üí Le d√©coupage ¬´ tl ; dr ¬ª n‚Äôexiste pas, la ponctuation change m√™me le sens pour un lectorat tech.  \n   ‚ûú Corriger en ¬´ tl;dr ¬ª (garder les deux points derri√®re si l‚Äôon veut coller au fran√ßais : ¬´ tl;dr : ¬ª).\n\n2. ¬´ Legacy modern code ¬ª ‚Üí ¬´ Code legacy (mais ‚Äúmoderne‚Äù) ¬ª  \n   ‚Äì Rend mal la nuance ¬´ code existant mais encore relativement moderne ¬ª.  \n   ‚ûú Proposer : ¬´ code existant relativement moderne ¬ª ou ¬´ code h√©rit√© encore dans un stack moderne ¬ª.\n\n3. ¬´ Discrete loops ¬ª ‚Üí ¬´ Boucles distinctes ¬ª  \n   ‚Äì Manque l‚Äôid√©e de ¬´ √©tapes s√©par√©es et boucl√©es ¬ª. On peut croire qu‚Äôil parle d‚Äôalgorithmes.  \n   ‚ûú ¬´ boucles s√©par√©es (une par phase) ¬ª ou ¬´ cycles bien distincts ¬ª.\n\n4. ¬´ Greenfield ¬ª / ¬´ Brownfield ¬ª  \n   ‚Äì T emploie tour √† tour ¬´ Code neuf (greenfield) ¬ª puis ¬´ Brownfield ¬ª sans expliquer la m√©taphore alors qu‚Äôelle est moins connue en fran√ßais.  \n   ‚ûú La premi√®re occurrence devrait expliciter : ¬´ projet greenfield (tout √† cr√©er) ¬ª et plus loin ¬´ projet brownfield (base existante) ¬ª. Ou conserver l‚Äôanglais mais ajouter la glose √† chaque fois.\n\n5. Manque de traduction (ou glose) pour les prompts anglais  \n   ‚Äì Les blocs de prompt restent intacts ; c‚Äôest souhaitable pour la r√©-utilisation mais il faut avertir le lecteur francophone qu‚Äôils sont √† conserver en anglais.  \n   ‚ûú Ajouter juste avant chaque bloc : ¬´ (Conservez le prompt en anglais, c‚Äôest la langue attendue par les LLM) ¬ª.\n\n6. Omission mineure dans ¬´ This entire process will take maybe 15 minutes. It is pretty quick. Wild tbh. ¬ª  \n   ‚Äì T : ¬´ L‚Äôensemble de ces deux premi√®res √©tapes prend 15 minutes maxi. Compl√®tement fou. ¬ª  \n   ‚Äì ¬´ tbh ¬ª (=franchement) disparu, mais on peut l‚Äôabsorber. Acceptable.  \n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nII. STYLE / TON / REGISTRE (MAJEUR)  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n\n1. Oscillations ¬´ tu ¬ª / ¬´ vous ¬ª / formes neutres  \n   ‚Äì Ex. ¬´ Utilise un LLM‚Ä¶ ¬ª (tu) vs ¬´ Votre outil de codegen‚Ä¶ ¬ª.  \n   ‚ûú Choisir un registre (id√©alement ¬´ tu ¬ª pour coller au ton conversationnel de l‚Äôoriginal) et uniformiser.\n\n2. Anglicismes bruts non justifi√©s  \n   ‚Ä¢ ¬´ faire un brainstorming ¬ª, ¬´ workflow ¬ª, ¬´ boilerplate ¬ª, ¬´ debuguer ¬ª, etc.  \n   ‚Äì Certains sont in√©vitables dans le milieu, mais on peut adapter :  \n     ¬´ faire un remue-m√©ninges ¬ª, ¬´ flux de travail ¬ª, ¬´ ossature (boilerplate) ¬ª, ¬´ d√©boguer ¬ª.  \n   ‚ûú D√©cider d‚Äôun glossaire et s‚Äôy tenir ; √† minima mettre l‚Äô√©quivalent fran√ßais suivi de l‚Äôanglais entre parenth√®ses la 1 ≥·µâ fois.\n\n3. Tournures trop litt√©rales ou calqu√©es  \n   ‚Äì ¬´ √áa marche super bien MAINTENANT ¬ª : majuscules agressives, inutile en fran√ßais, pr√©f√©rer ¬´ ... tr√®s bien POUR L‚ÄôINSTANT ¬ª.  \n   ‚Äì ¬´ Yes ! Un plan ! ¬ª sonne artificiel. ‚ûú ¬´ Yes ! On a un plan ! ¬ª ou ¬´ Youpi, on a un plan ! ¬ª.  \n\n4. Humour & exclamations  \n   ‚Äì Certaines touches d‚Äôhumour US sont aplaties : ¬´ wild tbh ¬ª ‚Üí ¬´ Compl√®tement fou ¬ª fonctionne, mais ¬´ I, however, prefer raw claude ¬ª ‚Üí ¬´ Perso, je pr√©f√®re Claude en mode ‚Äúraw‚Äù ¬ª perd le clin d‚Äô≈ìil (¬´ raw ¬ª ironique).  \n   ‚ûú Ajouter des guillemets + √©ventuelle note : ¬´ en mode ‚Äúraw‚Äù (brut) ¬ª.\n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nIII. GRAMMAIRE, TYPOGRAPHIE, FLUIDIT√â (MOYEN)  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n\n1. Ponctuation fran√ßaise  \n   ‚Äì Doubles espaces avant les ponctuations doubles (¬´ ; ¬ª, ¬´ : ¬ª, ¬´ ? ¬ª) manquent souvent ; ex. ¬´ tl ; dr : ¬ª ‚Üí ¬´ tl ;‚Äâdr : ¬ª.  \n   ‚ûú Suivre les r√®gles fran√ßaises : espace ins√©cable avant ; : ? !  \n\n2. Concordance des temps  \n   ‚Äì ¬´ C‚Äô√©tait amusant ‚Äî et utile. ¬ª devrait √™tre ¬´ C‚Äôest amusant ‚Äì et utile. ¬ª pour garder le pr√©sent comme l‚Äôoriginal.  \n\n3. Petites fautes  \n   ‚Äì ¬´ les fusions deviennent horribles ¬ª (merge) : neutre, mais ¬´ les conflits de fusion deviennent horribles ¬ª serait plus pr√©cis.  \n   ‚Äì ¬´ Je respectE cette vision ¬ª (actuellement ¬´ Je respecte ¬ª manque le e final ?)  \n\n4. Orthographe  \n   ‚Äì ¬´ white paper ¬ª non italique ni guillemets ; proposer ¬´ livre blanc (white paper) ¬ª.  \n   ‚Äì ¬´ vinyles ¬ª ‚Üí forme correcte, mais ¬´ j‚Äô√©coute des disques vinyles ¬ª.  \n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nIV. TERMINOLOGIE TECHNIQUE & COH√âRENCE (MOYEN)  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n\n1. ¬´ Spec ¬ª, ¬´ prompt_plan.md ¬ª, ¬´ todo.md ¬ª  \n   ‚Äì T utilise ¬´ spec ¬ª sans accent ; fixer une graphie (tout en gardant le nom de fichier) : ¬´ la spec (spec.md) ¬ª.  \n\n2. ¬´ Codegen ¬ª  \n   ‚Äì Parfois traduit (g√©n√©ration de code) parfois laiss√© anglais. Harmoniser (¬´ codegen (g√©n√©ration de code) ¬ª √† la premi√®re occurrence).  \n\n3. ¬´ Reasoning model ¬ª ‚Üí ¬´ mod√®le de raisonnement ¬ª : ok, mais on parle aussi de ¬´ mod√®le sp√©cialis√© dans le raisonnement ¬ª pour √©viter l‚Äôambigu√Øt√©.  \n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nV. NUANCES & IDIOMES MANQUANTS / MAL RENDUS (MINEUR)  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n\n1. ¬´ oh boy. how much time do you have! ¬ª  \n   ‚Äì T : ¬´ Oh l√† l√†‚Ä¶ tu as combien de temps ? ¬ª  \n   ‚Äì L‚Äôintonation exclamative de ¬´ how much time do you have! ¬ª (point d‚Äôexclamation) est perdue.  \n   ‚ûú ¬´ Oh l√† l√† ! T‚Äôas combien de temps devant toi ? ¬ª.  \n\n2. ¬´ Keep thinking of new things and knocking them out ¬ª  \n   ‚Äì T : ¬´ Je continue pourtant d‚Äôavoir de nouvelles id√©es que j‚Äôexp√©die‚Ä¶ ¬ª.  \n   ‚Äì L‚Äôid√©e de ¬´ knocking them out (rapidement) ¬ª presque violent/performatif pourrait √™tre ¬´ que je d√©coche √† la cha√Æne ¬ª.  \n\n3. ¬´ over my skis ¬ª  \n   ‚Äì La parenth√®se explicative est bonne mais on peut faire ressortir l‚Äôimage : ¬´ je me retrouve les spatules dans le vide ¬ª.  \n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nVI. IMPRESSIONS ¬´ MACHINE-LIKE ¬ª / LITERALIT√â (MINEUR)  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n\n1. R√©p√©titions proches de l‚Äôanglais  \n   ‚Äì ¬´ Initialiser le d√©p√¥t (boilerplate, uv init, cargo init, etc.) ¬ª : ¬´ boilerplate ¬ª laiss√© brut, donne un air copi√©-coll√©.  \n   ‚Äì S√©rie de verbes ¬´ lancer, lancer, lancer ¬ª √† la queue-leu-leu ; peut √™tre all√©g√©.  \n\n2. Longues phrases coul√©es sans d√©coupe  \n   ‚Äì Exemple dans la partie ¬´ Obtenir le contexte ¬ª : la phrase qui commence par ¬´ Une fois le output.txt g√©n√©r√©‚Ä¶ ¬ª fait cinq propositions.  \n   ‚ûú Fractionner pour la lisibilit√©.  \n\n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \nVII. RECOMMANDATIONS G√âN√âRALES  \n‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  \n\n‚Ä¢ Choisir un registre coh√©rent (¬´ tu ¬ª partout ou ¬´ vous ¬ª partout).  \n‚Ä¢ √âlaborer un petit lexique en d√©but d‚Äôarticle pour les termes laiss√©s en anglais (prompt, spec, codegen, greenfield, brownfield, boilerplate, etc.) et d√©cider lesquels traduire.  \n‚Ä¢ Uniformiser la ponctuation fran√ßaise : espaces ins√©cables, guillemets fran√ßais (¬´  ¬ª), tirets cadratins pour incises.  \n‚Ä¢ All√©ger les anglicismes inutiles et franciser les verbes quand c‚Äôest naturel (d√©boguer, planifier, ex√©cuter).  \n‚Ä¢ Ajouter des petites gloses culturelles pour les r√©f√©rences US (¬´ cookie clicker ¬ª, ¬´ juggalo ¬ª, ¬´ Haterade ¬ª) ou les garder mais avec un lien/parenth√®se explicative.  \n‚Ä¢ Relire la concordance des temps pour garder le m√™me rythme que l‚Äôoriginal (pr√©sent majoritairement).  \n\nEn appliquant ces corrections de sens, de registre et de fluidit√©, la traduction deviendra plus naturelle pour un lecteur francophone tout en restant fid√®le, pr√©cise et techniquement coh√©rente.",
      "CRITIQUE D√âTAILL√âE DE LA TRADUCTION  \n(les num√©ros renvoient aux passages dans le texte fran√ßais actuel)\n\n====================================================================\nI. PROBL√àMES CRITIQUES : SENS, FID√â¬≠LIT√â, OMISSIONS\n--------------------------------------------------------------------\n1. Slogan d‚Äôouverture  \n   FR : ¬´ brainstorme la spec, puis fais un plan ¬ª  \n   ‚Ä¢ Perte du clin-d‚Äô≈ìil ¬´ plan a plan ¬ª (double emploi volontairement absurde).  \n   ‚Ä¢ Suggestion : ¬´ ‚Ä¶ puis √©labore un plan de plan ‚Ä¶ ¬ª.\n\n2. Cat√©gorie ¬´ Legacy modern code ¬ª  \n   FR : ¬´ code existant relativement moderne (brownfield) ¬ª  \n   ‚Ä¢ ¬´ Legacy modern code ¬ª est oxymorique ; employer ¬´ code existant ‚Äúmoderne mais d√©j√† legacy‚Äù ¬ª ou conserver la tournure ironique pour ne pas lisser le propos.  \n   ‚Ä¢ ¬´ Brownfield ¬ª n‚Äôappara√Æt pas dans l‚Äôoriginal ici ; l‚Äôintroduire peut semer la confusion (l‚Äôauteur l‚Äôutilise plus tard).\n\n3. Titre ¬´ ## Brownfield : it√©ration incr√©mentale ¬ª  \n   ‚Ä¢ L‚Äôoriginal : ¬´ ## Non-greenfield: Iteration, incrementally ¬ª.  \n   ‚Ä¢ Passer de ¬´ Non-greenfield ¬ª √† ¬´ Brownfield ¬ª gomme la nuance (tout projet ‚â† greenfield n‚Äôest pas forc√©ment brownfield).  \n   ‚Ä¢ Proposer ¬´ ## Non-greenfield : it√©rations incr√©mentales ¬ª.\n\n4. ¬´ Je bricole‚Ä¶ plein de petits projets ¬ª  \n   ‚Ä¢ ¬´ I have been building so many small products ¬ª = cr√©er/fabriquer, pas ¬´ bricoler ¬ª.  \n   ‚Ä¢ ¬´ Bricoler ¬ª sous-entend amateurisme que l‚Äôauteur ne revendique pas.  \n   ‚Ä¢ Remplacer par ¬´ Je d√©veloppe / je r√©alise ¬ª.\n\n5. Omission de nuance ‚Äì Step 3 (¬´ I, however, prefer **raw** claude‚Ä¶ ¬ª)  \n   ‚Ä¢ Le texte FR garde ¬´ raw ¬ª, mais perd l‚Äôid√©e que l‚Äôauteur pr√©f√®re ¬´ claude brut (sans interface) ¬ª.  \n   ‚Ä¢ Ajouter explicitement ¬´ ‚Ä¶ en mode brut (sans surcouche) ¬ª.\n\n====================================================================\nII. PROBL√àMES MAJEURS : TON, STYLE, REGISTRE\n--------------------------------------------------------------------\n6. Oscillation ¬´ tu / vous ¬ª  \n   Exemples :  \n   6a) ¬´ (p.s. si tu d√©testes‚Ä¶) ¬ª vs ¬´ Conserve le prompt‚Ä¶ c‚Äôest la langue attendue ¬ª (impersonnel).  \n   6b) ¬´ Votre outil de codegen pourra‚Ä¶ ¬ª.  \n   ‚Ä¢ Choisir un vouvoiement ou un tutoiement constant (le tutoiement semble privil√©gi√©).  \n   ‚Ä¢ Harmoniser dans tout le doc, y compris les listes et encadr√©s.\n\n7. Anglicismes crus non justifi√©s  \n   ¬´ brainstorme ¬ª, ¬´ spec ¬ª, ¬´ prompt ¬ª, ¬´ codegen ¬ª, ¬´ brownfield ¬ª, ¬´ workflow ¬ª, etc.  \n   ‚Ä¢ Tol√©r√©s dans la communaut√© dev mais l‚Äôoriginal montre aussi un registre rel√¢ch√© ; d√©cider d‚Äôun √©quilibre. Proposer :  \n     ‚Äì ¬´ s√©ance de brainstorming ¬ª, ¬´ sp√©cification ¬ª, ¬´ g√©n√©ration de code ¬ª, ¬´ flux de travail ¬ª.  \n   ‚Ä¢ Conserver les mots-clefs techniques (¬´ prompt ¬ª‚Ä¶) quand ils sont intraduisibles, mais franciser le reste.\n\n8. Ton humoristique un peu liss√©  \n   ‚Ä¢ ¬´ Oh boy. how much time do you have! ¬ª ‚Üí ¬´ Oh l√† l√† ! ¬ª correct mais moins moqueur ; on peut ajouter ¬´ ‚Äî t‚Äôas combien d‚Äôheures devant toi ? ¬ª.  \n   ‚Ä¢ ¬´ rinse repeat ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß ¬ª rendu litt√©ral mais la blague (¬´ rinse and repeat ¬ª) pourrait √™tre traduite : ¬´ et on recommence, encore et encore ‚ú©‚Ä¶ ¬ª.\n\n====================================================================\nIII. PROBL√àMES MOYENS : GRAMMAIRE, SYNTAXE, FLUIDIT√â\n--------------------------------------------------------------------\n9. Ponctuation et espaces ins√©cables  \n   ‚Ä¢ En fran√ßais, espace ins√©cable avant ¬´ ; ¬ª, ¬´ : ¬ª, ¬´ ? ¬ª, ¬´ ! ¬ª (¬´ tl;dr : ¬ª, ¬´ Merci : ¬ª‚Ä¶).  \n   ‚Ä¢ Ajouter ins√©cables ou au moins espaces simples corrects.\n\n10. Inversions malhabiles  \n    ¬´ Voici donc mon flux de travail. Il repose sur mon exp√©rience perso‚Ä¶ ¬ª  \n    ‚Ä¢ ¬´ mon exp√©rience perso ¬ª = registre oral ; envisager ¬´ mon exp√©rience personnelle ¬ª.\n\n11. Faux amis / registres  \n    ¬´ Je d√©coche √† la cha√Æne ¬ª (anglicisme passif de ¬´ knocking them out ¬ª) sonne √©trange.  \n    ‚Ä¢ ¬´ j‚Äôencha√Æne les id√©es ¬ª, ¬´ je les r√©alise √† la cha√Æne ¬ª.\n\n12. Parenth√®ses excessives  \n    ‚Ä¢ Plusieurs digressions pourraient √™tre encadr√©es par tirets cadratins ou virgules pour all√©ger la lecture.\n\n====================================================================\nIV. PROBL√àMES MINEURS : TERMINOLOGIE, D√âTAILS TECHNIQUES\n--------------------------------------------------------------------\n13. ¬´ cookie clicker ¬ª  \n    ‚Ä¢ Le lien est conserv√© mais ¬´ Cookie Clicker ¬ª est un nom propre ; capitaliser syst√©matiquement.\n\n14. ¬´ disques vinyles ¬ª  \n    ‚Ä¢ ¬´ j‚Äô√©coute des vinyles ¬ª plus naturel pour un francophone.\n\n15. ¬´ UV init ¬ª  \n    ‚Ä¢ V√©rifier si ¬´ uv ¬ª (gestionnaire Python) doit rester en minuscule.\n\n16. ¬´ repomix pour envoyer tout le code √† Claude ¬ª  \n    ‚Ä¢ Ajouter une explication rapide : ¬´ repomix ‚Äë un empaqueteur de repo ‚Äë‚Ä¶ ¬ª pour le lecteur fran√ßais qui ne conna√Æt pas.\n\n====================================================================\nV. SONS ¬´ MACHINE / LITT√âRAL ¬ª\n--------------------------------------------------------------------\n17. Maintien syst√©matique de balises ¬´ (Conserve le prompt en anglais.) ¬ª  \n    ‚Ä¢ R√©p√©tition m√©canique. Une phrase unique au d√©but de la section suffirait.\n\n18. Traductions ligne-√†-ligne des listes  \n    ‚Ä¢ Certaines listes (workflow) auraient pu √™tre reformul√©es pour √©viter le copier-coller anglais ‚Üí fran√ßais (¬´ set up le repo (boilerplate‚Ä¶) ¬ª).  \n    ‚Ä¢ Proposer une version fluide : ¬´ ‚Äì initialise le d√©p√¥t (boilerplate, uv init, cargo init, etc.) ¬ª.\n\n====================================================================\nVI. SUGGESTIONS G√âN√âRALES DE R√âVISION\n--------------------------------------------------------------------\n1. Clarifier et uniformiser le registre (tutoiement) sur tout le document.  \n2. Franciser la plupart des termes sauf quand l‚Äôanglais est incontournable pour les devs.  \n3. R√©tablir les clins d‚Äô≈ìil et oxymores de l‚Äôoriginal (¬´ plan a plan ¬ª, ¬´ Legacy modern code ¬ª, etc.).  \n4. R√©duire les anglicismes traduits litt√©ralement (¬´ bricoler ¬ª ‚Üí ¬´ d√©velopper ¬ª, ¬´ d√©coche ¬ª ‚Üí ¬´ finalise ¬ª).  \n5. Appliquer la typographie fran√ßaise (espaces avant ponctuation double, guillemets fran√ßais si d√©sir√©).  \n6. Regrouper les indications ¬´ prompt √† laisser en anglais ¬ª pour fluidifier.  \n7. Relire en entier pour fluidit√© : coupes, parenth√®ses,/ou digressions.\n\nEn appliquant ces corrections, la traduction gagnera en naturel, en coh√©rence et en fid√©lit√© au ton fac√©tieux de l‚Äôauteur tout en restant parfaitement intelligible pour un lectorat francophone de d√©veloppeurs."
    ]
  },
  "critique_loop_details": {
    "critique_usages": [
      {
        "prompt_tokens": 9449,
        "completion_tokens": 1892,
        "total_tokens": 11341
      },
      {
        "prompt_tokens": 9538,
        "completion_tokens": 1917,
        "total_tokens": 11455
      },
      {
        "prompt_tokens": 9598,
        "completion_tokens": 2215,
        "total_tokens": 11813
      },
      {
        "prompt_tokens": 9584,
        "completion_tokens": 1740,
        "total_tokens": 11324
      }
    ],
    "feedback_usages": [
      {
        "prompt_tokens": 11328,
        "completion_tokens": 4354,
        "total_tokens": 15682
      },
      {
        "prompt_tokens": 11297,
        "completion_tokens": 4400,
        "total_tokens": 15697
      },
      {
        "prompt_tokens": 11730,
        "completion_tokens": 4456,
        "total_tokens": 16186
      },
      {
        "prompt_tokens": 11208,
        "completion_tokens": 4296,
        "total_tokens": 15504
      }
    ]
  },
  "timestamp": "2025-05-16T10:06:15.146433"
}