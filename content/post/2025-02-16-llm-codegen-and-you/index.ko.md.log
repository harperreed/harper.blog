{
  "input_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.md",
  "output_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.ko.md",
  "target_language": "korean",
  "language_code": "ko",
  "model": "o3",
  "skip_edit": false,
  "do_critique": true,
  "critique_loops": 4,
  "has_frontmatter": true,
  "token_usage": {
    "prompt_tokens": 95959,
    "completion_tokens": 63349,
    "total_tokens": 159308
  },
  "cost": "$3.4935",
  "prompts_and_responses": {
    "translation": {
      "model": "o3",
      "target_language": "korean",
      "system_prompt": "\n        1. Read the provided text carefully, preserving all formatting, markdown, and structure exactly as they appear.\n        2. Identify any block quotes and code blocks.\n        3. Do not translate text in block quotes or in code blocks (including text within code blocks).\n        4. Translate everything else into korean.\n        5. Maintain the original formatting, markdown, and structure in your output.\n        6. Provide a natural-sounding translation rather than a word-for-word one.\n        7. For idioms, colloquialisms, or slang, render them in an equivalent, natural way in korean whenever possible.\n        8. If there isn't a direct or natural translation for a particular term or phrase, keep it in the original language and surround it with quotes if necessary.\n        9. Ensure that technical terms or jargon remain accurate; if there's no suitable translation, keep the original term.\n        10. Strive for fluid, native-sounding prose that retains the tone and intent of the original text.\n        ",
      "user_prompt": "_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "response": "_tl:dr; 사양을 브레인스토밍 → 계획 짜기 → LLM 코드젠으로 실행. 개별 루프. 그리고 매직. ✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM으로 자잘한 제품을 정말 많이 만들고 있다. 재미도 있고, 유용하다. 하지만 시간을 낭비하게 만드는 함정도 꽤 있다. 얼마 전 친구가 “LLM으로 어떻게 소프트웨어를 쓰고 있냐”라고 물었다. “와… 시간 좀 많은가?” 싶은 마음에 이 글을 쓰게 됐다.\n\n(p.s. AI를 싫어한다면 ─ 맨 아래로 스크롤!)\n\n주변 개발자 친구들과 이야기를 나눠보면 다들 큰 틀은 비슷하고, 디테일만 조금씩 다르다.\n\n아래는 내 워크플로우다. 내 경험, 친구들과의 대화(고마워요 [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)) 그리고 온갖 지옥 같은 인터넷 [나쁜](https://news.ycombinator.com/) [장소](https://twitter.com)에서 공유된 베스트 프랙티스를 토대로 만들었다.\n\n지금은 **잘** 돌아가지만, 2주 뒤엔 안 먹히거나 두 배로 잘 될 수도 있다.  ¯\\\\\\_(ツ)\\_/¯\n\n## 시작!\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"AI가 만든 이미지는 늘 수상하다. 내 저글로 코딩 로봇 엔젤에게 인사!\" >}}\n\n개발 접근 방식은 다양하지만, 내 케이스는 보통 두 가지로 나뉜다.\n\n- 그린필드 코드\n- 레거시·모던 코드\n\n두 경로 모두에 대한 과정을 보여주겠다.\n\n## Greenfield\n\n그린필드 개발에서는 아래 프로세스가 잘 맞는다. 탄탄한 기획·문서를 만들고, 작은 단계로 쉽게 실행할 수 있다.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"오른쪽에 초록 들판이 있다. Leica Q, 2016.05.14\" >}}\n\n### Step 1: 아이디어 다듬기\n\n대화형 LLM(나는 ChatGPT 4o / o3 사용)으로 아이디어를 다듬는다.\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\n브레인스토밍이 자연스럽게 끝나면:\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\n꽤 괜찮은 스펙이 나온다. 리포지토리에 `spec.md`로 저장.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\n`spec`을 적절한 추론 모델(`o1*`, `o3*`, `r1`)에 넘긴다.\n\n(아래는 TDD용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(아래는 non-TDD용)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n실행 가능한 프롬프트 플랜이 나온다. `prompt_plan.md`로 저장.\n\n그리고 `todo.md`도 만든다.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\ncodegen 툴이 `todo.md`를 체크해가며 상태를 유지할 수 있어 편리하다.\n\n#### Yay. Plan!\n\n이제 빡센 플랜과 문서가 완성됐다. 실행만 남았다.\n\n전체 과정은 **15분** 정도면 끝난다. 진짜 빠르다.\n\n### Step 3: Execution\n\n실행 도구는 다양하다. Step 2가 잘 돼 있으면 무엇이든 성공 확률이 높다.\n\n[github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai) 등으로 다 해봤고 거의 다 잘 맞았다.\n\n나는 **순정** claude와 aider 조합을 선호한다.\n\n### Claude\n\n[claude.ai](https://claude.ai)와 페어 프로그래밍하듯 프롬프트를 하나씩 넣는다. 약간 번거롭지만 잘 굴러간다.\n\n초기 보일러플레이트 작성과 툴링 세팅은 내가 직접 한다. Claude가 리액트 코드만 뱉는 경향이 있어서, 원하는 언어·스타일·툴 체계를 먼저 잡아두면 편하다.\n\n막히면 [repomix](https://github.com/yamadashy/repomix)로 코드베이스를 통째로 넘겨 디버깅한다.\n\n워크플로우:\n\n- 리포 세팅(보일러플레이트, uv init, cargo init 등)\n- claude에 프롬프트 붙여넣기\n- claude 코드 복사해 IDE에 붙여넣기\n- 코드·테스트 실행\n- …\n- 잘 되면 다음 프롬프트\n- 안 되면 repomix로 코드베이스 전달해 디버깅\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/)는 재미있고 묘하다. Step 2 결과물이 있을 때 특히 잘 붙는다.\n\n작업 흐름은 Claude와 비슷하되, 프롬프트를 aider에 붙여넣는다는 점만 다르다.\n\naider가 알아서 “Just do it” 해주고 나는 [cookie clicker](https://orteil.dashnet.org/cookieclicker/) 모드.\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\naider는 테스트 자동 실행·디버깅까지 해줘서 더 손이 덜 간다.\n\n워크플로우:\n\n- 리포 세팅(보일러플레이트, uv init, cargo init 등)\n- aider 실행\n- 프롬프트 붙여넣기\n- aider 댄스 감상 ♪┏(・o･)┛♪\n- aider가 테스트 실행하거나 직접 앱 실행해 확인\n- 잘 되면 다음 프롬프트\n- 안 되면 Q&A로 수정\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\n이 방식으로 스크립트, expo 앱, rust CLI 등 정말 많이 만들었다. 언어·상황 가리지 않고 잘 된다.\n\n미뤄둔 프로젝트가 있다면 한번 써보길 권한다. 짧은 시간에 놀랄 만큼 진도가 나온다.\n\n할 일 리스트가 텅 빌 정도로 다 만들었다. 영화 보면서도 툭툭 새 언어·툴을 접하고 있으니, 프로그래밍 시야가 확장되는 기분이다.\n\n## Non-greenfield: 점진적 개선\n\n가끔 그린필드가 아닌 기존 코드베이스를 개선해야 할 때가 있다.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"여긴 초록 들판이 아님. 우리 할아버지 카메라에 있던 우간다 60년대 사진\" >}}\n\n이 경우 방법이 조금 다르다. 위 과정과 비슷하지만, 전사적 플랜 대신 작업 단위로 계획한다.\n\n### Get context\n\nAI 개발에 몰두한 사람마다 툴이 다른데, 핵심은 소스코드를 잘 추려서 LLM에 넣는 것이다.\n\n나는 [repomix](https://github.com/yamadashy/repomix)를 쓴다. 전역 `~/.config/mise/config.toml`에 태스크 모음이 있어 여러 작업을 한다([mise rules](https://mise.jdx.dev/)).\n\nLLM 태스크 리스트:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt`로 컨텍스트를 뽑는다. 토큰이 초과되면 관련 없는 디렉터리를 제외하도록 커맨드를 수정한다.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\n`output.txt`가 생기면 [LLM](https://github.com/simonw/LLM) 커맨드에 넘겨 변환하고, 마크다운으로 저장한다.\n\n결국 `mise` 태스크는 `cat output.txt | LLM -t readme-gen > README.md` 같은 식이다. 복잡할 거 없다. `LLM` 명령이 모델 선택, 키 관리, 프롬프트 템플릿 등을 해준다.\n\n예컨대 테스트 커버리지 리뷰·수정이 급할 때:\n\n#### Claude\n\n- 코드 디렉터리로 이동\n- `mise run LLM:generate_missing_tests` 실행\n- 생성된 `missing-tests.md` 확인\n- `mise run LLM:copy_buffer_bundle`로 컨텍스트 클립보드 복사\n- claude에 붙여넣고 첫 번째 이슈부터 해결\n- claude 코드 IDE에 붙여넣기\n- …\n- 테스트 실행\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- 코드 디렉터리로 이동\n- 새 브랜치에서 aider 실행\n- `mise run LLM:generate_missing_tests` 실행\n- `missing-tests.md` 확인\n- 첫 번째 이슈를 aider에 붙여넣기\n- aider 댄스 감상 ♪┏(・o･)┛♪\n- …\n- 테스트 실행\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n큰 코드베이스도 작은 단위로 꾸준히 개선할 수 있다.\n\n### Prompt magic\n\n이런 퀵 해킹은 프로젝트를 더 탄탄하게 만드는 좋은 방법이다. 빠르고 효과적.\n\n기존 코드에 쓸 프롬프트 몇 가지:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(실제 이슈 등록은 아직 자동화 못 함!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n이 프롬프트들은 좀 _구식_ 이다(“boomer prompts”랄까). 더 좋게 바꿀 아이디어가 있으면 알려 달라.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n이 과정을 설명할 때 “정신 바짝 차리고 진행 상황을 추적해야 한다”고 말한다. 안 그러면 순식간에 앞질러 가버린다.\n\nLLM 이야기할 때 “over my skis”라는 표현을 자주 쓴다. 파우더 눈에서 부드럽게 타다 갑자기 “뭐야 이거?!” 하며 절벽에서 굴러떨어지는 느낌이랄까.\n\n**Planning 단계**(위 그린필드 과정 참조)를 넣으면 통제가 좀 된다. 적어도 문서를 보고 재확인할 수 있다. 특히 aider처럼 와일드하게 코딩할 때는 테스트가 도움이 된다.\n\n그럼에도 **over my skis** 상태가 자주 온다. 잠깐 산책이나 휴식을 하면 해결되곤 한다. 본질적으로는 평범한 문제 해결 과정인데, 속도가 광속이라 그렇다.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\n이 워크플로우의 단점은 **1인 모드**에 가깝다는 것. 팀 프로젝트에 쓰기 어렵다. 봇끼리 충돌하고, 머지가 끔찍하고, 컨텍스트가 복잡하다.\n\nLLM 코딩을 멀티플레이 게임으로 바꿀 누군가가 필요하다. 솔로 해커 경험이 아니라. 이걸 제대로 풀면 엄청난 기회가 있을 것이다.\n\nGET TO WORK!  (어서 만들어줘!)\n\n## ⴵ Time ⴵ\n\n코드젠 덕분에 혼자 만들 수 있는 코드 양이 폭증했다. 하지만 LLM이 토큰 태우는 동안 “대기 시간”이 많아졌다.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"어제 일처럼 생생하다\" >}}\n\n그래서 기다리는 시간에 할 일을 바꿔봤다.\n\n- 다른 프로젝트 “브레인스토밍” 시작\n- LP 틀어놓고 음악 듣기\n- [cookie clicker](https://orteil.dashnet.org/cookieclicker/) 플레이\n- 친구·로봇과 수다\n\n이렇게 해킹할 수 있다는 게 멋지다. Hack Hack Hack. 이렇게 생산적이었던 때가 또 있었나 싶다.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\n친구들 중엔 “LLM 개구림. 다 못함” 하는 사람이 많다. 그 시각 이해한다. 비판적 시각은 중요하다. 나도 전력 소모와 환경 영향을 가장 걱정한다. 하지만… 코드는 흘러야 한다. 그렇지… 하아.\n\n더 알아보고 싶지만 사이보그 프로그래머가 되고 싶진 않다면, 이 책을 추천한다: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) by Ethan Mollick.\n\n기술 낙관론·자본주의 찬가 같은 책이 아니라, LLM의 장점을 균형 있게 설명한다. 읽은 친구들과 깊이 있는 대화를 많이 나눴다. 강추.\n\n회의적이지만 조금 궁금하다면 언제든 연락하라. LLM을 어떻게 쓰는지 보여주고, 같이 뭔가 만들어볼 수도 있다.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "usage": {
        "prompt_tokens": 4793,
        "completion_tokens": 6256,
        "total_tokens": 11049
      }
    },
    "editing": {
      "model": "o3",
      "target_language": "korean",
      "system_prompt": "\n        1. Carefully read the translated text alongside the original text in its entirety.\n        2. Compare both texts to ensure the translation accurately reflects the original meaning.\n        3. Correct any grammatical errors you find in the korean text.\n        4. Adjust phrasing to make it sound natural and fluent for korean speakers, making sure idioms and expressions are culturally appropriate.\n        5. Preserve the original tone, nuance, and style, including any formatting, markdown, and structure.\n        6. Avoid adding new information or altering the core meaning.\n        7. Ensure the final result doesn't feel machine-translated but remains faithful to the source.\n        8. Make only changes that genuinely improve the text's quality in korean.\n        7. Don't be too literal. If there isn't a direct translation, provide a natural-sounding translation.\n        9. If the text contains idioms or colloquialisms, translate them into the target language while maintaining their original meaning.\n        10. If the text contains technical terms or jargon, ensure that the translation is accurate and appropriate for the target audience, if there isn't a natural translation, keep it in the original language.\n        11. If there is not natural translation, keep it in the original language.\n        ",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# TRANSLATED TEXT\n_tl:dr; 사양을 브레인스토밍 → 계획 짜기 → LLM 코드젠으로 실행. 개별 루프. 그리고 매직. ✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM으로 자잘한 제품을 정말 많이 만들고 있다. 재미도 있고, 유용하다. 하지만 시간을 낭비하게 만드는 함정도 꽤 있다. 얼마 전 친구가 “LLM으로 어떻게 소프트웨어를 쓰고 있냐”라고 물었다. “와… 시간 좀 많은가?” 싶은 마음에 이 글을 쓰게 됐다.\n\n(p.s. AI를 싫어한다면 ─ 맨 아래로 스크롤!)\n\n주변 개발자 친구들과 이야기를 나눠보면 다들 큰 틀은 비슷하고, 디테일만 조금씩 다르다.\n\n아래는 내 워크플로우다. 내 경험, 친구들과의 대화(고마워요 [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)) 그리고 온갖 지옥 같은 인터넷 [나쁜](https://news.ycombinator.com/) [장소](https://twitter.com)에서 공유된 베스트 프랙티스를 토대로 만들었다.\n\n지금은 **잘** 돌아가지만, 2주 뒤엔 안 먹히거나 두 배로 잘 될 수도 있다.  ¯\\\\\\_(ツ)\\_/¯\n\n## 시작!\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"AI가 만든 이미지는 늘 수상하다. 내 저글로 코딩 로봇 엔젤에게 인사!\" >}}\n\n개발 접근 방식은 다양하지만, 내 케이스는 보통 두 가지로 나뉜다.\n\n- 그린필드 코드\n- 레거시·모던 코드\n\n두 경로 모두에 대한 과정을 보여주겠다.\n\n## Greenfield\n\n그린필드 개발에서는 아래 프로세스가 잘 맞는다. 탄탄한 기획·문서를 만들고, 작은 단계로 쉽게 실행할 수 있다.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"오른쪽에 초록 들판이 있다. Leica Q, 2016.05.14\" >}}\n\n### Step 1: 아이디어 다듬기\n\n대화형 LLM(나는 ChatGPT 4o / o3 사용)으로 아이디어를 다듬는다.\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\n브레인스토밍이 자연스럽게 끝나면:\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\n꽤 괜찮은 스펙이 나온다. 리포지토리에 `spec.md`로 저장.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\n`spec`을 적절한 추론 모델(`o1*`, `o3*`, `r1`)에 넘긴다.\n\n(아래는 TDD용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(아래는 non-TDD용)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n실행 가능한 프롬프트 플랜이 나온다. `prompt_plan.md`로 저장.\n\n그리고 `todo.md`도 만든다.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\ncodegen 툴이 `todo.md`를 체크해가며 상태를 유지할 수 있어 편리하다.\n\n#### Yay. Plan!\n\n이제 빡센 플랜과 문서가 완성됐다. 실행만 남았다.\n\n전체 과정은 **15분** 정도면 끝난다. 진짜 빠르다.\n\n### Step 3: Execution\n\n실행 도구는 다양하다. Step 2가 잘 돼 있으면 무엇이든 성공 확률이 높다.\n\n[github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai) 등으로 다 해봤고 거의 다 잘 맞았다.\n\n나는 **순정** claude와 aider 조합을 선호한다.\n\n### Claude\n\n[claude.ai](https://claude.ai)와 페어 프로그래밍하듯 프롬프트를 하나씩 넣는다. 약간 번거롭지만 잘 굴러간다.\n\n초기 보일러플레이트 작성과 툴링 세팅은 내가 직접 한다. Claude가 리액트 코드만 뱉는 경향이 있어서, 원하는 언어·스타일·툴 체계를 먼저 잡아두면 편하다.\n\n막히면 [repomix](https://github.com/yamadashy/repomix)로 코드베이스를 통째로 넘겨 디버깅한다.\n\n워크플로우:\n\n- 리포 세팅(보일러플레이트, uv init, cargo init 등)\n- claude에 프롬프트 붙여넣기\n- claude 코드 복사해 IDE에 붙여넣기\n- 코드·테스트 실행\n- …\n- 잘 되면 다음 프롬프트\n- 안 되면 repomix로 코드베이스 전달해 디버깅\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/)는 재미있고 묘하다. Step 2 결과물이 있을 때 특히 잘 붙는다.\n\n작업 흐름은 Claude와 비슷하되, 프롬프트를 aider에 붙여넣는다는 점만 다르다.\n\naider가 알아서 “Just do it” 해주고 나는 [cookie clicker](https://orteil.dashnet.org/cookieclicker/) 모드.\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\naider는 테스트 자동 실행·디버깅까지 해줘서 더 손이 덜 간다.\n\n워크플로우:\n\n- 리포 세팅(보일러플레이트, uv init, cargo init 등)\n- aider 실행\n- 프롬프트 붙여넣기\n- aider 댄스 감상 ♪┏(・o･)┛♪\n- aider가 테스트 실행하거나 직접 앱 실행해 확인\n- 잘 되면 다음 프롬프트\n- 안 되면 Q&A로 수정\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\n이 방식으로 스크립트, expo 앱, rust CLI 등 정말 많이 만들었다. 언어·상황 가리지 않고 잘 된다.\n\n미뤄둔 프로젝트가 있다면 한번 써보길 권한다. 짧은 시간에 놀랄 만큼 진도가 나온다.\n\n할 일 리스트가 텅 빌 정도로 다 만들었다. 영화 보면서도 툭툭 새 언어·툴을 접하고 있으니, 프로그래밍 시야가 확장되는 기분이다.\n\n## Non-greenfield: 점진적 개선\n\n가끔 그린필드가 아닌 기존 코드베이스를 개선해야 할 때가 있다.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"여긴 초록 들판이 아님. 우리 할아버지 카메라에 있던 우간다 60년대 사진\" >}}\n\n이 경우 방법이 조금 다르다. 위 과정과 비슷하지만, 전사적 플랜 대신 작업 단위로 계획한다.\n\n### Get context\n\nAI 개발에 몰두한 사람마다 툴이 다른데, 핵심은 소스코드를 잘 추려서 LLM에 넣는 것이다.\n\n나는 [repomix](https://github.com/yamadashy/repomix)를 쓴다. 전역 `~/.config/mise/config.toml`에 태스크 모음이 있어 여러 작업을 한다([mise rules](https://mise.jdx.dev/)).\n\nLLM 태스크 리스트:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt`로 컨텍스트를 뽑는다. 토큰이 초과되면 관련 없는 디렉터리를 제외하도록 커맨드를 수정한다.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\n`output.txt`가 생기면 [LLM](https://github.com/simonw/LLM) 커맨드에 넘겨 변환하고, 마크다운으로 저장한다.\n\n결국 `mise` 태스크는 `cat output.txt | LLM -t readme-gen > README.md` 같은 식이다. 복잡할 거 없다. `LLM` 명령이 모델 선택, 키 관리, 프롬프트 템플릿 등을 해준다.\n\n예컨대 테스트 커버리지 리뷰·수정이 급할 때:\n\n#### Claude\n\n- 코드 디렉터리로 이동\n- `mise run LLM:generate_missing_tests` 실행\n- 생성된 `missing-tests.md` 확인\n- `mise run LLM:copy_buffer_bundle`로 컨텍스트 클립보드 복사\n- claude에 붙여넣고 첫 번째 이슈부터 해결\n- claude 코드 IDE에 붙여넣기\n- …\n- 테스트 실행\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- 코드 디렉터리로 이동\n- 새 브랜치에서 aider 실행\n- `mise run LLM:generate_missing_tests` 실행\n- `missing-tests.md` 확인\n- 첫 번째 이슈를 aider에 붙여넣기\n- aider 댄스 감상 ♪┏(・o･)┛♪\n- …\n- 테스트 실행\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n큰 코드베이스도 작은 단위로 꾸준히 개선할 수 있다.\n\n### Prompt magic\n\n이런 퀵 해킹은 프로젝트를 더 탄탄하게 만드는 좋은 방법이다. 빠르고 효과적.\n\n기존 코드에 쓸 프롬프트 몇 가지:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(실제 이슈 등록은 아직 자동화 못 함!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n이 프롬프트들은 좀 _구식_ 이다(“boomer prompts”랄까). 더 좋게 바꿀 아이디어가 있으면 알려 달라.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n이 과정을 설명할 때 “정신 바짝 차리고 진행 상황을 추적해야 한다”고 말한다. 안 그러면 순식간에 앞질러 가버린다.\n\nLLM 이야기할 때 “over my skis”라는 표현을 자주 쓴다. 파우더 눈에서 부드럽게 타다 갑자기 “뭐야 이거?!” 하며 절벽에서 굴러떨어지는 느낌이랄까.\n\n**Planning 단계**(위 그린필드 과정 참조)를 넣으면 통제가 좀 된다. 적어도 문서를 보고 재확인할 수 있다. 특히 aider처럼 와일드하게 코딩할 때는 테스트가 도움이 된다.\n\n그럼에도 **over my skis** 상태가 자주 온다. 잠깐 산책이나 휴식을 하면 해결되곤 한다. 본질적으로는 평범한 문제 해결 과정인데, 속도가 광속이라 그렇다.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\n이 워크플로우의 단점은 **1인 모드**에 가깝다는 것. 팀 프로젝트에 쓰기 어렵다. 봇끼리 충돌하고, 머지가 끔찍하고, 컨텍스트가 복잡하다.\n\nLLM 코딩을 멀티플레이 게임으로 바꿀 누군가가 필요하다. 솔로 해커 경험이 아니라. 이걸 제대로 풀면 엄청난 기회가 있을 것이다.\n\nGET TO WORK!  (어서 만들어줘!)\n\n## ⴵ Time ⴵ\n\n코드젠 덕분에 혼자 만들 수 있는 코드 양이 폭증했다. 하지만 LLM이 토큰 태우는 동안 “대기 시간”이 많아졌다.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"어제 일처럼 생생하다\" >}}\n\n그래서 기다리는 시간에 할 일을 바꿔봤다.\n\n- 다른 프로젝트 “브레인스토밍” 시작\n- LP 틀어놓고 음악 듣기\n- [cookie clicker](https://orteil.dashnet.org/cookieclicker/) 플레이\n- 친구·로봇과 수다\n\n이렇게 해킹할 수 있다는 게 멋지다. Hack Hack Hack. 이렇게 생산적이었던 때가 또 있었나 싶다.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\n친구들 중엔 “LLM 개구림. 다 못함” 하는 사람이 많다. 그 시각 이해한다. 비판적 시각은 중요하다. 나도 전력 소모와 환경 영향을 가장 걱정한다. 하지만… 코드는 흘러야 한다. 그렇지… 하아.\n\n더 알아보고 싶지만 사이보그 프로그래머가 되고 싶진 않다면, 이 책을 추천한다: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) by Ethan Mollick.\n\n기술 낙관론·자본주의 찬가 같은 책이 아니라, LLM의 장점을 균형 있게 설명한다. 읽은 친구들과 깊이 있는 대화를 많이 나눴다. 강추.\n\n회의적이지만 조금 궁금하다면 언제든 연락하라. LLM을 어떻게 쓰는지 보여주고, 같이 뭔가 만들어볼 수도 있다.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\nPlease review and improve the translated text to make it natural and accurate in korean.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl:dr; 사양을 브레인스토밍 → 계획 수립 → LLM 코드젠으로 실행. 개별 루프. 그리고 매직. ✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM으로 작은 제품을 정말 많이 만들고 있다. 재미있고 유용하다. 하지만 시간을 낭비하게 만드는 함정도 꽤 있다. 얼마 전 친구가 “LLM으로 어떻게 소프트웨어를 작성하느냐”라고 물었다. ‘이야, 시간이 얼마나 있니?’ 싶은 마음에 이 글을 쓰게 됐다.\n\n(p.s. AI를 싫어한다면 ─ 맨 아래로 스크롤!)\n\n주변 개발자 친구들과 이야기를 나눠보면 다들 큰 틀은 비슷하고 디테일만 조금씩 다르다.\n\n아래는 내 워크플로우다. 내 경험, 친구들과의 대화(고마워요 [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)) 그리고 온갖 지옥 같은 인터넷 [나쁜](https://news.ycombinator.com/) [장소](https://twitter.com)에서 공유된 베스트 프랙티스를 토대로 만들었다.\n\n지금은 **잘** 돌아가지만, 2주 뒤엔 안 먹히거나 두 배로 잘 될 수도 있다.  ¯\\\\\\_(ツ)\\_/¯\n\n## 시작!\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"AI가 만든 이미지는 늘 수상하다. 내 저글로 코딩 로봇 엔젤에게 인사!\" >}}\n\n개발 접근 방식은 다양하지만, 내 경우는 보통 두 가지다.\n\n- 그린필드 코드\n- 레거시 코드\n\n두 경로 모두에 대한 과정을 보여주겠다.\n\n## Greenfield\n\n그린필드 개발에서는 아래 프로세스가 잘 맞는다. 탄탄한 계획과 문서를 마련하고, 작은 단계로 쉽게 실행할 수 있다.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"오른쪽에 초록 들판이 있다. Leica Q, 2016.05.14\" >}}\n\n### Step 1: 아이디어 다듬기\n\n대화형 LLM(나는 ChatGPT 4o / o3 사용)으로 아이디어를 다듬는다.\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\n브레인스토밍이 자연스럽게 끝나면:\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\n꽤 괜찮은 스펙이 나온다. 리포지토리에 `spec.md`로 저장.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\n`spec`을 적절한 추론 모델(`o1*`, `o3*`, `r1`)에 넘긴다.\n\n(아래는 TDD용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(아래는 non-TDD용)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n실행 가능한 프롬프트 플랜이 나온다. `prompt_plan.md`로 저장.\n\n그리고 `todo.md`도 만든다.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\ncodegen 툴이 `todo.md`를 체크해 가며 상태를 유지할 수 있어 편리하다.\n\n#### Yay. Plan!\n\n이제 탄탄한 플랜과 문서가 생겼다. 실행만 남았다.\n\n전체 과정은 **15분** 정도면 끝난다. 정말 빠르다.\n\n### Step 3: Execution\n\n사용할 수 있는 도구는 정말 많다. Step 2만 잘 만들어 두면 무엇으로 실행해도 성공 확률이 높다.\n\n[github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai) 등으로 다 해봤고 거의 다 잘 맞았다.\n\n나는 **순정** Claude와 Aider 조합을 선호한다.\n\n### Claude\n\n[claude.ai](https://claude.ai)와 페어 프로그래밍하듯 프롬프트를 하나씩 넣는다. 약간 번거롭지만 잘 굴러간다.\n\n초기 보일러플레이트 작성과 툴링 세팅은 내가 직접 한다. Claude가 React 코드만 뱉는 경향이 있어서, 원하는 언어·스타일·툴 체계를 먼저 잡아두면 편하다.\n\n막히면 [repomix](https://github.com/yamadashy/repomix)로 코드베이스를 통째로 넘겨 디버깅한다.\n\n워크플로우:\n\n- 리포 세팅(보일러플레이트, `uv init`, `cargo init` 등)\n- Claude에 프롬프트 붙여넣기\n- Claude가 준 코드를 IDE에 붙여넣기\n- 코드·테스트 실행\n- …\n- 잘 되면 다음 프롬프트\n- 안 되면 repomix로 코드베이스 전달해 디버깅\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/)는 재미있고 묘하다. Step 2 결과물이 있을 때 특히 잘 맞는다.\n\n작업 흐름은 위와 거의 같지만 프롬프트를 Aider에 붙여넣는다는 점만 다르다.\n\nAider가 알아서 “Just do it” 해주고 나는 [cookie clicker](https://orteil.dashnet.org/cookieclicker/)를 누른다.\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nAider는 테스트 실행과 디버깅까지 자동으로 해줘서 더 손이 덜 간다.\n\n워크플로우:\n\n- 리포 세팅(보일러플레이트, `uv init`, `cargo init` 등)\n- Aider 실행\n- 프롬프트 붙여넣기\n- Aider 댄스 감상 ♪┏(・o･)┛♪\n- Aider가 테스트 실행하거나 직접 앱 실행해 확인\n- 잘 되면 다음 프롬프트\n- 안 되면 Q&A로 수정\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\n이 방식으로 스크립트, Expo 앱, Rust CLI 등 정말 많이 만들었다. 언어와 상황을 가리지 않고 잘 된다.\n\n미뤄둔 프로젝트가 있다면 한번 시도해 보길 권한다. 짧은 시간에 놀랄 만큼 진도가 나온다.\n\n내 해킹 To-Do 리스트는 텅 빌 지경이다. 영화 보면서도 새 언어와 툴을 익히고 있으니 프로그래밍 시야가 확장되는 느낌이다.\n\n## Non-greenfield: 점진적 개선\n\n가끔 그린필드가 아닌 기존 코드베이스를 개선해야 할 때가 있다.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"여긴 초록 들판이 아님. 우리 할아버지 카메라에 있던 60년대 우간다 사진\" >}}\n\n이 경우 방법이 조금 다르다. 위 과정과 비슷하지만, 프로젝트 전체가 아니라 작업 단위로 계획한다.\n\n### Get context\n\nAI 개발자마다 도구는 다르지만, 핵심은 소스코드를 잘 추려서 LLM에 넣는 것이다.\n\n나는 [repomix](https://github.com/yamadashy/repomix)를 쓴다. 전역 `~/.config/mise/config.toml`에 태스크 모음이 있어 여러 작업을 수행한다([mise rules](https://mise.jdx.dev/)).\n\nLLM 태스크 리스트:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt`로 컨텍스트를 추출한다. 토큰이 초과되면 관련 없는 디렉터리를 제외하도록 커맨드를 수정한다.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\n`output.txt`가 생기면 [LLM](https://github.com/simonw/LLM) 커맨드에 넘겨 변환하고, 마크다운으로 저장한다.\n\n결국 `mise` 태스크는 `cat output.txt | LLM -t readme-gen > README.md` 같은 식이다. 복잡할 것 없다. `LLM` 명령이 모델 선택, 키 관리, 프롬프트 템플릿 등을 해준다.\n\n예컨대 테스트 커버리지를 빠르게 보강해야 할 때:\n\n#### Claude\n\n- 코드 디렉터리로 이동\n- `mise run LLM:generate_missing_tests` 실행\n- 생성된 `missing-tests.md` 확인\n- `mise run LLM:copy_buffer_bundle`로 컨텍스트를 클립보드에 복사\n- Claude에 붙여넣고 첫 번째 이슈부터 해결\n- Claude가 준 코드를 IDE에 붙여넣기\n- …\n- 테스트 실행\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- 코드 디렉터리로 이동\n- 새 브랜치에서 Aider 실행\n- `mise run LLM:generate_missing_tests` 실행\n- `missing-tests.md` 확인\n- 첫 번째 이슈를 Aider에 붙여넣기\n- Aider 댄스 감상 ♪┏(・o･)┛♪\n- …\n- 테스트 실행\n- 반복 ✩₊˚.⋆☾⋆⁺₊✧\n\n큰 코드베이스도 이런 식으로 작은 단위로 꾸준히 개선할 수 있다.\n\n### Prompt magic\n\n이런 퀵 해킹은 프로젝트를 더 탄탄하게 만드는 데 탁월하다. 빠르고 효과적이다.\n\n기존 코드에 쓸 프롬프트 몇 가지:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(실제 이슈 등록은 아직 자동화 못 함!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n이 프롬프트들은 좀 _구식_ 이다(“boomer prompts”랄까). 더 좋게 바꿀 아이디어가 있으면 알려 달라.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n이 과정을 설명할 때 “정신 바짝 차리고 진행 상황을 추적해야 한다”고 말한다. 안 그러면 순식간에 앞질러 간다.\n\n왜인지 LLM 얘기를 할 때 “over my skis”라는 표현을 자주 쓴다. 파우더 눈을 부드럽게 타다 갑자기 “뭐야 이거?!” 하고 절벽에서 굴러떨어지는 느낌이랄까.\n\n**Planning 단계**(위 그린필드 과정 참조)를 넣으면 통제가 좀 된다. 적어도 문서를 보고 재확인할 수 있다. 특히 Aider처럼 와일드하게 코딩할 때는 테스트가 도움이 된다.\n\n그럼에도 **over my skis** 상태가 자주 온다. 잠깐 산책이나 휴식을 하면 해결되곤 한다. 본질적으로는 평범한 문제 해결 과정인데, 속도가 광속이라 그렇다.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\n이 워크플로우의 단점은 **1인 모드**에 가깝다는 것. 팀 프로젝트에 쓰기 어렵다. 봇끼리 충돌하고, 머지는 끔찍하고, 컨텍스트는 복잡하다.\n\nLLM 코딩을 멀티플레이 게임으로 바꿀 누군가가 필요하다. 솔로 해커 경험이 아니라. 이걸 제대로 풀면 엄청난 기회가 있을 것이다.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\n코드젠 덕분에 혼자 만들 수 있는 코드 양이 폭증했다. 하지만 LLM이 토큰을 태우는 동안 “대기 시간”도 그만큼 늘었다.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"어제 일처럼 생생하다\" >}}\n\n그래서 기다리는 시간에 할 일을 바꿔 봤다.\n\n- 다른 프로젝트 브레인스토밍 시작\n- LP 틀어놓고 음악 듣기\n- [cookie clicker](https://orteil.dashnet.org/cookieclicker/) 플레이\n- 친구·로봇과 수다\n\n이렇게 해킹할 수 있다는 게 멋지다. Hack Hack Hack. 이렇게 생산적이었던 때가 또 있었나 싶다.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\n친구들 중엔 “LLM 개구림. 다 못함” 하는 사람이 많다. 그 시각 이해한다. 비판적 시각은 중요하다. 나도 전력 소모와 환경 영향을 가장 걱정한다. 하지만… 코드는 흘러야 한다. 그렇지… 하아.\n\n더 알아보고 싶지만 사이보그 프로그래머가 되고 싶진 않다면, 이 책을 추천한다: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) by Ethan Mollick.\n\n기술 낙관론·자본주의 찬가 같은 책이 아니라, LLM의 장점을 균형 있게 설명한다. 읽은 친구들과 깊이 있는 대화를 많이 나눴다. 강추.\n\n회의적이지만 조금 궁금하다면 언제든 연락하라. LLM을 어떻게 쓰는지 보여주고, 같이 뭔가 만들어볼 수도 있다.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "usage": {
        "prompt_tokens": 9257,
        "completion_tokens": 11182,
        "total_tokens": 20439
      }
    },
    "critique": {
      "model": "o3",
      "target_language": "korean",
      "system_prompt": "You are a highly critical professional translator and linguistic expert specializing in korean.\nYour task is to ruthlessly critique the translation by:\n\n1. Meticulously comparing the translated text with the original, identifying ANY inaccuracies, mistranslations, or omissions\n2. Highlighting nuances, cultural references, or idioms that were lost or mistranslated\n3. Scrutinizing for grammatical errors, awkward phrasing, or unnatural expressions in korean\n4. Checking for inconsistencies in tone, style, or register compared to the original\n5. Verifying that technical terms are translated accurately and consistently\n6. Ensuring no content was accidentally skipped or added\n7. Finding places where the translation sounds machine-like or overly literal\n\nBe extremely thorough and critical in your assessment. Do not accept mediocre translations.\nList specific issues and suggestions for improvement, organized by severity and category.\nYour critique should be detailed enough for another translator to address all the issues.\n\nYour goal is to help create a perfect translation that reads as if originally written in korean while being 100% faithful to the source.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr: 스펙을 브레인스토밍한 뒤 → ‘계획을 위한 계획’을 세우고 → LLM 코드 생성(Codegen)으로 실행한다. 각 단계는 독립 루프. 그리고 매직! ✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM 덕분에 작은 제품을 정말 많이 만들었다. 재미있고 유용하다. 하지만 시간을 왕창 잡아먹는 함정도 수두룩하다. 얼마 전 친구가 “LLM으로 어떻게 소프트웨어를 짜?”라고 묻길래 “이야, 시간 좀 있어?” 싶어 이 글을 쓴다.\n\n(p.s. AI가 싫다면 ― 맨 끝으로 스크롤!)\n\n개발자 친구들과 이야기해 보면 큰 틀은 비슷하지만, 각자 양쪽으로 살짝씩 튜닝이 다르다.\n\n아래 워크플로는 내 경험, 친구들과의 대화(고마워요 [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)) 그리고 인터넷의 악명 높은 구석구석([Hacker News](https://news.ycombinator.com/), [X/Twitter](https://twitter.com) 같은)에서 떠도는 베스트 프랙티스를 뒤섞어 만들었다.\n\n지금은 **엄청** 잘 통하지만 두 주 뒤엔 안 통하거나 두 배로 잘 통할 수도 있다. ¯\\\\_(ツ)_/¯\n\n## 시작!\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"AI가 만든 이미지는 늘 수상하다. 저글로(Juggalo) 광대 분장의 코딩 로봇 천사에게 인사!\" >}}\n\n개발 방식은 여럿이지만 내 경우는 대체로 둘이다.\n\n- 그린필드(Greenfield) 코드\n- 기존(레거시·모던 포함) 코드\n\n두 갈래 모두의 과정을 차례로 소개한다.\n\n## Greenfield\n\n그린필드 개발에는 다음 프로세스가 잘 맞는다. 탄탄한 계획·문서를 제공하고, 작은 단계로 쉽게 실행할 수 있다.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"오른쪽에 진짜 그린필드가 있다. Leica Q, 2016-05-14\" >}}\n\n### Step 1: 아이디어 다듬기\n\n대화형 LLM(ChatGPT 4o / o3)을 이용해 아이디어를 정제한다.\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\n아이디어가 충분히 정리됐다 싶을 때:\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\n꽤 괜찮은 스펙이 나온다. 리포지토리에 `spec.md`로 저장한다.\n\n> 이 스펙은 여러 용도로 쓸 수 있다. 우리는 코드 생성에 쓸 거지만, 추론 모델에 넘겨 아이디어의 허점을 찾거나(더 깊이!), 백서를 뽑아내거나, 1만 단어짜리 지원 문서를 받아내도 좋다.\n\n### Step 2: Planning\n\n`spec.md`를 추론 특화 모델(`o1*`, `o3*`, `r1`)에 보낸다.\n\n(다음은 TDD용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(다음은 TDD 미적용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n프롬프트 계획이 출력된다. `prompt_plan.md`로 저장한다.\n\n이어 체크리스트용 `todo.md`를 만든다.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n코드 생성 도구가 `todo.md`를 체크해 가며 상태를 유지하기 편하다.\n\n#### 플랜 완성! 야호!\n\n이제 탄탄한 계획과 문서가 생겼으니 실행만 남았다.\n\n전체 과정은 **15분**이면 끝난다. 솔직히 말도 안 될 정도로 빠르다—Wild tbh.\n\n### Step 3: Execution\n\n도구는 정말 많다. 2단계를 잘 해두면 무엇으로 돌려도 성공 확률이 높다.\n\n[GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai) 등 써본 도구마다 잘 작동했다.\n\n나는 기본 웹 인터페이스의 Claude와 Aider 조합을 선호한다.\n\n### Claude\n\n[Claude.ai](https://claude.ai)와 페어 프로그래밍하듯 프롬프트(prompt)를 하나씩 넣는다. 왔다 갔다가 번거롭지만 대체로 잘 굴러간다.\n\n초기 보일러플레이트와 툴 셋업은 내가 직접 한다. Claude가 React 코드만 던지는 버릇이 있어 원하는 언어·스타일·툴 체계를 먼저 잡아두면 편하다.\n\n막히면 [repomix](https://github.com/yamadashy/repomix)로 코드베이스 전체를 넘겨 디버깅한다(뒤에서 다시 다룬다).\n\n워크플로:\n\n- 리포지토리 셋업(보일러플레이트, `uv init`, `cargo init` 등)\n- Claude에 프롬프트 붙여넣기\n- Claude가 준 코드를 IDE에 붙여넣기\n- 코드·테스트 실행\n- …\n- 잘 되면 다음 프롬프트\n- 안 되면 repomix로 디버깅\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/)는 재미있고 묘하다. 2단계에서 뽑은 프롬프트 계획과 궁합이 특히 좋다.\n\n워크플로는 거의 같지만, 프롬프트를 Aider에 붙여넣는다는 점만 다르다.\n\nAider가 “Just do it” 해주고 나는 [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)나 두드린다.\n\n> 참고: Aider는 [LLM 리더보드](https://aider.chat/docs/leaderboards/)에서 새 모델의 코드 생성 성능을 깔끔하게 벤치마킹한다. 새 모델 효율을 보기 좋은 자료다.\n\n테스트까지 자동으로 돌려주니 손이 훨씬 덜 간다.\n\n워크플로:\n\n- 리포지토리 셋업(보일러플레이트, `uv init`, `cargo init` 등)\n- Aider 실행\n- 프롬프트 붙여넣기\n- watch aider dance ♪┏(・o･)┛♪\n- Aider가 테스트를 돌리거나 직접 앱을 실행해 확인\n- 잘 되면 다음 프롬프트\n- 안 되면 Q&A로 수정\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\n이 방식으로 스크립트, Expo 앱, Rust CLI 등 엄청 많이 만들었다. 언어와 상황 가리지 않고 잘 된다.\n\n작든 크든 미뤄둔 프로젝트가 있다면 한번 써보라. 짧은 시간에 놀랄 만큼 진도가 나간다.\n\n‘해킹 to-do 리스트’가, 다 만들어 버린 덕에 텅 비었다. 영화 보면서 새 언어·툴을 만지니 프로그래밍 시야가 쑥 넓어진다.\n\n## Non-greenfield: 점진적 개선\n\n때로는 그린필드가 아니라 이미 있는 코드베이스를 조금씩 다듬어야 한다.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"이건 브라운필드다. 할아버지 카메라에 담긴 1960년대 우간다 어딘가\" >}}\n\n이 경우 방법이 살짝 다르다. 프로젝트 전체가 아니라 작업 단위로 계획한다.\n\n### Get context\n\nAI 개발자마다 도구는 다르지만, 핵심은 소스 코드를 잘 추려 LLM에 효율적으로 집어넣는 것이다.\n\n나는 [repomix](https://github.com/yamadashy/repomix)를 쓴다. 전역 `~/.config/mise/config.toml`에 작업 모음을 정의해 두었다([mise 규칙](https://mise.jdx.dev/)).\n\nLLM 작업 목록:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt`로 컨텍스트를 추출한다. 토큰이 초과되면 관련 없는 부분을 제외하도록 명령을 수정한다.\n\n> `mise`의 좋은 점은 작업을 해당 디렉터리의 `.mise.toml`에서 재정의·오버라이드할 수 있다는 것. 코드 덤프 도구를 바꿔도 `output.txt`만 나오면 LLM 작업을 그대로 쓸 수 있다. 코드베이스 구조가 제각각이라 자주 `repomix` 단계를 덮어쓰거나 더 효율적인 툴로 갈아탄다.\n\n`output.txt`가 생기면 [LLM](https://github.com/simonw/LLM) 명령에 파이프로 넘겨 변환하고 결과를 마크다운으로 저장한다.\n\n결국 mise 작업은  \n`cat output.txt | LLM -t readme-gen > README.md`  \n또는  \n`cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`  \n같은 꼴이다. `LLM` 명령이 모델 선택, 키 관리, 프롬프트 템플릿을 맡아준다.\n\n예컨대 테스트 커버리지를 빠르게 보강해야 할 때:\n\n#### Claude\n\n- 코드 디렉터리로 이동  \n- `mise run LLM:generate_missing_tests` 실행  \n- 생성된 `missing-tests.md` 확인  \n- `mise run LLM:copy_buffer_bundle`로 컨텍스트를 클립보드에 복사  \n- Claude에 붙여넣고 첫 번째 ‘누락 테스트’ 이슈부터 해결  \n- Claude가 준 코드를 IDE에 붙여넣기  \n- …  \n- 테스트 실행  \n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- 코드 디렉터리로 이동  \n- 새 브랜치에서 Aider 실행  \n- `mise run LLM:generate_missing_tests` 실행  \n- `missing-tests.md` 확인  \n- 첫 번째 ‘누락 테스트’ 이슈를 Aider에 붙여넣기  \n- watch aider dance ♪┏(・o･)┛♪  \n- …  \n- 테스트 실행  \n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧  \n\n큰 코드베이스도 이런 식으로 작은 단위로 꾸준히 개선할 수 있다.\n\n### Prompt magic\n\n이런 퀵 해킹은 프로젝트를 더 탄탄하게 만든다. 빠르고 효과적이다.\n\n기존 코드에 쓰는 내 단골 프롬프트 몇 가지:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(실제 이슈 등록은 아직 자동화 못 함!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n이 프롬프트들은 좀 구닥다리(“boomer prompts”랄까). 더 좋은 아이디어가 있으면 꼭 알려 달라.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n이 과정을 설명할 때면 “정신 바짝 차리고 진행 상황을 추적해야 한다, 안 그러면 금방 스스로를 앞질러 버린다”고 말한다.\n\n나는 ‘over my skis’(스키가 너무 앞으로 나가 균형을 잃는 상황)라는 표현을 자주 쓴다. 부드러운 파우더를 타다 갑자기 “뭐야?!” 하고 절벽에서 구르는 느낌.\n\n**Planning 단계**(그린필드 과정 참조)를 두면 통제력이 생긴다. 문서를 보고 재확인할 수 있다. 특히 Aider처럼 와일드하게 코딩할 때는 테스트가 큰 도움이 된다.\n\n그래도 가끔은 over my skis 상태가 온다. 잠깐 쉬거나 산책하면 머리가 리셋된다. 문제 해결 과정 자체는 평범하지만 속도가 광속이라 그렇다.\n\n> 우리는 종종 LLM에게 엉뚱한 걸 코드에 끼워 넣으라고 시킨다. 예컨대 ‘lore 파일을 만들고 UI에서 참조하라’고 요구하면 파이썬 CLI 툴에도 lore와 글리치 UI가 생겨난다. 하늘이 한계다.\n\n## I am so lonely (｡•́︿•̀｡)\n\n단점 하나: 대부분 **싱글 플레이 모드**다. 팀으로 쓰기 어렵다. 봇끼리 충돌하고, 머지는 끔찍하고, 컨텍스트는 복잡하다.\n\nLLM 코딩을 멀티플레이 게임으로 바꿔 줄 누군가가 절실하다. 솔로 해커 경험이 아니라 다 같이 즐길 수 있도록. 기회가 어마어마하다.\n\n**어서 일해라!** (GET TO WORK!)\n\n## ⴵ Time ⴵ\n\n코드 생성 덕분에 한 사람이 찍어내는 코드 양이 폭증했다. 반면 LLM이 토큰을 태우는 동안 ‘대기 시간’도 길어졌다.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"이 화면, 어제 본 것처럼 생생하다\" >}}\n\n그래서 기다리는 시간에는:\n\n- 다른 프로젝트 브레인스토밍  \n- LP 꺼내 음악 듣기  \n- Cookie Clicker 두드리기  \n- 친구·로봇과 수다  \n\n이렇게 해킹할 수 있다니 멋지다. Hack Hack Hack. 이렇게 생산적이었던 적이 또 있었나?\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\n주변엔 “LLM 별로야, 다 못 해”라는 친구도 많다. 비판적 시각은 중요하다. 나도 전력 소모와 환경 영향을 걱정한다. 하지만… 코드는 흘러야지. 하아.\n\n더 알고 싶지만 ‘사이보그 프로그래머’까지는 싫다면 Ethan Mollick의 책 [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)을 권한다.\n\n기술 낙관·자본 예찬이 아닌 균형 잡힌 시선으로 LLM 활용법을 설명한다. 읽은 친구들과 깊은 대화를 나눌 수 있었다. 강추!\n\n회의적이지만 조금이라도 궁금하다면 언제든 연락하라. LLM을 어떻게 쓰는지 보여주고, 함께 뭔가 만들어 볼 수도 있다.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\nPlease critique this translation mercilessly and provide detailed feedback on what needs to be improved.\nFormat your critique as a structured list of issues, organized by severity and category.\nInclude specific suggestions for how to fix each issue.",
      "response": "[Severity legend]  \nCritical = Alters meaning or leaves out content.  \nMajor    = Meaning mostly intact but nuance/important detail lost, or Korean sounds plainly unnatural.  \nModerate = Minor nuance/flow/consistency problems.  \nMinor/Stylistic = Pure polish.\n\n──────────────────────────────  \n1. Critical ‑ Meaning/Content Errors  \n──────────────────────────────  \n1-A. Omitted purposes of the spec  \n• Source: “ … to generate a white paper, or to generate a business model.”  \n• Kor: “백서를 뽑아내거나, 1만 단어짜리 지원 문서를 받아내도 … ” → “business model” 생략.  \n  Fix: “백서를 만들거나 비즈니스 모델을 뽑아내거나 …”\n\n1-B. Sentence fully dropped (Results section)  \n• Source: “I keep thinking of new things and knocking them out while watching a movie or something.”  \n• Missing in Kor.  \n  Fix: 추가: “영화를 보면서도 새 아이디어가 떠오르면 바로 만들어 버린다.”\n\n1-C. Sentence dropped (Non-greenfield)  \n• Source: “I have found that I can do any sized tasks with this method.”  \n• Missing in Kor.  \n  Fix: “이 방식으로 규모에 관계없이 어떤 작업도 해낼 수 있었다.”\n\n1-D. “Raw claude” mis-rendered  \n• Source: “I, however, prefer **raw** claude and aider” (의미: 래퍼 없이 ‘날것’ API/UI).  \n• Kor: “기본 웹 인터페이스의 Claude” → ‘raw’ = ‘웹 인터페이스’ 아님.  \n  Fix: “별도 래퍼 없이 ‘생(生) CLAUDE’(API 직접/기본 UI)와 Aider를 선호한다.”\n\n1-E. “Over my skis” imagery truncated  \n• Source includes vivid cliff-falling sentence (“WHAT THE **** … fall off a cliff”).  \n• Kor 요약으로 끝. 강렬한 유머·놀람 감정 유실.  \n  Fix: 전체 비유 살려 추가.\n\n1-F. Misc. small omissions  \n– “It resonates with me. I don’t know why.”  \n– “Generate a business model” (covered 1-A).  \nEnsure 완전한 반영.\n\n──────────────────────────────  \n2. Major ‑ Nuance / Idiom / Register  \n──────────────────────────────  \n2-A. “양쪽으로 살짝씩 튜닝이 다르다”  \n  • 영어 “tweaks in either direction” → 의미는 ‘사람마다 조금씩 다르다’.  \n  • 현재 표현은 방향이 두 개뿐인 듯 어색.  \n  • 제안: “저마다 약간씩 다르게 튜닝한다.”\n\n2-B. “Cookie Clicker나 두드린다”  \n  • 한국어 관용 맞지 않음.  \n  • 제안: “Cookie Clicker를 두드리며 논다” or “Cookie Clicker나 하면서 논다”.\n\n2-C. “리포지토리 셋업”  \n  • IT 용례 있지만 연속 사용 잦음. 한두 번은 “리포지토리를 초기화한다” 등으로 자연화.\n\n2-D. “기존(레거시·모던 포함) 코드”  \n  • 원문 “legacy modern code” 는 자조적 표현. 현재 번역은 정보 전달만 있고 익살 빠짐.  \n  • 가능: “레거시(?) ‘모던’ 코드” 같이 따옴표로 뉘앙스 살리기.\n\n2-E. 톤 불균일  \n  • 원문은 대체로 속어·친구에게 말하듯. 몇몇 구간(“왕창 잡아먹는 함정도 수두룩하다” vs “탄탄한 계획·문서를 제공하고”) 사이 어투 급격히 바뀜.  \n  • 제안: 반말/친근어 vs 서술형 존댓말 중 하나로 통일, 혹은 반말 체 유지.\n\n──────────────────────────────  \n3. Grammar / Flow Issues (Moderate)  \n──────────────────────────────  \n3-A. 겹말·군더더기  \n  • “이 경우 방법이 살짝 다르다.” → “방법이 조금 다르다.”  \n3-B. 불필요한 영어 괄호·역슬래시  \n  • “¯\\\\_(ツ)_/¯” 역-이스케이프 제거.  \n3-C. 과도한  ·  기호  \n  • “―” “—” 혼용, markdown 일관성 필요.\n\n──────────────────────────────  \n4. Terminology Consistency  \n──────────────────────────────  \n4-A. Codegen / 코드 생성 혼용   → 최초 괄호 병기 뒤 일관된 한국어 사용 권장.  \n4-B. “Prompt”는 대부분 영문 그대로 두었는데 몇 군데 ‘프롬프트’ 사용. 통일.\n\n──────────────────────────────  \n5. Minor / Stylistic  \n──────────────────────────────  \n5-A. 날짜 표현 ↔ “2016-05-14” vs “5/14/2016” 통일.  \n5-B. “Wild tbh.” 그대로 유지했으나 한국어 독자 이해 어렵다. 주해 또는 “솔직히 미친 속도다 (wild tbh).”  \n5-C. 밑줄/기울임 기호: 원문 형식 유지 필요.\n\n──────────────────────────────  \n6. Machine-like residue  \n──────────────────────────────  \n6-A. 영어 문장을 그대로 남겨 놓은 Prompt 영역은 의도된 것이나, 본문 내 “review the results … small enough” 한 줄 그대로 남아있음 → 번역 누락 의심.  \n6-B. 장황한 괄호 삽입 스타일이 GPT 번역 느낌. 일부 간결화 권장.\n\n──────────────────────────────  \nOverall Recommendations  \n──────────────────────────────  \n• 빠진 문장·의미(1-A~1-F) 반드시 추가.  \n• ‘raw’, ‘legacy modern code’, ‘over my skis’ 등 농담성 키워드는 직역+주해로 유머 살리기.  \n• 구어체 톤을 일정하게 유지하되 군더더기·어색한 직역(2-A, 2-B 등) 다듬기.  \n• 영어 전문어는 첫 등장 시 병기 후 한국어 일관성 유지.  \n• Prompt 본문 외의 영어 잔여 문장은 모두 번역.  \n• 자잘한 문장부호·형식 통일로 가독성 개선.\n\n이 리스트를 반영하면 “영어 원서인 줄 몰랐다”는 말이 나올 만큼 자연스럽고 충실한 번역이 될 것입니다.",
      "usage": {
        "prompt_tokens": 9271,
        "completion_tokens": 7661,
        "total_tokens": 16932
      }
    },
    "feedback": {
      "model": "o3",
      "target_language": "korean",
      "system_prompt": "You are a master translator and editor specializing in korean.\nYour task is to improve a translation based on detailed critique feedback.\n\n1. Carefully read the original text, current translation, and the critique feedback\n2. Address ALL issues identified in the critique\n3. Apply the specific suggestions for improvement\n4. Ensure the translation is accurate, natural-sounding, and faithful to the original\n5. Preserve all formatting, markdown, and structure of the original text\n6. Make sure the final text reads as if it were originally written in korean\n\nDo not ignore any of the critique points. Every issue identified must be addressed in your improved version.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl;dr: 스펙을 브레인스토밍한 뒤 → ‘계획을 위한 계획’을 세우고 → LLM 코드 생성(Codegen)으로 실행한다. 각 단계는 독립 루프. 그리고 매직! ✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM 덕분에 작은 제품을 정말 많이 만들었다. 재미있고 유용하다. 하지만 시간을 왕창 잡아먹는 함정도 수두룩하다. 얼마 전 친구가 “LLM으로 어떻게 소프트웨어를 짜?”라고 묻길래 “이야, 시간 좀 있어?” 싶어 이 글을 쓴다.\n\n(p.s. AI가 싫다면 ― 맨 끝으로 스크롤!)\n\n개발자 친구들과 이야기해 보면 큰 틀은 비슷하지만, 각자 양쪽으로 살짝씩 튜닝이 다르다.\n\n아래 워크플로는 내 경험, 친구들과의 대화(고마워요 [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)) 그리고 인터넷의 악명 높은 구석구석([Hacker News](https://news.ycombinator.com/), [X/Twitter](https://twitter.com) 같은)에서 떠도는 베스트 프랙티스를 뒤섞어 만들었다.\n\n지금은 **엄청** 잘 통하지만 두 주 뒤엔 안 통하거나 두 배로 잘 통할 수도 있다. ¯\\\\_(ツ)_/¯\n\n## 시작!\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"AI가 만든 이미지는 늘 수상하다. 저글로(Juggalo) 광대 분장의 코딩 로봇 천사에게 인사!\" >}}\n\n개발 방식은 여럿이지만 내 경우는 대체로 둘이다.\n\n- 그린필드(Greenfield) 코드\n- 기존(레거시·모던 포함) 코드\n\n두 갈래 모두의 과정을 차례로 소개한다.\n\n## Greenfield\n\n그린필드 개발에는 다음 프로세스가 잘 맞는다. 탄탄한 계획·문서를 제공하고, 작은 단계로 쉽게 실행할 수 있다.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"오른쪽에 진짜 그린필드가 있다. Leica Q, 2016-05-14\" >}}\n\n### Step 1: 아이디어 다듬기\n\n대화형 LLM(ChatGPT 4o / o3)을 이용해 아이디어를 정제한다.\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\n아이디어가 충분히 정리됐다 싶을 때:\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\n꽤 괜찮은 스펙이 나온다. 리포지토리에 `spec.md`로 저장한다.\n\n> 이 스펙은 여러 용도로 쓸 수 있다. 우리는 코드 생성에 쓸 거지만, 추론 모델에 넘겨 아이디어의 허점을 찾거나(더 깊이!), 백서를 뽑아내거나, 1만 단어짜리 지원 문서를 받아내도 좋다.\n\n### Step 2: Planning\n\n`spec.md`를 추론 특화 모델(`o1*`, `o3*`, `r1`)에 보낸다.\n\n(다음은 TDD용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(다음은 TDD 미적용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n프롬프트 계획이 출력된다. `prompt_plan.md`로 저장한다.\n\n이어 체크리스트용 `todo.md`를 만든다.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n코드 생성 도구가 `todo.md`를 체크해 가며 상태를 유지하기 편하다.\n\n#### 플랜 완성! 야호!\n\n이제 탄탄한 계획과 문서가 생겼으니 실행만 남았다.\n\n전체 과정은 **15분**이면 끝난다. 솔직히 말도 안 될 정도로 빠르다—Wild tbh.\n\n### Step 3: Execution\n\n도구는 정말 많다. 2단계를 잘 해두면 무엇으로 돌려도 성공 확률이 높다.\n\n[GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai) 등 써본 도구마다 잘 작동했다.\n\n나는 기본 웹 인터페이스의 Claude와 Aider 조합을 선호한다.\n\n### Claude\n\n[Claude.ai](https://claude.ai)와 페어 프로그래밍하듯 프롬프트(prompt)를 하나씩 넣는다. 왔다 갔다가 번거롭지만 대체로 잘 굴러간다.\n\n초기 보일러플레이트와 툴 셋업은 내가 직접 한다. Claude가 React 코드만 던지는 버릇이 있어 원하는 언어·스타일·툴 체계를 먼저 잡아두면 편하다.\n\n막히면 [repomix](https://github.com/yamadashy/repomix)로 코드베이스 전체를 넘겨 디버깅한다(뒤에서 다시 다룬다).\n\n워크플로:\n\n- 리포지토리 셋업(보일러플레이트, `uv init`, `cargo init` 등)\n- Claude에 프롬프트 붙여넣기\n- Claude가 준 코드를 IDE에 붙여넣기\n- 코드·테스트 실행\n- …\n- 잘 되면 다음 프롬프트\n- 안 되면 repomix로 디버깅\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/)는 재미있고 묘하다. 2단계에서 뽑은 프롬프트 계획과 궁합이 특히 좋다.\n\n워크플로는 거의 같지만, 프롬프트를 Aider에 붙여넣는다는 점만 다르다.\n\nAider가 “Just do it” 해주고 나는 [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)나 두드린다.\n\n> 참고: Aider는 [LLM 리더보드](https://aider.chat/docs/leaderboards/)에서 새 모델의 코드 생성 성능을 깔끔하게 벤치마킹한다. 새 모델 효율을 보기 좋은 자료다.\n\n테스트까지 자동으로 돌려주니 손이 훨씬 덜 간다.\n\n워크플로:\n\n- 리포지토리 셋업(보일러플레이트, `uv init`, `cargo init` 등)\n- Aider 실행\n- 프롬프트 붙여넣기\n- watch aider dance ♪┏(・o･)┛♪\n- Aider가 테스트를 돌리거나 직접 앱을 실행해 확인\n- 잘 되면 다음 프롬프트\n- 안 되면 Q&A로 수정\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\n이 방식으로 스크립트, Expo 앱, Rust CLI 등 엄청 많이 만들었다. 언어와 상황 가리지 않고 잘 된다.\n\n작든 크든 미뤄둔 프로젝트가 있다면 한번 써보라. 짧은 시간에 놀랄 만큼 진도가 나간다.\n\n‘해킹 to-do 리스트’가, 다 만들어 버린 덕에 텅 비었다. 영화 보면서 새 언어·툴을 만지니 프로그래밍 시야가 쑥 넓어진다.\n\n## Non-greenfield: 점진적 개선\n\n때로는 그린필드가 아니라 이미 있는 코드베이스를 조금씩 다듬어야 한다.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"이건 브라운필드다. 할아버지 카메라에 담긴 1960년대 우간다 어딘가\" >}}\n\n이 경우 방법이 살짝 다르다. 프로젝트 전체가 아니라 작업 단위로 계획한다.\n\n### Get context\n\nAI 개발자마다 도구는 다르지만, 핵심은 소스 코드를 잘 추려 LLM에 효율적으로 집어넣는 것이다.\n\n나는 [repomix](https://github.com/yamadashy/repomix)를 쓴다. 전역 `~/.config/mise/config.toml`에 작업 모음을 정의해 두었다([mise 규칙](https://mise.jdx.dev/)).\n\nLLM 작업 목록:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt`로 컨텍스트를 추출한다. 토큰이 초과되면 관련 없는 부분을 제외하도록 명령을 수정한다.\n\n> `mise`의 좋은 점은 작업을 해당 디렉터리의 `.mise.toml`에서 재정의·오버라이드할 수 있다는 것. 코드 덤프 도구를 바꿔도 `output.txt`만 나오면 LLM 작업을 그대로 쓸 수 있다. 코드베이스 구조가 제각각이라 자주 `repomix` 단계를 덮어쓰거나 더 효율적인 툴로 갈아탄다.\n\n`output.txt`가 생기면 [LLM](https://github.com/simonw/LLM) 명령에 파이프로 넘겨 변환하고 결과를 마크다운으로 저장한다.\n\n결국 mise 작업은  \n`cat output.txt | LLM -t readme-gen > README.md`  \n또는  \n`cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`  \n같은 꼴이다. `LLM` 명령이 모델 선택, 키 관리, 프롬프트 템플릿을 맡아준다.\n\n예컨대 테스트 커버리지를 빠르게 보강해야 할 때:\n\n#### Claude\n\n- 코드 디렉터리로 이동  \n- `mise run LLM:generate_missing_tests` 실행  \n- 생성된 `missing-tests.md` 확인  \n- `mise run LLM:copy_buffer_bundle`로 컨텍스트를 클립보드에 복사  \n- Claude에 붙여넣고 첫 번째 ‘누락 테스트’ 이슈부터 해결  \n- Claude가 준 코드를 IDE에 붙여넣기  \n- …  \n- 테스트 실행  \n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- 코드 디렉터리로 이동  \n- 새 브랜치에서 Aider 실행  \n- `mise run LLM:generate_missing_tests` 실행  \n- `missing-tests.md` 확인  \n- 첫 번째 ‘누락 테스트’ 이슈를 Aider에 붙여넣기  \n- watch aider dance ♪┏(・o･)┛♪  \n- …  \n- 테스트 실행  \n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧  \n\n큰 코드베이스도 이런 식으로 작은 단위로 꾸준히 개선할 수 있다.\n\n### Prompt magic\n\n이런 퀵 해킹은 프로젝트를 더 탄탄하게 만든다. 빠르고 효과적이다.\n\n기존 코드에 쓰는 내 단골 프롬프트 몇 가지:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(실제 이슈 등록은 아직 자동화 못 함!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n이 프롬프트들은 좀 구닥다리(“boomer prompts”랄까). 더 좋은 아이디어가 있으면 꼭 알려 달라.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n이 과정을 설명할 때면 “정신 바짝 차리고 진행 상황을 추적해야 한다, 안 그러면 금방 스스로를 앞질러 버린다”고 말한다.\n\n나는 ‘over my skis’(스키가 너무 앞으로 나가 균형을 잃는 상황)라는 표현을 자주 쓴다. 부드러운 파우더를 타다 갑자기 “뭐야?!” 하고 절벽에서 구르는 느낌.\n\n**Planning 단계**(그린필드 과정 참조)를 두면 통제력이 생긴다. 문서를 보고 재확인할 수 있다. 특히 Aider처럼 와일드하게 코딩할 때는 테스트가 큰 도움이 된다.\n\n그래도 가끔은 over my skis 상태가 온다. 잠깐 쉬거나 산책하면 머리가 리셋된다. 문제 해결 과정 자체는 평범하지만 속도가 광속이라 그렇다.\n\n> 우리는 종종 LLM에게 엉뚱한 걸 코드에 끼워 넣으라고 시킨다. 예컨대 ‘lore 파일을 만들고 UI에서 참조하라’고 요구하면 파이썬 CLI 툴에도 lore와 글리치 UI가 생겨난다. 하늘이 한계다.\n\n## I am so lonely (｡•́︿•̀｡)\n\n단점 하나: 대부분 **싱글 플레이 모드**다. 팀으로 쓰기 어렵다. 봇끼리 충돌하고, 머지는 끔찍하고, 컨텍스트는 복잡하다.\n\nLLM 코딩을 멀티플레이 게임으로 바꿔 줄 누군가가 절실하다. 솔로 해커 경험이 아니라 다 같이 즐길 수 있도록. 기회가 어마어마하다.\n\n**어서 일해라!** (GET TO WORK!)\n\n## ⴵ Time ⴵ\n\n코드 생성 덕분에 한 사람이 찍어내는 코드 양이 폭증했다. 반면 LLM이 토큰을 태우는 동안 ‘대기 시간’도 길어졌다.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"이 화면, 어제 본 것처럼 생생하다\" >}}\n\n그래서 기다리는 시간에는:\n\n- 다른 프로젝트 브레인스토밍  \n- LP 꺼내 음악 듣기  \n- Cookie Clicker 두드리기  \n- 친구·로봇과 수다  \n\n이렇게 해킹할 수 있다니 멋지다. Hack Hack Hack. 이렇게 생산적이었던 적이 또 있었나?\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\n주변엔 “LLM 별로야, 다 못 해”라는 친구도 많다. 비판적 시각은 중요하다. 나도 전력 소모와 환경 영향을 걱정한다. 하지만… 코드는 흘러야지. 하아.\n\n더 알고 싶지만 ‘사이보그 프로그래머’까지는 싫다면 Ethan Mollick의 책 [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)을 권한다.\n\n기술 낙관·자본 예찬이 아닌 균형 잡힌 시선으로 LLM 활용법을 설명한다. 읽은 친구들과 깊은 대화를 나눌 수 있었다. 강추!\n\n회의적이지만 조금이라도 궁금하다면 언제든 연락하라. LLM을 어떻게 쓰는지 보여주고, 함께 뭔가 만들어 볼 수도 있다.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CRITIQUE FEEDBACK\n[Severity legend]  \nCritical = Alters meaning or leaves out content.  \nMajor    = Meaning mostly intact but nuance/important detail lost, or Korean sounds plainly unnatural.  \nModerate = Minor nuance/flow/consistency problems.  \nMinor/Stylistic = Pure polish.\n\n──────────────────────────────  \n1. Critical ‑ Meaning/Content Errors  \n──────────────────────────────  \n1-A. Omitted purposes of the spec  \n• Source: “ … to generate a white paper, or to generate a business model.”  \n• Kor: “백서를 뽑아내거나, 1만 단어짜리 지원 문서를 받아내도 … ” → “business model” 생략.  \n  Fix: “백서를 만들거나 비즈니스 모델을 뽑아내거나 …”\n\n1-B. Sentence fully dropped (Results section)  \n• Source: “I keep thinking of new things and knocking them out while watching a movie or something.”  \n• Missing in Kor.  \n  Fix: 추가: “영화를 보면서도 새 아이디어가 떠오르면 바로 만들어 버린다.”\n\n1-C. Sentence dropped (Non-greenfield)  \n• Source: “I have found that I can do any sized tasks with this method.”  \n• Missing in Kor.  \n  Fix: “이 방식으로 규모에 관계없이 어떤 작업도 해낼 수 있었다.”\n\n1-D. “Raw claude” mis-rendered  \n• Source: “I, however, prefer **raw** claude and aider” (의미: 래퍼 없이 ‘날것’ API/UI).  \n• Kor: “기본 웹 인터페이스의 Claude” → ‘raw’ = ‘웹 인터페이스’ 아님.  \n  Fix: “별도 래퍼 없이 ‘생(生) CLAUDE’(API 직접/기본 UI)와 Aider를 선호한다.”\n\n1-E. “Over my skis” imagery truncated  \n• Source includes vivid cliff-falling sentence (“WHAT THE **** … fall off a cliff”).  \n• Kor 요약으로 끝. 강렬한 유머·놀람 감정 유실.  \n  Fix: 전체 비유 살려 추가.\n\n1-F. Misc. small omissions  \n– “It resonates with me. I don’t know why.”  \n– “Generate a business model” (covered 1-A).  \nEnsure 완전한 반영.\n\n──────────────────────────────  \n2. Major ‑ Nuance / Idiom / Register  \n──────────────────────────────  \n2-A. “양쪽으로 살짝씩 튜닝이 다르다”  \n  • 영어 “tweaks in either direction” → 의미는 ‘사람마다 조금씩 다르다’.  \n  • 현재 표현은 방향이 두 개뿐인 듯 어색.  \n  • 제안: “저마다 약간씩 다르게 튜닝한다.”\n\n2-B. “Cookie Clicker나 두드린다”  \n  • 한국어 관용 맞지 않음.  \n  • 제안: “Cookie Clicker를 두드리며 논다” or “Cookie Clicker나 하면서 논다”.\n\n2-C. “리포지토리 셋업”  \n  • IT 용례 있지만 연속 사용 잦음. 한두 번은 “리포지토리를 초기화한다” 등으로 자연화.\n\n2-D. “기존(레거시·모던 포함) 코드”  \n  • 원문 “legacy modern code” 는 자조적 표현. 현재 번역은 정보 전달만 있고 익살 빠짐.  \n  • 가능: “레거시(?) ‘모던’ 코드” 같이 따옴표로 뉘앙스 살리기.\n\n2-E. 톤 불균일  \n  • 원문은 대체로 속어·친구에게 말하듯. 몇몇 구간(“왕창 잡아먹는 함정도 수두룩하다” vs “탄탄한 계획·문서를 제공하고”) 사이 어투 급격히 바뀜.  \n  • 제안: 반말/친근어 vs 서술형 존댓말 중 하나로 통일, 혹은 반말 체 유지.\n\n──────────────────────────────  \n3. Grammar / Flow Issues (Moderate)  \n──────────────────────────────  \n3-A. 겹말·군더더기  \n  • “이 경우 방법이 살짝 다르다.” → “방법이 조금 다르다.”  \n3-B. 불필요한 영어 괄호·역슬래시  \n  • “¯\\\\_(ツ)_/¯” 역-이스케이프 제거.  \n3-C. 과도한  ·  기호  \n  • “―” “—” 혼용, markdown 일관성 필요.\n\n──────────────────────────────  \n4. Terminology Consistency  \n──────────────────────────────  \n4-A. Codegen / 코드 생성 혼용   → 최초 괄호 병기 뒤 일관된 한국어 사용 권장.  \n4-B. “Prompt”는 대부분 영문 그대로 두었는데 몇 군데 ‘프롬프트’ 사용. 통일.\n\n──────────────────────────────  \n5. Minor / Stylistic  \n──────────────────────────────  \n5-A. 날짜 표현 ↔ “2016-05-14” vs “5/14/2016” 통일.  \n5-B. “Wild tbh.” 그대로 유지했으나 한국어 독자 이해 어렵다. 주해 또는 “솔직히 미친 속도다 (wild tbh).”  \n5-C. 밑줄/기울임 기호: 원문 형식 유지 필요.\n\n──────────────────────────────  \n6. Machine-like residue  \n──────────────────────────────  \n6-A. 영어 문장을 그대로 남겨 놓은 Prompt 영역은 의도된 것이나, 본문 내 “review the results … small enough” 한 줄 그대로 남아있음 → 번역 누락 의심.  \n6-B. 장황한 괄호 삽입 스타일이 GPT 번역 느낌. 일부 간결화 권장.\n\n──────────────────────────────  \nOverall Recommendations  \n──────────────────────────────  \n• 빠진 문장·의미(1-A~1-F) 반드시 추가.  \n• ‘raw’, ‘legacy modern code’, ‘over my skis’ 등 농담성 키워드는 직역+주해로 유머 살리기.  \n• 구어체 톤을 일정하게 유지하되 군더더기·어색한 직역(2-A, 2-B 등) 다듬기.  \n• 영어 전문어는 첫 등장 시 병기 후 한국어 일관성 유지.  \n• Prompt 본문 외의 영어 잔여 문장은 모두 번역.  \n• 자잘한 문장부호·형식 통일로 가독성 개선.\n\n이 리스트를 반영하면 “영어 원서인 줄 몰랐다”는 말이 나올 만큼 자연스럽고 충실한 번역이 될 것입니다.\n\nPlease address ALL issues identified in the critique and provide an improved translation.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr: 스펙을 브레인스토밍한 뒤 → ‘계획을 위한 계획’을 세우고 → LLM 코드 생성(codegen)으로 실행한다. 각 단계는 독립 루프. 그리고 매직! ✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM 덕분에 작은 제품을 진짜 많이 만들었다. 재미있고 유용하다. 하지만 시간을 왕창 잡아먹는 함정도 수두룩하다. 얼마 전 친구가 “LLM으로 어떻게 소프트웨어를 짜?”라고 묻길래 “이야, 시간 좀 있어?” 싶어 이 글을 쓴다.\n\n(p.s. AI가 싫다면 ― 맨 끝으로 스크롤!)\n\n개발자 친구들과 이야기해 보면 저마다 약간씩 다르게 튜닝한다.\n\n아래 워크플로는 내 경험, 친구들과의 대화(고마워요 [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)), 그리고 인터넷의 악명 높은 구석구석([Hacker News](https://news.ycombinator.com/), [X/Twitter](https://twitter.com) 같은)에서 떠도는 베스트 프랙티스를 뒤섞어 만들었다.\n\n지금은 **엄청** 잘 통하지만 두 주 뒤엔 안 통하거나 두 배로 잘 통할 수도 있다. ¯\\_(ツ)_/¯\n\n## 시작!\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"AI가 만든 이미지는 늘 수상하다. 저글로(Juggalo) 광대 분장의 코딩 로봇 천사에게 인사!\" >}}\n\n개발 방식은 여럿이지만 내 경우는 대체로 둘이다.\n\n- 그린필드(Greenfield) 코드\n- 레거시(?) ‘모던’ 코드\n\n두 갈래 모두의 과정을 차례로 소개한다.\n\n## Greenfield\n\n그린필드 개발에는 다음 프로세스가 잘 맞는다. 탄탄한 계획과 문서를 갖추고, 작은 단계로 쉽게 실행할 수 있다.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"오른쪽에 진짜 그린필드가 있다. Leica Q, 2016-05-14\" >}}\n\n### Step 1: 아이디어 다듬기\n\n대화형 LLM(ChatGPT 4o / o3)을 이용해 아이디어를 정제한다.\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\n아이디어가 충분히 정리됐다고 느끼면:\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\n꽤 괜찮은 스펙이 나온다. 리포지토리에 `spec.md`로 저장한다.\n\n> 이 스펙은 여러 용도로 쓸 수 있다. 우리는 코드 생성에 쓸 거지만, 추론 모델에 넘겨 아이디어의 허점을 찾거나(더 깊이!), 백서를 만들거나 비즈니스 모델을 뽑아내거나, 1만 단어짜리 지원 문서를 받아내도 좋다.\n\n### Step 2: Planning\n\n`spec.md`를 추론 특화 모델(`o1*`, `o3*`, `r1`)에 보낸다.\n\n(아래는 TDD용 프롬프트)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(TDD를 안 쓸 때)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n프롬프트 계획이 출력된다. `prompt_plan.md`로 저장한다.\n\n이어 체크리스트용 `todo.md`를 만든다.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n코드 생성 도구가 `todo.md`를 체크해 가며 상태를 유지하기 좋다.\n\n#### 플랜 완성! 야호!\n\n이제 탄탄한 계획과 문서를 손에 넣었으니 실행만 남았다.\n\n전체 과정은 **15분**이면 끝난다. 솔직히 미친 속도다 (wild tbh).\n\n### Step 3: Execution\n\n도구는 정말 많다. 2단계를 잘 해두면 무엇으로 돌려도 성공 확률이 높다.\n\n[GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai) 등 써본 도구마다 잘 작동했다.\n\n나는 별도 래퍼 없이 **생(生) Claude**(API 직통 또는 기본 UI)와 Aider 조합을 선호한다.\n\n### Claude\n\n[Claude.ai](https://claude.ai)와 페어 프로그래밍하듯 프롬프트를 하나씩 넣는다. 왔다 갔다가 번거롭지만 대체로 잘 굴러간다.\n\n초기 보일러플레이트와 툴 셋업은 내가 직접 한다. Claude가 React 코드만 던지는 버릇이 있어 원하는 언어·스타일·툴 체계를 먼저 잡아두면 편하다.\n\n막히면 [repomix](https://github.com/yamadashy/repomix)로 코드베이스 전체를 넘겨 디버깅한다(뒤에서 다시 다룬다).\n\n워크플로:\n\n- 리포지토리를 초기화한다(보일러플레이트, `uv init`, `cargo init` 등)\n- Claude에 프롬프트 붙여넣기\n- Claude가 준 코드를 IDE에 붙여넣기\n- 코드·테스트 실행\n- …\n- 잘 되면 다음 프롬프트\n- 안 되면 repomix로 디버깅\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/)는 재미있고 묘하다. 2단계에서 뽑은 프롬프트 계획과 궁합이 특히 좋다.\n\n워크플로는 거의 같지만, 프롬프트를 Aider에 붙여넣는다는 점만 다르다.\n\nAider가 “Just do it” 해주고 나는 [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)를 두드리며 논다.\n\n> 참고: Aider는 [LLM 리더보드](https://aider.chat/docs/leaderboards/)에서 새 모델의 코드 생성 성능을 깔끔하게 벤치마킹한다. 새 모델 효율을 보기 좋은 자료다.\n\n테스트까지 자동으로 돌려주니 손이 훨씬 덜 간다.\n\n워크플로:\n\n- 리포지토리를 초기화한다(보일러플레이트, `uv init`, `cargo init` 등)\n- Aider 실행\n- 프롬프트 붙여넣기\n- watch aider dance ♪┏(・o･)┛♪\n- Aider가 테스트를 돌리거나 직접 앱을 실행해 확인\n- 잘 되면 다음 프롬프트\n- 안 되면 Q&A로 수정\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\n이 방식으로 스크립트, Expo 앱, Rust CLI 등 정말 많~이 만들었다. 언어와 상황 가리지 않고 잘 된다.\n\n영화를 보면서도 새로운 아이디어가 떠오르면 바로 만들어 버린다. 작은 프로젝트든 큰 프로젝트든 미뤄둔 게 있다면 한번 써보라. 짧은 시간에 놀랄 만큼 진도가 나간다.\n\n내 ‘해킹 to-do 리스트’는, 다 만들어 버린 덕에 텅 비었다. 새 아이디어만 떠오르면 바로 구현하고 있다. 덕분에 오랜만에 새로운 언어와 툴을 만지며 프로그래밍 시야가 확 넓어졌다.\n\n## Non-greenfield: 점진적 개선\n\n때로는 그린필드가 아니라 이미 있는 코드베이스를 조금씩 다듬어야 한다.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"이건 브라운필드다. 할아버지 카메라에 담긴 1960년대 우간다 어딘가\" >}}\n\n이 경우 방법이 조금 다르다. 프로젝트 전체가 아니라 작업 단위로 계획한다.\n\n### Get context\n\nAI 개발자마다 도구는 다르지만, 핵심은 소스 코드를 잘 추려 LLM에 효율적으로 집어넣는 것이다.\n\n나는 [repomix](https://github.com/yamadashy/repomix)를 쓴다. 전역 `~/.config/mise/config.toml`에 작업 모음을 정의해 두었다([mise 규칙](https://mise.jdx.dev/)).\n\nLLM 작업 목록:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt`로 컨텍스트를 추출한다. 토큰이 초과되면 관련 없는 부분을 제외하도록 명령을 수정한다.\n\n> `mise`의 좋은 점은 작업을 해당 디렉터리의 `.mise.toml`에서 재정의·오버라이드할 수 있다는 것. 코드 덤프 도구를 바꿔도 `output.txt`만 나오면 LLM 작업을 그대로 쓸 수 있다. 코드베이스 구조가 제각각이라 자주 `repomix` 단계를 덮어쓰거나 더 효율적인 툴로 갈아탄다.\n\n`output.txt`가 생기면 [LLM](https://github.com/simonw/LLM) 명령에 파이프로 넘겨 변환하고 결과를 마크다운으로 저장한다.\n\n결국 mise 작업은  \n`cat output.txt | LLM -t readme-gen > README.md`  \n또는  \n`cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`  \n같은 꼴이다. `LLM` 명령이 모델 선택, 키 관리, 프롬프트 템플릿을 맡아준다.\n\n예컨대 테스트 커버리지를 빠르게 보강해야 할 때:\n\n#### Claude\n\n- 코드 디렉터리로 이동  \n- `mise run LLM:generate_missing_tests` 실행  \n- 생성된 `missing-tests.md` 확인  \n- `mise run LLM:copy_buffer_bundle`로 컨텍스트를 클립보드에 복사  \n- Claude에 붙여넣고 첫 번째 ‘누락 테스트’ 이슈부터 해결  \n- Claude가 준 코드를 IDE에 붙여넣기  \n- …  \n- 테스트 실행  \n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- 코드 디렉터리로 이동  \n- 새 브랜치에서 Aider 실행  \n- `mise run LLM:generate_missing_tests` 실행  \n- `missing-tests.md` 확인  \n- 첫 번째 ‘누락 테스트’ 이슈를 Aider에 붙여넣기  \n- watch aider dance ♪┏(・o･)┛♪  \n- …  \n- 테스트 실행  \n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧  \n\n이 방식으로 규모와 상관없이 어떤 작업도 해낼 수 있었다.\n\n### Prompt magic\n\n이런 퀵 해킹은 프로젝트를 더 탄탄하게 만든다. 빠르고 효과적이다.\n\n기존 코드에 쓰는 내 단골 프롬프트 몇 가지:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(실제 이슈 등록은 아직 자동화 못 함!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n이 프롬프트들은 좀 구닥다리(“boomer prompts”랄까). 더 좋은 아이디어가 있으면 꼭 알려 달라.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n이 과정을 친구들에게 설명할 때면 “정신 바짝 차리고 진행 상황을 추적해야 한다, 안 그러면 금방 스스로를 앞질러 버린다”고 말한다.\n\n나는 ‘over my skis’(스키가 너무 앞으로 나가 균형을 잃는 상황)라는 표현을 자주 쓴다. 왜인지는 모르지만 꽂힌다. 부드러운 파우더를 가르며 달리다가, 어느 순간 “WHAT THE FUCK IS GOING ON!” 하고 소리치며 절벽 아래로 곤두박질치는 그런 느낌이다.\n\n**Planning 단계**(그린필드 과정 참조)를 두면 통제력이 생긴다. 문서를 보고 재확인할 수 있다. 특히 Aider처럼 와일드하게 코딩할 때는 테스트가 큰 도움이 된다.\n\n그래도 가끔은 여전히 **over my skis** 상태가 온다. 잠깐 쉬거나 산책하면 머리가 리셋된다. 문제 해결 과정 자체는 평범하지만 속도가 광속이라 그렇다.\n\n> 우리는 종종 LLM에게 엉뚱한 걸 코드에 끼워 넣으라고 시킨다. 예컨대 ‘lore 파일을 만들고 UI에서 참조하라’고 요구하면 파이썬 CLI 툴에도 lore와 글리치 UI가 생겨난다. 하늘이 한계다.\n\n## I am so lonely (｡•́︿•̀｡)\n\n단점 하나: 대부분 **싱글 플레이 모드**다. 팀으로 쓰기 어렵다. 봇끼리 충돌하고, 머지는 끔찍하고, 컨텍스트는 복잡하다.\n\nLLM 코딩을 멀티플레이 게임으로 바꿔 줄 누군가가 절실하다. 솔로 해커 경험이 아니라 다 같이 즐길 수 있도록. 기회가 어마어마하다.\n\n**어서 일해라!**\n\n## ⴵ Time ⴵ\n\n코드 생성 덕분에 한 사람이 찍어내는 코드 양이 폭증했다. 반면 LLM이 토큰을 태우는 동안 ‘대기 시간’도 길어졌다.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"이 화면, 어제 본 것처럼 생생하다\" >}}\n\n그래서 기다리는 시간에는:\n\n- 다른 프로젝트 브레인스토밍  \n- LP 꺼내 음악 듣기  \n- Cookie Clicker를 두드리며 놀기  \n- 친구·로봇과 수다  \n\n이렇게 해킹할 수 있다니 멋지다. Hack Hack Hack. 이렇게 생산적이었던 적이 또 있었나?\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\n주변엔 “LLM 별로야, 다 못 해”라는 친구도 많다. 비판적 시각은 중요하다. 나도 전력 소모와 환경 영향을 걱정한다. 하지만… 코드는 흘러야지. 하아.\n\n더 알고 싶지만 ‘사이보그 프로그래머’까지는 싫다면 Ethan Mollick의 책 [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)을 권한다.\n\n기술 낙관·자본 예찬이 아닌 균형 잡힌 시선으로 LLM 활용법을 설명한다. 읽은 친구들과 깊은 대화를 나눌 수 있었다. 강추!\n\n회의적이지만 조금이라도 궁금하다면 언제든 연락하라. LLM을 어떻게 쓰는지 보여주고, 함께 뭔가 만들어 볼 수도 있다.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "usage": {
        "prompt_tokens": 10631,
        "completion_tokens": 5285,
        "total_tokens": 15916
      }
    },
    "frontmatter": {
      "model": "o3",
      "target_language": "korean",
      "system_prompt": "You are a professional translator. Translate the following frontmatter fields to korean.\nEach field is in the format \"field_name: content\". Translate ONLY the content, not the field names.\nReturn the translated content in the exact same format, preserving all field names.",
      "user_prompt": "title: My LLM codegen workflow atm\n\ndescription: A detailed walkthrough of my current workflow for using LLms to build software, from brainstorming through planning and execution.\n\n",
      "response": "title: 현재 나의 LLM 코드생성 워크플로\ndescription: 브레인스토밍부터 계획 수립과 실행까지, LLM을 활용하여 소프트웨어를 개발할 때 내가 현재 사용하는 워크플로를 자세히 설명합니다.",
      "usage": {
        "prompt_tokens": 96,
        "completion_tokens": 393,
        "total_tokens": 489
      },
      "fields": [
        "title",
        "description"
      ]
    },
    "all_critiques": [
      "Translation Quality Audit  \n==========================  \nLegend  \n• Critical = alters meaning or omits information  \n• Major = makes text feel unnatural / hard to read, but meaning still guessable  \n• Minor = style, polish, readability  \n• Consist = terminology / register consistency  \n\n----------------------------------------------------------------  \nA. Accuracy ‑ Mistranslation / Omission / Addition  \n----------------------------------------------------------------  \n1. Critical – Large Blocks Left Un-translated  \n   a.  Entire explanatory paragraphs remain in English (e.g.  \n       – “> You can use this spec for a number of things …”  \n       – “> An aside: Aider does really great benchmarking …”  \n       – “> One thing really nice about `mise` is …”  \n       – Long quote under “We will often ask the LLM to include ridiculous things …”).  \n       → Fix: Translate these narrative sections; keep only literal prompts and command lines in English code-blocks.  \n\n2. Critical – Missing Example Command  \n   Original lists two commands (`readme-gen` and `code-review-gen`).  \n   Translation keeps only the first, so information is lost.  \n   → Fix: Add “… 또는 `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`”  \n\n3. Major – “Legacy modern code” Simplified to “레거시 코드”  \n   Nuance that the code is “modern-ish legacy” is lost.  \n   → Possible rendering: “현대식 레거시 코드(legacy-but-modern code)” or brief note.  \n\n4. Major – “plan a plan” / “plan the plan”  \n   Source plays with repetition. “계획도 계획한다” 정도의 재치가 사라짐.  \n   → Suggest: “사양을 브레인스토밍 → ‘계획까지도 계획’ → …”  \n\n5. Minor – “Wild tbh.” rendered “정말 빠르다.”  \n   Original nuance = “솔직히 미친 듯이 빠르다.”  \n   → “솔직히 말해 어처구니없을 정도로 빠르다.”  \n\n----------------------------------------------------------------  \nB. Tone / Register Consistency  \n----------------------------------------------------------------  \n1. Major – Irregular Switching Between English Slang & Korean  \n   Frequent untouched English words (“프롬프트 플랜”, “와일드”, “코드젠”, “cookie clicker” 등) makes prose feel machine-translated.  \n   → Decide a guideline: keep proper nouns, but translate general nouns/verbs (“프롬프트 계획”, “코드 생성” 등).  \n\n2. Major – Source’s Casual, Humorous Voice not Fully Reflected  \n   Examples: “oh boy. how much time do you have!”, “Yay. Plan!”, “GET TO WORK!”.  \n   Current Korean is more subdued.  \n   → Inject similar playful interjections (“와– 이거 길어질 텐데!”, “플랜 완성! 야호!”, “일하러 가자!!”).  \n\n----------------------------------------------------------------  \nC. Grammar / Fluency  \n----------------------------------------------------------------  \n1. Major – Repeated Omission of 주어/조사 Causing Choppiness  \n   ex) “이제 탄탄한 플랜과 문서가 생겼다. 실행만 남았다.” acceptable, but earlier lines like  \n   “소개할 과정을 보여주겠다.” ← awkward double verb.  \n   → Smooth with connectors: “두 경로 모두의 과정을 하나씩 소개하겠다.”  \n\n2. Minor – Abbreviations (“리포”, “보일러플레이트”)  \n   Tech readers will understand, yet choose one style or provide first-time expansion.  \n\n3. Minor – Anglicised “Codegen” / “코드젠”  \n   Use 한글 표기 consistently: either “코드 생성” or “코드젠” throughout.  \n\n----------------------------------------------------------------  \nD. Nuance / Idiom  \n----------------------------------------------------------------  \n1. Major – Skiing Metaphor “over my skis”  \n   Translator explained it, but loses self-deprecating tone of “I keep getting over my skis.”  \n   → Consider idiom like “자꾸 앞서가다 착착 꼬인다” or retain English with 설명: “over my skis(속도가 제어 불가 상태)”.  \n\n2. Minor – Caption Humour  \n   “Say hi to my juggalo coding robot angel!” rendered “내 저글로 코딩 로봇 엔젤에게 인사!”  \n   “저글로” should be “저글로” → “저글로(광대 분장)”. Add parenthetical for Korean readers unfamiliar with “Juggalo”.  \n\n----------------------------------------------------------------  \nE. Technical Terminology Consistency  \n----------------------------------------------------------------  \n1. Consist – “Greenfield” / “Brownfield”  \n   First kept in English(“그린필드”), later caption says “여긴 초록 들판이 아님.” Acceptable; keep consistent transliteration.  \n\n2. Consist – Model names (o1*, o3*) sometimes surrounded by backquotes, sometimes not.  \n   → Keep code font backquotes for all model identifiers.  \n\n----------------------------------------------------------------  \nF. Machine-like / Literal Spots  \n----------------------------------------------------------------  \n1. Major – Sentence “테스트 실행과 디버깅까지 자동으로 해줘서 더 손이 덜 간다.” repeated pattern of “~해서 ~다.” Many such sentences give MT flavour.  \n   → Vary structure, combine clauses.  \n\n2. Minor – Bulleted workflows copy original order but ignore natural Korean ellipsis; could be compressed.  \n\n----------------------------------------------------------------  \nG. Formatting / Punctuation  \n----------------------------------------------------------------  \n1. Minor – Underscore in opening line “_tl:dr; …_” retains Markdown italic correctly, but Korean headings have inconsistent spaces after “##”.  \n2. Minor – Backslash escaping “¯\\\\_(ツ)_/¯” doubled; in markdown only one backslash needed.  \n\n----------------------------------------------------------------  \nSuggested Global Fix Checklist  \n----------------------------------------------------------------  \n• Translate all remaining English narrative text; keep prompts/commands in code-blocks only.  \n• Restore omitted command example under mise section.  \n• Re-capture playful tone: use Korean interjections, rhetorical questions, onomatopoeia.  \n• Unify terminology: “코드 생성(코드젠)”, “프롬프트 계획”, “레거시-모던 코드”.  \n• Polish grammar: avoid fragmentary noun-phrases, add subjects and connectors.  \n• Provide short glosses for niche slang (“Juggalo”, “boomer prompt”).  \n• Proof-read for punctuation consistency and escape characters.  \n\nAddressing the above will bring the translation up to native-level readability while staying 100 % faithful to the source.",
      "────────────────────────────────────────────\n전체 총평\n────────────────────────────────────────────\n전반적으로 원문의 흐름과 정보 구조를 비교적 잘 살린 번역이지만, 세밀하게 보면 의미 왜곡·뉘앙스 손실·용어 혼란·문체 불안정·자잘한 누락/추가가 상당히 존재합니다. 특히 ①핵심 용어 번역 오류(“spec→사양”, “10k word→1만 자” 등), ②장난기·구어체 어투의 미묘한 뉘앙스 미반영, ③영어/한글 혼용과 용어 통일성, ④군데군데 기계 번역-스러움이 두드러집니다.  \n아래 항목별 + 심각도별로 모든 문제를 정리했으니, 한 항목씩 수정하면 원문 의도와 자연스러운 한국어를 모두 살릴 수 있습니다.\n\n────────────────────────────────────────────\n1. 의미 왜곡·오역·정보 손실  ―  Critical\n────────────────────────────────────────────\n1-1. 제목  \n ‑ “사양을 브레인스토밍”  \n   • ‘spec’은 한국 개발자 커뮤니티에서 거의 “스펙”으로 쓰임. “사양”은 HW specification 뉘앙스를 풍겨 전혀 다른 의미로 오해될 수 있음.  \n   → 스펙(사양) 둘 다 병기하거나 “스펙” 단독 사용.\n\n ‑ “‘계획까지도 계획’”  \n   • 원문 “plan a plan”의 의도는 ‘계획을 위한 계획을 세우다’라는 말장난. 현재 표현은 엉뚱하고 어색.  \n   → “계획을 위한 계획 세우기” 같이 직설적이면서 언어유희 살리기.\n\n1-2. 10k word → 1만 자  \n ‑ “1만 자짜리 지원 문서”  \n   • word → 단어인데 ‘자’(character)로 오역. 분량 감각이 5배 이상 차이.  \n   • “지원 문서”도 supporting document 의미를 놓침 → “참고 문서”, “보조 문서”.  \n   → “1만 단어 분량의 참고 문서”로 수정.\n\n1-3. “Legacy modern code”  \n ‑ “레거시-모던 코드(legacy-but-modern code)”  \n   • 원문은 ‘현대 스택이지만 이미 레거시가 된 코드’라는 자조적 뉘앙스. 괄호만 달아두면 전달 안 됨.  \n   → “(모던하지만 이미 레거시가 된 코드)” 등 설명을 풀어서 추가.\n\n1-4. “Discrete loops” → “개별 루프”  \n   • ‘discrete’는 ‘끊어진, 독립된’ 뉘앙스. “개별”만으로는 반복·루프성을 놓침.  \n   → “각 단계마다 독립적으로 도는 루프” 정도로 구체화.\n\n1-5. 브레인스토밍 단계 끝 설명  \n   • “꽤 괜찮고 단순한 스펙이 나온다” → ‘straightforward’엔 ‘명확하다’(복잡하지 않다) 뉘앙스가 더 강함.  \n   → “명료한 스펙” 등으로 보강.\n\n1-6. “robust planning and documentation approach”  \n   • “빡빡한 계획과 문서를 만들어 주고”  \n   • ‘빡빡하다’(tight) ↔ robust(견고한). 의미 살짝 어긋남.  \n   → “견고한 계획·문서” 등.\n\n1-7. “My hack to-do list is empty because I built everything.”  \n   • “해킹 To-Do 리스트가 텅 비었다.”  \n   • 이유(‘다 만들어버려서’)가 빠짐.  \n   → “해킹 할 일 리스트가, 다 만들어버린 덕에 텅 비었다.” 등.\n\n1-8. “brownfield” 대체 텍스트  \n   • “여기는 초록 들판이 아님”  \n   • 원문 alt: “a brown field” → 단순 묘사임. 농담 맥락이 사라짐.  \n   → “진짜 brownfield(갈색 들판)” 등.\n\n1-9. “over my skis” 은유  \n   • 번역문에서 ‘속도 제어 불가 상태’ 설명은 있으나, 원래 표현이 가진 ‘스스로 컨트롤 못해 곤두박질’ 뉘앙스가 부분적으로만 전달.  \n   → 부가 설명 한 줄 추가 “스키 속도가 몸을 앞질러 균형을 잃는 상황” 등.\n\n────────────────────────────────────────────\n2. 뉘앙스·문화적 참조 손실  ―  Major\n────────────────────────────────────────────\n2-1. “various terrible internet bad places”  \n ‑ 직역 “험난한 인터넷 나쁜 장소” → 어색하고 유머 사라짐.  \n   → “인터넷의 악명높은 구석구석(hacker news, 트위터 같은)에서 떠도는 베스트 프랙티스”.\n\n2-2. “cookie clicker”  \n ‑ 두 번 등장. 첫 번역 “cookie clicker를 두드린다”는 콘텍스트 OK. 두 번째 “한 손으로 돌리기”는 원문 “play cookie clicker”의 ‘킬링타임’ 느낌이 희미.  \n   → “쿠키 클릭커를 두드리며 시간 때우기” 등으로 일관.\n\n2-3. 제스처 표현  \n ‑ 원문 곳곳에 “rinse repeat ✩₊˚…”, “watch aider dance ♪┏(・o･)┛♪” 등 톤. 번역본은 일부 살렸으나 어감 조정 부족.  \n   → 같은 ASCII art 그대로 두되 한글 주석 한 줄 추가(“다시 반복 ✩₊˚…”)로 리듬 유지.\n\n────────────────────────────────────────────\n3. 용어 선택·일관성 ― Major\n────────────────────────────────────────────\n3-1. spec / 스펙 / 사양  \n ‑ “사양”, “spec”, “spec.md” 혼재.  \n   → 전 문서 ‘스펙(spec)’으로 통일하고 최초 등장에만 (사양) 부연.\n\n3-2. repo / 리포지토리 / 리포  \n ‑ “리포지토리”, “리포”, “리포 세팅” 섞임.  \n   → “리포지토리(Repo)”로 고정하거나 필요 시 줄임말 병기.\n\n3-3. codegen / 코드 생성  \n ‑ 대부분 “코드 생성”이지만 중간에 “codegen 툴” 남아있음.  \n   → “코드 생성(codegen)” 등으로 일관.\n\n3-4. 실행 단계 용어  \n ‑ “Execution” 절에서 “실행”과 “실행 도구” 혼재.  \n   → “실행(Execution) 단계”, “실행 도구(Execution tool)” 등 병렬성 유지.\n\n────────────────────────────────────────────\n4. 문체·톤·구어체 유지 ― Major\n────────────────────────────────────────────\n4-1. 원문은 장난스럽고 1인칭 구어체(친근) → 번역은 때때로 공식·설명조.  \n   예) “Wild tbh” → “솔직히 말해 어처구니없을 정도로 빠르다.” (OK)  \n   하지만 “oh boy. how much time do you have!” → “와— 할 얘기 끝도 없는데!”  \n   • ‘와—’ 음성어+긴 대시가 어색.  \n   → “와, 시간 좀 있어? 할 말이 산더미야!” 등.\n\n4-2. 원문 괄호 농담  \n   • “(more about that later)” 등. 번역에서 일부 생략 또는 톤 완화.  \n   → “(이건 뒤에서 다시 자세히 다룸)”처럼 농담 톤 유지.\n\n────────────────────────────────────────────\n5. 문법·어법·표현 자연성 ― Moderate\n────────────────────────────────────────────\n5-1. 콤마 남발/영문식 쉼표  \n   • “재밌고, 쓸모도 많다.” → 한국어에선 동격 나열이므로 콤마 생략.  \n   • 여러 곳에서 “, 등” 반복.\n\n5-2. 불필요한 한글 따옴표 종류 혼재 (‘ “ ” “ ’ 등)  \n   → 전부 “ ” 또는 ‘ ’로 통일.\n\n5-3. 외래어 표기  \n   • “세팅”보단 “셋업”, “보일러플레이트” → ‘보일러플레이트 코드’ 등 통합.\n\n5-4. 날짜 표기 “2016.05.14”  \n   • 원텍스트 미국식(May 14, 2016). 큰 문제는 아니지만 사진 캡션이니 “2016-05-14” 또는 “2016년 5월 14일” 권장.\n\n────────────────────────────────────────────\n6. 누락·불필요한 추가 ― Moderate\n────────────────────────────────────────────\n6-1. 원문 “This is working well NOW, it will probably not work in 2 weeks, or it will work twice as well.” 의 NOW 대문자 강조.  \n   • 번역은 “지금은 **잘** 돌아가지만” 강조 심도 낮음. “지금은 **엄청** 잘 돌아가지만” 정도로 과장 어투 유지 가능.\n\n6-2. 원문 여러 곳의 “GET TO WORK!” 같은 대문자 강세는 괄호로 묻힘.  \n   → “얼른 일하라구!(GET TO WORK!)” 등 감탄 박력 유지.\n\n6-3. “(I need to automate the actual issue posting!)”  \n   • 번역에 ‘!’ 빠짐. 미미하지만 톤 다운.  \n   → 원문대로 느낌표 유지.\n\n────────────────────────────────────────────\n7. 기계 번역·직역 티나는 부분 ― Minor\n────────────────────────────────────────────\n7-1. “이 워크플로우는 순정 Claude와 Aider 조합을 선호한다.”  \n   • 주어 뒤틀림 + ‘순정’ 어색. → “나는 Claude ‘순정’ 웹 인터페이스와 Aider 조합을 선호한다.”\n\n7-2. “It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.”  \n   → “지금까지 써본 도구마다 잘 작동했고, 다른 코드 생성 툴에서도 잘 돌아갈 거라 생각한다.” 정도로 매끈하게.\n\n7-3. “Testing is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.”  \n   • 번역은 문장 길이 그대로 두어 장황. → 두 문장으로 끊어 자연스럽게.\n\n────────────────────────────────────────────\n8. 형식·마크다운·프롬프트 처리 ― Minor\n────────────────────────────────────────────\n8-1. 원문 코드블록 내부 영어를 그대로 둔 것은 OK.  \n   다만 프롬프트 전후 해설은 한글이므로, 코드블록 직후 “(아래 프롬프트는 영어 원문 그대로 인용)” 같은 안내 넣으면 독자 혼란 ↓.\n\n8-2. ‘르포’→‘리포’, ‘Code’ 등 번역 내부 영어가 Title Case/소문자 뒤섞임.  \n   → 마크다운 헤더·링크 텍스트 스타일 통일.\n\n────────────────────────────────────────────\n9. 개선 후 예시(제목 부분)\n────────────────────────────────────────────\n원 번역:  \n_tl:dr; 사양을 브레인스토밍 → ‘계획까지도 계획’ → LLM 코드 생성으로 실행. 개별 루프. 그리고 매직._\n\n수정 제안:  \n_tl;dr: 스펙을 브레인스토밍하고 → ‘계획을 위한 계획’을 세운 뒤 → LLM 코드 생성으로 실행한다. 단계별로 독립된 루프를 돌리고, 그다음은 매직! ✩₊˚.⋆☾⋆⁺₊✧_\n\n────────────────────────────────────────────\n요약 체크리스트\n────────────────────────────────────────────\n[ ] spec→스펙, repo 등 핵심 용어 일관화  \n[ ] 10k word 오역 수정(단어 vs 자)  \n[ ] 제목·표제어 장난기 살려 재번역  \n[ ] ‘Legacy modern code’, ‘discrete loops’ 등 의미 재정비  \n[ ] 구어체·농담 톤 복원(대문자/감탄/ASCII art)  \n[ ] 문장부호·띄어쓰기 한국어 맞춤법 재점검  \n[ ] 반복되는 영어·한글 혼용 정돈  \n[ ] 누락 및 강세 표현 보강(예: NOW, GET TO WORK!)  \n\n위 항목을 반영하면 원문 톤을 유지하면서도 자연스럽고 정확한 한국어 번역으로 개선될 것입니다.",
      "전체적으로 충실히 옮기려 노력한 흔적이 보이지만, 세부·뉘앙스·문체 측면에서 개선할 부분이 상당히 많습니다. 아래는 (1) 의미 왜곡·누락 등 “치명적(Critical)” 문제, (2) 의미‧뉘앙스 손실·가독성 저하 같은 “주요(Major)” 문제, (3) 자연스러움·통일성·맞춤법 등 “경미(Minor / Stylistic)” 문제로 분류한 상세 지적사항과 개선 제안입니다.\n\n--------------------------------------------------\nA. Critical – 의미가 바뀌거나 내용이 빠진 부분\n--------------------------------------------------\n1. “Legacy modern code” 오역  \n   • 번역: “(모던하지만 이미 레거시가 된) 레거시 코드”  \n   • 문제: 원문은 “그린필드 vs ‘레거시 혹은 모던’ 코드”라는 대비가 아니라, “Greenfield”와 “Legacy/modern(기존) code” 두 갈래라는 의미다. “이미 레거시가 된 모던 코드”라고 하면 ‘모순적 표현’이 사라진다.  \n   • 수정 제안: “기존(레거시) 코드” 정도로 간결하게 옮기고 괄호 설명은 빼거나 “이미 존재하는 현대적 코드까지 포함” 등으로 보강.\n\n2. 순서‧논리적 구조 변경  \n   • Aider 워크플로우 부분에서 ‘rinse repeat’ 항목이 중간으로 당겨져 리스트 구조가 달라짐. 단계별 과정(실행→검증→문제 시 Q&A→반복)이 흐트러져 독자가 실제 절차를 오해할 수 있다.  \n   • 수정 제안: 원문 순서대로 배열.\n\n3. 일부 콘텐트 누락·첨가  \n   • “watch aider dance” 뒤의 이모티콘과 같은 장난기 있는 표현은 다른 곳에서 중복되며, 번역본에서는 위치‧빈도 불일치가 있어 문체 흐름이 달라짐.  \n   • “GET TO WORK!”를 그냥 영어로 살려 두어 톤이 툭 끊긴다. 한국어 본문 흐름에 맞춰 “어서 일해라!” 등으로 번역 필요.  \n   • 전체적으로 큰 단락·문장은 빠진 곳이 없으나, 위처럼 어조·유머 장치가 잘못 삽입·누락되어 미묘하게 의미·톤이 달라진 사례 다수.\n\n--------------------------------------------------\nB. Major – 뉘앙스·문화 참조 손실, 어색한 표현\n--------------------------------------------------\n1. 문화적 고유명 “Juggalo” 삭제  \n   • 번역: “광대 분장 코딩 로봇”  \n   • 문제: ‘Juggalo’는 Insane Clown Posse 팬덤 하위문화를 가리키는 고유명이다. ‘광대 분장’으로만 치환하면 서브컬처 뉘앙스가 사라진다.  \n   • 수정: “저글로(Juggalo) 풍의 광대 분장을 한…” 같이 원어 병기 후 설명.\n\n2. “over my skis” 설명 부족  \n   • 번역은 장황하게 풀이했지만, ‘속도가 앞질러 균형 잃음’이라는 핵심 은유가 흐릿함.  \n   • 제안: “스키 앞꿈치가 너무 앞으로 나가 균형을 잃는다(=앞서 나간다)”는 우회 설명 + 원어 병기.\n\n3. 구어체 유머 번역 미흡  \n   • “Wild tbh.”, “oh boy. how much time do you have!” 등은 영어 그대로 두거나 직역으로만 처리해 리듬감이 깨짐.  \n   • 제안: “솔직히 말도 안 되죠 ㅋㅋ” 등 자연스러운 한국어 구어체로 변환해 리듬 살리기.\n\n4. 기술 용어 번역 일관성 붕괴  \n   • ‘codegen’ → “코드 생성”, “코드젠”, “코드 생성(codegen)” 등 혼재.  \n   • ‘prompt’는 그대로, ‘프롬프트’ 병기하지만 어떤 곳은 영어 그대로.  \n   • 제안: “코드 생성(Codegen)”/“프롬프트(prompt)”처럼 첫 등장 시 병기, 이후 통일.\n\n5. 불필요한 과잉 해석·주석  \n   • “모던하지만 이미 레거시가 된”처럼 원문보다 한층 주관적 뉘앙스를 추가.  \n   • “아래 프로세스” 등 일부 문장에 ‘정직한’ 번역 대신 필자의 해설 삽입.  \n   • 제안: 객관적‧간결하게 유지, 해석은 괄호 부연에 머무를 것.\n\n--------------------------------------------------\nC. Minor / Stylistic – 자연스러움·문법·맞춤법\n--------------------------------------------------\n1. 맞춤법‧어휘  \n   • “재밌고” → ‘재미있고’  \n   • “함정도 숱하다” → ‘함정도 많다’/‘함정이 수두룩하다’  \n   • “독립 루프를 돌리고” → ‘독립 루프를 한 번씩 돌린 뒤’ 등 어순·조사 다듬기.\n\n2. 문체 혼란  \n   • 구어체(반말)·서술체(문어체)가 문장마다 뒤섞임: “재밌고 유용하다.” vs “야호!” vs 영어 원문 직삽 등.  \n   • 블로그 특유의 자유분방함은 살리되, 2인칭/존댓말 혼용만은 정리(전체를 반말 블로그체로 통일 권장).\n\n3. 기호·구두점  \n   • 긴 대시 ‘―’ 사용과 ‘—’ 혼용, 띄어쓰기 불균형(예: “15분**이면**”).  \n   • 마크다운 인라인 코드(`...`) 안의 역따옴표 표기 한국어 구문과 부딪침.\n\n4. 영어 잔재  \n   • “wild tbh”, “cookie clicker” 등 원문을 그대로 둘 땐 한글 주석을 넣거나 이탤릭·괄호 처리 필요.  \n   • “raw Claude” → ‘웹 인터페이스의 기본 Claude(원문 “raw”)’ 등 설명 추가.\n\n5. 리듬·가독성  \n   • 길이 3줄 이상 문장은 끊어 주고, 리스트 앞뒤에 짧은 완충 문장 삽입.  \n   • ‘✩₊˚.⋆☾⋆⁺₊✧’ 같은 이모티콘은 원문 유지하되 앞뒤 띄어쓰기 통일.\n\n--------------------------------------------------\nD. Consistency – 용어·표기\n--------------------------------------------------\n| 원문 | 제안된 통일어 | 비고 |\n|------|---------------|------|\n| codegen | 코드 생성(Codegen) | 첫 등장 병기, 이후 ‘코드 생성’ |\n| Greenfield / Brownfield | 그린필드 / 브라운필드 | 필요 시 괄호에 “신규/기존” 설명 |\n| prompt | 프롬프트(prompt) | 일관 유지 |\n| repomix / mise | 그대로 표기 | 고유명 |\n| LLM | LLM | 영문 유지 |\n\n--------------------------------------------------\nE. Machine-like / Over-literal\n--------------------------------------------------\n• “브레인스토밍이 자연스럽게 끝나면:” 같은 구절이 원문의 구두점을 기계적으로 따라가 번역 리듬이 딱딱함. → “충분히 아이디어를 정리했다 싶을 때는,” 정도로 변환.  \n• 코드를 제외한 부분에서는 영어 원문 문장 구조를 그대로 복사하지 말고 한국어 화제-서술 구조로 재배열.\n\n--------------------------------------------------\n요약 개선 가이드\n--------------------------------------------------\n1. 의미 위주 재검토: “Legacy modern code” 등 오해 소지가 있는 곳 우선 수정.  \n2. 문화 참조 보존: ‘Juggalo’, ‘over my skis’ 등은 원어+간단 해설.  \n3. 통일성 확보: codegen/프롬프트/그린필드 등 표기 일관.  \n4. 문체 다듬기: 블로그 특유 구어체는 살리되 맞춤법·어미 통일.  \n5. 유머·톤 유지: 영어 감탄사·인터넷 밈을 한국어식 재치로 옮겨, 원문 ‘친근-장난’ 느낌 살리기.",
      "[Severity legend]  \nCritical = Alters meaning or leaves out content.  \nMajor    = Meaning mostly intact but nuance/important detail lost, or Korean sounds plainly unnatural.  \nModerate = Minor nuance/flow/consistency problems.  \nMinor/Stylistic = Pure polish.\n\n──────────────────────────────  \n1. Critical ‑ Meaning/Content Errors  \n──────────────────────────────  \n1-A. Omitted purposes of the spec  \n• Source: “ … to generate a white paper, or to generate a business model.”  \n• Kor: “백서를 뽑아내거나, 1만 단어짜리 지원 문서를 받아내도 … ” → “business model” 생략.  \n  Fix: “백서를 만들거나 비즈니스 모델을 뽑아내거나 …”\n\n1-B. Sentence fully dropped (Results section)  \n• Source: “I keep thinking of new things and knocking them out while watching a movie or something.”  \n• Missing in Kor.  \n  Fix: 추가: “영화를 보면서도 새 아이디어가 떠오르면 바로 만들어 버린다.”\n\n1-C. Sentence dropped (Non-greenfield)  \n• Source: “I have found that I can do any sized tasks with this method.”  \n• Missing in Kor.  \n  Fix: “이 방식으로 규모에 관계없이 어떤 작업도 해낼 수 있었다.”\n\n1-D. “Raw claude” mis-rendered  \n• Source: “I, however, prefer **raw** claude and aider” (의미: 래퍼 없이 ‘날것’ API/UI).  \n• Kor: “기본 웹 인터페이스의 Claude” → ‘raw’ = ‘웹 인터페이스’ 아님.  \n  Fix: “별도 래퍼 없이 ‘생(生) CLAUDE’(API 직접/기본 UI)와 Aider를 선호한다.”\n\n1-E. “Over my skis” imagery truncated  \n• Source includes vivid cliff-falling sentence (“WHAT THE **** … fall off a cliff”).  \n• Kor 요약으로 끝. 강렬한 유머·놀람 감정 유실.  \n  Fix: 전체 비유 살려 추가.\n\n1-F. Misc. small omissions  \n– “It resonates with me. I don’t know why.”  \n– “Generate a business model” (covered 1-A).  \nEnsure 완전한 반영.\n\n──────────────────────────────  \n2. Major ‑ Nuance / Idiom / Register  \n──────────────────────────────  \n2-A. “양쪽으로 살짝씩 튜닝이 다르다”  \n  • 영어 “tweaks in either direction” → 의미는 ‘사람마다 조금씩 다르다’.  \n  • 현재 표현은 방향이 두 개뿐인 듯 어색.  \n  • 제안: “저마다 약간씩 다르게 튜닝한다.”\n\n2-B. “Cookie Clicker나 두드린다”  \n  • 한국어 관용 맞지 않음.  \n  • 제안: “Cookie Clicker를 두드리며 논다” or “Cookie Clicker나 하면서 논다”.\n\n2-C. “리포지토리 셋업”  \n  • IT 용례 있지만 연속 사용 잦음. 한두 번은 “리포지토리를 초기화한다” 등으로 자연화.\n\n2-D. “기존(레거시·모던 포함) 코드”  \n  • 원문 “legacy modern code” 는 자조적 표현. 현재 번역은 정보 전달만 있고 익살 빠짐.  \n  • 가능: “레거시(?) ‘모던’ 코드” 같이 따옴표로 뉘앙스 살리기.\n\n2-E. 톤 불균일  \n  • 원문은 대체로 속어·친구에게 말하듯. 몇몇 구간(“왕창 잡아먹는 함정도 수두룩하다” vs “탄탄한 계획·문서를 제공하고”) 사이 어투 급격히 바뀜.  \n  • 제안: 반말/친근어 vs 서술형 존댓말 중 하나로 통일, 혹은 반말 체 유지.\n\n──────────────────────────────  \n3. Grammar / Flow Issues (Moderate)  \n──────────────────────────────  \n3-A. 겹말·군더더기  \n  • “이 경우 방법이 살짝 다르다.” → “방법이 조금 다르다.”  \n3-B. 불필요한 영어 괄호·역슬래시  \n  • “¯\\\\_(ツ)_/¯” 역-이스케이프 제거.  \n3-C. 과도한  ·  기호  \n  • “―” “—” 혼용, markdown 일관성 필요.\n\n──────────────────────────────  \n4. Terminology Consistency  \n──────────────────────────────  \n4-A. Codegen / 코드 생성 혼용   → 최초 괄호 병기 뒤 일관된 한국어 사용 권장.  \n4-B. “Prompt”는 대부분 영문 그대로 두었는데 몇 군데 ‘프롬프트’ 사용. 통일.\n\n──────────────────────────────  \n5. Minor / Stylistic  \n──────────────────────────────  \n5-A. 날짜 표현 ↔ “2016-05-14” vs “5/14/2016” 통일.  \n5-B. “Wild tbh.” 그대로 유지했으나 한국어 독자 이해 어렵다. 주해 또는 “솔직히 미친 속도다 (wild tbh).”  \n5-C. 밑줄/기울임 기호: 원문 형식 유지 필요.\n\n──────────────────────────────  \n6. Machine-like residue  \n──────────────────────────────  \n6-A. 영어 문장을 그대로 남겨 놓은 Prompt 영역은 의도된 것이나, 본문 내 “review the results … small enough” 한 줄 그대로 남아있음 → 번역 누락 의심.  \n6-B. 장황한 괄호 삽입 스타일이 GPT 번역 느낌. 일부 간결화 권장.\n\n──────────────────────────────  \nOverall Recommendations  \n──────────────────────────────  \n• 빠진 문장·의미(1-A~1-F) 반드시 추가.  \n• ‘raw’, ‘legacy modern code’, ‘over my skis’ 등 농담성 키워드는 직역+주해로 유머 살리기.  \n• 구어체 톤을 일정하게 유지하되 군더더기·어색한 직역(2-A, 2-B 등) 다듬기.  \n• 영어 전문어는 첫 등장 시 병기 후 한국어 일관성 유지.  \n• Prompt 본문 외의 영어 잔여 문장은 모두 번역.  \n• 자잘한 문장부호·형식 통일로 가독성 개선.\n\n이 리스트를 반영하면 “영어 원서인 줄 몰랐다”는 말이 나올 만큼 자연스럽고 충실한 번역이 될 것입니다."
    ]
  },
  "critique_loop_details": {
    "critique_usages": [
      {
        "prompt_tokens": 9224,
        "completion_tokens": 3791,
        "total_tokens": 13015
      },
      {
        "prompt_tokens": 9358,
        "completion_tokens": 7350,
        "total_tokens": 16708
      },
      {
        "prompt_tokens": 9380,
        "completion_tokens": 6057,
        "total_tokens": 15437
      },
      {
        "prompt_tokens": 9271,
        "completion_tokens": 7661,
        "total_tokens": 16932
      }
    ],
    "feedback_usages": [
      {
        "prompt_tokens": 10522,
        "completion_tokens": 5048,
        "total_tokens": 15570
      },
      {
        "prompt_tokens": 12205,
        "completion_tokens": 5046,
        "total_tokens": 17251
      },
      {
        "prompt_tokens": 11222,
        "completion_tokens": 5280,
        "total_tokens": 16502
      },
      {
        "prompt_tokens": 10631,
        "completion_tokens": 5285,
        "total_tokens": 15916
      }
    ]
  },
  "timestamp": "2025-05-15T09:52:12.221361"
}