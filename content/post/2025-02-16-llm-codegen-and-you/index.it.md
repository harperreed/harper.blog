---
bsky: https://bsky.app/profile/harper.lol/post/3lidixzdr5j2e
date: 2025-02-16 18:00:00-05:00
description: Una guida dettagliata del mio flusso di lavoro attuale per utilizzare
  gli LLM nella realizzazione di software, dal brainstorming alla pianificazione e
  all'esecuzione.
draft: false
generateSocialImage: true
slug: my-llm-codegen-workflow-atm
tags:
- LLM
- coding
- ai
- workflow
- software-development
- productivity
title: 'Il mio flusso di lavoro di generazione di codice con LLM al momento

  description: Una guida dettagliata del mio flusso di lavoro attuale per utilizzare
  gli LLM nella realizzazione di software, dal brainstorming alla pianificazione e
  all''esecuzione.'
translationKey: My LLM codegen workflow atm
---

_tl;dr ‚Äì Fai brainstorming sulla specifica, poi prepara il piano, quindi esegui con la generazione di codice via LLM. Cicli discreti. Poi magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_

Da qualche tempo realizzo un sacco di piccoli prodotti con gli LLM: √® divertente e utile. Per√≤ ci sono tranelli che possono farti sprecare un mare di tempo. Un po‚Äô di tempo fa un amico mi ha chiesto come stessi usando gli LLM per scrivere software. Ho pensato: ¬´Oh boy, quanto tempo hai?!¬ª ‚Äî ed ecco questo post.

(p.s. se detesti l‚ÄôIA ‚Äî scorri pure fino in fondo)

Parlo spesso con parecchi amici sviluppatori: abbiamo tutti un approccio simile, con qualche variazione qua e l√†.

Ecco il mio flusso di lavoro. Si basa sul mio lavoro, sulle chiacchiere con amici (grazie [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) ed [Erik](https://thinks.lol/)) e su un mucchio di best practice raccolte in quei terribili [angoli](https://news.ycombinator.com/) [dell‚ÄôInternet](https://twitter.com).

Funziona bene **ORA**: fra due settimane forse non funzioner√† pi√π o andr√† il doppio meglio. ¬Ø\\\_(„ÉÑ)\_/¬Ø

## Andiamo

{{< image src="llm-coding-robot.webp" alt="Juggalo Robot" caption="Trovo sempre sospette queste immagini generate dall‚ÄôIA. Saluta il mio juggalo coding robot!" >}}

Di solito mi trovo in una di due situazioni:

- Greenfield (codice del tutto nuovo)  
- Codice legacy ma comunque recente

Ti mostrer√≤ il mio flusso di lavoro per entrambi i casi.

## Greenfield

Per lo sviluppo greenfield il processo seguente funziona bene: offre una pianificazione e una documentazione robuste e ti permette di procedere facilmente a piccoli passi.

{{< image src="greenfield.jpg" alt="Green field" caption="Tecnicamente, un campo verde √® sulla destra. Leica Q, 14 maggio 2016" >}}

### Fase 1: affinare l‚Äôidea

Perfeziona l‚Äôidea con un LLM in modalit√† conversazionale (io uso ChatGPT 4o/4o3):

```prompt
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here‚Äôs the idea:

<IDEA>
```

Alla fine del brainstorming (arriver√† a una conclusione naturale):

```prompt
Now that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.
```

Otterrai una specifica solida e chiara da passare alla fase di pianificazione. Io la salvo come `spec.md` nel repo.

> Puoi usare questa specifica per un sacco di cose. Qui la useremo per la generazione di codice, ma l‚Äôho gi√† sfruttata per rafforzare idee chiedendo a un modello di ragionamento di trovare falle (must go deeper!), per creare un white paper o un business model. Se la infili in una ‚Äúricerca profonda‚Äù, pu√≤ tornarti un documento di supporto da 10 000 parole.

### Fase 2: pianificazione

Prendi la `spec` e passala a un modello di puro ragionamento (`o1*`, `o3*`, `r1`).

(Questo √® il prompt TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

(Questo √® il prompt non TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

Otterrai un piano di prompt eseguibile con Aider, Cursor, ecc. Io lo salvo come `prompt_plan.md` nel repo.

Poi gli chiedo di generare un `todo.md` da spuntare:

```prompt
Can you make a `todo.md` that I can use as a checklist? Be thorough.
```

Salvalo come `todo.md` nel repo.

Il tuo strumento di generazione del codice dovrebbe spuntare il `todo.md` mentre lavora: √® utile per mantenere lo stato fra le sessioni.

#### Grandioso, abbiamo un piano!

Ora hai un piano robusto e la documentazione che ti aiuteranno a costruire il progetto.

Tutto il processo richiede forse **15 minuti**. √à piuttosto folle, a dirla tutta.

### Fase 3: esecuzione

Le opzioni di esecuzione sono tante; il successo dipende da quanto bene √® andata la fase 2.

Ho usato questo flusso di lavoro con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai) e altri. Finora ha funzionato con tutti gli strumenti di code-gen che ho provato e immagino che funzioni bene con qualunque tool del genere.

Io per√≤ preferisco Claude ‚Äúpuro‚Äù e Aider.

### Claude

In pratica faccio pair programming con [Claude.ai](https://claude.ai) e inserisco ogni prompt in modo iterativo. Funziona bene; il continuo back-and-forth pu√≤ essere noioso, ma di solito rende.

Mi occupo del boilerplate iniziale e di configurare gli strumenti: avere gi√† un fondamento solido con linguaggio, stile e tooling scelti aiuta molto, visto che Claude tende a generare soprattutto codice React.

Quando le cose si bloccano uso un tool come [Repomix](https://github.com/yamadashy/repomix) per iterare (ne parlo pi√π avanti).

Il flusso di lavoro √® il seguente:

- preparo il repo (boilerplate, `uv init`, `cargo init`, ecc.)  
- incollo il prompt in Claude  
- copio il codice da Claude.ai nell‚ÄôIDE  
- avvio il codice, faccio girare i test  
- ‚Ä¶  
- se funziona, passo al prompt successivo  
- se non funziona, uso Repomix per passare l‚Äôintera codebase a Claude e fare debug  
- ripeti da capo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

### Aider

[Aider](https://aider.chat/) √® divertente e un po‚Äô particolare. Si integra bene con l‚Äôoutput della fase 2: con pochissimo sforzo puoi andare molto avanti.

Il flusso √® pressoch√© lo stesso, ma invece di incollare in Claude incolli i prompt in Aider.

Aider ¬´fa e basta¬ª e nel frattempo ti fai una partita a [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).

> Piccola parentesi: Aider pubblica ottimi benchmark dei nuovi modelli di code-gen nei suoi [LLM leaderboards](https://aider.chat/docs/leaderboards/); √® una grande risorsa per valutarne l‚Äôefficacia.

Il testing con Aider √® quasi automatico: pu√≤ eseguire la test-suite e fare debug per te.

Il flusso di lavoro √® il seguente:

- preparo il repo (boilerplate, `uv init`, `cargo init`, ecc.)  
- avvio Aider  
- incollo il prompt in Aider  
- guardo Aider all‚Äôopera ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™  
- Aider esegue i test, oppure avvio l‚Äôapp per verificare  
- se funziona, passo al prompt successivo  
- se non funziona, dialogo con Aider per sistemare  
- ripeti da capo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

### Risultati

Con questo flusso di lavoro ho costruito di tutto: script, app Expo, CLI in Rust, ecc. Ha funzionato con diversi linguaggi e contesti e lo adoro.

Se hai un progetto (piccolo o grande) che stai rimandando, prova: rimarrai sorpreso da quanto lontano puoi arrivare in poco tempo.

La mia to-do list di hack √® vuota perch√© ho costruito tutto. Continuo a pensare nuove cose e le completo mentre guardo un film. Per la prima volta da anni sto sperimentando nuovi linguaggi e strumenti, ampliando la mia prospettiva di programmatore.

## Non-greenfield: iterare in modo incrementale

A volte non hai un greenfield: devi iterare o fare lavoro incrementale su una codebase esistente.

{{< image src="brownfield.jpg" alt="Campo bruno" caption="Questo non √® un campo verde. Foto a caso dalla macchina fotografica di mio nonno ‚Äî Uganda, anni ‚Äô60" >}}

Per questo uso un metodo leggermente diverso: simile a quello sopra, ma meno ¬´basato sulla pianificazione¬ª. Qui la pianificazione √® per singolo task, non per l‚Äôintero progetto.

### Recuperare contesto

Chi sviluppa con gli LLM usa strumenti diversi, ma serve qualcosa che prenda il tuo codice e lo infili efficacemente nel modello.

Io uso [Repomix](https://github.com/yamadashy/repomix). Ho una raccolta di task definita nel mio `~/.config/mise/config.toml` globale che mi permette di fare varie cose con la codebase ([regole mise](https://mise.jdx.dev/)).

Ecco la lista di task LLM:

```shell
LLM:clean_bundles           Generate LLM bundle output file using repomix
LLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use
LLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation
LLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation
LLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation
LLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation
LLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation
```

Genero un `output.txt` con il contesto della codebase. Se il file √® troppo grande e consumo troppi token, modifico il comando di generazione per ignorare parti non rilevanti.

> Una cosa splendida di `mise` √® che i task possono essere ridefiniti nel `.mise.toml` della directory di lavoro. Posso usare un altro tool per impacchettare il codice e, finch√© produce `output.txt`, i miei task LLM funzionano. √à utile quando le codebase sono molto diverse. Spesso sovrascrivo lo step `repomix` con pattern di ignore pi√π ampi o un tool pi√π efficace.

Una volta generato `output.txt`, lo passo al comando [LLM](https://github.com/simonw/LLM) per varie trasformazioni e salvo l‚Äôoutput in un file markdown.

In pratica il task mise esegue `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. Niente di complesso: il comando `LLM` fa il grosso (supportando diversi modelli, gestendo le chiavi e usando template di prompt).

Per esempio, se mi serve una rapida revisione della copertura dei test faccio cos√¨.

#### Claude

- entro nella directory del codice  
- eseguo `mise run LLM:generate_missing_tests`  
- apro `missing-tests.md`  
- copio il contesto completo con `mise run LLM:copy_buffer_bundle`  
- incollo tutto in Claude insieme alla prima issue sui test mancanti  
- copio il codice generato da Claude nell‚ÄôIDE  
- ‚Ä¶  
- lancio i test  
- ripeti da capo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

#### Aider

- entro nella directory del codice  
- avvio Aider (assicurati di essere su un nuovo branch)  
- eseguo `mise run LLM:generate_missing_tests`  
- apro `missing-tests.md`  
- incollo la prima issue in Aider  
- guardo Aider all‚Äôopera ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™  
- ‚Ä¶  
- lancio i test  
- ripeti da capo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

√à un ottimo modo per migliorare incrementalmente una codebase e funziona bene anche per task di qualsiasi dimensione.

### Magia dei prompt

Questi hack veloci funzionano alla grande per rendere un progetto pi√π robusto, in modo rapido ed efficace.

Ecco alcuni prompt che uso su codebase esistenti:

#### Code review

```prompt
You are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.
```

#### Generazione di issue GitHub

```prompt
You are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

#### Test mancanti

```prompt
You are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

Questi prompt sono un po‚Äô old and busted (¬´prompt da boomer¬ª, se vogliamo): avrebbero bisogno di refactoring. Se hai idee per migliorarli, fammi sapere.

## Sci ·®í‚Üü ñ†∞·®í‚Üü ñ†∞

Quando descrivo questo processo dico spesso: ¬´devi tenere traccia di ci√≤ che succede in modo aggressivo, perch√© puoi facilmente ritrovarti troppo avanti¬ª.

Per qualche motivo dico ¬´over my skis¬ª parlando di LLM. Non so perch√©. Mi risuona parecchio. Forse perch√© √® come sciare su polvere perfetta, poi all‚Äôimprovviso pensi ¬´CHE DIAVOLO STA SUCCEDENDO!¬ª e ti ritrovi perso, precipitando da un dirupo.

Una fase di pianificazione (come nel processo greenfield) aiuta a tenere tutto sotto controllo. Almeno hai un documento su cui ricontrollare. Credo anche che i test siano utili ‚Äî soprattutto se fai coding stile wild con Aider: aiutano a mantenere tutto solido e pulito.

Comunque mi ritrovo ancora over my skis abbastanza spesso. A volte bastano una breve pausa o una passeggiata. In fondo √® un normale problem-solving, ma accelerato a velocit√† folle.

> Capita spesso di chiedere all‚ÄôLLM di inserire cose assurde in un codice che di suo non sarebbe cos√¨ folle. Per esempio gli abbiamo chiesto di creare un file di lore e poi di citarlo nell‚Äôinterfaccia utente di un tool CLI Python. All‚Äôimprovviso compaiono lore, interfacce glitchate ecc. Tutto per gestire le tue cloud function, la tua to-do list o chiss√† che altro. Il cielo √® il limite.

## Sono cos√¨ solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)

La mia principale lamentela su questi flussi di lavoro √® che sono per lo pi√π un‚Äôesperienza in solitaria: le interfacce sono tutte in modalit√† giocatore singolo.

Ho passato anni a programmare da solo, in pair e in team. √à sempre meglio con altre persone. Questi flussi non sono facili da usare in squadra: i bot collidono, i merge sono orribili, il contesto √® complicato.

Vorrei davvero che qualcuno risolvesse questo problema e rendesse la programmazione con un LLM un gioco multiplayer, non un‚Äôesperienza da hacker solitario. C‚Äô√® un‚Äôenorme opportunit√† per farlo diventare fantastico.

GET TO WORK!

## ‚¥µ Tempo ‚¥µ

Tutta questa code-gen ha aumentato di molto la quantit√† di codice che riesco a produrre da solo. C‚Äô√® per√≤ un effetto collaterale strano: ho un sacco di ¬´tempo morto¬ª mentre l‚ÄôLLM macina token.

{{< image src="apple-print-shop-printing.png" alt="Printing" caption="Me lo ricordo come fosse ieri" >}}

Ho quindi cambiato modo di lavorare e ora sfrutto quell‚Äôattesa per:

- avviare il brainstorming di un altro progetto  
- ascoltare vinili  
- giocare a Cookie Clicker  
- chiacchierare con amici e robot  

√à fantastico poter hackerare in questo modo. Hack, hack, hack. Non ricordo un altro momento in cui sia stato cos√¨ produttivo con il codice.

## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ

Molti amici mi dicono: ¬´fanculo gli LLM, fanno schifo in tutto¬ª. Non mi infastidisce questo punto di vista: non lo condivido, ma credo sia importante essere scettici. Ci sono parecchi motivi per odiare l‚ÄôIA. La mia paura principale √® il consumo energetico e l‚Äôimpatto ambientale. Ma‚Ä¶ the code must flow. Sigh.

Se sei curioso ma non vuoi diventare un programmatore cyborg, ti suggerisco di leggere il libro di Ethan Mollick sugli LLM e sul loro utilizzo: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).

Spiega i benefici senza essere un tomo da bro anarco-capitalista tech. L‚Äôho trovato molto utile e ho fatto tante conversazioni interessanti con amici che l‚Äôhanno letto. Consigliatissimo.

Se sei scettico ma un po‚Äô curioso, scrivimi: parliamo di tutta questa follia e magari costruiamo qualcosa insieme.

_grazie a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) ed [Erik](https://thinks.lol/) per aver letto questo post e suggerito modifiche. Vi apprezzo._