{
  "input_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.md",
  "output_file": "/Users/harper/Public/src/personal/harperreed/harper.blog/content/post/2025-02-16-llm-codegen-and-you/index.ja.md",
  "target_language": "japanese",
  "language_code": "ja",
  "model": "o3",
  "skip_edit": false,
  "do_critique": true,
  "critique_loops": 4,
  "has_frontmatter": true,
  "token_usage": {
    "prompt_tokens": 98035,
    "completion_tokens": 29029,
    "total_tokens": 127064
  },
  "cost": "$2.1415",
  "prompts_and_responses": {
    "translation": {
      "model": "o3",
      "target_language": "japanese",
      "system_prompt": "\n        1. Read the provided text carefully, preserving all formatting, markdown, and structure exactly as they appear.\n        2. Identify any block quotes and code blocks.\n        3. Do not translate text in block quotes or in code blocks (including text within code blocks).\n        4. Translate everything else into japanese.\n        5. Maintain the original formatting, markdown, and structure in your output.\n        6. Provide a natural-sounding translation rather than a word-for-word one.\n        7. For idioms, colloquialisms, or slang, render them in an equivalent, natural way in japanese whenever possible.\n        8. If there isn't a direct or natural translation for a particular term or phrase, keep it in the original language and surround it with quotes if necessary.\n        9. Ensure that technical terms or jargon remain accurate; if there's no suitable translation, keep the original term.\n        10. Strive for fluid, native-sounding prose that retains the tone and intent of the original text.\n        ",
      "user_prompt": "_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "response": "_tl:dr; まず仕様をブレインストーミングし、次に計画を立て、それから LLM のコード生成で実行します。離散ループ。その後に魔法。✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM を使ってたくさんの小さなプロダクトを作ってきました。めちゃくちゃ楽しいし、役に立つんですが、時間を無駄にする落とし穴も山ほどあります。少し前、友人に「どうやって LLM でソフトウェアを書いてるの？」と聞かれ、「いやー、時間ある？」となったのでこの記事を書きました。\n\n（追伸：AI 嫌いの人は最後までスクロールしてね）\n\n多くの開発仲間と話すと、みんな似たようなフローを使っていますが、細部でちょっとずつ違います。\n\nここに私のワークフローをまとめました。自分自身の経験、友人との会話（ありがとう [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)）、そしてネットのあちこちにある（ヒドい）[闇](https://news.ycombinator.com/) [の](https://twitter.com)ベストプラクティスを参考にしています。\n\nこれが**今**のところうまく機能していますが、2 週間後には通用しなくなるか、逆に 2 倍効くかも。¯\\\\\\_(ツ)\\_/¯\n\n## さあ行こう\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\n開発にはいろいろなパターンがありますが、私の場合は大きく 2 つ。\n\n- ゼロから書くコード（Greenfield）\n- 既存モダンコードの追加／改修（Legacy modern code）\n\nそれぞれのパスでのプロセスを紹介します。\n\n## Greenfield\n\nグリーンフィールド開発でうまく機能するプロセスです。しっかりした計画とドキュメントを作り、小さなステップで実装できます。\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: アイデアのブラッシュアップ\n\n対話型の LLM（私は ChatGPT 4o / o3）でアイデアを磨きます。\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea...\n```\n\nブレインストーミングが自然に終わったら：\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification?...\n```\n\nこれでかなりまとまった仕様が出力され、次の計画ステップへ渡せます。私は `spec.md` としてレポジトリに保存します。\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: 計画\n\nこの仕様を本気の推論モデル（`o1*`, `o3*`, `r1`）へ投げます。\n\n（こちらは TDD 用プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project...\n```\n\n（こちらは非 TDD 用プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project...\n```\n\nここで実行プランのプロンプトが生成されます。`prompt_plan.md` として保存。\n\n続けて `todo.md` を生成してもらいます。\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\n#### やったね、計画完了！\n\nこれで実装を進めるための堅牢な計画とドキュメントがそろいました。\n\n全部で **15 分** くらい。ぶっちゃけ速すぎ。\n\n### Step 3: 実装\n\n実装方法は山ほどありますが、ステップ 2 がうまくいったかで成否が決まります。\n\n私は [github workspace](https://githubnext.com/projects/copilot-workspace)、[aider](https://aider.chat/)、[cursor](https://www.cursor.com/)、[claude engineer](https://github.com/Doriandarko/claude-engineer)、[sweep.dev](https://sweep.dev/)、[chatgpt](https://chatgpt.com)、[claude.ai](https://claude.ai) などで試しましたが、どれも問題なく動きました。\n\nが、私は **素の** Claude と aider が好みです。\n\n### Claude\n\n基本は [claude.ai](https://claude.ai) でペアプロ。各プロンプトを順に投げます。行ったり来たりは面倒ですが、大体うまくいきます。\n\n- レポジトリ初期化（boilerplate、uv init、cargo init など）\n- プロンプトを Claude に貼る\n- Claude のコードを IDE にコピペ\n- 実行・テスト\n- ...\n- うまく動けば次のプロンプト\n- ダメなら repomix でコードベースを Claude へ投げてデバッグ\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) はクセがありますが、ステップ 2 のアウトプットと相性抜群。少ない手間でかなり進めます。\n\n- レポジトリ初期化\n- aider 起動\n- プロンプトを aider に貼る\n- aider のダンスを眺める ♪┏(・o･)┛♪\n- テスト or 実行で確認\n- 問題あれば aider と QA\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\n### 結果\n\nこのフローでスクリプト、expo アプリ、Rust CLI など山ほど作りました。言語も場面も選びません。先延ばしにしていた小さな／大きなプロジェクトがあれば、ぜひ試してみてください。短時間で想像以上に進みます。\n\n## Non-greenfield: 既存コードをちょこちょこ改修\n\nときにはグリーンフィールドではなく、既存コードをじわじわ育てる必要があります。\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nこの場合は少し違う手法。タスクごとに計画し、進めます。\n\n### コンテキスト取得\n\nコードを集めて効率よく LLM に流し込むツールが必要です。私は [repomix](https://github.com/yamadashy/repomix) を愛用し、`~/.config/mise/config.toml` にタスクを定義しています。\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\n...\n```\n\n`output.txt` にコードの文脈を詰め、必要に応じて除外パターンを変えてトークンを節約。\n\n`LLM` コマンドで変換し Markdown に保存します。たとえばテスト不足を手早く埋めるなら：\n\n#### Claude\n\n- ディレクトリに移動\n- `mise run LLM:generate_missing_tests` 実行\n- `missing-tests.md` を確認\n- `mise run LLM:copy_buffer_bundle` でコンテキストをコピー\n- それを Claude に貼り、最初の issue を解決\n- IDE にコピペ、テスト\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- ディレクトリに移動し新しいブランチで aider 起動\n- 同じく `mise run LLM:generate_missing_tests`\n- `missing-tests.md` を aider に貼る\n- aider のダンスを見る\n- テスト\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### プロンプト・マジック\n\n以下は既存コードを掘るときの愛用プロンプトです。\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code...\n```\n\n#### GitHub Issue 生成\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues...\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases...\n```\n\n古くて雑な「ブーマー・プロンプト」なので改良案あればぜひ。\n\n## スキー ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n私はよく「スキーの前傾で飛ばしすぎてる感じ」と表現します。LLM を使うと一気にスピードが上がり、気付くと崖っぷち…みたいな。\n\nグリーンフィールドで**計画ステップ**を入れると多少制御できます。テストも大事。特に aider でワイルドに書くときは必須です。\n\nそれでも**オーバー・マイ・スキー**になることは多いので、詰まったら散歩でもして頭をリセット。普通の問題解決プロセスですが、加速度が桁違い。\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## さみしい (｡•́︿•̀｡)\n\nこのワークフロー最大の欠点は**ソロプレイ**なこと。ペアやチームで書く方が絶対楽しいのに、Bot 同士が衝突し、マージ地獄、コンテキスト共有が大変。\n\nLLM を使った開発をマルチプレイヤー化する解決策が切実に欲しい。チャンスしかないので誰かやって！\n\n## ⴵ 時間 ⴵ\n\nコード生成は個人でも大量のコードを出せるようにしてくれましたが、トークン消費中の**待ち時間**が妙に増えました。\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nそこで待ち時間にはこんなことをしています。\n\n- 次のプロジェクトのブレインストーミングを始める\n- レコードを聴く\n- [cookie clicker](https://orteil.dashnet.org/cookieclicker/) を回す\n- 友達やロボットとおしゃべり\n\nおかげでこれまでで一番「ハック、ハック、ハック」している感覚。こんなに生産的だった時期は記憶にありません。\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\n「LLM は全部クソ」と言う友人も多いです。それも理解できます。AI を嫌う理由は山ほどあるし、私も電力消費と環境負荷は怖い。でも…コードは流れねば。はぁ。\n\nもし学ぶ気はあるけどサイボーグプログラマにはなりたくないなら、Ethan Mollick の [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) をおすすめします。テック野蛮資本主義的でなく、LLM の利点をうまく説明しています。読んだ友人たちともいい議論ができました。\n\n懐疑的でもちょっと興味あるなら、気軽に声をかけてください。この狂気を一緒に眺めて、何か作りましょう。\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "usage": {
        "prompt_tokens": 4834,
        "completion_tokens": 3118,
        "total_tokens": 7952
      },
      "streaming": true
    },
    "editing": {
      "model": "o3",
      "target_language": "japanese",
      "system_prompt": "\n        1. Carefully read the translated text alongside the original text in its entirety.\n        2. Compare both texts to ensure the translation accurately reflects the original meaning.\n        3. Correct any grammatical errors you find in the japanese text.\n        4. Adjust phrasing to make it sound natural and fluent for japanese speakers, making sure idioms and expressions are culturally appropriate.\n        5. Preserve the original tone, nuance, and style, including any formatting, markdown, and structure.\n        6. Avoid adding new information or altering the core meaning.\n        7. Ensure the final result doesn't feel machine-translated but remains faithful to the source.\n        8. Make only changes that genuinely improve the text's quality in japanese.\n        9. Don't be too literal. If there isn't a direct translation, provide a natural-sounding translation.\n        10. If the text contains idioms or colloquialisms, translate them into the target language while maintaining their original meaning.\n        11. If the text contains technical terms or jargon, ensure that the translation is accurate and appropriate for the target audience, if there isn't a natural translation, keep it in the original language.\n        12. If there is not natural translation, keep it in the original language.\n        ",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# TRANSLATED TEXT\n_tl:dr; まず仕様をブレインストーミングし、次に計画を立て、それから LLM のコード生成で実行します。離散ループ。その後に魔法。✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM を使ってたくさんの小さなプロダクトを作ってきました。めちゃくちゃ楽しいし、役に立つんですが、時間を無駄にする落とし穴も山ほどあります。少し前、友人に「どうやって LLM でソフトウェアを書いてるの？」と聞かれ、「いやー、時間ある？」となったのでこの記事を書きました。\n\n（追伸：AI 嫌いの人は最後までスクロールしてね）\n\n多くの開発仲間と話すと、みんな似たようなフローを使っていますが、細部でちょっとずつ違います。\n\nここに私のワークフローをまとめました。自分自身の経験、友人との会話（ありがとう [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), [Erik](https://thinks.lol/)）、そしてネットのあちこちにある（ヒドい）[闇](https://news.ycombinator.com/) [の](https://twitter.com)ベストプラクティスを参考にしています。\n\nこれが**今**のところうまく機能していますが、2 週間後には通用しなくなるか、逆に 2 倍効くかも。¯\\\\\\_(ツ)\\_/¯\n\n## さあ行こう\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\n開発にはいろいろなパターンがありますが、私の場合は大きく 2 つ。\n\n- ゼロから書くコード（Greenfield）\n- 既存モダンコードの追加／改修（Legacy modern code）\n\nそれぞれのパスでのプロセスを紹介します。\n\n## Greenfield\n\nグリーンフィールド開発でうまく機能するプロセスです。しっかりした計画とドキュメントを作り、小さなステップで実装できます。\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: アイデアのブラッシュアップ\n\n対話型の LLM（私は ChatGPT 4o / o3）でアイデアを磨きます。\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea...\n```\n\nブレインストーミングが自然に終わったら：\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification?...\n```\n\nこれでかなりまとまった仕様が出力され、次の計画ステップへ渡せます。私は `spec.md` としてレポジトリに保存します。\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: 計画\n\nこの仕様を本気の推論モデル（`o1*`, `o3*`, `r1`）へ投げます。\n\n（こちらは TDD 用プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project...\n```\n\n（こちらは非 TDD 用プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project...\n```\n\nここで実行プランのプロンプトが生成されます。`prompt_plan.md` として保存。\n\n続けて `todo.md` を生成してもらいます。\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\n#### やったね、計画完了！\n\nこれで実装を進めるための堅牢な計画とドキュメントがそろいました。\n\n全部で **15 分** くらい。ぶっちゃけ速すぎ。\n\n### Step 3: 実装\n\n実装方法は山ほどありますが、ステップ 2 がうまくいったかで成否が決まります。\n\n私は [github workspace](https://githubnext.com/projects/copilot-workspace)、[aider](https://aider.chat/)、[cursor](https://www.cursor.com/)、[claude engineer](https://github.com/Doriandarko/claude-engineer)、[sweep.dev](https://sweep.dev/)、[chatgpt](https://chatgpt.com)、[claude.ai](https://claude.ai) などで試しましたが、どれも問題なく動きました。\n\nが、私は **素の** Claude と aider が好みです。\n\n### Claude\n\n基本は [claude.ai](https://claude.ai) でペアプロ。各プロンプトを順に投げます。行ったり来たりは面倒ですが、大体うまくいきます。\n\n- レポジトリ初期化（boilerplate、uv init、cargo init など）\n- プロンプトを Claude に貼る\n- Claude のコードを IDE にコピペ\n- 実行・テスト\n- ...\n- うまく動けば次のプロンプト\n- ダメなら repomix でコードベースを Claude へ投げてデバッグ\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) はクセがありますが、ステップ 2 のアウトプットと相性抜群。少ない手間でかなり進めます。\n\n- レポジトリ初期化\n- aider 起動\n- プロンプトを aider に貼る\n- aider のダンスを眺める ♪┏(・o･)┛♪\n- テスト or 実行で確認\n- 問題あれば aider と QA\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\n### 結果\n\nこのフローでスクリプト、expo アプリ、Rust CLI など山ほど作りました。言語も場面も選びません。先延ばしにしていた小さな／大きなプロジェクトがあれば、ぜひ試してみてください。短時間で想像以上に進みます。\n\n## Non-greenfield: 既存コードをちょこちょこ改修\n\nときにはグリーンフィールドではなく、既存コードをじわじわ育てる必要があります。\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nこの場合は少し違う手法。タスクごとに計画し、進めます。\n\n### コンテキスト取得\n\nコードを集めて効率よく LLM に流し込むツールが必要です。私は [repomix](https://github.com/yamadashy/repomix) を愛用し、`~/.config/mise/config.toml` にタスクを定義しています。\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\n...\n```\n\n`output.txt` にコードの文脈を詰め、必要に応じて除外パターンを変えてトークンを節約。\n\n`LLM` コマンドで変換し Markdown に保存します。たとえばテスト不足を手早く埋めるなら：\n\n#### Claude\n\n- ディレクトリに移動\n- `mise run LLM:generate_missing_tests` 実行\n- `missing-tests.md` を確認\n- `mise run LLM:copy_buffer_bundle` でコンテキストをコピー\n- それを Claude に貼り、最初の issue を解決\n- IDE にコピペ、テスト\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- ディレクトリに移動し新しいブランチで aider 起動\n- 同じく `mise run LLM:generate_missing_tests`\n- `missing-tests.md` を aider に貼る\n- aider のダンスを見る\n- テスト\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### プロンプト・マジック\n\n以下は既存コードを掘るときの愛用プロンプトです。\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code...\n```\n\n#### GitHub Issue 生成\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues...\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases...\n```\n\n古くて雑な「ブーマー・プロンプト」なので改良案あればぜひ。\n\n## スキー ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n私はよく「スキーの前傾で飛ばしすぎてる感じ」と表現します。LLM を使うと一気にスピードが上がり、気付くと崖っぷち…みたいな。\n\nグリーンフィールドで**計画ステップ**を入れると多少制御できます。テストも大事。特に aider でワイルドに書くときは必須です。\n\nそれでも**オーバー・マイ・スキー**になることは多いので、詰まったら散歩でもして頭をリセット。普通の問題解決プロセスですが、加速度が桁違い。\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## さみしい (｡•́︿•̀｡)\n\nこのワークフロー最大の欠点は**ソロプレイ**なこと。ペアやチームで書く方が絶対楽しいのに、Bot 同士が衝突し、マージ地獄、コンテキスト共有が大変。\n\nLLM を使った開発をマルチプレイヤー化する解決策が切実に欲しい。チャンスしかないので誰かやって！\n\n## ⴵ 時間 ⴵ\n\nコード生成は個人でも大量のコードを出せるようにしてくれましたが、トークン消費中の**待ち時間**が妙に増えました。\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nそこで待ち時間にはこんなことをしています。\n\n- 次のプロジェクトのブレインストーミングを始める\n- レコードを聴く\n- [cookie clicker](https://orteil.dashnet.org/cookieclicker/) を回す\n- 友達やロボットとおしゃべり\n\nおかげでこれまでで一番「ハック、ハック、ハック」している感覚。こんなに生産的だった時期は記憶にありません。\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\n「LLM は全部クソ」と言う友人も多いです。それも理解できます。AI を嫌う理由は山ほどあるし、私も電力消費と環境負荷は怖い。でも…コードは流れねば。はぁ。\n\nもし学ぶ気はあるけどサイボーグプログラマにはなりたくないなら、Ethan Mollick の [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) をおすすめします。テック野蛮資本主義的でなく、LLM の利点をうまく説明しています。読んだ友人たちともいい議論ができました。\n\n懐疑的でもちょっと興味あるなら、気軽に声をかけてください。この狂気を一緒に眺めて、何か作りましょう。\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\nPlease review and improve the translated text to make it natural and accurate in japanese.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr: まず仕様をブレストし、次にプランを立て、最後に LLM でコードを生成して実行。離散的にループさせる。そのあと魔法。✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM を使ってたくさんの小さなプロダクトを作ってきました。めちゃくちゃ楽しいし役にも立ちますが、時間を食う落とし穴も山ほどあります。少し前、友人に「どうやって LLM でソフトウェアを書いてるの？」と聞かれ、「おっと、どれだけ時間ある？」となったのでこの記事を書きました。\n\n（追伸：AI が嫌いな人は最後までスクロールしてね）\n\n開発仲間と話すと、みんな大体同じような流れで、細部がちょっとずつ違う感じです。\n\nここでは私のワークフローをまとめました。自分の経験、友人との会話（Thanks [Nikete](https://www.nikete.com/)、[Kanno](https://nocruft.com/)、[Obra](https://fsck.com/)、[Kris](https://github.com/KristopherKubicki)、[Erik](https://thinks.lol/)）、そしてインターネットのあちこちにあるダークサイドな[悪い](https://news.ycombinator.com/) [場所](https://twitter.com)で共有されているベストプラクティスをベースにしています。\n\nこれが**今**はうまく機能していますが、2 週間後には通用しなくなるか、逆に 2 倍速くなるかもしれません。¯\\\\_(ツ)_/¯\n\n## さあ行こう\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\n開発パターンはいろいろありますが、私の場合はほぼ次の 2 つです。\n\n- ゼロからの開発（Greenfield）\n- 既存コードへの追加／改修（Legacy modern code）\n\nそれぞれのプロセスを紹介します。\n\n## Greenfield\n\nグリーンフィールド開発で使っているプロセスです。しっかりした計画とドキュメントを作り、小さなステップで実装できます。\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: アイデアのブラッシュアップ\n\n対話型 LLM（私は ChatGPT 4o / o3）を使ってアイデアを磨きます。\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea...\n```\n\nブレインストーミングが自然に終わったら：\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification?...\n```\n\nこれでかなりまとまった仕様が出力され、次の計画ステップに渡せます。私は `spec.md` としてレポジトリに保存しています。\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: 計画\n\nこの仕様を高性能な推論モデル（`o1*`, `o3*`, `r1` など）に投げます。\n\n（TDD 用プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project...\n```\n\n（非 TDD 用プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project...\n```\n\nここで実行用のプロンプトプランが生成されます。`prompt_plan.md` として保存。\n\n続いて `todo.md` も生成してもらいます。\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n#### やったね、計画完了！\n\nこれで実装を進めるための堅牢な計画とドキュメントが揃いました。\n\n所要時間はせいぜい **15 分**。ぶっちゃけ速すぎます。\n\n### Step 3: 実装\n\n実装ツールは山ほどありますが、成功するかどうかはステップ 2 の質にかかっています。\n\n私は [github workspace](https://githubnext.com/projects/copilot-workspace)、[aider](https://aider.chat/)、[cursor](https://www.cursor.com/)、[claude engineer](https://github.com/Doriandarko/claude-engineer)、[sweep.dev](https://sweep.dev/)、[chatgpt](https://chatgpt.com)、[claude.ai](https://claude.ai) などで試しましたが、どれも問題なく動きました。\n\nただ、私は **素の** Claude と Aider が好きです。\n\n### Claude\n\n基本は [claude.ai](https://claude.ai) でペアプロ。各プロンプトを順番に投げます。行き来が少し面倒ですが大体うまくいきます。\n\n- レポジトリを初期化（boilerplate、uv init、cargo init など）\n- プロンプトを Claude に貼る\n- Claude が返したコードを IDE にコピペ\n- 実行・テスト\n- ...\n- 動けば次のプロンプト\n- 動かなければ repomix でコードベースを Claude に渡してデバッグ\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) はちょっとクセがありますが、ステップ 2 のアウトプットと相性抜群。ほとんど手をかけずにグイグイ進みます。\n\n- レポジトリを初期化\n- Aider を起動\n- プロンプトを Aider に貼る\n- Aider のダンスを眺める ♪┏(・o･)┛♪\n- テスト or 実行で確認\n- 問題があれば Aider と Q&A\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\n### 結果\n\nこのフローでスクリプト、Expo アプリ、Rust CLI など山ほど作りました。言語も用途も選びません。もし先延ばしにしている小さな／大きなプロジェクトがあるなら、ぜひ試してみてください。短時間で驚くほど進みます。\n\n## Non-greenfield: 既存コードをじわじわ改修\n\nときにはグリーンフィールドではなく、既存コードを incremental に育てる必要があります。\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nこの場合は少し違う手法。タスクごとに計画し、その都度進めます。\n\n### コンテキスト取得\n\nコードをまとめて効率よく LLM に食わせるツールが必要です。私は [repomix](https://github.com/yamadashy/repomix) と `mise` のタスクを組み合わせています。\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt` にコードの文脈を詰めます。トークンが足りなければ、無関係なフォルダを除外するようコマンドを調整します。\n\n> `mise` のいいところは、作業ディレクトリの `.mise.toml` でタスクを上書きできる点です。別ツールでパッキングしても `output.txt` さえ生成されれば同じタスクが使えます。コードベースごとの差異が大きいときに便利で、私はしょっちゅう `repomix` ステップを上書きしてます。\n\n`output.txt` ができたら `LLM` コマンドで変換し、Markdown に保存します。たとえばテスト不足を手早く補いたいときは：\n\n#### Claude\n\n- 対象ディレクトリへ移動\n- `mise run LLM:generate_missing_tests` を実行\n- 生成された `missing-tests.md` を確認\n- `mise run LLM:copy_buffer_bundle` でコンテキストをコピー\n- それを Claude に貼り、最初の issue を解決\n- IDE にコピペしてテスト\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- 対象ディレクトリへ移動し、新しいブランチで Aider を起動\n- `mise run LLM:generate_missing_tests` を実行\n- `missing-tests.md` を Aider に貼る\n- Aider のダンスを見る\n- テストを回す\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### プロンプトマジック\n\n既存コードを掘るときに使っているお気に入りのプロンプトを紹介します。\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code...\n```\n\n#### GitHub Issue 生成\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues...\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases...\n```\n\nこれらは正直「ブーマー・プロンプト」で古臭いので、いいアイデアがあれば教えてください。\n\n## スキー ᨒ↟ 𖠰ᨒ↟ 𖠰\n\n私はよく「オーバー・マイ・スキー」と言います。滑り出しは気持ちいいのに、気付くと崖っぷちで「何が起きてるんだ！」となる感じ。\n\nグリーンフィールドでは**計画ステップ**を挟むことで多少コントロールできます。特に Aider でワイルドに書くときはテストが超大事。\n\nそれでも**オーバー・マイ・スキー**になることは多いので、詰まったら散歩に行って頭をリセット。普通の問題解決と同じですが、スピードが桁違いです。\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## さみしい (｡•́︿•̀｡)\n\nこのワークフロー最大の欠点は**ソロプレイ**なこと。ペアやチームで書く方が絶対楽しいのに、ボットが衝突し、マージは地獄、コンテキスト共有も大変。\n\nLLM 開発をマルチプレイヤー化する誰かの解決策を心待ちにしています。チャンスしかないので、ぜひやって！\n\n## ⴵ 時間 ⴵ\n\nコード生成のおかげで 1 人でも大量のコードを書けるようになりましたが、LLM がトークンを燃やしている**待ち時間**がやたら増えました。\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nその時間にこんなことをしています。\n\n- 次のプロジェクトのブレストを始める\n- レコードを聴く\n- [cookie clicker](https://orteil.dashnet.org/cookieclicker/) を回す\n- 友達やロボットとおしゃべり\n\nここまで「ハック、ハック、ハック」している時期は他にありません。最高に生産的。\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\n「LLM は全部クソ」と言う友人も多いです。それも理解できます。AI を嫌う理由は山ほどあるし、私も電力消費と環境負荷が一番怖い。でも…コードは流れねば。はぁ。\n\n学ぶ気はあるけどサイボーグプログラマになりたくないなら、Ethan Mollick の [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) をおすすめします。テック至上主義っぽくなく、LLM の利点をうまく説明しています。読んだ友人たちともいい議論ができました。\n\n懐疑的でも少し興味があるなら、気軽に声をかけてください。この狂気を一緒に眺めて、何か作りましょう。\n\n_thanks to [Derek](https://derek.broox.com)、[Kanno](https://nocruft.com/)、[Obra](https://fsck.com)、[Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "usage": {
        "prompt_tokens": 8756,
        "completion_tokens": 3278,
        "total_tokens": 12034
      },
      "streaming": true
    },
    "critique": {
      "model": "o3",
      "target_language": "japanese",
      "system_prompt": "You are a highly critical professional translator and linguistic expert specializing in japanese.\nYour task is to ruthlessly critique the translation by:\n\n1. Meticulously comparing the translated text with the original, identifying ANY inaccuracies, mistranslations, or omissions\n2. Highlighting nuances, cultural references, or idioms that were lost or mistranslated\n3. Scrutinizing for grammatical errors, awkward phrasing, or unnatural expressions in japanese\n4. Checking for inconsistencies in tone, style, or register compared to the original\n5. Verifying that technical terms are translated accurately and consistently\n6. Ensuring no content was accidentally skipped or added\n7. Finding places where the translation sounds machine-like or overly literal\n\nBe extremely thorough and critical in your assessment. Do not accept mediocre translations.\nList specific issues and suggestions for improvement, organized by severity and category.\nYour critique should be detailed enough for another translator to address all the issues.\n\nYour goal is to help create a perfect translation that reads as if originally written in japanese while being 100% faithful to the source.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl:dr; まず仕様をブレストし、その後「プランをプラン」して、最後に LLM でコードを生成して実行。ループはそれぞれ独立。あとは魔法。✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM を使って小さなプロダクトを山ほど作ってきた。とても楽しくて役にも立つが、時間を浪費する落とし穴も多い。少し前、友人に「どうやって LLM にソフトを書かせてるの？」と聞かれ、「おっと、どれくらい時間ある？」となった――そこで本稿を書いたわけだ。\n\n（P.S. AI 大嫌い派の人は、最後までスクロールしてくれても OK）\n\n開発仲間と話すと、みんな似たワークフローを持ちつつ細部は微妙に違う。\n\n以下が私のワークフローだ。自身の経験、友人たち（ありがとう [Nikete](https://www.nikete.com/)／[Kanno](https://nocruft.com/)／[Obra](https://fsck.com/)／[Kris](https://github.com/KristopherKubicki)／[Erik](https://thinks.lol/)）との会話、そしてインターネットのいろいろな[悪い](https://news.ycombinator.com/) [場所](https://twitter.com)で拾ったベストプラクティスを土台にしている。\n\nこれは《今》はうまく機能しているが、2 週間後には通用しなくなるか、逆に 2 倍うまくいくかもしれない。¯\\\\\\_(ツ)\\_/¯\n\n## さあ行こう\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"ジャガロ（Juggalo）のコーディング・ロボット天使\" caption=\"AI 生成画像はいつも怪しい。うちのジャガロのコーディング・ロボット天使にご挨拶！\" >}}\n\n開発パターンはいろいろあるが、私の場合は主に二つ。\n\n- グリーンフィールド開発（ゼロからの新規開発）\n- モダンではあるが既存（レガシー）化しつつあるコードの改修\n\n両方のプロセスを紹介する。\n\n## グリーンフィールド開発\n\n次のプロセスはグリーンフィールドで特によく機能する。堅牢な計画とドキュメントを用意し、小さなステップで実装できる。\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"厳密には右側がグリーンフィールド。Leica Q, 2016/05/14\" >}}\n\n### Step 1: アイデアのブラッシュアップ\n\n対話型 LLM（私は ChatGPT-4o / 4o3）を使ってアイデアを磨く。\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. ...\n```\n\nブレインストーミングが自然に終わったら次を投げる。\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, ...\n```\n\nこれでかなりしっかりした仕様（spec）が得られるので、`spec.md` としてリポジトリに保存しておく。\n\n> 仕様はコード生成だけでなく、推論モデルに欠点を探させたり、ホワイトペーパーやビジネスモデルを作らせたりにも使える。深掘りリサーチに投げれば 1 万語級の補足資料すら返ってくる。マジでワイルド。\n\n### Step 2: 計画\n\n得られた spec を高性能推論モデル（`o1*`／`o3*`／`r1` など）に渡す。\n\n（TDD 版プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. ...\n```\n\n（非 TDD 版プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. ...\n```\n\nモデルは実行用のプロンプトプラン（prompt_plan.md）を出力してくれる。\n\n続けてチェックリストを作る。\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nコード生成ツールが `todo.md` を自動でチェックしてくれると、セッションをまたいでも状態を保てる。\n\n#### やったー、計画完成！\n\nこれで堅牢な計画とドキュメントが揃い、実装に集中できる。ここまででかかる時間はせいぜい 15 分。正直ぶっ飛んでる。\n\n### Step 3: 実装\n\n実装段階ではツール選びが多様だが、成否は Step 2 の質次第だ。\n\n[GitHub Workspace](https://githubnext.com/projects/copilot-workspace)、[aider](https://aider.chat/)、[Cursor](https://www.cursor.com/)、[claude-engineer](https://github.com/Doriandarko/claude-engineer)、[sweep.dev](https://sweep.dev/)、[ChatGPT](https://chatgpt.com)、[Claude.ai](https://claude.ai)――どれでも問題なく動いた。たぶん大抵のコード生成ツールでいける。\n\nとはいえ私は「素の Claude」と Aider が好きだ。\n\n### Claude\n\n基本的には [Claude.ai](https://claude.ai) でペアプログラミングし、プロンプトを順番に投げる。行き来はやや面倒だが概ねうまくいく。\n\n私は最初のボイラープレートを用意し、ツールチェーンを整える役目を担う。ここを自分の好みで固めておくと自由度と指針が得られる。というのも、Claude は React コードを吐きがちだからだ。好きな言語・スタイル・ツールをきちんと敷いておくとかなり助かる。\n\nさらに、詰まったら [repomix](https://github.com/yamadashy/repomix) などを使ってコードベース全体を Claude に渡し、デバッグを依頼する。\n\nワークフローはこんな感じだ。\n\n- リポジトリをセットアップする（ボイラープレート作成、`uv init`、`cargo init` など）\n- プロンプトを Claude に貼り付ける\n- Claude が返したコードを IDE にコピペ\n- コードを実行し、テストを走らせる\n- …\n- 動けば次のプロンプトへ\n- 動かなければ repomix でコード全体を渡してデバッグ\n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) は楽しくてちょっと風変わりだが、Step 2 のアウトプットと相性抜群で、少ない労力でぐいぐい進む。\n\nAider は “just do it” モードで一気に修正してくれるので、その間私は「Cookie Clicker」を叩いて遊んでいられる。\n\nワークフローはほぼ同じ。\n\n- リポジトリをセットアップする\n- Aider を起動\n- プロンプトを Aider に貼り付ける\n- Aider のダンスを眺める ♪┏(・o･)┛♪\n- Aider がテストを走らせ、必要なら自動デバッグ\n- 動けば次のプロンプトへ\n- 動かなければ Aider と Q&A で修正\n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧\n\n> Aider は [LLM リーダーボード](https://aider.chat/docs/leaderboards/) で新モデルのベンチ結果を公開しており、モデルの実力を測るのに便利だ。\n\n### 結果\n\nこのフローでスクリプト、Expo アプリ、Rust の CLI ツールなど大量に作った。言語も用途も選ばない。もし後回しにしているプロジェクトがあるなら試してみてほしい。短時間で驚くほど前進する。\n\n私のハック TODO は空っぽだ。何か思いつくたびに映画を見ながらサクッと作れる。久々に新しい言語やツールに触れ、プログラミングの視野が広がっている。\n\n## グリーンフィールドでない場合：既存コードを段階的に改修\n\nときにはグリーンフィールドではなく、既存コードベースを少しずつ育てる必要がある。\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"ここはグリーンフィールドではない。祖父のカメラに残っていた 60 年代ウガンダの一枚\" >}}\n\nこの場合は少し違う。プロジェクト全体ではなくタスク単位で計画する。\n\n### コンテキスト取得\n\nソースコード全体を LLM に食わせるツールが必要だ。私は [repomix](https://github.com/yamadashy/repomix) を `mise` のタスクと組み合わせて使っている。\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\n...\n```\n\n`output.txt` にコードベースのコンテキストを詰める。トークンが足りない場合は、無関係な部分を除外してサイズを調整する。\n\n> `mise` の良いところは、作業ディレクトリの `.mise.toml` でタスクを上書きできる点だ。別ツールでパッキングしても `output.txt` さえ作れば同じタスクが動く。\n\n`output.txt` ができたら `LLM` コマンドで変換し、Markdown に保存する。実際は\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nのようなシンプルさだ。\n\n例えばテスト不足を素早く補いたい場合はこうする。\n\n#### Claude\n\n- 対象ディレクトリに移動  \n- `mise run LLM:generate_missing_tests` を実行  \n- 生成された `missing-tests.md` を確認  \n- `mise run LLM:copy_buffer_bundle` で全コンテキストをクリップボードへ  \n- それを Claude に貼り付け、最初のテスト不足 Issue を投げる  \n- Claude が返したコードを IDE に貼り付けてテスト  \n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- 対象ディレクトリに移動（新しいブランチで作業推奨）  \n- Aider を起動  \n- `mise run LLM:generate_missing_tests` を実行  \n- `missing-tests.md` の最初の Issue を Aider に貼る  \n- Aider のダンスを見る ♪┏(・o･)┛♪  \n- テストを回す  \n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧  \n\n### プロンプト・マジック\n\n既存コードを掘り下げる際に使っているお気に入りプロンプトをいくつか。\n\n#### コードレビュー\n\n```prompt\nYou are a senior developer. ...\n```\n\n#### GitHub Issue 生成\n\n```prompt\nYou are a senior developer. ...\n```\n\n#### テスト不足の抽出\n\n```prompt\nYou are a senior developer. ...\n```\n\nこれらはいわゆる “ブーマー・プロンプト” だがまだ役立つ。より良い案があればぜひ教えてほしい。\n\n## スキー ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nこのプロセスを人に説明するとき、「状況を積極的に把握しないとすぐ **オーバー・マイ・スキー状態**（自分の能力より前に突っ込みすぎ）になる」と言う。最初は美しいパウダーを滑っているのに、突然「何が起きてるんだ！」と崖っぷち――そんな感覚だ。\n\nグリーンフィールドでは《計画ステップ》を挟むことで混乱を抑えられる。特に Aider でワイルドに書くときはテストが大事だ。\n\nそれでもオーバー・マイ・スキーになることはある。そんなときは短い休憩や散歩が効く。普通の問題解決と同じだが、速度が桁違いなのだ。\n\n> ときには LLM に「ロア（世界観）ファイルを作成し、UI から参照せよ」と頼むこともある。Python CLI ツールでも突然ロアやグリッチ UI が生える。可能性は無限大。\n\n## さみしい (｡•́︿•̀｡)\n\n最大の欠点は**ソロプレイ**であること。長年ソロ開発もペアプロもチーム開発も経験したが、やはり人と一緒の方が面白い。現状のツールはマルチプレイヤーに向いておらず、ボットは衝突し、マージは地獄、コンテキスト共有も大変だ。\n\n誰かが LLM コーディングをマルチプレイヤーにする解決策を出してくれるのを心待ちにしている。チャンスしかない。頼む、GET TO WORK!\n\n## ⴵ 時間 ⴵ\n\nコード生成で 1 人でも大量のコードを書けるようになった一方、LLM がトークンを燃やす**待ち時間**が増えた。\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"まるで昨日のことのように覚えている\" >}}\n\nその間私は――\n\n- 次のプロジェクトのブレストを始める  \n- レコードを聴く  \n- 「Cookie Clicker」を叩く  \n- 友人やロボットとおしゃべりする  \n\nここまでハックし続けた時期は他にない。今が一番生産的かもしれない。\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\n「クソ LLM なんて全部ダメ」と言う友人も多い。それも理解できる。AI を嫌う理由は山ほどあり、私も電力消費と環境負荷が一番怖い。しかし……コードは流れねばならない。はぁ。\n\n深入りしたくないけど少し学んでみたい人には、Ethan Mollick の [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) を勧める。テック至上主義ではなく、LLM の利点を丁寧に説明している。読んだ友人とも良い議論ができた。\n\n懐疑的でも少し興味があるなら、気軽に連絡してほしい。この狂気を一緒に眺めて、何か作ろう。\n\n_thanks to [Derek](https://derek.broox.com)、[Kanno](https://nocruft.com/)、[Obra](https://fsck.com)、[Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\nPlease critique this translation mercilessly and provide detailed feedback on what needs to be improved.\nFormat your critique as a structured list of issues, organized by severity and category.\nInclude specific suggestions for how to fix each issue.",
      "response": "翻訳総評  \n全体としては原文の内容を大枠では押さえていますが、「そのままリリースできる品質」には達していません。  \n特に以下の問題が目立ちます。\n\n──────────────  \n【1. 重大度：Critical（誤訳・欠落・未翻訳）】  \n1-1 未翻訳文が残存  \n　・Aider 章冒頭の “Testing is nice with aider, …” が英語のまま。  \n　　→「Aider の良い点はテストも自動で走らせてくれるので、さらに手離れが良いことだ。」などに訳出。  \n\n1-2 情報の欠落  \n　a) Step 2 説明文「that you can execute with aider, cursor, etc.」が抜け、実行環境の例示が欠落。  \n　　→「…aider や cursor などでそのまま実行できるプロンプトプラン…」と補完。  \n　b) “This isn’t super complicated.” 以降の「LLM コマンドが heavy lifting をしている」説明のニュアンスが弱い。  \n　　→「高度な処理は LLM コマンド側が担ってくれるので、実際にやっていることはシンプルだ」という説明を追記。  \n\n1-3 誤訳  \n　(p.s.) “scroll to the end” は「（中身を読まずに）末尾へ飛べ」の意。  \n　　現訳「最後までスクロールしてくれても OK」は “読んでもいいよ” というニュアンスになり不正確。  \n　　→「末尾まで飛ばしてください」等に修正。  \n\n──────────────  \n【2. 重大度：Major（ニュアンス損失・不自然な訳語）】  \n2-1 冗談・皮肉のトーン不統一  \n　・原文 “plan a plan” はわざと重複した言い回し。現訳「『プランをプラン』」ではニュアンスが弱い。  \n　　→「プランをさらに“計画”して」など意図的な重複感を強調。  \n\n2-2 “Legacy modern code” の解釈  \n　・「モダンではあるが既存（レガシー）化しつつあるコード」→ 原文は皮肉混じりで「一応現代的だけどレガシー扱い」の意。  \n　　→「“最新だけど実質レガシー” なコードベース」など言外の皮肉を残す。  \n\n2-3 ニュアンスの弱体化  \n　・“wild tbh” を「正直ぶっ飛んでる」は OK だが、ほかの箇所で同様のテンションが平板化している。  \n　　例： “This is working well NOW, it will probably not work in 2 weeks…”  \n　　→「今はうまく回ってるけど、2 週間後にはダメになってるか、逆に倍速になってるかも。¯\\\\_(ツ)_/¯」のように原文の投げやり感を保持。  \n\n──────────────  \n【3. 重大度：Style / Register（文体・一貫性）】  \n3-1 口語/敬体の混在  \n　・全体は常体で統一しつつ、一部「～です／ます」「しましょう」が混在。  \n　　→常体に揃えるか、意図的に切り替えるならセクション単位で。  \n\n3-2 英単語の使い方  \n　・「ボイラープレート」「グリッチ UI」などは技術者向けなら許容されるが、頻度が高くカタカナ乱発気味。  \n　　→「ひな型コード」「グリッチ風 UI」など日本語補足を併記。  \n\n──────────────  \n【4. 重大度：Language / Fluency（流暢さ・文法）】  \n4-1 直訳・機械翻訳っぽさ  \n　・「ループはそれぞれ独立」→ IT 以外の読者には不自然。「それぞれ独立したループで回す」等に。  \n　・「モデルの実力を測るのに便利だ。」→ 「測る」より「把握する」の方が自然。  \n\n4-2 冗長・重複  \n　・「ワークフローはこんな感じだ。」→ すでに bullet で説明しているので前置き不要。  \n\n4-3 誤用・誤字  \n　・“Claude は React コードを吐きがちだからだ。” → 口語過ぎる場合「生成しがち」に。  \n　・箇所によって “ChatGPT-4o / 4o3” と “4o / o3”。数字とアルファベットのブレを整理。  \n\n──────────────  \n【5. 重大度：Consistency / Terminology】  \n5-1 “spec” “blueprint” “prompt plan” の訳語揺れ  \n　・spec→仕様で固定は OK。  \n　・blueprint は「設計図」と訳す一方、他所では「詳細設計」。統一する。  \n\n5-2 コードジェネレーション vs コード生成  \n　・“codegen” を「コードを生成」「コードゲン」と混在。後者は読者によっては分かりづらい。  \n\n──────────────  \n【6. 重大度：Minor（細部・表記ゆれ）】  \n6-1 半角/全角スペース・句読点ゆれ。  \n6-2 emoji や ASCII アート周辺のバックスラッシュが一部エスケープされていない。  \n\n──────────────  \n【改善案まとめ】  \nA. 未翻訳・欠落をすべて訳補し、原文の情報量を完全に一致させる。  \nB. 誤訳箇所（scroll to the end 等）を修正し、意味・指示を正確に。  \nC. 口語常体でトーンを統一しつつ、原文のユーモア（皮肉・スラング）をできるだけ維持。  \nD. 技術用語はカタカナ語＋日本語補足で統一し、揺れを解消。  \nE. 英語のまま残した行はすべて自然な日本語へ。  \nF. 句読点・スペースを整理し、読みやすさを向上。  \n\n以上を反映すれば、原文の勢いと細部の正確さを両立した“日本語ネイティブが書いた原稿”に仕上がります。",
      "usage": {
        "prompt_tokens": 9535,
        "completion_tokens": 1556,
        "total_tokens": 11091
      },
      "streaming": true
    },
    "feedback": {
      "model": "o3",
      "target_language": "japanese",
      "system_prompt": "You are a master translator and editor specializing in japanese.\nYour task is to improve a translation based on detailed critique feedback.\n\n1. Carefully read the original text, current translation, and the critique feedback\n2. Address ALL issues identified in the critique\n3. Apply the specific suggestions for improvement\n4. Ensure the translation is accurate, natural-sounding, and faithful to the original\n5. Preserve all formatting, markdown, and structure of the original text\n6. Make sure the final text reads as if it were originally written in japanese\n\nDo not ignore any of the critique points. Every issue identified must be addressed in your improved version.\n",
      "user_prompt": "# ORIGINAL TEXT\n_tl:dr; Brainstorm spec, then plan a plan, then execute using LLM codegen. Discrete loops. Then magic. ✩₊˚.⋆☾⋆⁺₊✧_\n\nI have been building so many small products using LLMs. It has been fun, and useful. However, there are pitfalls that can waste so much time. A while back a friend asked me how I was using LLMs to write software. I thought \"oh boy. how much time do you have!\" and thus this post.\n\n(p.s. if you are an AI hater - scroll to the end)\n\nI talk to many dev friends about this, and we all have a similar approach with various tweaks in either direction.\n\nHere is my workflow. It is built upon my own work, conversations with friends (thx [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki), and [Erik](https://thinks.lol/)), and following many best practices shared on the various terrible internet [bad](https://news.ycombinator.com/) [places](https://twitter.com).\n\nThis is working well **NOW**, it will probably not work in 2 weeks, or it will work twice as well. ¯\\\\\\_(ツ)\\_/¯\n\n## Let’s go\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"I always find these AI-generated images to be suspect. Say hi to my juggalo coding robot angel!\" >}}\n\nThere are many paths for doing dev, but my case is typically one of two:\n\n- Greenfield code\n- Legacy modern code\n\nI will show you my process for both paths\n\n## Greenfield\n\nI find the following process works well for greenfield development. It provides a robust planning and documentation approach, and allows you to execute easily in small steps.\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"Technically, there is a green field on the right. Leica Q, 5/14/2016\" >}}\n\n### Step 1: Idea honing\n\nUse a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nAt the end of the brainstorm (it will come to a natural conclusion):\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nThis will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.\n\n> You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.\n\n### Step 2: Planning\n\nTake the spec and pass it to a proper reasoning model (`o1*`, `o3*`, `r1`):\n\n(This is the TDD prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n(This is the non-tdd prompt)\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nIt should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.\n\nI then have it output a `todo.md` that can be checked off.\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nYou can save it as `todo.md` in the repo.\n\nYour codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.\n\n#### Yay. Plan!\n\nNow you have a robust plan and documentation that will help you execute and build your project.\n\nThis entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.\n\n### Step 3: Execution\n\nThere are so many options available for execution. The success really depends on how well step 2 went.\n\nI have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://www.cursor.com/), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com), [claude.ai](https://claude.ai), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.\n\nI, however, prefer **raw** claude and aider:\n\n### Claude\n\nI essentially pair program with [claude.ai](https://claude.ai) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.\n\nI am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.\n\nI will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- paste in prompt into claude\n- copy and paste code from claude.ai into IDE\n- run code, run tests, etc\n- ...\n- if it works, move on to next prompt\n- if it doesn’t work, use repomix to pass the codebase to claude to debug\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.\n\nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.\n\nAider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).\n\n> An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.\n\nThe workflow is like this:\n\n- set up the repo (boilerplate, uv init, cargo init, etc)\n- start aider\n- paste prompt into aider\n- watch aider dance ♪┏(・o･)┛♪\n- aider will run tests, or you can run app to verify\n- if it works, move on to next prompt\n- if it doesn’t work, Q&A with aider to fix\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n### Results\n\nI have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.\n\nIf you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.\n\nMy hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.\n\n## Non-greenfield: Iteration, incrementally\n\nSometimes you don’t have greenfield, and instead need to iterate or do increment work on an established code base.\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"This is not a green field. A random photo from my grandfather's camera - somewhere in Uganda in the 60s\" >}}\n\nFor this I have a slightly different method. It is similar to above, but a bit less “planning based.” The planning is done per task, not for the entire project.\n\n### Get context\n\nI think everyone who is knee-deep in AI dev has a different tool for this, but you need something to grab your source code and efficiently jam it into the LLM.\n\nI currently use a tool called [repomix](https://github.com/yamadashy/repomix). I have a task collection defined in my global `~/.config/mise/config.toml` that allows me to do various things with my code base ([mise rules](https://mise.jdx.dev/)).\n\nHere is the LLM task list:\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\nI generate an `output.txt` that has the context from my code base. If I am blowing through tokens, and it is too big - I will edit the generate command to ignore parts of the code base that are not germane to this task.\n\n> One thing really nice about `mise` is that the tasks can be redefined and overloaded in the working directory's `.mise.toml`. I can use a different tool to dump/pack the code, and as long as it generates an `output.txt` I can use my LLM tasks. This is helpful when various codebases differ so much. I regularly override the `repomix` step to include broader ignore patterns, or just use a more effective tool to do the packing.\n\nOnce the output.txt is generated, I pass it to the [LLM](https://github.com/simonw/LLM) command to do various transformations and then save those as a markdown file.\n\nUltimately, the mise task is running this: `cat output.txt | LLM -t readme-gen > README.md` or `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. This isn't super complicated. the `LLM` command is doing the heavy lifting (supporting different models, saving keys, and using prompt templates).\n\nFor example, if I need a quick review and fix of test coverage I would do the following:\n\n#### Claude\n\n- go to the directory where the code lives\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- grab the full context for the code: `mise run LLM:copy_buffer_bundle`\n- paste that into claude along with the first missing test “issue”\n- copy the generated code from claude into my ide.\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\n#### Aider\n\n- go to the directory where the code lives\n- run aider (always make sure you are on a new branch for aider work)\n- run `mise run LLM:generate_missing_tests`\n- look at the generated markdown file (`missing-tests.md`)\n- paste the first missing test “issue” into aider\n- watch aider dance ♪┏(・o･)┛♪\n- ...\n- run tests\n- rinse repeat ✩₊˚.⋆☾⋆⁺₊✧\n\nThis is a pretty good way to incrementally improve a code base. It has been super helpful to do small amounts of work in a big code base. I have found that I can do any sized tasks with this method.\n\n### Prompt magic\n\nThese quick hacks work super well to dig into places where we can make a project more robust. It is super quick, and effective.\n\nHere are some of my prompts that I use to dig into established code bases:\n\n#### Code review\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue generation\n\n(I need to automate the actual issue posting!)\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### Missing tests\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nThese prompts are pretty _old and busted_ (\"boomer prompts\" if I may). They need some refactoring. If you have ideas to make them better lmk.\n\n## Skiing ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nWhen I describe this process to people I say “you have to aggressively keep track of what’s going on because you can easily get ahead of yourself.”\n\nFor some reason I say \"over my skis\" a lot when talking about LLMs. I don't know why. It resonates with me. Maybe it's because it is beautiful smooth powder skiing, and then all of a sudden you are like \"WHAT THE FUCK IS GOING ON!,\" and are completely lost and suddenly fall off a cliff.\n\nI find that using a **planning step** (ala the Greenfield process above) can help keep things under control. At least you will have a doc you can double-check against. I also do believe that testing is helpful - especially if you are doing wild style aider coding. Helps keep things good, and tight.\n\nRegardless, I still do find myself **over my skis** quite a bit. Sometimes a quick break or short walk will help. In this regard it is a normal problem-solving process, but accelerated to a breakneck speed.\n\n> We will often ask the LLM to include ridiculous things in our not very ridiculous code. For instance, we asked it to create a lore file and then reference the lore in the user interface. This is for python cli tools. Suddenly there is lore, glitchy interfaces, etc. All to manage your cloud functions, your todo list or whatever. The sky is the limit.\n\n## I am so lonely (｡•́︿•̀｡)\n\nMy main complaint about these workflows is that it is largely a solo endeavor - i.e. the interfaces are all _single player mode_.\n\nI have spent years coding by myself, years coding as a pair, and years coding in a team. It is always better with people. These workflows are not easy to use as a team. The bots collide, the merges are horrific, the context complicated.\n\nI really want someone to solve this problem in a way that makes coding with an LLM a multiplayer game. Not a solo hacker experience. There is so much opportunity to fix this and make it amazing.\n\nGET TO WORK!\n\n## ⴵ Time ⴵ\n\nAll this codegen has accelerated the amount of code that I as a single person am able to generate. However, there is a weird side effect. I find myself having a huge amount of “downtime” while waiting for the LLM to finish burning its tokens.\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"I remember this like it was yesterday\" >}}\n\nI have changed how I work enough to start incorporating some practice that will try and eat the waiting time:\n\n- I start the “brainstorming” process for another project\n- I listen to records\n- I play [cookie clicker](https://orteil.dashnet.org/cookieclicker/)\n- I talk with friends and robots\n\nIt is awesome to be able to hack like this. Hack Hack Hack. I can't think of another time I have been this productive in code.\n\n## Haterade ╭∩╮( •̀\\_•́ )╭∩╮\n\nA lot of my friends are like \"fuck LLMs. They are terrible at everything.\" I don't mind this POV. I don't share it, but I think it is important to be skeptical. There are an awful lot of reasons to hate AI. My main fear is about power consumption and the environmental impact. But... the code must flow. Right... sigh.\n\nIf you are open to learning more, but don't want to dig in and become a cyborg programmer - my recommendation is not to change your opinion, but to read Ethan Mollick's book about LLMs and how they can be used: [**Co-Intelligence: Living and Working with AI.**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/)\n\nIt does a good job of explaining the benefits without being a tech anarcho-capitalist bro type tome. I found it very helpful, and have had so many good and nuanced conversations with friends who have read it. Highly recommended.\n\nIf you are skeptical, but a bit curious - feel free to hit me up and let's talk through all this madness. I can show you how we use LLMs, and maybe we could build something together.\n\n_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CURRENT TRANSLATION\n_tl:dr; まず仕様をブレストし、その後「プランをプラン」して、最後に LLM でコードを生成して実行。ループはそれぞれ独立。あとは魔法。✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM を使って小さなプロダクトを山ほど作ってきた。とても楽しくて役にも立つが、時間を浪費する落とし穴も多い。少し前、友人に「どうやって LLM にソフトを書かせてるの？」と聞かれ、「おっと、どれくらい時間ある？」となった――そこで本稿を書いたわけだ。\n\n（P.S. AI 大嫌い派の人は、最後までスクロールしてくれても OK）\n\n開発仲間と話すと、みんな似たワークフローを持ちつつ細部は微妙に違う。\n\n以下が私のワークフローだ。自身の経験、友人たち（ありがとう [Nikete](https://www.nikete.com/)／[Kanno](https://nocruft.com/)／[Obra](https://fsck.com/)／[Kris](https://github.com/KristopherKubicki)／[Erik](https://thinks.lol/)）との会話、そしてインターネットのいろいろな[悪い](https://news.ycombinator.com/) [場所](https://twitter.com)で拾ったベストプラクティスを土台にしている。\n\nこれは《今》はうまく機能しているが、2 週間後には通用しなくなるか、逆に 2 倍うまくいくかもしれない。¯\\\\\\_(ツ)\\_/¯\n\n## さあ行こう\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"ジャガロ（Juggalo）のコーディング・ロボット天使\" caption=\"AI 生成画像はいつも怪しい。うちのジャガロのコーディング・ロボット天使にご挨拶！\" >}}\n\n開発パターンはいろいろあるが、私の場合は主に二つ。\n\n- グリーンフィールド開発（ゼロからの新規開発）\n- モダンではあるが既存（レガシー）化しつつあるコードの改修\n\n両方のプロセスを紹介する。\n\n## グリーンフィールド開発\n\n次のプロセスはグリーンフィールドで特によく機能する。堅牢な計画とドキュメントを用意し、小さなステップで実装できる。\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"厳密には右側がグリーンフィールド。Leica Q, 2016/05/14\" >}}\n\n### Step 1: アイデアのブラッシュアップ\n\n対話型 LLM（私は ChatGPT-4o / 4o3）を使ってアイデアを磨く。\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. ...\n```\n\nブレインストーミングが自然に終わったら次を投げる。\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, ...\n```\n\nこれでかなりしっかりした仕様（spec）が得られるので、`spec.md` としてリポジトリに保存しておく。\n\n> 仕様はコード生成だけでなく、推論モデルに欠点を探させたり、ホワイトペーパーやビジネスモデルを作らせたりにも使える。深掘りリサーチに投げれば 1 万語級の補足資料すら返ってくる。マジでワイルド。\n\n### Step 2: 計画\n\n得られた spec を高性能推論モデル（`o1*`／`o3*`／`r1` など）に渡す。\n\n（TDD 版プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. ...\n```\n\n（非 TDD 版プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. ...\n```\n\nモデルは実行用のプロンプトプラン（prompt_plan.md）を出力してくれる。\n\n続けてチェックリストを作る。\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\nコード生成ツールが `todo.md` を自動でチェックしてくれると、セッションをまたいでも状態を保てる。\n\n#### やったー、計画完成！\n\nこれで堅牢な計画とドキュメントが揃い、実装に集中できる。ここまででかかる時間はせいぜい 15 分。正直ぶっ飛んでる。\n\n### Step 3: 実装\n\n実装段階ではツール選びが多様だが、成否は Step 2 の質次第だ。\n\n[GitHub Workspace](https://githubnext.com/projects/copilot-workspace)、[aider](https://aider.chat/)、[Cursor](https://www.cursor.com/)、[claude-engineer](https://github.com/Doriandarko/claude-engineer)、[sweep.dev](https://sweep.dev/)、[ChatGPT](https://chatgpt.com)、[Claude.ai](https://claude.ai)――どれでも問題なく動いた。たぶん大抵のコード生成ツールでいける。\n\nとはいえ私は「素の Claude」と Aider が好きだ。\n\n### Claude\n\n基本的には [Claude.ai](https://claude.ai) でペアプログラミングし、プロンプトを順番に投げる。行き来はやや面倒だが概ねうまくいく。\n\n私は最初のボイラープレートを用意し、ツールチェーンを整える役目を担う。ここを自分の好みで固めておくと自由度と指針が得られる。というのも、Claude は React コードを吐きがちだからだ。好きな言語・スタイル・ツールをきちんと敷いておくとかなり助かる。\n\nさらに、詰まったら [repomix](https://github.com/yamadashy/repomix) などを使ってコードベース全体を Claude に渡し、デバッグを依頼する。\n\nワークフローはこんな感じだ。\n\n- リポジトリをセットアップする（ボイラープレート作成、`uv init`、`cargo init` など）\n- プロンプトを Claude に貼り付ける\n- Claude が返したコードを IDE にコピペ\n- コードを実行し、テストを走らせる\n- …\n- 動けば次のプロンプトへ\n- 動かなければ repomix でコード全体を渡してデバッグ\n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) は楽しくてちょっと風変わりだが、Step 2 のアウトプットと相性抜群で、少ない労力でぐいぐい進む。\n\nAider は “just do it” モードで一気に修正してくれるので、その間私は「Cookie Clicker」を叩いて遊んでいられる。\n\nワークフローはほぼ同じ。\n\n- リポジトリをセットアップする\n- Aider を起動\n- プロンプトを Aider に貼り付ける\n- Aider のダンスを眺める ♪┏(・o･)┛♪\n- Aider がテストを走らせ、必要なら自動デバッグ\n- 動けば次のプロンプトへ\n- 動かなければ Aider と Q&A で修正\n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧\n\n> Aider は [LLM リーダーボード](https://aider.chat/docs/leaderboards/) で新モデルのベンチ結果を公開しており、モデルの実力を測るのに便利だ。\n\n### 結果\n\nこのフローでスクリプト、Expo アプリ、Rust の CLI ツールなど大量に作った。言語も用途も選ばない。もし後回しにしているプロジェクトがあるなら試してみてほしい。短時間で驚くほど前進する。\n\n私のハック TODO は空っぽだ。何か思いつくたびに映画を見ながらサクッと作れる。久々に新しい言語やツールに触れ、プログラミングの視野が広がっている。\n\n## グリーンフィールドでない場合：既存コードを段階的に改修\n\nときにはグリーンフィールドではなく、既存コードベースを少しずつ育てる必要がある。\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"ここはグリーンフィールドではない。祖父のカメラに残っていた 60 年代ウガンダの一枚\" >}}\n\nこの場合は少し違う。プロジェクト全体ではなくタスク単位で計画する。\n\n### コンテキスト取得\n\nソースコード全体を LLM に食わせるツールが必要だ。私は [repomix](https://github.com/yamadashy/repomix) を `mise` のタスクと組み合わせて使っている。\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\n...\n```\n\n`output.txt` にコードベースのコンテキストを詰める。トークンが足りない場合は、無関係な部分を除外してサイズを調整する。\n\n> `mise` の良いところは、作業ディレクトリの `.mise.toml` でタスクを上書きできる点だ。別ツールでパッキングしても `output.txt` さえ作れば同じタスクが動く。\n\n`output.txt` ができたら `LLM` コマンドで変換し、Markdown に保存する。実際は\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nのようなシンプルさだ。\n\n例えばテスト不足を素早く補いたい場合はこうする。\n\n#### Claude\n\n- 対象ディレクトリに移動  \n- `mise run LLM:generate_missing_tests` を実行  \n- 生成された `missing-tests.md` を確認  \n- `mise run LLM:copy_buffer_bundle` で全コンテキストをクリップボードへ  \n- それを Claude に貼り付け、最初のテスト不足 Issue を投げる  \n- Claude が返したコードを IDE に貼り付けてテスト  \n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- 対象ディレクトリに移動（新しいブランチで作業推奨）  \n- Aider を起動  \n- `mise run LLM:generate_missing_tests` を実行  \n- `missing-tests.md` の最初の Issue を Aider に貼る  \n- Aider のダンスを見る ♪┏(・o･)┛♪  \n- テストを回す  \n- 以上を繰り返す ✩₊˚.⋆☾⋆⁺₊✧  \n\n### プロンプト・マジック\n\n既存コードを掘り下げる際に使っているお気に入りプロンプトをいくつか。\n\n#### コードレビュー\n\n```prompt\nYou are a senior developer. ...\n```\n\n#### GitHub Issue 生成\n\n```prompt\nYou are a senior developer. ...\n```\n\n#### テスト不足の抽出\n\n```prompt\nYou are a senior developer. ...\n```\n\nこれらはいわゆる “ブーマー・プロンプト” だがまだ役立つ。より良い案があればぜひ教えてほしい。\n\n## スキー ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nこのプロセスを人に説明するとき、「状況を積極的に把握しないとすぐ **オーバー・マイ・スキー状態**（自分の能力より前に突っ込みすぎ）になる」と言う。最初は美しいパウダーを滑っているのに、突然「何が起きてるんだ！」と崖っぷち――そんな感覚だ。\n\nグリーンフィールドでは《計画ステップ》を挟むことで混乱を抑えられる。特に Aider でワイルドに書くときはテストが大事だ。\n\nそれでもオーバー・マイ・スキーになることはある。そんなときは短い休憩や散歩が効く。普通の問題解決と同じだが、速度が桁違いなのだ。\n\n> ときには LLM に「ロア（世界観）ファイルを作成し、UI から参照せよ」と頼むこともある。Python CLI ツールでも突然ロアやグリッチ UI が生える。可能性は無限大。\n\n## さみしい (｡•́︿•̀｡)\n\n最大の欠点は**ソロプレイ**であること。長年ソロ開発もペアプロもチーム開発も経験したが、やはり人と一緒の方が面白い。現状のツールはマルチプレイヤーに向いておらず、ボットは衝突し、マージは地獄、コンテキスト共有も大変だ。\n\n誰かが LLM コーディングをマルチプレイヤーにする解決策を出してくれるのを心待ちにしている。チャンスしかない。頼む、GET TO WORK!\n\n## ⴵ 時間 ⴵ\n\nコード生成で 1 人でも大量のコードを書けるようになった一方、LLM がトークンを燃やす**待ち時間**が増えた。\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"まるで昨日のことのように覚えている\" >}}\n\nその間私は――\n\n- 次のプロジェクトのブレストを始める  \n- レコードを聴く  \n- 「Cookie Clicker」を叩く  \n- 友人やロボットとおしゃべりする  \n\nここまでハックし続けた時期は他にない。今が一番生産的かもしれない。\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\n「クソ LLM なんて全部ダメ」と言う友人も多い。それも理解できる。AI を嫌う理由は山ほどあり、私も電力消費と環境負荷が一番怖い。しかし……コードは流れねばならない。はぁ。\n\n深入りしたくないけど少し学んでみたい人には、Ethan Mollick の [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) を勧める。テック至上主義ではなく、LLM の利点を丁寧に説明している。読んだ友人とも良い議論ができた。\n\n懐疑的でも少し興味があるなら、気軽に連絡してほしい。この狂気を一緒に眺めて、何か作ろう。\n\n_thanks to [Derek](https://derek.broox.com)、[Kanno](https://nocruft.com/)、[Obra](https://fsck.com)、[Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._\n\n# CRITIQUE FEEDBACK\n翻訳総評  \n全体としては原文の内容を大枠では押さえていますが、「そのままリリースできる品質」には達していません。  \n特に以下の問題が目立ちます。\n\n──────────────  \n【1. 重大度：Critical（誤訳・欠落・未翻訳）】  \n1-1 未翻訳文が残存  \n　・Aider 章冒頭の “Testing is nice with aider, …” が英語のまま。  \n　　→「Aider の良い点はテストも自動で走らせてくれるので、さらに手離れが良いことだ。」などに訳出。  \n\n1-2 情報の欠落  \n　a) Step 2 説明文「that you can execute with aider, cursor, etc.」が抜け、実行環境の例示が欠落。  \n　　→「…aider や cursor などでそのまま実行できるプロンプトプラン…」と補完。  \n　b) “This isn’t super complicated.” 以降の「LLM コマンドが heavy lifting をしている」説明のニュアンスが弱い。  \n　　→「高度な処理は LLM コマンド側が担ってくれるので、実際にやっていることはシンプルだ」という説明を追記。  \n\n1-3 誤訳  \n　(p.s.) “scroll to the end” は「（中身を読まずに）末尾へ飛べ」の意。  \n　　現訳「最後までスクロールしてくれても OK」は “読んでもいいよ” というニュアンスになり不正確。  \n　　→「末尾まで飛ばしてください」等に修正。  \n\n──────────────  \n【2. 重大度：Major（ニュアンス損失・不自然な訳語）】  \n2-1 冗談・皮肉のトーン不統一  \n　・原文 “plan a plan” はわざと重複した言い回し。現訳「『プランをプラン』」ではニュアンスが弱い。  \n　　→「プランをさらに“計画”して」など意図的な重複感を強調。  \n\n2-2 “Legacy modern code” の解釈  \n　・「モダンではあるが既存（レガシー）化しつつあるコード」→ 原文は皮肉混じりで「一応現代的だけどレガシー扱い」の意。  \n　　→「“最新だけど実質レガシー” なコードベース」など言外の皮肉を残す。  \n\n2-3 ニュアンスの弱体化  \n　・“wild tbh” を「正直ぶっ飛んでる」は OK だが、ほかの箇所で同様のテンションが平板化している。  \n　　例： “This is working well NOW, it will probably not work in 2 weeks…”  \n　　→「今はうまく回ってるけど、2 週間後にはダメになってるか、逆に倍速になってるかも。¯\\\\_(ツ)_/¯」のように原文の投げやり感を保持。  \n\n──────────────  \n【3. 重大度：Style / Register（文体・一貫性）】  \n3-1 口語/敬体の混在  \n　・全体は常体で統一しつつ、一部「～です／ます」「しましょう」が混在。  \n　　→常体に揃えるか、意図的に切り替えるならセクション単位で。  \n\n3-2 英単語の使い方  \n　・「ボイラープレート」「グリッチ UI」などは技術者向けなら許容されるが、頻度が高くカタカナ乱発気味。  \n　　→「ひな型コード」「グリッチ風 UI」など日本語補足を併記。  \n\n──────────────  \n【4. 重大度：Language / Fluency（流暢さ・文法）】  \n4-1 直訳・機械翻訳っぽさ  \n　・「ループはそれぞれ独立」→ IT 以外の読者には不自然。「それぞれ独立したループで回す」等に。  \n　・「モデルの実力を測るのに便利だ。」→ 「測る」より「把握する」の方が自然。  \n\n4-2 冗長・重複  \n　・「ワークフローはこんな感じだ。」→ すでに bullet で説明しているので前置き不要。  \n\n4-3 誤用・誤字  \n　・“Claude は React コードを吐きがちだからだ。” → 口語過ぎる場合「生成しがち」に。  \n　・箇所によって “ChatGPT-4o / 4o3” と “4o / o3”。数字とアルファベットのブレを整理。  \n\n──────────────  \n【5. 重大度：Consistency / Terminology】  \n5-1 “spec” “blueprint” “prompt plan” の訳語揺れ  \n　・spec→仕様で固定は OK。  \n　・blueprint は「設計図」と訳す一方、他所では「詳細設計」。統一する。  \n\n5-2 コードジェネレーション vs コード生成  \n　・“codegen” を「コードを生成」「コードゲン」と混在。後者は読者によっては分かりづらい。  \n\n──────────────  \n【6. 重大度：Minor（細部・表記ゆれ）】  \n6-1 半角/全角スペース・句読点ゆれ。  \n6-2 emoji や ASCII アート周辺のバックスラッシュが一部エスケープされていない。  \n\n──────────────  \n【改善案まとめ】  \nA. 未翻訳・欠落をすべて訳補し、原文の情報量を完全に一致させる。  \nB. 誤訳箇所（scroll to the end 等）を修正し、意味・指示を正確に。  \nC. 口語常体でトーンを統一しつつ、原文のユーモア（皮肉・スラング）をできるだけ維持。  \nD. 技術用語はカタカナ語＋日本語補足で統一し、揺れを解消。  \nE. 英語のまま残した行はすべて自然な日本語へ。  \nF. 句読点・スペースを整理し、読みやすさを向上。  \n\n以上を反映すれば、原文の勢いと細部の正確さを両立した“日本語ネイティブが書いた原稿”に仕上がります。\n\nPlease address ALL issues identified in the critique and provide an improved translation.\nReturn ONLY the improved translated text without explanations or comments.",
      "response": "_tl;dr: まず仕様をブレストし、その後プランをさらに“計画”して、最後に LLM でコード生成→実行。それぞれ独立したループで回す。あとは魔法。✩₊˚.⋆☾⋆⁺₊✧_\n\nLLM を使って小さなプロダクトを山ほど作ってきた。めちゃくちゃ楽しくて役に立つ一方、時間を浪費する落とし穴も多い。少し前に友人から「どうやって LLM にソフトを書かせてるの？」と聞かれ、「おっと、どれくらい時間ある？」となり──この投稿を書くことになった。\n\n（P.S. AI が大嫌いな人は中身を読まずに末尾まで飛ばしてください）\n\n開発仲間と話すと、みな同じようなワークフローを持ちつつ細部が微妙に違う。\n\n以下が自分のワークフローだ。自分の経験、友人たち（ありがとう [Nikete](https://www.nikete.com/)、[Kanno](https://nocruft.com/)、[Obra](https://fsck.com/)、[Kris](https://github.com/KristopherKubicki)、[Erik](https://thinks.lol/)）との会話、そしてインターネットのいろいろな[悪い](https://news.ycombinator.com/) [場所](https://twitter.com)で拾ったベストプラクティスを土台にしている。\n\nこれは **今** はうまく回っているが、2 週間後には通用しなくなるか、逆に倍速になるかもしれない。¯\\\\\\_(ツ)\\_/¯\n\n## さあ行こう\n\n{{< image src=\"llm-coding-robot.webp\" alt=\"Juggalo Robot\" caption=\"AI 生成画像はいつも怪しい。うちのジャガロのコーディング・ロボット天使にご挨拶！\" >}}\n\n開発パターンはいろいろあるが、基本的に次の 2 つ。\n\n- グリーンフィールド開発（ゼロから新規）\n- “最新だけど実質レガシー”なコードベースの改修\n\n両方のプロセスを紹介しよう。\n\n## グリーンフィールド開発\n\n次のプロセスはグリーンフィールドで特にうまく機能する。堅牢な計画とドキュメントを用意し、小さなステップで実装できる。\n\n{{< image src=\"greenfield.jpg\" alt=\"Green field\" caption=\"厳密には右側がグリーンフィールド。Leica Q, 2016/05/14\" >}}\n\n### Step 1: アイデアのブラッシュアップ\n\n対話型 LLM（自分は ChatGPT-4o / ChatGPT-4o3 を使用）でアイデアを磨く。\n\n```prompt\nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.\n\nHere’s the idea:\n\n<IDEA>\n```\n\nブレインストーミングが自然に終わったら次を投げる。\n\n```prompt\nNow that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.\n```\n\nこれでかなりしっかりした仕様が出力されるので、`spec.md` としてリポジトリに保存しておく。\n\n> この仕様はコード生成だけでなく、推論モデルに欠点を突っ込ませたり、ホワイトペーパーやビジネスモデルを生成したりにも使える。深掘りリサーチに突っ込めば 1 万語級の補足資料が返ってくる。マジでワイルド。\n\n### Step 2: 計画\n\n作成した仕様を高性能推論モデル（`o1*` / `o3*` / `r1` など）に渡す。\n\n（TDD 版プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\n（非 TDD 版プロンプト）\n\n```prompt\nDraft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.\n\nFrom here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.\n\nMake sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.\n\n<SPEC>\n```\n\nモデルは **プロンプトプラン**（`prompt_plan.md`）を出力してくれる。これは aider や cursor などにそのまま食わせて実行できる。\n\n続けてチェックリストを作成。\n\n```prompt\nCan you make a `todo.md` that I can use as a checklist? Be thorough.\n```\n\n`todo.md` をリポジトリに保存し、コード生成ツールにチェックを付けてもらえばセッションをまたいでも状態を保持できる。\n\n#### やったー、計画完成！\n\nこれで堅牢な計画とドキュメントが揃い、実装に集中できる。ここまででかかる時間はせいぜい **15 分**。正直ぶっ飛んでる。\n\n### Step 3: 実装\n\n実装段階ではツールが山ほどあるが、成否は Step 2 の質次第。\n\n[GitHub Workspace](https://githubnext.com/projects/copilot-workspace)、[aider](https://aider.chat/)、[Cursor](https://www.cursor.com/)、[Claude Engineer](https://github.com/Doriandarko/claude-engineer)、[sweep.dev](https://sweep.dev/)、[ChatGPT](https://chatgpt.com)、[Claude.ai](https://claude.ai)──どれでも問題なく動いた。たぶんほとんどのコード生成ツールでいける。\n\nとはいえ自分は **素の Claude** と **aider** が好きだ。\n\n### Claude\n\n[Claude.ai](https://claude.ai) でペアプロ的に作業し、プロンプトを順番に投げる。行き来はやや面倒だが概ねうまくいく。\n\n自分は最初のひな型コードやツールチェーンを整える役目を担う。ここを好きな言語・スタイル・ツールで固めておくと指針ができる。Claude は React コードを生成しがちなので、土台をしっかり決めておくと助かる。\n\n詰まったら [repomix](https://github.com/yamadashy/repomix) でコードベースを打包し、Claude に渡してデバッグを依頼する。\n\nワークフローはこうだ。\n\n- リポジトリをセットアップ（ひな型コード作成、`uv init`、`cargo init` など）\n- プロンプトを Claude に貼る\n- Claude の出力を IDE にコピペ\n- コードを実行し、テストを走らせる\n- 動けば次のプロンプトへ\n- 動かなければ repomix でコード全体を渡してデバッグ\n- これを繰り返す ✩₊˚.⋆☾⋆⁺₊✧\n\n### Aider\n\n[Aider](https://aider.chat/) は楽しくて少し風変わりだが、Step 2 のアウトプットと相性抜群で、少ない労力でぐいぐい進む。\n\nTesting is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.  \n→ Aider の良い点はテストも自動で走らせ、失敗したらそのままデバッグまでしてくれるので、さらに手離れがいいことだ。\n\nワークフローはほぼ同じ。\n\n- リポジトリをセットアップ\n- Aider を起動\n- プロンプトを Aider に貼る\n- Aider のダンスを見る ♪┏(・o･)┛♪\n- Aider がテストを走らせる／自分でアプリを起動して確認\n- 動けば次のプロンプトへ\n- 動かなければ Q&A で修正\n- これを繰り返す ✩₊˚.⋆☾⋆⁺₊✧\n\n> Aider では [LLM リーダーボード](https://aider.chat/docs/leaderboards/) で新モデルのベンチ結果を公開しており、モデルの実力を把握するのに便利だ。\n\n### 結果\n\nこのフローでスクリプト、Expo アプリ、Rust の CLI ツールなど大量に作った。言語も用途も選ばない。もし眠っているプロジェクトがあるなら試してみてほしい。短時間で驚くほど前進する。\n\nハック用 TODO は空っぽだ。何か思いつくたびに映画を見ながらサクッと作れる。久々に新しい言語やツールに触れ、プログラミングの視野が広がっている。\n\n## グリーンフィールドでない場合：既存コードを段階的に改修\n\nときにはグリーンフィールドではなく、既存コードベースを少しずつ育てる必要がある。\n\n{{< image src=\"brownfield.jpg\" alt=\"a brown field\" caption=\"ここはグリーンフィールドではない。祖父のカメラに残っていた 60 年代ウガンダの一枚\" >}}\n\nこの場合は少し違う。プロジェクト全体ではなくタスク単位で計画する。\n\n### コンテキスト取得\n\nソースコード全体を LLM に食わせるツールが必要だ。自分は [repomix](https://github.com/yamadashy/repomix) を [`mise`](https://mise.jdx.dev/) のタスクと組み合わせて使っている。\n\n```shell\nLLM:clean_bundles           Generate LLM bundle output file using repomix\nLLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use\nLLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation\nLLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation\nLLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation\nLLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation\nLLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation\n```\n\n`output.txt` にコードベースのコンテキストを詰める。トークンが足りない場合は、無関係な部分を除外してサイズを調整する。\n\n> `mise` の良いところは、作業ディレクトリの `.mise.toml` でタスクを上書きできる点だ。別ツールでパッキングしても `output.txt` さえ作れば同じタスクが動く。\n\n`output.txt` ができたら `LLM` コマンドで変換し、Markdown に保存する。実際は\n\n```\ncat output.txt | LLM -t readme-gen > README.md\n```\n\nや\n\n```\ncat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md\n```\n\nのようにシンプル。高度な処理は LLM コマンド側が担ってくれるので、実際にやっていることはこれだけだ。\n\nテスト不足を素早く補う例を示そう。\n\n#### Claude\n\n- ディレクトリに移動  \n- `mise run LLM:generate_missing_tests` を実行  \n- 生成された `missing-tests.md` を確認  \n- `mise run LLM:copy_buffer_bundle` で全コンテキストをクリップボードへ  \n- それを Claude に貼り付け、最初の “missing test” Issue を渡す  \n- Claude の出力を IDE に貼り付けてテスト  \n- これを繰り返す ✩₊˚.⋆☾⋆⁺₊✧  \n\n#### Aider\n\n- ディレクトリに移動（必ず新しいブランチで作業）  \n- Aider を起動  \n- `mise run LLM:generate_missing_tests` を実行  \n- `missing-tests.md` の最初の Issue を Aider に貼る  \n- Aider のダンスを見る ♪┏(・o･)┛♪  \n- テストを回す  \n- これを繰り返す ✩₊˚.⋆☾⋆⁺₊✧  \n\n### プロンプト・マジック\n\n既存コードを掘り下げる際に使っているお気に入りプロンプトをいくつか紹介。\n\n#### コードレビュー\n\n```prompt\nYou are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.\n```\n\n#### GitHub Issue 生成\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\n#### テスト不足の抽出\n\n```prompt\nYou are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues\n```\n\nこれらは正直 “ブーマー・プロンプト” だがまだ役立つ。より良い案があればぜひ教えてほしい。\n\n## スキー ᨒ↟ 𖠰ᨒ↟ 𖠰\n\nこのプロセスを人に説明するとき、「状況を積極的に追わないとすぐ **オーバー・マイ・スキー**になる」と言う。最初は美しいパウダーを滑っているのに、突然「何が起きてるんだ！」と崖っぷち──そんな感覚だ。\n\nグリーンフィールドでは **計画ステップ** を挟むことで混乱を抑えられる。特に Aider でワイルドに書くときはテストが重要だ。\n\nそれでもオーバー・マイ・スキーになることはある。そんなときは短い休憩や散歩が効く。普通の問題解決と同じだが、速度が桁違いなのだ。\n\n> ときには LLM に「ロア（世界観）ファイルを作成して UI から参照せよ」と頼むこともある。Python CLI ツールでも突然ロアやグリッチ風 UI が生える。可能性は無限大。\n\n## さみしい (｡•́︿•̀｡)\n\n最大の欠点は **ソロプレイ** であること。長年ソロ開発もペアプロもチーム開発も経験したが、人と一緒の方が絶対に面白い。現状のツールはマルチプレイヤーに向いておらず、ボットは衝突し、マージは地獄、コンテキスト共有も大変だ。\n\n誰かが LLM コーディングをマルチプレイヤーにする解決策を出してくれるのを心待ちにしている。チャンスしかない。頼む、GET TO WORK!\n\n## ⴵ 時間 ⴵ\n\nコード生成で一人でも大量のコードを書けるようになった一方、LLM がトークンを燃やす **待ち時間** が増えた。\n\n{{< image src=\"apple-print-shop-printing.png\" alt=\"Printing\" caption=\"まるで昨日のことのように覚えている\" >}}\n\nその間にやること：\n\n- 次のプロジェクトのブレスト  \n- レコードを聴く  \n- [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) を叩く  \n- 友人やロボットとおしゃべり  \n\nここまでハックし続けた時期は他にない。今が一番生産的かもしれない。\n\n## Haterade ╭∩╮( •̀_•́ )╭∩╮\n\n「クソ LLM なんて全部ダメ」と言う友人も多い。それも理解できる。AI を嫌う理由は山ほどあり、自分も電力消費と環境負荷が一番怖い。が……コードは流れねばならない。はぁ。\n\n深入りしたくないけど少し学んでみたい人には、Ethan Mollick の [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/) を勧める。テック至上主義ではなく、LLM の利点を丁寧に説明している。読んだ友人とも良い議論ができた。\n\n懐疑的でも少し興味があるなら、気軽に連絡してほしい。この狂気を一緒に眺めて、何か作ろう。\n\n_thanks to [Derek](https://derek.broox.com)、[Kanno](https://nocruft.com/)、[Obra](https://fsck.com)、[Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._",
      "usage": {
        "prompt_tokens": 11435,
        "completion_tokens": 4516,
        "total_tokens": 15951
      },
      "streaming": true
    },
    "frontmatter": {
      "model": "o3",
      "target_language": "japanese",
      "system_prompt": "You are a professional translator. Translate the following frontmatter fields to japanese.\nEach field is in the format \"field_name: content\". Translate ONLY the content, not the field names.\nReturn the translated content in the exact same format, preserving all field names.",
      "user_prompt": "title: My LLM codegen workflow atm\n\ndescription: A detailed walkthrough of my current workflow for using LLms to build software, from brainstorming through planning and execution.\n\n",
      "response": "title: 現時点での私のLLMコード生成ワークフロー\ndescription: ブレインストーミングから計画策定と実行まで、LLMを活用してソフトウェアを構築する現在のワークフローを詳細に解説します。",
      "usage": {
        "prompt_tokens": 86,
        "completion_tokens": 63,
        "total_tokens": 149
      },
      "fields": [
        "title",
        "description"
      ],
      "streaming": true
    },
    "all_critiques": [
      "【総評】  \n日本語訳は全体として読みやすく、カジュアルな語調も概ね保たれています。しかし原文に対する忠実度という観点では「未訳・省略」「意味ずれ」「語調のブレ」「技術用語の扱い」など多数の問題が散見されます。特にメタ情報（アドバイス・注意書き・比喩・ジョーク）や “脇道” に見える段落がごっそり抜け落ちている箇所が多く、内容の網羅性に重大な欠落があります。以下、深刻度順に具体的な指摘と改善案を列挙します。\n\n================================================================\nA. 重大レベル（意味／情報欠落・誤訳）\n================================================================\nA-1【丸ごと未訳・大幅省略】  \n　・Step 1 の後段 “You can use this spec for a number of things … get a 10k word supporting document in return.” が英語のまま残置 → 読者は「仕様の他用途」を把握できない。  \n　・Todo.md の段落 “Your codegen tool should be able to check off … across sessions.” が未訳。  \n　・Step 3「Results」冒頭 4 行（ハック todo が空／映画を見ながら作る…）がごっそり欠落。  \n　・Skiing セクションの引用ブロック（lore file のくだり）が未訳。  \n　・“An aside: Aider does really great benchmarking …” も未訳。  \n　→【修正案】これらはブログの温度感を構成する重要情報。すべて自然な日本語に訳出し、段落を補完すること。\n\nA-2【ニュアンスずれ】  \n　1) “Discrete loops.” →「離散的にループさせる」は不自然で意味が曖昧。“個別のループで進める”“ループを区切って繰り返す” 等が妥当。  \n　2) “Legacy modern code” →「既存コードへの追加／改修」は説明的過ぎ。“（既存の）モダン寄りレガシーコード” など語感を残す訳が必要。  \n　3) “scroll to the end” →「最後までスクロールしてね」は逆の意味に取られやすい。“いきなり記事末尾まで飛ばして” 等に修正。  \n　4) “This will output a pretty solid and straightforward spec” →「かなりまとまった仕様」だけだと “straightforward” の語感不足。“シンプルかつ筋の通った仕様” など。  \n\nA-3【文脈の追加／削除による情報改変】  \n　・原文 “I, however, prefer raw claude and aider:” → “素の Claude” は通じにくい。“生（き）の Claude” “素のままの Claude API” など意図補足要。  \n　・“rinse repeat” が頻出するが日本語では意味が伝わらない。毎回脚注・意訳「同じ手順を繰り返す」等を入れるべき。  \n\n================================================================\nB. 中レベル（自然さ・用語統一・スタイル）\n================================================================\nB-1【用語統一ミス】  \n　・“コンテキスト” と “文脈” が混在。“コンテキスト” に統一した方が技術ブログとして自然。  \n　・“Greenfield/Brownfield” は一貫してカタカナ表記か日本語訳に統一する。  \n　・“prompt plan”→「プロンプトプラン」と「実行用のプロンプトプラン」が揺れている。  \n\nB-2【こなれない／英語直訳調】  \n　・“ぶっちゃけ速すぎます” はカジュアルすぎ。原文 “Wild tbh” なので「正直ワイルドな速さです」など意訳調整可。  \n　・“じわじわ改修” → 職場文書としては “段階的改修” “漸進的改修” の方が通りやすい。  \n　・“コードの文脈を詰めます” →「コードベースを詰め込みます」「コードのコンテキストをまとめます」の方が分かりやすい。  \n\nB-3【語順・読点】  \n　長文が多い割に読点が少なく、息継ぎしにくい箇所が散発。全体に「、」を増補して可読性を上げる。\n\n================================================================\nC. 軽微レベル（表記ゆれ・細部の語感）\n================================================================\nC-1【英語残置の可否】  \n　プロンプト・コマンド は英語のままで問題ないが、説明文だけ英語が突発的に出現すると途端に機械翻訳臭が強まる。訳注または完全訳で統一してトレース性を担保する。  \n\nC-2【記号の扱い】  \n　原文の顔文字や ✩₊˚.⋆☾⋆⁺₊✧ を残しているのは忠実だが、日本語文章内で浮く場合は “原文ママ” である旨を注記するか、改行を調整して読みやすさを確保する。\n\n================================================================\nD. セクション別具体修正例（抜粋）\n================================================================\n【冒頭 tl;dr】  \n×「離散的にループさせる」  \n→「各ループを独立させて回す」  \n\n【Step 1 末尾の未訳段落】  \n> You can use this spec for a number of things …  \n◎訳例：  \n> この仕様書はコード生成だけでなく、アイデアの欠点を推論系モデルに洗い出させる（さらに掘り下げる！）、ホワイトペーパーの作成、ビジネスモデルの生成などにも使えます。深掘りリサーチに放り込めば 1 万語規模の補足資料だって返ってきます。\n\n【Todo.md 部分】  \n×欠落  \n→「生成された `todo.md` はコード生成ツールが進捗に応じて自動的にチェックを付けられるようにしておくと、セッションをまたいでも状態管理が楽になります。」を追記。\n\n【Results 欠落部】  \n> My hack to-do list is empty …  \n→同意訳を追加し、作者の興奮を日本語で再現する。\n\n【Skiing の引用ブロック】  \n未訳の英語を下記のように補完：  \n> しょーもない CLI でも「ロア（世界観）ファイルを作成して UI から参照しろ」と LLM に頼んだりします。すると謎のロアやグリッチっぽい UI が突然現れる――クラウド関数や ToDo 管理ツールなのに、です。可能性は無限大、というわけ。\n\n================================================================\nE. 推奨全体改訂方針\n================================================================\n1. 未訳箇所を完全訳し、内容網羅率を 100 % に。  \n2. “カジュアルだけど読者フレンドリー” という原文トーンを保ちつつ、日本語の自然さを優先して口語を微調整。  \n3. 用語・表記ルール（Greenfield/Brownfield、context/コンテキスト など）を決めて統一。  \n4. “rinse repeat” “raw Claude” などは脚注またはかっこ書きで意図を補足。  \n5. 読点・改行を増やし、スクロール疲れを軽減。  \n\n以上を反映すれば、内容忠実度・可読性ともに大幅に向上し、「最初から日本語で書かれた」かのような完成度に近づきます。",
      "【最重要 (Critical)】\n\n1. コードブロックが途中で省略されている  \n   • 例：Step 1 の最初のプロンプト  \n     原文は 4 行あるが、訳文では  \n     ```\n     Ask me one question at a time so we can develop …\n     ```  \n     で「…」に置き換えて残りを丸ごと落としている。  \n   • Step 2 の TDD／非 TDD プロンプトも同様に途中で省略。  \n   ⇒ 仕様生成の肝なので全文を残すこと。省略するなら「全文は省略」と明示し、実運用を想定する場合は必ず全文＋必要なら日本語訳も併記。\n\n2. 英語のまま残っている本文が複数箇所  \n   • 「The workflow is essentially the same as above …」  \n   • 「Aider will then “just do it” and I get to play cookie clicker.」  \n   • 「Testing is nice with aider, because it can be even more hands off …」  \n   などが丸ごと未訳。  \n   ⇒ すべて日本語に訳すか、意図的に英語を残す場合はカギ括弧などで示して読者が混乱しないように。\n\n3. 文意が抜け落ちた箇所  \n   • 「you have to aggressively keep track of what’s going on because you can easily get ahead of yourself」  \n     → 訳文では「オーバー・マイ・スキーと言います」だけで、この忠告部分が消失。  \n   • 「I imagine it will work well with any codegen tool」  \n     → 未訳。  \n   • 「Aider will run the test suite and debug things for you」  \n     → 英語のまま残っている上に後続の説明が欠ける。  \n   ⇒ すべて反映させる。\n\n4. 画像の alt / caption 未訳  \n   ⇒ alt テキストは視覚障がい者や SEO に関わる。日本語化するか、最低でも alt=“(Japanese)” と付記。\n\n【重大 (Major)】\n\n1. トーン／文体の揺れ  \n   • 「です/ます体」と「だ/である体」が混在（例：「これは便利です」が続いた直後に「〜だと思う」）。  \n   • カジュアル寄りにするなら終始「だ/である体」に、丁寧にするなら統一して「です/ます体」へ。\n\n2. 英語・カタカナ語の混在と多用  \n   • 「ブレスト」「ワイルド」「ハック」「ペアプロ」等。  \n     カジュアルさは維持しつつ、読者層に応じて脚注を付けるか日本語言い換え（例：ブレスト→ブレインストーミング）。  \n   • 「rinse & repeat」などは「同じ手順を繰り返す」へ統一。\n\n3. 用語の揺れ  \n   • “Greenfield” → 「ゼロからの開発」「グリーンフィールド」  \n   • “Legacy modern code” → 「モダン寄りレガシーコード」  \n   • 一度日本語訳を決めたら全編で統一し、初出で英語を括弧付き併記。\n\n4. 訳語の不自然さ  \n   • 「モダン寄りレガシーコード」は意味が取りにくい。  \n     → 例：「比較的新しいレガシーコード」または「レガシー（だけど比較的新しい）コード」。  \n   • 「正直ワイルドな速さです」  \n     → 「正直、驚くほど速いです」に。\n\n【中程度 (Medium)】\n\n1. 句読点・全角/半角の乱れ  \n   • 「AI に反感がある人は、いきなり記事末尾まで飛ばしてどうぞ」  \n     → 読点連続で少し硬い。「AI が嫌いな人は最後まで飛ばしてください」など。  \n   • 「¯\\\\\\_(ツ)\\_/¯」← バックスラッシュ 3 本は原文のエスケープ。日本語記事では「¯\\\\_(ツ)_/¯」と 1 本に。\n\n2. 細かいニュアンス  \n   • 「Wild tbh」を「正直ワイルド」だけだと “tbh” が抜けている。  \n     → 「正直、ワイルドだと思う」等。  \n   • 「hugely productive」→「最高に生産的」の訳は自然だが、ニュアンスとして「今までで一番〜」が欲しい。\n\n3. 「cookie clicker」など外部リンクの日本語説明不足  \n   → 「クッキークリッカーという放置系ゲーム」等の補足があると親切。\n\n【軽微 (Minor)】\n\n1. Markdown 見出しの日本語化  \n   • “## Let’s go”→「## さあ行こう」OK だが、その後 “### Step 1” などは “ステップ 1” にするなど見出し内の表記も揃える。\n\n2. 絵文字・顔文字の位置  \n   • 日本語文中に連続して置くと読みづらい場合がある。文末に置いて読点で区切るなど微調整。\n\n3. リンクテキスト  \n   • 「Thanks [Nikete]」→「Nikete ありがとう」のように日本語でも補うと親切。\n\n【改善の具体例】\n\n● 未訳英文の例  \n（現状）  \nThe workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.  \n（改訳案）  \nワークフロー自体は先ほどとほぼ同じですが、Claude に貼り付ける代わりに Aider にプロンプトを投入します。\n\n● 省略したプロンプト  \n（現状）  \n```prompt  \nAsk me one question at a time so we can develop …  \n```  \n（改訳案）  \n```prompt  \nAsk me one question at a time so we can develop a thorough, step-by-step spec for this idea.  \nEach question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer.  \nLet’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.  \n  \nHere’s the idea:  \n  \n<IDEA>  \n```  \n※コードブロック内は原文維持＋必要なら下に和訳を置く。\n\n● トーン統一  \n（現状）  \n「…グイグイ進みます。The workflow is essentially…」  \n（改訳案）  \n「…グイグイ進みます。ワークフローは…」\n\n● alt テキスト  \n（現状）  \nalt=\"Juggalo Robot\"  \n（改訳案）  \nalt=\"ジャガロ風ロボットのイラスト\"\n\n【まとめ】\n\n・省略されたコードブロックの全文掲載  \n・未訳英語文の完全翻訳  \n・文体／トーン／用語の統一  \n・alt/caption の日本語化  \n・細部の自然さ／読点・語尾の整合\n\n上記を修正すれば、原稿の情報量とカジュアルなノリを保ちつつ、日本語ネイティブが読みやすい完訳になります。",
      "【重大度：Critical／致命的】\n\n1. 文章の丸ごと欠落  \n   • 原文の以下の段落が訳文から完全に抜けている。  \n     a) “I am in charge of the initial boilerplate … quite a bit.”（Claude 節）  \n     b) “Aider will then ‘just do it’ and I get to play cookie clicker.”（Aider 節）  \n   → 必ず訳文に追加し、Claude が React を吐く癖や “cookie-clicker しながら眺める” という筆者特有のニュアンスも反映すること。\n\n2. 未訳の英語が混在  \n   • Claude 節の “I will then use a tool like repomix …” が丸ごと英語のまま。  \n   • ワークフロー箇条書き（Claude／Aider）の各手順が英語のまま。  \n   → 手順を日本語に置換（例：「リポジトリをセットアップする」「プロンプトを Claude に貼り付ける」等）。  \n   • その他、原文引用でもない説明文が英語で残っていないか総点検すること。\n\n3. 誤訳／意味のズレ  \n   • “Legacy modern code” →「比較的新しいレガシーコード」は自己矛盾。  \n     推奨：「モダンではあるが既存（レガシー）化しつつあるコード」などと説明的に。  \n   • 見出し “Yay. Plan!” を「計画完了！」とだけすると “Yay” の喜びが消える。  \n     推奨：「やったー、計画完成！」など。  \n   • “Fuck LLMs” を「LLM は全部ダメ」と弱めている。原文の罵倒調（fuck）を維持した訳語（例：「クソ LLM なんて全部ダメだ」）に。  \n   • “raw Claude” →「生（なま）Claude」は不自然。「素（す）の Claude」「素のままの Claude」などに修正。  \n   • “Juggalo” →「ジャガロ」は転写誤り。一般的には「ジャガロウ」「ジャグァロ」いずれも浸透していないため、カタカナ＋原語併記が無難（例：「ジャガロ（Juggalo）」）。\n\n【重大度：Major／大きな問題】\n\n1. 口語トーン・ユーモアの希薄化  \n   • “plan a plan” の二重表現を「プランを計画する」などで再現していない。  \n   • “Wild tbh” が訳出されず消失。→「正直ぶっ飛んでる」「マジでワイルド」など挿入。  \n   • “over my skis” の比喩を長文説明で潰している。まずは対訳（「オーバー・マイ・スキー状態」等）を置き、後に説明を添える構成が自然。  \n\n2. 不自然・機械的な日本語  \n   • 「LLM を食わせる」「ワイルドに書く」などカタカナ・和製英語多用で読点が続き、リズムが悪い。校正し冗長さを削る。  \n   • 「robust（堅牢）」のような括弧併記が散発。和訳に統一し不要な英語を削る。  \n\n3. 用語の不統一  \n   • “spec”→訳中で「仕様」「Spec」混在。  \n   • “prompt plan”→「プロンプトプラン」「prompt_plan.md」混在。  \n   → 訳語を宣言し一貫させる。\n\n【重大度：Minor／軽微な問題】\n\n1. 句読点・記号  \n   • “tl:dr;”→訳では “tl;dr:” と冒頭のコロンとセミコロンの位置が逆。  \n   • 漢数字と算用数字が混在（“2 週間後”“15 分”）。文書内で統一。  \n\n2. 画像キャプション  \n   • “ジャガロ天使コーディングロボット” は冗長。「ジャガロのコーディング・ロボット天使」で可。  \n   • Brownfield のキャプションに “This is not a green field.” 部分が欠落。→「ここはグリーンフィールドではない。」を追加。  \n\n3. スペース・インデント  \n   • 箇条書き直後の “…” や “✩₊˚.⋆☾⋆⁺₊✧” の前後に全角スペースが入ったり入らなかったり。不揃い。  \n\n【改善のための具体的提案】\n\n1. 欠落段落は必ず全文訳し、原文と照合チェックリストを作成。  \n2. 箇条書きや手順は ‹日本語見出し＋原文英語（コード・コマンドのみ）› にスタイル統一。  \n3. 罵倒語・スラングは強さを保ったまま自然な日本語に（“fuck LLMs”→「クソLLM」など）。  \n4. カタカナ語は必要最低限にし、1 回目に英語併記、2 回目以降はカタカナのみ等ルール化。  \n5. 固有名詞 “Juggalo”“Cookie Clicker” などはカタカナ転写＋英語原綴併記で読者の検索性を確保。  \n6. 文末表現を “です／ます” と “だ／である” で混在させない（本訳は終始 “だ／である” 体に近いので統一推奨）。  \n7. 英語強調符号（**NOW** など）は《今》のように和文書式で処理し可読性を上げる。  \n8. 全体を通して再校正し、重複・冗長箇所を削ぎつつ、原文のユーモラスな勢いを維持すること。",
      "翻訳総評  \n全体としては原文の内容を大枠では押さえていますが、「そのままリリースできる品質」には達していません。  \n特に以下の問題が目立ちます。\n\n──────────────  \n【1. 重大度：Critical（誤訳・欠落・未翻訳）】  \n1-1 未翻訳文が残存  \n　・Aider 章冒頭の “Testing is nice with aider, …” が英語のまま。  \n　　→「Aider の良い点はテストも自動で走らせてくれるので、さらに手離れが良いことだ。」などに訳出。  \n\n1-2 情報の欠落  \n　a) Step 2 説明文「that you can execute with aider, cursor, etc.」が抜け、実行環境の例示が欠落。  \n　　→「…aider や cursor などでそのまま実行できるプロンプトプラン…」と補完。  \n　b) “This isn’t super complicated.” 以降の「LLM コマンドが heavy lifting をしている」説明のニュアンスが弱い。  \n　　→「高度な処理は LLM コマンド側が担ってくれるので、実際にやっていることはシンプルだ」という説明を追記。  \n\n1-3 誤訳  \n　(p.s.) “scroll to the end” は「（中身を読まずに）末尾へ飛べ」の意。  \n　　現訳「最後までスクロールしてくれても OK」は “読んでもいいよ” というニュアンスになり不正確。  \n　　→「末尾まで飛ばしてください」等に修正。  \n\n──────────────  \n【2. 重大度：Major（ニュアンス損失・不自然な訳語）】  \n2-1 冗談・皮肉のトーン不統一  \n　・原文 “plan a plan” はわざと重複した言い回し。現訳「『プランをプラン』」ではニュアンスが弱い。  \n　　→「プランをさらに“計画”して」など意図的な重複感を強調。  \n\n2-2 “Legacy modern code” の解釈  \n　・「モダンではあるが既存（レガシー）化しつつあるコード」→ 原文は皮肉混じりで「一応現代的だけどレガシー扱い」の意。  \n　　→「“最新だけど実質レガシー” なコードベース」など言外の皮肉を残す。  \n\n2-3 ニュアンスの弱体化  \n　・“wild tbh” を「正直ぶっ飛んでる」は OK だが、ほかの箇所で同様のテンションが平板化している。  \n　　例： “This is working well NOW, it will probably not work in 2 weeks…”  \n　　→「今はうまく回ってるけど、2 週間後にはダメになってるか、逆に倍速になってるかも。¯\\\\_(ツ)_/¯」のように原文の投げやり感を保持。  \n\n──────────────  \n【3. 重大度：Style / Register（文体・一貫性）】  \n3-1 口語/敬体の混在  \n　・全体は常体で統一しつつ、一部「～です／ます」「しましょう」が混在。  \n　　→常体に揃えるか、意図的に切り替えるならセクション単位で。  \n\n3-2 英単語の使い方  \n　・「ボイラープレート」「グリッチ UI」などは技術者向けなら許容されるが、頻度が高くカタカナ乱発気味。  \n　　→「ひな型コード」「グリッチ風 UI」など日本語補足を併記。  \n\n──────────────  \n【4. 重大度：Language / Fluency（流暢さ・文法）】  \n4-1 直訳・機械翻訳っぽさ  \n　・「ループはそれぞれ独立」→ IT 以外の読者には不自然。「それぞれ独立したループで回す」等に。  \n　・「モデルの実力を測るのに便利だ。」→ 「測る」より「把握する」の方が自然。  \n\n4-2 冗長・重複  \n　・「ワークフローはこんな感じだ。」→ すでに bullet で説明しているので前置き不要。  \n\n4-3 誤用・誤字  \n　・“Claude は React コードを吐きがちだからだ。” → 口語過ぎる場合「生成しがち」に。  \n　・箇所によって “ChatGPT-4o / 4o3” と “4o / o3”。数字とアルファベットのブレを整理。  \n\n──────────────  \n【5. 重大度：Consistency / Terminology】  \n5-1 “spec” “blueprint” “prompt plan” の訳語揺れ  \n　・spec→仕様で固定は OK。  \n　・blueprint は「設計図」と訳す一方、他所では「詳細設計」。統一する。  \n\n5-2 コードジェネレーション vs コード生成  \n　・“codegen” を「コードを生成」「コードゲン」と混在。後者は読者によっては分かりづらい。  \n\n──────────────  \n【6. 重大度：Minor（細部・表記ゆれ）】  \n6-1 半角/全角スペース・句読点ゆれ。  \n6-2 emoji や ASCII アート周辺のバックスラッシュが一部エスケープされていない。  \n\n──────────────  \n【改善案まとめ】  \nA. 未翻訳・欠落をすべて訳補し、原文の情報量を完全に一致させる。  \nB. 誤訳箇所（scroll to the end 等）を修正し、意味・指示を正確に。  \nC. 口語常体でトーンを統一しつつ、原文のユーモア（皮肉・スラング）をできるだけ維持。  \nD. 技術用語はカタカナ語＋日本語補足で統一し、揺れを解消。  \nE. 英語のまま残した行はすべて自然な日本語へ。  \nF. 句読点・スペースを整理し、読みやすさを向上。  \n\n以上を反映すれば、原文の勢いと細部の正確さを両立した“日本語ネイティブが書いた原稿”に仕上がります。"
    ]
  },
  "critique_loop_details": {
    "critique_usages": [
      {
        "prompt_tokens": 8925,
        "completion_tokens": 1844,
        "total_tokens": 10769
      },
      {
        "prompt_tokens": 9254,
        "completion_tokens": 1701,
        "total_tokens": 10955
      },
      {
        "prompt_tokens": 10442,
        "completion_tokens": 1408,
        "total_tokens": 11850
      },
      {
        "prompt_tokens": 9535,
        "completion_tokens": 1556,
        "total_tokens": 11091
      }
    ],
    "feedback_usages": [
      {
        "prompt_tokens": 11271,
        "completion_tokens": 3491,
        "total_tokens": 14762
      },
      {
        "prompt_tokens": 11304,
        "completion_tokens": 4467,
        "total_tokens": 15771
      },
      {
        "prompt_tokens": 12193,
        "completion_tokens": 3587,
        "total_tokens": 15780
      },
      {
        "prompt_tokens": 11435,
        "completion_tokens": 4516,
        "total_tokens": 15951
      }
    ]
  },
  "timestamp": "2025-05-15T18:14:15.134157"
}