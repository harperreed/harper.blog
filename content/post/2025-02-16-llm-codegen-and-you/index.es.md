---
bsky: https://bsky.app/profile/harper.lol/post/3lidixzdr5j2e
date: 2025-02-16 18:00:00-05:00
description:
    Un recorrido detallado por mi flujo de trabajo actual para usar LLMs
    para crear software, desde la lluvia de ideas hasta la planificaci√≥n y la ejecuci√≥n.
draft: false
generateSocialImage: true
slug: my-llm-codegen-workflow-atm
tags:
    - LLM
    - coding
    - ai
    - workflow
    - software-development
    - productivity
title: "Mi flujo de trabajo de generaci√≥n de c√≥digo con LLM en este momento"
translationKey: My LLM codegen workflow atm
---

_tl;dr: Primero genera una **especificaci√≥n (spec)** con una lluvia de ideas; luego **planea un plan** y, por √∫ltimo, ejecuta con generaci√≥n de c√≥digo mediante LLMs. **Bucles discretos**. Despu√©s, magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_

He estado creando un mont√≥n de peque√±os productos con LLMs. Ha sido divertido y √∫til. Sin embargo, hay obst√°culos que pueden hacerte perder much√≠simo tiempo. Hace un tiempo un amigo me pregunt√≥ c√≥mo estaba usando los LLMs para escribir software. Pens√©: ¬´¬°Madre m√≠a! ¬øCu√°nto tiempo tienes?¬ª y as√≠ naci√≥ este post.

(P. D.: si odias la IA, ve hasta el final).

Hablo con muchos amigos _dev_ sobre esto y todos tenemos un enfoque parecido, con matices en una u otra direcci√≥n.

Este es mi flujo de trabajo. Se basa en mi propio trabajo, en conversaciones con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)) y en muchas buenas pr√°cticas compartidas en esos infames rincones de Internet, por ejemplo HN o Twitter.

Esto funciona muy bien **AHORA**; quiz√° dentro de dos semanas no funcione‚Ä¶ o funcione el doble de bien. ¬Ø\\\_(„ÉÑ)\_/¬Ø

## Vamos all√°

{{< image src="llm-coding-robot.webp" alt="Robot juggalo" caption="Siempre desconf√≠o un poco de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel robot juggalo programador!" >}}

Hay muchos caminos para desarrollar, pero en mi caso suelo enfrentarme a uno de dos escenarios:

- C√≥digo _greenfield_ (proyecto empezado desde cero)
- C√≥digo heredado _moderno_

Te mostrar√© mi proceso para ambos casos.

## _Greenfield_

El siguiente proceso me funciona bien para proyectos _greenfield_. Proporciona una planificaci√≥n y documentaci√≥n s√≥lidas y permite avanzar f√°cilmente en peque√±os pasos.

{{< image src="greenfield.jpg" alt="Campo verde" caption="T√©cnicamente, hay un campo verde a la derecha. Leica Q, 14/05/2016" >}}

### Paso 1: Afinar la idea

Utiliza un LLM conversacional para concretar la idea (yo uso ChatGPT 4o / o3):

```prompt
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here‚Äôs the idea:

<IDEA>
```

Al final de la sesi√≥n de _brainstorming_ (llegar√° a una conclusi√≥n natural):

```prompt
Now that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.
```

Esto genera una _spec_ bastante s√≥lida y directa que puedes pasar a la fase de planificaci√≥n. Me gusta guardarla como `spec.md` en el repositorio.

> Puedes emplear esta especificaci√≥n para varias cosas. Aqu√≠ la usaremos para _codegen_, pero tambi√©n la he usado para reforzar ideas pidi√©ndole a un modelo de razonamiento que les busque puntos d√©biles (¬°profundiza m√°s!), para generar un _white paper_ o un modelo de negocio. Incluso puedes enviarla a un modelo de investigaci√≥n profunda y obtener a cambio un documento de 10 000 palabras de soporte.

### Paso 2: Planificaci√≥n

Toma la _spec_ y p√°sala a un modelo de razonamiento (`o1*`, `o3*`, `r1`):

(√âste es el _prompt_ TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break them into smaller steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

(√âste es el _prompt_ sin TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break them into smaller steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

Deber√≠a generar un **plan de _prompts_** (`prompt_plan.md`) que puedas ejecutar con Aider, Cursor, etc.

Luego pido un `todo.md` para usarlo como lista de verificaci√≥n:

```prompt
Can you make a `todo.md` that I can use as a checklist? Be thorough.
```

Gu√°rdalo como `todo.md` en el repositorio.

Tu herramienta de generaci√≥n de c√≥digo deber√≠a poder ir marcando el `todo.md` mientras avanza. As√≠ se mantiene el estado entre sesiones.

#### ¬°Yay, plan!

Ahora tienes un plan robusto y documentaci√≥n que te ayudar√°n a ejecutar y construir tu proyecto.

Todo este proceso lleva quiz√° **15 minutos**. Bastante r√°pido, la verdad. ¬°Una locura, sinceramente!

### Paso 3: Ejecuci√≥n

Las opciones para ejecutar son much√≠simas. El √©xito depende en gran medida de lo bien que haya salido el paso 2.

He usado este proceso con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai), etc. En todos los casos ha funcionado bastante bien, y supongo que ir√° igual con cualquier herramienta de generaci√≥n de c√≥digo.

Yo, sin embargo, prefiero **Claude en bruto** y Aider:

### Claude

B√°sicamente programo en pareja con [Claude.ai](https://claude.ai) y voy pegando cada _prompt_ de forma iterativa. Funciona bastante bien; el ida y vuelta puede ser un poco tedioso, pero se lleva.

Me ocupo del _boilerplate_ inicial y de que las herramientas est√©n configuradas. Eso da libertad y gu√≠a al principio. Claude tiende a escupir c√≥digo React, y contar con una base s√≥lida en el lenguaje, estilo y _tooling_ de tu elecci√≥n ayuda mucho.

Cuando algo se atasca, uso [repomix](https://github.com/yamadashy/repomix) para iterar (hablo de ello m√°s adelante).

El proceso es as√≠:

- crear el repo (boilerplate, `uv init`, `cargo init`, etc);
- pegar el _prompt_ en Claude;
- copiar el c√≥digo de Claude.ai al IDE;
- ejecutar el c√≥digo y las pruebas;
- ‚Ä¶;
- si funciona, pasar al siguiente _prompt_;
- si no funciona, usar repomix para pasar la base de c√≥digo a Claude y depurar;
- repetir el ciclo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

### Aider

[Aider](https://aider.chat/) es divertido y un poco peculiar. Encaja bien con la salida del paso 2: puedo avanzar much√≠simo con muy poco esfuerzo.

El flujo es esencialmente el mismo, pero en vez de pegar en Claude, pego las instrucciones en Aider.

Aider entonces ¬´simplemente lo hace¬ª y yo juego a _Cookie Clicker_.

> Nota: Aider hace una excelente evaluaci√≥n comparativa de los nuevos modelos de generaci√≥n de c√≥digo en su [LLM leaderboard](https://aider.chat/docs/leaderboards/). Es un recurso buen√≠simo para ver la eficacia de los modelos.

Probar es c√≥modo con Aider: puede ser a√∫n m√°s autom√°tico; Aider ejecuta la _suite_ de tests y depura por ti.

El proceso es as√≠:

- crear el repo (boilerplate, `uv init`, `cargo init`, etc);
- iniciar Aider;
- pegar la instrucci√≥n en Aider;
- ver a Aider hacer su magia ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™;
- Aider ejecuta las pruebas o puedes lanzar la app para verificar;
- si funciona, siguiente instrucci√≥n;
- si no, preguntas y respuestas con Aider para arreglar;
- repetir el ciclo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

### Resultados

He construido un mont√≥n de cosas con este proceso: scripts, apps en Expo, herramientas CLI en Rust, etc. Ha funcionado con distintos lenguajes y contextos. Me encanta.

Si tienes un proyecto ‚Äîgrande o peque√±o‚Äî que est√°s posponiendo, te recomiendo probar este m√©todo. Te sorprender√° lo lejos que puedes llegar en poco tiempo.

Mi lista de hacks pendientes est√° vac√≠a porque ya lo hice todo. Cada vez que se me ocurre algo nuevo lo construyo mientras veo una peli o lo que sea. Por primera vez en a√±os estoy dedicando tiempo a nuevos lenguajes y herramientas, lo que ampl√≠a mi perspectiva como programador.

## _Brownfield_: iteraci√≥n incremental

A veces no tienes un proyecto _greenfield_ y necesitas iterar o hacer trabajo incremental sobre una base de c√≥digo ya existente.

{{< image src="brownfield.jpg" alt="Un campo marr√≥n" caption="Esto no es un campo verde. Foto aleatoria de la c√°mara de mi abuelo, en alg√∫n lugar de Uganda en los 60" >}}

Para esto uso un m√©todo ligeramente distinto. Es parecido al anterior, pero algo menos ‚Äúbasado en planificaci√≥n‚Äù: la planificaci√≥n se hace por tarea, no para todo el proyecto.

### Obtener contexto

Cada persona metida en desarrollo con IA tiene su herramienta para esto, pero necesitas algo que capture tu c√≥digo fuente y lo empaquete eficientemente para el LLM.

Actualmente uso [repomix](https://github.com/yamadashy/repomix). Tengo una colecci√≥n de tareas definida en mi `~/.config/mise/config.toml` global que me permite hacer varias cosas con la base de c√≥digo ([reglas de mise](https://mise.jdx.dev/)).

Lista de tareas LLM:

```shell
LLM:clean_bundles           Generate LLM bundle output file using repomix
LLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use
LLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation
LLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation
LLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation
LLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation
LLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation
```

Genero un `output.txt` con el contexto del c√≥digo. Si me paso de tokens y es demasiado grande, modifico el comando para ignorar las partes que no sean relevantes para la tarea.

> Algo muy √∫til de `mise` es que las tareas pueden redefinirse y sobrecargarse en el `.mise.toml` del directorio de trabajo. Puedo usar otra herramienta para empaquetar el c√≥digo y, mientras genere un `output.txt`, mis tareas LLM seguir√°n funcionando. Esto ayuda cuando las bases de c√≥digo son muy distintas. A menudo sobrescribo el paso de `repomix` para ampliar patrones de _ignore_ o uso otra herramienta m√°s eficaz.

Una vez generado `output.txt`, lo paso al comando [LLM](https://github.com/simonw/LLM) para hacer varias transformaciones y guardarlas como archivo Markdown.

En esencia, la tarea de mise ejecuta algo como: `cat output.txt | LLM -t readme-gen > README.md` o `cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md`. No tiene mayor complicaci√≥n; el comando `LLM` hace el trabajo pesado.

Por ejemplo, si necesito una revisi√≥n r√°pida y mejorar la cobertura de tests, har√≠a lo siguiente:

#### Claude

- ir al directorio del c√≥digo;
- ejecutar `mise run LLM:generate_missing_tests`;
- revisar el Markdown generado (`missing-tests.md`);
- copiar el contexto completo con `mise run LLM:copy_buffer_bundle`;
- pegar eso en Claude junto con el primer _issue_ de tests faltantes;
- copiar el c√≥digo generado por Claude al IDE;
- ‚Ä¶;
- ejecutar las pruebas;
- repetir el ciclo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

#### Aider

- ir al directorio del c√≥digo;
- iniciar Aider (siempre en una rama nueva);
- ejecutar `mise run LLM:generate_missing_tests`;
- revisar el Markdown (`missing-tests.md`);
- pegar el primer _issue_ de tests faltantes en Aider;
- ver a Aider hacer su magia ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™;
- ‚Ä¶;
- ejecutar las pruebas;
- repetir el ciclo ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

Es una forma bastante buena de mejorar una base de c√≥digo de manera incremental. Me ha resultado √∫til para tareas de cualquier tama√±o.

### Magia de _prompts_

Estos hacks r√°pidos funcionan muy bien para profundizar en los puntos donde un proyecto puede hacerse m√°s robusto. Son r√°pidos y efectivos.

Algunos de mis _prompts_ para bases de c√≥digo establecidas (se dejan en ingl√©s porque as√≠ se usan con el modelo):

#### Revisi√≥n de c√≥digo

```prompt
You are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.
```

#### Generaci√≥n de _issues_ de GitHub

(¬°Tengo que automatizar la publicaci√≥n real de los _issues_!)

```prompt
You are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to execute on, so they should be in a format that is compatible with GitHub issues
```

#### Tests faltantes

```prompt
You are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to execute on, so they should be in a format that is compatible with GitHub issues
```

Estos _prompts_ est√°n algo _old and busted_ (¬´_prompts_ boomer¬ª, si se quiere). Necesitan refactorizaci√≥n. Si tienes ideas para mejorarlos, av√≠same.

## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞

Cuando describo este proceso suelo decir: ¬´tienes que llevar un control agresivo de lo que est√° pasando porque puedes adelantarte f√°cilmente¬ª.

Por alguna raz√≥n, cuando hablo de LLMs digo mucho _over my skis_ (ir demasiado r√°pido). No s√© por qu√©, pero me resuena: es como deslizarte por nieve polvo perfecta y, de repente, pensar ¬´¬°¬øQU√â DEMONIOS PASA?!¬ª, perderte y caer por un precipicio.

Creo que usar un **paso de planificaci√≥n** (como en el proceso _greenfield_) ayuda a mantener las cosas bajo control: al menos tendr√°s un documento para comprobar. Tambi√©n creo que las pruebas son √∫tiles, sobre todo si vas a lo loco con Aider; ayudan a mantener todo ordenado y ajustado.

Aun as√≠, sigo encontr√°ndome **over my skis** con frecuencia. A veces un descanso corto o una caminata ayudan. En ese sentido es un proceso de resoluci√≥n de problemas normal, pero acelerado a velocidad de v√©rtigo.

> A menudo pedimos al LLM que incluya cosas rid√≠culas en nuestro c√≥digo no tan rid√≠culo. Por ejemplo, le pedimos que creara un archivo de _lore_ y luego lo referenciara en la interfaz de usuario (para herramientas CLI en Python). De pronto aparece _lore_, interfaces glitchy, etc. Todo para gestionar funciones en la nube, tu lista de tareas o lo que sea. El cielo es el l√≠mite.

## Estoy tan solooo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)

Mi principal queja sobre estos procesos es que, en gran medida, son de **modo de un solo jugador**.

He pasado a√±os programando solo, a√±os programando en pareja y a√±os en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en equipo: los bots chocan, las fusiones son horribles y el contexto se complica.

Quiero que alguien resuelva esto y convierta la programaci√≥n con un LLM en un juego multijugador, no en la experiencia del hacker solitario. Hay much√≠simo por mejorar.

¬°A TRABAJAR!

## ‚¥µ Tiempo ‚¥µ

Todo este _codegen_ ha acelerado la cantidad de c√≥digo que puedo generar yo solo. Sin embargo, hay un efecto curioso: tengo mucho ‚Äútiempo muerto‚Äù esperando a que el LLM termine de quemar tokens.

{{< image src="apple-print-shop-printing.png" alt="Imprimiendo" caption="Lo recuerdo como si fuera ayer" >}}

He cambiado mi forma de trabajar e incorporado algunas pr√°cticas para aprovechar ese tiempo de espera:

- comienzo el _brainstorming_ de otro proyecto;
- escucho discos;
- juego a _Cookie Clicker_;
- converso con amigos y robots.

Es genial poder hackear as√≠. Hack, hack, hack. No recuerdo otra √©poca en la que fuera tan productivo programando.

## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ

Muchos amigos me dicen: ¬´Los LLMs apestan, son malos en todo¬ª. No me molesta ese punto de vista. Yo no lo comparto, pero creo que es importante ser esc√©ptico. Hay un mont√≥n de razones para odiar la IA. Mi mayor temor es el consumo energ√©tico y el impacto medioambiental. Pero‚Ä¶ el c√≥digo debe fluir. ¬øVerdad? _Suspiro_.

Si quieres saber m√°s, pero no te apetece convertirte en un ¬´programador c√≠borg¬ª, mi recomendaci√≥n no es que cambies de opini√≥n, sino que leas el libro de Ethan Mollick sobre LLMs y su uso: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).

Explica muy bien los beneficios sin ser un panfleto tecno-anarcocapitalista. Me result√≥ √∫til y he tenido conversaciones buenas y matizadas con amigos que lo leyeron. Muy recomendado.

Si eres esc√©ptico pero tienes algo de curiosidad, escr√≠beme y hablamos de esta locura. Puedo mostrarte c√≥mo usamos LLMs y quiz√° construir algo juntos.

_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar este post y sugerir cambios. ¬°Lo aprecio!_
