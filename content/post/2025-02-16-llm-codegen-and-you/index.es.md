---
bsky: https://bsky.app/profile/harper.lol/post/3lidixzdr5j2e
date: 2025-02-16 18:00:00-05:00
description: Un recorrido detallado de mi flujo de trabajo actual para usar LLMs en
  la construcci√≥n de software, desde la lluvia de ideas hasta la planificaci√≥n y la
  ejecuci√≥n.
draft: false
generateSocialImage: true
tags:
- LLM
- coding
- ai
- workflow
- software-development
- productivity
title: Mi flujo de trabajo de generaci√≥n de c√≥digo con LLM en este momento
translationKey: My LLM codegen workflow atm
---

_tl;dr: Tormenta de ideas para la especificaci√≥n (*spec*), luego planificar el plan (s√≠, planificar el plan), despu√©s ejecutar con generaci√≥n de c√≥digo (*codegen*) mediante los LLM. Bucles discretos. Y luego‚Ä¶ magia. ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß_

He estado construyendo **much√≠simos** productos peque√±os con los LLM. Ha sido divertido y √∫til, pero hay trampas que pueden hacerte perder much√≠simo tiempo. Hace un tiempo, un amigo me pregunt√≥ c√≥mo estaba usando los LLM para escribir software. Pens√©: ¬´¬°Madre m√≠a! ¬øCu√°nto tiempo tienes?¬ª y as√≠ naci√≥ esta entrada.

(P. D.: si odias la IA, salta al final).

Hablo con muchos amigos desarrolladores sobre esto y todos seguimos un enfoque parecido, con matices aqu√≠ y all√°.

Aqu√≠ va mi *workflow* (flujo de trabajo). Se basa en mi experiencia, en charlas con amigos (gracias [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) y [Erik](https://thinks.lol/)), y en un pu√±ado de buenas pr√°cticas compartidas en los m√°s infames y terribles rincones de Internet ([uno](https://news.ycombinator.com/) y [otro](https://twitter.com)).

Esto funciona bien **AHORA**; puede que en dos semanas deje de servir‚Ä¶ o que funcione el doble de bien. ¬Ø\\\_(„ÉÑ)\_/¬Ø

## Vamos all√°

{{< image src="llm-coding-robot.webp" alt="Juggalo Robot" caption="Siempre desconf√≠o de estas im√°genes generadas por IA. ¬°Saluda a mi √°ngel-robot *juggalo* programador!" >}}

Hay muchos caminos para desarrollar, pero mis proyectos suelen caer en uno de estos dos escenarios:

- C√≥digo nuevo desde cero (*greenfield*)
- Base de c√≥digo heredada pero moderna (*non-greenfield*)

Te mostrar√© mi proceso para ambos.

## Greenfield

El siguiente proceso me funciona de maravilla cuando parto de cero. Aporta una planificaci√≥n y documentaci√≥n s√≥lidas y permite avanzar f√°cilmente en pasos peque√±os.

{{< image src="greenfield.jpg" alt="Campo verde" caption="T√©cnicamente, hay un campo verde a la derecha. Leica Q, 14/5/2016" >}}

### Paso 1: Afinar la idea

Usa un LLM conversacional para pulir la idea (yo utilizo ChatGPT-4o / o3):

```prompt
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let‚Äôs do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here‚Äôs the idea:

<IDEA>
```

Al final de la lluvia de ideas (llegar√° a una conclusi√≥n natural):

```prompt
Now that we‚Äôve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.
```

Obtendr√°s una especificaci√≥n bastante s√≥lida que podr√°s pasar al paso de planificaci√≥n. Suelo guardarla como `spec.md` en el repositorio.

> Esa especificaci√≥n sirve para muchas cosas. Aqu√≠ la usamos para generaci√≥n de c√≥digo (*codegen*), pero tambi√©n la he empleado para pedirle a un modelo de razonamiento que busque puntos d√©biles (¬°hay que ir m√°s profundo!), para generar un *white paper* o un modelo de negocio. Incluso puedes lanzarla a una investigaci√≥n exhaustiva y recibir a cambio un documento de apoyo de 10 000 palabras.

### Paso 2: Planificaci√≥n

Pasa la *spec* a un modelo de razonamiento (`o1*`, `o3*`, `r1`):

(Este es el *prompt* con TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

(Este es el *prompt* sin TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

El modelo devolver√° un plan de *prompts* que podr√°s ejecutar con Aider, Cursor, etc. Yo lo guardo como `prompt_plan.md` en el repositorio.

Despu√©s le pido una lista de comprobaci√≥n:

```prompt
Can you make a `todo.md` that I can use as a checklist? Be thorough.
```

Gu√°rdalo como `todo.md`. Tu herramienta de generaci√≥n de c√≥digo deber√≠a ir marcando esta lista para mantener el estado entre sesiones.

#### ¬°Plan listo!

Con esto tienes un plan robusto y documentaci√≥n clara para construir tu proyecto.

Todo el proceso lleva, como mucho, **15 minutos**. Una locura, la verdad.

### Paso 3: Ejecuci√≥n

Hay much√≠simas opciones; el √©xito depende de lo bien que sali√≥ el Paso 2.

He usado este flujo con [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)‚Ä¶ Funciona bien con todas las que he probado y, seguramente, con cualquier otra herramienta de generaci√≥n de c√≥digo (*codegen*).

Aun as√≠, prefiero **Claude puro** y Aider.

### Claude

B√°sicamente hago *pair programming* con [Claude.ai](https://claude.ai) pegando cada instrucci√≥n de forma iterativa. Funciona bastante bien: el ida y vuelta puede ser pesado, pero cumple.

Yo me encargo del c√≥digo base inicial y de que las herramientas est√©n configuradas. Esto da cierta libertad y gu√≠a al principio. Claude tiende a escupir c√≥digo React a la m√≠nima; contar con una base s√≥lida en el lenguaje y estilo de tu elecci√≥n ayuda mucho.

Cuando las cosas se atascan, uso [Repomix](https://github.com/yamadashy/repomix) para iterar.

Flujo de trabajo:

- preparo el repositorio (`uv init`, `cargo init`, etc.);
- pego la instrucci√≥n en Claude;
- copio el c√≥digo al IDE;
- ejecuto el c√≥digo y la suite de pruebas;
- si funciona, paso a la siguiente instrucci√≥n;
- si no, paso la base de c√≥digo a Claude con Repomix para depurar;
- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

### Aider

[Aider](https://aider.chat/) es divertido y algo peculiar. Encaja muy bien con la salida del Paso 2: avanzo much√≠simo con muy poco esfuerzo.

El flujo es casi id√©ntico, pero pegando las instrucciones en Aider.

Aider ¬´simplemente lo hace¬ª y yo me pongo a jugar a [*Cookie Clicker*](https://orteil.dashnet.org/cookieclicker/).

> Aider publica un *benchmark* excelente de modelos nuevos en su [LLM Leaderboard](https://aider.chat/docs/leaderboards/). Es un recurso brutal para ver qu√© tan efectivos son los modelos.

Las pruebas son a√∫n m√°s autom√°ticas con Aider, porque ejecuta la suite y depura por ti.

Flujo de trabajo:

- preparo el repositorio (`uv init`, `cargo init`, etc.);
- inicio Aider (procura estar siempre en una rama nueva);
- pego la instrucci√≥n;
- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™;
- Aider ejecuta pruebas o corro la app para verificar;
- si funciona, siguiente instrucci√≥n;
- si no, sesi√≥n de preguntas y respuestas con Aider hasta arreglarlo;
- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß

### Resultados

He construido scripts, apps de Expo, herramientas CLI en Rust, etc., usando este m√©todo. Funciona en distintos lenguajes y contextos. La verdad, me encanta.

Si tienes un proyecto ‚Äîgrande o peque√±o‚Äî aparcado, prueba esto: te sorprender√° lo lejos que avanzas en poco tiempo.

Mi lista de *hacks* pendientes est√° vac√≠a porque ya constru√≠ todo. Pienso ideas nuevas y las tacho mientras veo una peli. Por primera vez en a√±os estoy jugando con lenguajes y herramientas nuevas, y eso ampl√≠a mi perspectiva como programador.

## No-greenfield: iteraci√≥n incremental (sobre c√≥digo existente)

A veces no partes de cero y toca mejorar o a√±adir funcionalidades a una base de c√≥digo existente.

{{< image src="brownfield.jpg" alt="a brown field" caption="Esto NO es un *greenfield*. Foto aleatoria de la c√°mara de mi abuelo ‚Äî Uganda, a√±os 60." >}}

Para esto uso un m√©todo parecido, pero menos de ‚Äúplanificaci√≥n global‚Äù: planifico por tarea, no por proyecto.

### Obtener contexto

Quienes estamos hasta las rodillas en desarrollo con IA solemos tener cada uno nuestra herramienta favorita para empaquetar el c√≥digo y pasarlo eficazmente a los LLM.

Yo utilizo [Repomix](https://github.com/yamadashy/repomix) y un conjunto de tareas en `~/.config/mise/config.toml` (ver [reglas de mise](https://mise.jdx.dev/)):

```shell
LLM:clean_bundles           Generate LLM bundle output file using repomix
LLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use
LLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation
LLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation
LLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation
LLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation
LLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation
```

Genero un `output.txt` con el contexto de la base de c√≥digo. Si se pasa de tokens, ajusto el comando para ignorar partes irrelevantes.

> Algo estupendo de `mise` es que las tareas pueden redefinirse en el `.mise.toml` del proyecto. Puedo usar otra herramienta para empaquetar el c√≥digo y, mientras genere un `output.txt`, mis tareas LLM siguen funcionando. Suelo sobreescribir el paso de Repomix para incluir patrones de *ignore* m√°s amplios o usar una herramienta m√°s eficaz seg√∫n el caso.

Luego paso `output.txt` al comando [LLM](https://github.com/simonw/LLM) y guardo la salida como Markdown.

En el fondo, la tarea ejecuta algo como:

```bash
cat output.txt | LLM -t readme-gen > README.md
# o
cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md
```

Por ejemplo, para mejorar la cobertura de pruebas:

#### Claude

- voy al directorio del c√≥digo;
- `mise run LLM:generate_missing_tests`;
- reviso `missing-tests.md`;
- copio el contexto con `mise run LLM:copy_buffer_bundle`;
- pego eso en Claude junto con el primer ‚Äúissue‚Äù de pruebas faltantes;
- copio el c√≥digo generado al IDE;
- ejecuto pruebas;
- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  

#### Aider

- voy al directorio del c√≥digo;
- abro Aider (siempre en una rama nueva);
- `mise run LLM:generate_missing_tests`;
- reviso `missing-tests.md`;
- pego el primer ‚Äúissue‚Äù en Aider;
- veo a Aider bailar ‚ô™‚îè(„ÉªoÔΩ•)‚îõ‚ô™;
- ejecuto pruebas;
- y a repetir ‚ú©‚ÇäÀö.‚ãÜ‚òæ‚ãÜ‚Å∫‚Çä‚úß  

Esta metodolog√≠a es muy √∫til para mejorar gradualmente cualquier base de c√≥digo, sin importar el tama√±o de la tarea.

### Magia de *prompts*

Estos peque√±os *hacks* van de maravilla para hurgar en el proyecto y hacerlo m√°s robusto.

#### Revisi√≥n de c√≥digo

```prompt
You are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply  before writing the code review. Review every part, and don't hallucinate.
```

#### Generaci√≥n de issues de GitHub

```prompt
You are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

#### Tests faltantes

```prompt
You are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues  will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

Estos *prompts de boomer* necesitan un repaso. Si tienes ideas para mejorarlos, av√≠same.

## Esqu√≠ ·®í‚Üü ñ†∞·®í‚Üü ñ†∞

Cuando explico este proceso digo: ¬´Hay que llevar el control de forma agresiva porque es muy f√°cil adelantarte a ti mismo.¬ª

Por alguna raz√≥n digo mucho *over my skis* (pasado de vueltas) cuando hablo de los LLM. Quiz√° porque es como esquiar en polvo perfecto y, de pronto, ¬´¬°¬øQU√â CARAJO EST√Å PASANDO?!¬ª, te pierdes y caes por un precipicio.

Usar un **paso de planificaci√≥n** (como en el proceso *greenfield*) ayuda: al menos tienes un documento para comprobar. Tambi√©n creo que las pruebas son clave ‚Äîsobre todo si codificas ‚Äúa lo loco‚Äù con Aider‚Äî: mantienen todo ajustado.

Aun as√≠, a menudo sigo sinti√©ndome *over my skis*. Un descanso r√°pido o un paseo corto suele ayudar. Al fin y al cabo es el proceso normal de resolver problemas, solo que a velocidad de v√©rtigo.

> A veces pedimos a los LLM que incluyan cosas rid√≠culas en nuestro c√≥digo no tan rid√≠culo. Por ejemplo, le pedimos que creara un archivo de *lore* y luego lo referenciara en la interfaz de usuario de una herramienta CLI de Python. De repente tienes *lore*, interfaces glitchy‚Ä¶ Todo ello, parad√≥jicamente, solo para gestionar tus funciones en la nube, tu lista de tareas o lo que sea. El cielo es el l√≠mite.

## Estoy tan solo (ÔΩ°‚Ä¢ÃÅÔ∏ø‚Ä¢ÃÄÔΩ°)

Mi mayor queja es que estos flujos son, b√°sicamente, _single-player_. He pasado a√±os programando solo, en pareja y en equipo. Siempre es mejor con gente. Estos flujos no son f√°ciles de usar en grupo: los bots chocan, las fusiones son horribles, el contexto se complica.

Quiero que alguien convierta la programaci√≥n con LLM en un juego multijugador. ¬°Hay una oportunidad enorme! **GET TO WORK!**

## ‚¥µ Tiempo ‚¥µ

Toda esta generaci√≥n de c√≥digo ha disparado la cantidad de trabajo que puedo producir. Pero hay un efecto raro: mucho tiempo muerto mientras el LLM quema tokens.

{{< image src="apple-print-shop-printing.png" alt="Printing" caption="Lo recuerdo como si fuera ayer" >}}

Para aprovechar la espera:

- inicio la lluvia de ideas de otro proyecto;
- pongo vinilos;
- juego a *Cookie Clicker*;
- charlo con amigos‚Ä¶ y con robots.

Hack, hack, hack. No recuerdo otra √©poca en la que fuera tan productivo.

## Haterade ‚ï≠‚à©‚ïÆ( ‚Ä¢ÃÄ\_‚Ä¢ÃÅ )‚ï≠‚à©‚ïÆ

Muchos colegas dicen: ¬´Los LLM apestan; fallan en todo¬ª. No comparto esa opini√≥n, pero el escepticismo es sano. Hay razones de sobra para odiar la IA. Mi miedo principal es el consumo energ√©tico y el impacto ambiental. Pero‚Ä¶ el c√≥digo debe fluir. *Suspiro.* ¬Ø\\\_(„ÉÑ)\_/¬Ø

Si quieres saber m√°s sin convertirte en c√≠borg programador, te recomiendo el libro de Ethan Mollick: [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/). Explica los beneficios sin rollo *tech-bro* y me ha permitido charlas muy matizadas con amigos. Muy recomendado.

Si eres esc√©ptico pero curioso, escr√≠beme: te ense√±o c√≥mo usamos los LLM y quiz√° construyamos algo juntos.

_Gracias a [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) y [Erik](https://thinks.lol/) por revisar esta entrada y sugerir cambios. ¬°Lo aprecio!_