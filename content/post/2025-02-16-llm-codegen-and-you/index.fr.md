---
bsky: https://bsky.app/profile/harper.lol/post/3lidixzdr5j2e
date: 2025-02-16 18:00:00-05:00
description: Un aperÃ§u dÃ©taillÃ© de mon flux de travail actuel pour utiliser les LLM
  afin de dÃ©velopper des logiciels, de la phase de remue-mÃ©ninges jusquâ€™Ã  la planification
  et lâ€™exÃ©cution.
draft: false
generateSocialImage: true
slug: my-llm-codegen-workflow-atm
tags:
- LLM
- coding
- ai
- workflow
- software-development
- productivity
title: Mon flux de travail de gÃ©nÃ©ration de code LLM en ce moment
translationKey: My LLM codegen workflow atm
---

_TL;DR â€” On peaufine dâ€™abord la spÃ©cification au moyen de sÃ©ances de brainstorming, on Ã©labore ensuite un plan, puis on exÃ©cute grÃ¢ce Ã  la gÃ©nÃ©ration de code par LLM. Boucles distinctes. Et, au bout du compte, la magie. âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§_

Jâ€™ai enchaÃ®nÃ© les petits projets Ã  base de LLM : câ€™est fun et utile, mais les piÃ¨ges peuvent faire perdre un temps fou. Il y a quelque temps, un ami mâ€™a demandÃ© comment jâ€™utilisais les LLM pour coder. Je me suis dit : Â« Ouh lÃ  ! Tu as combien de temps ? Â» â€” dâ€™oÃ¹ ce billet.

(p.s. : si vous dÃ©testez lâ€™IA, filez directement Ã  la fin)

Je discute souvent avec des amis dev ; chacun bidouille un peu diffÃ©remment, mais on suit globalement la mÃªme approche.

Voici donc ma dÃ©marche. Elle sâ€™appuie sur mon expÃ©rience, des Ã©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur pas mal de bonnes pratiques glanÃ©es dans les recoins (parfois douteux) du Net : [ici](https://news.ycombinator.com/) et [lÃ ](https://twitter.com).

Ã‡a marche trÃ¨s bien **MAINTENANT** ; dans deux semaines, ce sera peut-Ãªtre cassÃ©â€¦ ou deux fois plus efficace. Â¯\\\_(ãƒ„)\_/Â¯

## Allons-y

{{< image src="llm-coding-robot.webp" alt="Robot Juggalo" caption="Je me mÃ©fie toujours un peu de ces images gÃ©nÃ©rÃ©es par IA. Dites bonjour Ã  mon ange robot juggalo codeur !" >}}

Il existe mille faÃ§ons de dÃ©velopper, mais je me retrouve gÃ©nÃ©ralement dans lâ€™un de ces deux cas :

- Code neuf (greenfield)  
- Code existant moderne (legacy modern/brownfield)

Voici mon mode opÃ©ratoire pour chacun.

## Greenfield

Pour un projet neuf, la dÃ©marche qui suit fonctionne bien : planification et documentation bÃ©ton, puis exÃ©cution en petites Ã©tapes.

{{< image src="greenfield.jpg" alt="Champ vert" caption="Techniquement, il y a un champ vert Ã  droite. Leica Q, 14/05/2016" >}}

### Ã‰tape 1 : affiner lâ€™idÃ©e

Utilisez un LLM conversationnel pour clarifier lâ€™idÃ©e (jâ€™emploie ChatGPT 4o / o3) :

```prompt
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Letâ€™s do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Hereâ€™s the idea:

<IDEA>
```

Ã€ la fin du brainstorming (vous le sentirez) :

```prompt
Now that weâ€™ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.
```

Vous obtenez ainsi une spÃ©cification carrÃ©e, prÃªte pour la phase suivante. Je la sauvegarde en `spec.md` dans le dÃ©pÃ´t.

> On peut faire plein de choses avec cette spÃ©cification. Ici on fait de la gÃ©nÃ©ration de code, mais je lâ€™ai dÃ©jÃ  utilisÃ©e pour demander Ã  un modÃ¨le de raisonnement de percer des trous dans lâ€™idÃ©e (toujours plus !), rÃ©diger un white paper ou carrÃ©ment un business model. Vous pouvez mÃªme lancer une recherche approfondie et recevoir un doc de 10 k mots en retour.

### Ã‰tape 2 : planification

Passez la spÃ©cification Ã  un modÃ¨le de raisonnement (Â« o1* Â», Â« o3* Â», Â« r1 Â»).

(Prompt â€“ TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

(Prompt â€“ non-TDD)

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

Le modÃ¨le doit produire un plan de prompts exÃ©cutable avec Aider, Cursor, etc. Je lâ€™enregistre en `prompt_plan.md` dans le dÃ©pÃ´t.

Je lui fais ensuite gÃ©nÃ©rer un `todo.md` :

```prompt
Can you make a `todo.md` that I can use as a checklist? Be thorough.
```

Enregistrez-le dans le dÃ©pÃ´t.  
Lâ€™outil de gÃ©nÃ©ration pourra cocher les cases de `todo.md` en avanÃ§ant : parfait pour garder lâ€™Ã©tat dâ€™une session Ã  lâ€™autre.

#### Yay. Plan !

Vous avez maintenant un plan solide et une documentation de rÃ©fÃ©rence qui vous permettront de garder le cap.  
Le tout prend **environ 15 minutes**. Dingue.

### Ã‰tape 3 : exÃ©cution

Il existe un tas dâ€™options pour lâ€™exÃ©cution. Le succÃ¨s dÃ©pend surtout de la qualitÃ© de lâ€™Ã©tape 2.

Jâ€™ai testÃ© ce flux de travail avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude Engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [claude.ai](https://claude.ai), etc. Ã‡a tourne avec tout ce que jâ€™ai essayÃ© â€” et sÃ»rement avec nâ€™importe quel outil de gÃ©nÃ©ration de code.

Perso, je prÃ©fÃ¨re **Claude en mode natif** et Aider.

### Claude

Je fais du pair-programming sur [claude.ai](https://claude.ai) : je soumets les prompts lâ€™un aprÃ¨s lâ€™autre. Les allers-retours sont parfois pÃ©nibles, mais Ã§a fonctionne.

Je suis responsable du boilerplate et de la config au dÃ©part : Ã§a Ã©vite que Claude parte par dÃ©faut sur du React et Ã§a fixe la stack de mon choix.

Quand Ã§a bloque, jâ€™utilise [repomix](https://github.com/yamadashy/repomix) pour filer toute la base de code Ã  Claude et dÃ©boguer.

Flux :

- initialiser le dÃ©pÃ´t (boilerplate, `uv init`, `cargo init`, etc.)  
- coller le prompt dans Claude  
- copier-coller le code dans lâ€™IDE  
- exÃ©cuter le code, lancer les tests, etc.  
- â€¦  
- si Ã§a passe : prompt suivant  
- sinon : repomix + Claude pour dÃ©boguer  
- on recommence âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

### Aider

[Aider](https://aider.chat/) est fun et un peu Ã©trange. Il sâ€™emboÃ®te nickel avec la sortie de lâ€™Ã©tape 2 : on avance trÃ¨s vite avec presque rien.

MÃªme flux, mais en collant les prompts dans Aider, qui Â« fait le taf Â» pendant quâ€™on joue Ã  [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).

> Au passage : Aider publie dâ€™excellents benchmarks des nouveaux modÃ¨les dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/) â€” super pour jauger les derniÃ¨res bÃªtes.

Les tests ? Encore plus simple : Aider lance la suite et corrige.

Flux :

- init du dÃ©pÃ´t (boilerplate, `uv init`, `cargo init`, etc.)  
- lancer Aider  
- coller le prompt  
- regarder Aider danser â™ªâ”(ãƒ»oï½¥)â”›â™ª  
- Aider lance les tests, ou vous exÃ©cutez pour vÃ©rifier  
- si Ã§a passe : prompt suivant  
- sinon : Q/R avec Aider  
- on recommence âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

### RÃ©sultats

Jâ€™ai bÃ¢ti une tonne de trucs avec ce flux : scripts, apps Expo, CLI Rust, etc. Ã‡a marche quel que soit le langage et le contexte.

Si vous repoussez un projet, petit ou gros, testez-le : vous serez bluffÃ©Â·e par la vitesse dâ€™avancement.

Ma todo Â« hacks Â» est vide parce que jâ€™ai tout fait. Je pense Ã  un nouveau truc, je le sors en regardant un film. Pour la premiÃ¨re fois depuis des annÃ©es, je joue avec de nouveaux langages et outils : Ã§a Ã©largit ma perspective de dev.

## Legacy modern (Brownfield) : itÃ©rer, petit Ã  petit

Parfois, pas de terrain vierge : il faut amÃ©liorer une base de code existante.

{{< image src="brownfield.jpg" alt="un champ brun" caption="Ce nâ€™est pas un champ vert. Photo prise par mon grand-pÃ¨re â€“ quelque part en Ouganda dans les annÃ©es 60" >}}

La mÃ©thode est proche, mais moins centrÃ©e sur un grand plan ; on planifie tÃ¢che par tÃ¢che.

### Choper le contexte

Chacun a son outil, mais il faut extraire la base de code et lâ€™injecter efficacement dans le LLM.

Jâ€™utilise [repomix](https://github.com/yamadashy/repomix) avec des tÃ¢ches dÃ©finies dans `~/.config/mise/config.toml`.

Liste :

```shell
LLM:clean_bundles           Generate LLM bundle output file using repomix
LLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use
LLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation
LLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation
LLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation
LLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation
LLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation
```

Je gÃ©nÃ¨re un `output.txt` avec le contexte. Si je **crame trop de jetons** et que le bundle est trop volumineux, jâ€™ajuste pour ignorer ce qui nâ€™est pas utile.

> Avantage de `mise` : on peut redÃ©finir ces tÃ¢ches dans le `.mise.toml` du projet. Tant que Ã§a sort un `output.txt`, mes commandes LLM tournent. Top quand les bases de code divergent.

Une fois `output.txt` prÃªt, je passe Ã§a Ã  [LLM](https://github.com/simonw/LLM) pour diverses transformations, puis je sauvegarde en Markdown.

```shell
cat output.txt | LLM -t readme-gen > README.md
# ou
cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md
```

> Ce nâ€™est pas trÃ¨s compliquÃ© : la commande `LLM` fait le gros du travail (gestion des modÃ¨les, des clÃ©s et des templates de prompt).

Besoin dâ€™un examen express **et dâ€™une correction** de la couverture de tests ? VoilÃ  :

#### Claude

- se placer dans le dossier  
- `mise run LLM:generate_missing_tests`  
- ouvrir `missing-tests.md`  
- copier le bundle : `mise run LLM:copy_buffer_bundle`  
- coller le tout dans Claude avec la premiÃ¨re *issue*  
- copier le code gÃ©nÃ©rÃ© dans lâ€™IDE  
- â€¦  
- lancer les tests  
- on recommence âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

#### Aider

- se placer dans le dossier  
- lancer Aider (sur une branche dÃ©diÃ©e)  
- `mise run LLM:generate_missing_tests`  
- ouvrir `missing-tests.md`  
- coller la premiÃ¨re *issue* dans Aider  
- regarder Aider danser â™ªâ”(ãƒ»oï½¥)â”›â™ª  
- â€¦  
- exÃ©cuter les tests  
- on recommence âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

MÃ©thode efficace pour amÃ©liorer progressivement une grosse base de code ; jâ€™ai pu prendre des tÃ¢ches de toute taille avec Ã§a.

### Magie des prompts

Ces mini-hacks permettent de repÃ©rer trÃ¨s vite les points Ã  renforcer dans un projet. Câ€™est extrÃªmement rapide et efficace.

Quelques-uns de mes prompts :

#### Revue de code

```prompt
You are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.
```

#### GÃ©nÃ©ration dâ€™issues GitHub

```prompt
You are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

#### Tests manquants

```prompt
You are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

Ces prompts sont un peu *old and busted* (Â« prompts de boomer Â», quoi). Ils mÃ©ritent un refacto. Si vous avez des idÃ©es, faites signe !

## Le ski á¨’â†Ÿ ğ– °á¨’â†Ÿ ğ– °

Quand jâ€™explique ce processus, je dis toujours quâ€™il faut **suivre de prÃ¨s tout ce qui se passe, sinon on se retrouve vite â€œover oneâ€™s skisâ€** â€” autrement dit, on va trop vite et on perd le contrÃ´le.

La phase **planification** (cf. Greenfield) aide Ã  rester droit : au moins, vous avez un doc de rÃ©fÃ©rence sur lequel revenir. Je crois aussi que les tests sont indispensables â€” surtout en freestyle avec Aider â€” pour garder un code propre et rigoureux.

MalgrÃ© Ã§a, je me retrouve encore souvent *over my skis*. Parfois, une pause ou une courte marche suffit. Câ€™est du problem-solving classiqueâ€¦ mais en accÃ©lÃ©rÃ©.

> On demande parfois au LLM dâ€™ajouter des trucs improbables dans un code pas si improbable. Exemple : crÃ©er un fichier de *lore*, des interfaces bancales (*glitchy interfaces*), puis les rÃ©fÃ©rencer dans lâ€™UI. Tout Ã§a pour simplement gÃ©rer tes fonctions cloud, ta todo-list, ou nâ€™importe quoi dâ€™autre. Tout est possible.

## Je me sens seul (ï½¡â€¢Ìï¸¿â€¢Ì€ï½¡)

Mon principal reproche : tout Ã§a se joue surtout en solo â€” des interfaces Â« single player Â».

Jâ€™ai codÃ© seul, en binÃ´me, en Ã©quipe ; câ€™est toujours mieux Ã  plusieurs. Ces flux ne sont pas simples Ã  partager : bots qui se marchent dessus, merges horribles, contexte compliquÃ©.

Je rÃªve dâ€™une solution pour que coder avec un LLM devienne un jeu multi, pas une expÃ© de hacker solitaire. Il y a un boulevard : **AU BOULOT !**

## â´µ Temps â´µ

Toute cette gÃ©nÃ©ration de code a dÃ©cuplÃ© ce quâ€™une seule personne peut produire. Effet secondaire : pas mal de temps mort en attendant que le LLM brÃ»le ses jetons.

{{< image src="apple-print-shop-printing.png" alt="Impression" caption="Je mâ€™en souviens comme si câ€™Ã©tait hier" >}}

Jâ€™ai donc adaptÃ© ma faÃ§on de bosser pour occuper ces moments :

- je lance le brainstorming dâ€™un autre projet  
- jâ€™Ã©coute des vinyles  
- je joue Ã  [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/)  
- je papote avec des amis (humains ou robots)

Câ€™est gÃ©nial de hacker comme Ã§a. Hack ! Hack ! Hack ! Je nâ€™ai jamais Ã©tÃ© aussi productif.

## Haterade â•­âˆ©â•®( â€¢Ì€\_â€¢Ì )â•­âˆ©â•®

Pas mal dâ€™amis me disent : Â« fuck les LLM, câ€™est naze. Â» Je **ne partage pas** cette opinion, mais je pense quâ€™il est sain de rester sceptique. Les raisons de haÃ¯r lâ€™IA ne manquent pas. Ma crainte principale : la consommation dâ€™Ã©nergie et lâ€™impact sur le climat. Maisâ€¦ *the code must flow*. *Sigh*.

Si vous voulez creuser sans devenir unÂ·e dev cyborg, lisez le bouquin dâ€™Ethan Mollick : [**Co-Intelligence: Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).

Ã‡a expose bien les bÃ©nÃ©fices sans le ton techno-libertarien. Jâ€™ai eu plein de discussions nuancÃ©es avec des amis qui lâ€™ont lu. RecommandÃ©.

Sceptique mais un peu curieuxÂ·se ? Pinguez-moi : je peux vous montrer comment on se sert des LLM, et on pourra peut-Ãªtre construire quelque chose ensemble.

_thanks to [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com), and [Erik](https://thinks.lol/) for taking a look at this post and suggesting edits. I appreciate it._