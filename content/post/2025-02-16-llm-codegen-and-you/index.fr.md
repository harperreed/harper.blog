---
bsky: https://bsky.app/profile/harper.lol/post/3lidixzdr5j2e
date: 2025-02-16 18:00:00-05:00
description: Une prÃ©sentation dÃ©taillÃ©e de mon workflow actuel pour utiliser les LLMs
  afin de crÃ©er des logiciels, du brainstorming Ã  la planification et Ã  l'exÃ©cution.
draft: false
generateSocialImage: true
tags:
- LLM
- coding
- ai
- workflow
- software-development
- productivity
title: Mon workflow de gÃ©nÃ©ration de code LLM en ce moment
translationKey: My LLM codegen workflow atm
---

_tl ; dr : fais un brainstorming de la spÃ©cification, puis Ã©labore un plan de plan, puis exÃ©cute avec de la gÃ©nÃ©ration de code par LLM. Boucles bien distinctes. Ensuite, la magie. âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§_

Je dÃ©veloppe depuis quelque temps une foule de petits produits grÃ¢ce aux LLM. Câ€™est funâ€Šâ€”â€Šet utile. Mais il y a aussi des piÃ¨ges qui font perdre un temps fou. Un jour, un ami mâ€™a demandÃ© comment jâ€™utilisais les LLM pour Ã©crire du logiciel. Jâ€™ai pensÃ© : Â« Oh boy, tâ€™as combien dâ€™heures devant toi ? Â»â€Šâ€”â€Šdâ€™oÃ¹ ce billet.

(p.s. si tu dÃ©testes lâ€™IA, file direct Ã  la fin)

Jâ€™en parle souvent avec des potes dev et on suit tous Ã  peu prÃ¨s la mÃªme approche, chacun y ajoutant ses petits rÃ©glages.

Voici donc mon flux de travail. Il repose sur mon expÃ©rience personnelle, sur des Ã©changes avec des amis (merci [Nikete](https://www.nikete.com/), [Kanno](https://nocruft.com/), [Obra](https://fsck.com/), [Kris](https://github.com/KristopherKubicki) et [Erik](https://thinks.lol/)), ainsi que sur de bonnes pratiques glanÃ©es dans les recoins (parfois douteux) du Net : [bad](https://news.ycombinator.com/) [places](https://twitter.com).

Ã‡a marche super bien **MAINTENANT** ; dans deux semaines ce sera peut-Ãªtre cassÃ©â€¦ ou deux fois plus performant. Â¯\\\_(ãƒ„)_/Â¯

## Allons-y

{{< image src="llm-coding-robot.webp" alt="Juggalo Robot" caption="Je trouve toujours ces images gÃ©nÃ©rÃ©es par IA un peu louches. Voici mon ange-robot codeur faÃ§on juggalo !" >}}

Il existe mille maniÃ¨res de dÃ©velopper, mais je me retrouve gÃ©nÃ©ralement dans lâ€™un de ces deux cas :

- nouveau projet (greenfield) ;
- code Â« legacy moderne Â» (un projet assez rÃ©cent mais dÃ©jÃ  hÃ©ritÃ©).

Je vais te montrer mon processus pour les deux pistes.

## Greenfield

Pour un projet greenfield, ce processus fonctionne bien : planification solide, docs propres et avancÃ©e par petits pas.

{{< image src="greenfield.jpg" alt="Green field" caption="Techniquement, il y a bien un champ vert Ã  droite. Leica Q, 14/05/2016" >}}

### Ã‰tape 1 : affiner lâ€™idÃ©e

Utilise un LLM conversationnel pour peaufiner lâ€™idÃ©e (jâ€™emploie ChatGPT 4o / o3).

Conserve les prompts suivants en anglais (les modÃ¨les les prÃ©fÃ¨rent ainsi).

```prompt
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Letâ€™s do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Hereâ€™s the idea:

<IDEA>
```

Quand le brainstorming arrive Ã  sa conclusion naturelle :

```prompt
Now that weâ€™ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.
```

Tu obtiens une spÃ©cification bien nette que je sauvegarde dâ€™habitude sous `spec.md`.

> On peut tirer beaucoup de choses de cette spec. Ici, on vise le codegen, mais je lâ€™utilise aussi pour demander Ã  un modÃ¨le de raisonnement de dÃ©nicher les failles (toujours plus profond !), pour rÃ©diger un white paper ou imaginer un business model. Tu peux mÃªme lancer une recherche poussÃ©e et rÃ©cupÃ©rer un document de 10 000 mots en retour.

### Ã‰tape 2 : planification

Envoie la spec Ã  un modÃ¨le orientÃ© raisonnement (`o1*`, `o3*`, `r1`).

#### Prompt TDD

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

#### Prompt non-TDD

```prompt
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

Le modÃ¨le te fournit alors un plan de prompts Ã  exÃ©cuter (je le sauvegarde en `prompt_plan.md`).

Demande-lui ensuite une todo-list :

```prompt
Can you make a `todo.md` that I can use as a checklist? Be thorough.
```

Ton outil de gÃ©nÃ©ration de code pourra cocher `todo.md` au fil de la session : parfait pour garder le contexte.

#### Youpi, un plan !

Tu as dÃ©sormais un plan solide et une doc prÃªte Ã  piloter ton projet.

Ces deux premiÃ¨res Ã©tapes prennent quoiâ€¦ **15 minutes** ? Câ€™est dingue.

### Ã‰tape 3 : exÃ©cution

Il existe une foule dâ€™outils ; leur succÃ¨s dÃ©pend surtout de la qualitÃ© de lâ€™Ã©tape 2.

Jâ€™ai testÃ© ce workflow avec [GitHub Workspace](https://githubnext.com/projects/copilot-workspace), [Aider](https://aider.chat/), [Cursor](https://www.cursor.com/), [Claude-Engineer](https://github.com/Doriandarko/claude-engineer), [Sweep.dev](https://sweep.dev/), [ChatGPT](https://chatgpt.com), [Claude.ai](https://claude.ai)â€¦ Ils sâ€™en sortent tous.

Moi, je prÃ©fÃ¨re Claude en mode brut (sans surcouche) et Aider.

### Claude

Je fais du pair-programming sur [Claude.ai](https://claude.ai) : je colle chaque prompt tour Ã  tour. Les allers-retours peuvent Ãªtre pÃ©nibles, mais Ã§a fonctionne.

Je gÃ¨re le boilerplate et le setup tooling ; ainsi, Claude nâ€™impose pas dâ€™office du React et je garde la main sur la stack.

Quand Ã§a coince, jâ€™utilise [Repomix](https://github.com/yamadashy/repomix) (un empaqueteur de dÃ©pÃ´t) pour envoyer tout le code Ã  Claude et dÃ©boguer.

Workflow :

- initialise le dÃ©pÃ´t (boilerplate, `uv init`, `cargo init`, etc.) ;
- colle le prompt dans Claude ;
- copie le code gÃ©nÃ©rÃ© dans ton IDE ;
- lance lâ€™appli, exÃ©cute les tests ;
- â€¦  
- si Ã§a roule : prompt suivant ;  
- sinon : repomix + Claude pour dÃ©boguer ;
- on rince, on rÃ©pÃ¨te âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

### Aider

[Aider](https://aider.chat/) est fun et un peu Ã©trange ; il sâ€™imbrique bien avec la sortie de lâ€™Ã©tape 2 et permet dâ€™aller trÃ¨s loin sans effort.

MÃªme logique : on colle les prompts dans Aider.

Aider Â« fait le taf Â» et je joue Ã  [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/).

> Au passage, Aider publie dâ€™excellents benchmarks de modÃ¨les de codegen dans ses [LLM leaderboards](https://aider.chat/docs/leaderboards/). IdÃ©al pour jauger les nouveaux modÃ¨les.

GrÃ¢ce aux tests, Aider peut Ãªtre encore plus mains libres : il exÃ©cute la suite et dÃ©bogue tout seul.

Workflow :

- initialise le dÃ©pÃ´t ;
- lance Aider ;
- colle le prompt ;
- regarde Aider danser â™ªâ”(ãƒ»oï½¥)â”›â™ª ;
- Aider lance les tests ou tu lances lâ€™appli pour vÃ©rifier ;
- si OK : prompt suivant ;
- sinon : questions/rÃ©ponses avec Aider pour corriger ;
- on rince, on rÃ©pÃ¨te âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

### RÃ©sultats

Jâ€™ai rÃ©alisÃ© une quantitÃ© folle de trucs : scripts, applis Expo, CLI Rust, etc. Tout langages confondus. Ultra efficace.

Ma todo hack est vide parce que jâ€™ai tout fini. Je continue dâ€™avoir de nouvelles idÃ©es que jâ€™enchaÃ®ne pendant un film. Pour la premiÃ¨re fois depuis des annÃ©es, je dÃ©couvre de nouveaux langages et outils ; Ã§a Ã©largit vraiment mon horizon.

## Non-greenfield : itÃ©rations incrÃ©mentales

Parfois, on nâ€™est pas en terrain vierge : il faut itÃ©rer sur une base de code existante.

{{< image src="brownfield.jpg" alt="a brown field" caption="Ce nâ€™est pas un champ vert. Photo prise par mon grand-pÃ¨re â€” Ouganda, annÃ©es 60" >}}

Dans ce cas, mÃ©thode un peu diffÃ©rente : moins de plan global, plus de planification tÃ¢che par tÃ¢che.

### Obtenir le contexte

Chacun a sa technique pour empaqueter le code et lâ€™injecter dans le LLM. Jâ€™utilise actuellement [Repomix](https://github.com/yamadashy/repomix) via des tÃ¢ches dÃ©finies dans `~/.config/mise/config.toml` (voir les [rÃ¨gles Mise](https://mise.jdx.dev/)).

Voici la liste des tÃ¢ches LLM :

```shell
LLM:clean_bundles           Generate LLM bundle output file using repomix
LLM:copy_buffer_bundle      Copy generated LLM bundle from output.txt to system clipboard for external use
LLM:generate_code_review    Generate code review output from repository content stored in output.txt using LLM generation
LLM:generate_github_issues  Generate GitHub issues from repository content stored in output.txt using LLM generation
LLM:generate_issue_prompts  Generate issue prompts from repository content stored in output.txt using LLM generation
LLM:generate_missing_tests  Generate missing tests for code in repository content stored in output.txt using LLM generation
LLM:generate_readme         Generate README.md from repository content stored in output.txt using LLM generation
```

Je gÃ©nÃ¨re un `output.txt` contenant tout le contexte. Si Ã§a dÃ©borde en tokens, jâ€™exclus les parties inutiles.

> Atout de `mise` : on peut redÃ©finir ou surcharger ces tÃ¢ches dans le `.mise.toml` du projet. Tant que Ã§a produit un `output.txt`, mes tÃ¢ches LLM tournent. Pratique quand les bases de code sont trÃ¨s diffÃ©rentes. Je surcharge souvent lâ€™Ã©tape Repomix pour Ã©largir les motifs dâ€™exclusion ou utiliser un empaqueteur plus adaptÃ©.

Une fois `output.txt` prÃªt, je le passe Ã  la commande [LLM](https://github.com/simonw/LLM) pour diverses transformations et je sauvegarde la sortie en markdown.

En pratique :

```
cat output.txt | LLM -t readme-gen > README.md
```

ou :

```
cat output.txt | LLM -m claude-3.5-sonnet -t code-review-gen > code-review.md
```

`LLM` gÃ¨re modÃ¨les, clÃ©s et templates.

Exemple : amÃ©liorer rapidement la couverture de tests.

#### Claude

- place-toi dans le dossier du code ;  
- `mise run LLM:generate_missing_tests` ;  
- ouvre `missing-tests.md` ;  
- copie le bundle : `mise run LLM:copy_buffer_bundle` ;  
- colle-le dans Claude avec la premiÃ¨re Â« issue Â» ;  
- copie le code gÃ©nÃ©rÃ© dans ton IDE ;  
- exÃ©cute les tests ;  
- on rince, on rÃ©pÃ¨te âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

#### Aider

- place-toi dans le dossier ;  
- lance Aider (sur une nouvelle branche) ;  
- `mise run LLM:generate_missing_tests` ;  
- ouvre `missing-tests.md` ;  
- colle la premiÃ¨re Â« issue Â» dans Aider ;  
- regarde Aider danser â™ªâ”(ãƒ»oï½¥)â”›â™ª ;  
- exÃ©cute les tests ;  
- on rince, on rÃ©pÃ¨te âœ©â‚ŠËš.â‹†â˜¾â‹†âºâ‚Šâœ§

Super efficace pour amÃ©liorer progressivement une grosse base de code.

### Magie des prompts

Ces petites astuces sont redoutables pour rendre un projet plus robuste. Vite fait, bien fait.

Voici quelques prompts que jâ€™utilise sur du code Ã©tabli (Ã  conserver en anglais) :

#### Code review

```prompt
You are a senior developer. Your job is to do a thorough code review of this code. You should write it up and output markdown. Include line numbers, and contextual info. Your code review will be passed to another teammate, so be thorough. Think deeply before writing the code review. Review every part, and don't hallucinate.
```

#### GÃ©nÃ©ration dâ€™issues GitHub

```prompt
You are a senior developer. Your job is to review this code, and write out the top issues that you see with the code. It could be bugs, design choices, or code cleanliness issues. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

#### Tests manquants

```prompt
You are a senior developer. Your job is to review this code, and write out a list of missing test cases, and code tests that should exist. You should be specific, and be very good. Do Not Hallucinate. Think quietly to yourself, then act - write the issues. The issues will be given to a developer to executed on, so they should be in a format that is compatible with github issues
```

Ces prompts datent un peu (Â« prompts de boomer Â»). Si tu as des idÃ©es pour les amÃ©liorer, fais signe !

## Skiing á¨’â†Ÿ ğ– °á¨’â†Ÿ ğ– °

Quand jâ€™explique ce procÃ©dÃ©, je dis : Â« Il faut suivre de prÃ¨s ce qui se passe, sinon tu te retrouves vite **over your skis**. Â»

Je parle souvent dâ€™Ãªtre ***over my skis*** avec les LLM : tu skies dans de la poudre parfaite et, soudain, Â« WHAT THE FUCK IS GOING ON ? Â»â€Šâ€”â€Štu pars en vrille et tu chutes.

La **phase de planification** (cf. greenfield) aide Ã  garder le contrÃ´le : tu as au moins un doc de rÃ©fÃ©rence. Les tests aussi, surtout avec Aider en mode freestyle : Ã§a garde le code propre et serrÃ©.

MalgrÃ© Ã§a, je me retrouve encore souvent ***over my skis***. Parfois, une pause ou une petite marche suffit. Au fond, câ€™est le mÃªme processus de rÃ©solution de problÃ¨mes, mais Ã  vitesse supersonique.

> On demande parfois au LLM dâ€™ajouter des trucs totalement absurdes dans un code qui ne lâ€™est pas tant que Ã§a. Exemple : crÃ©er un fichier de lore puis le rÃ©fÃ©rencer dans lâ€™interface dâ€™un outil CLI Python. Dâ€™un coup, il y a du lore, des interfaces glitchy, etc. Tout Ã§a pour gÃ©rer tes fonctions cloud, ta todo list ou nâ€™importe quoi. Le ciel est la limite.

## Je suis si seul (ï½¡â€¢Ìï¸¿â€¢Ì€ï½¡)

Mon principal reproche : tout Ã§a reste principalement **solo**â€Šâ€”â€Šle mode Â« single player Â».

Jâ€™ai codÃ© des annÃ©es seul, en pair, en Ã©quipe ; Ã  plusieurs, câ€™est toujours mieux. LÃ , les bots se percutent, les merges deviennent atroces, le contexte est complexe.

Je veux vraiment quâ€™on transforme le dev avec LLM en expÃ©rience multijoueur, pas juste un trip de hacker solitaire. Il y a un boulevard Ã  ouvrir.

AU BOULOT !

## â´µ Temps â´µ

La gÃ©nÃ©ration de code a multipliÃ© la quantitÃ© de code quâ€™une seule personne peut produire. Effet secondaire Ã©trange : beaucoup de Â« temps mort Â» pendant que le LLM brÃ»le ses tokens.

{{< image src="apple-print-shop-printing.png" alt="Printing" caption="Je mâ€™en souviens comme si câ€™Ã©tait hier" >}}

Jâ€™ai donc adaptÃ© ma faÃ§on de bosser pour combler ces attentes :

- je lance le brainstorming dâ€™un autre projet ;
- jâ€™Ã©coute des vinyles ;
- je joue Ã  [Cookie Clicker](https://orteil.dashnet.org/cookieclicker/) ;
- je discute avec des amis et des robots.

Câ€™est gÃ©nial de hacker comme Ã§a. Hack ! Hack ! Hack ! Je ne me souviens pas avoir Ã©tÃ© aussi productif.

## Haterade â•­âˆ©â•®( â€¢Ì€_â€¢Ì )â•­âˆ©â•®

Pas mal de potes me disent : Â« Les LLM, câ€™est naze. Â» Je respecte ce point de vue, mÃªme si je ne le partage pas. Il y a plein de raisons de se mÃ©fier de lâ€™IA. Ma plus grande crainte : la conso Ã©lectrique et lâ€™impact environnemental. Maisâ€¦ le code doit couler. *soupir*

Si tu es curieux sans vouloir devenir un Â« cyborg programmer Â», lis le livre dâ€™Ethan Mollick : [**Co-Intelligence : Living and Working with AI**](https://www.penguinrandomhouse.com/books/741805/co-intelligence-by-ethan-mollick/).

Bonne intro, sans le ton bro techno-libertarien. Jâ€™ai eu plein de discussions nuancÃ©es avec des amis aprÃ¨s lâ€™avoir lu. RecommandÃ©.

Si tu es sceptique mais un peu curieux, contacte-moi et on parlera de toute cette folie. On pourra peut-Ãªtre construire un truc ensemble.

_merci Ã  [Derek](https://derek.broox.com), [Kanno](https://nocruft.com/), [Obra](https://fsck.com) et [Erik](https://thinks.lol/) dâ€™avoir relu ce billet et proposÃ© des modifs. Je vous suis reconnaissant._