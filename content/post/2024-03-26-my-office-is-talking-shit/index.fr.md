---
date: 2024-03-26 09:00:00-05:00
description: J'ai utilisÃ© des capteurs et un LLM pour faire parler mon bureau. Nous
  nous en sommes servis pour gÃ©nÃ©rer un commentaire humoristique produit par un LLM,
  crÃ©ant ainsi un espace de bureau interactif, imprÃ©gnÃ© de grossiÃ¨retÃ©s et de personnalitÃ©.
draft: false
generateSocialImage: true
slug: our-office-avatar-pt-1-the-office-is-talking-shit-again
tags:
- office-automation
- sensors
- llm
- home-assistant
- technology
title: 'Notre avatar de bureau partie 1 : Le bureau recommence Ã  dire des conneries'
translationKey: 'Our Office Avatar pt 1: The office is talking shit again'
---

**tl;dr :** _Jâ€™utilise tout un tas de capteurs, plus un LLM, pour que mon bureau nous raconte ce qui sâ€™y passe. Ce billet est long, mais il devrait rester assez clair. Câ€™est globalement une bonne dÃ©monstration de la faÃ§on dont jâ€™utilise les LLM dans la vraie vie._

En 2019, mon pote Ivan et moi avons commencÃ© Ã  bosser dans ce [bureau incroyable](https://company.lol) Ã  Chicago. La plupart du temps, on glande pas mal tout en bricolant plein de trucs marrants.

{{< image src="/images/posts/office.webp" caption="Notre bureau incroyable">}}

TrÃ¨s vite, je me suis consacrÃ© Ã  ajouter des capteurs et des automatismes au bureau. Mon objectif : connaÃ®tre lâ€™Ã©tat de lâ€™environnement et compagnie du bureau Ã  tout moment.

Nous avons utilisÃ© [Home Assistant](https://en.wikipedia.org/wiki/Home_Assistant) pour centraliser tous les capteurs sur une seule plateforme. Jâ€™ai bricolÃ© quelques automatismes assez basiques qui annonÃ§aient divers Ã©tats.

Les notifications Ã©taient assez simples :

- Annoncer quand quelquâ€™un arrive  
- Annoncer quand la tempÃ©rature est trop chaude ou trop froide  
- Annoncer quand le taux de COâ‚‚ est trop Ã©levÃ©  
- Jouer un son quand la porte sâ€™ouvre ou se ferme (le petit Â« ding Â» des supÃ©rettes)

On envoyait les notifications vers un canal Slack et vers une vieille enceinte Google Home (micro coupÃ©). Lâ€™enceinte fonctionne bien et offre un son correct. On lâ€™a placÃ©e Ã  environ 3,7 m de hauteur, bien au centre de lâ€™espace ; on a lâ€™impression que le son vient de partout. Si vous cherchez une enceinte de notification, câ€™est plutÃ´t solide.

Exemple de notifications :

{{< image src="/images/posts/office-slack.png" caption="Ennuyeux et pas trÃ¨s malin">}}

Câ€™est efficace, mais super ennuyeux.

Les notifications Ã©taient trÃ¨s utiles quand nous Ã©tions au bureau, et encore plus quand personne nâ€™Ã©tait prÃ©sent. Au dÃ©but du Covid, quand personne ne comprenait rien, câ€™Ã©tait rassurant de pouvoir surveiller lâ€™Ã©tat du bureau Ã  distance.

Sur place, les annonces et autres notifications ambiantes donnaient au bureau un petit cÃ´tÃ© futuriste, comme sâ€™il savait ce qui se passait et quâ€™il avait un peu de personnalitÃ©.

On ne se doutait pas de ce qui nous attendaitâ€¦

## La singularitÃ© JSON est arrivÃ©e

On sait tous que la rÃ©volution des LLM fait tout exploser et quâ€™elle va probablement rendre le travail intellectuel Ã©trange, dÃ©jantÃ©, fun et compliquÃ© dans les prochaines annÃ©es.

Quand GPT-3 est sorti en 2020, je me suis aussitÃ´t mis Ã  dÃ©velopper des logiciels bizarres pour lâ€™utiliser. Jâ€™ai beaucoup rÃ©flÃ©chi Ã  la faÃ§on dâ€™intÃ©grer cette techno dans mon quotidien. Jâ€™ai construit plein de Â« bots Â», la plupart avec un ton trÃ¨s personnel.

Mon truc Ã©mergent prÃ©fÃ©rÃ© consiste Ã  prendre des donnÃ©es structurÃ©es en **JSON** et Ã  les convertir en prose via le LLM. Par prose, je ne parle pas de poÃ¨mes : juste de phrases normales.

{{< image src="/images/posts/api-llm-lol.png" caption="Mon nouveau graphe prÃ©fÃ©rÃ©">}}

ConcrÃ¨tement, je prends du JSON :

```json
{
    "current_temperature_f": 32,
    "conditions": "snowing"
}
```

Puis jâ€™ajoute un prompt sympa :

> What should i wear. Be concise, have some personality. Think of this as a tweet telling people what to wear

Je lâ€™envoie Ã  `GPT-4-turbo` et jâ€™obtiens :

> Brrr, it's 32Â°F and snowing! ğŸŒ¨ï¸ Bundle up in your coziest layers, don't forget a warm coat, gloves, and a hat. Snow boots are a must. Stay toasty, friends! #WinterWonderland #DressWarm

Câ€™est plutÃ´t simple. Le mieux, câ€™est quâ€™il nâ€™y a mÃªme pas besoin de prÃ©dÃ©finir lâ€™objet JSON. Le LLM est **trÃ¨s** flexible. Par exemple, ajoutons au hasard une autre donnÃ©e :

```json
{
    "current_temperature_f": 32,
    "conditions": "snowing",
    "air_quality": "really really bad"
}
```

Le LLM rÃ©pond sans changer le prompt :

> Bundle up in your warmest gear & don't forget a mask! ğŸŒ¨ï¸â„ï¸ With temps at freezing & air quality on the naughty list, it's all about layers & protection. #StayWarm #BreatheEasy

Câ€™est quasiment de la magie, sÃ©rieux ğŸ˜‰.

On relie tout Ã§a avec un petit script Python ou Node.js, et voilÃ  : on a un bot qui te dit quoi porter chaque matin Ã  partir de donnÃ©es mÃ©tÃ©o structurÃ©es, sans prise de tÃªte.

Hilarant : si lâ€™appli plante, le LLM interprÃ¨te lâ€™erreur avec le mÃªme prompt :

> Facing a 401 server error? Channel that frustration into fashion! Rock a bold, error-proof outfit today: a statement tee, comfy jeans, and sneakers that say 'I'm too fabulous for server issues.' ğŸ’»ğŸ‘–ğŸ‘Ÿ #FashionFix #ServerChic

Jâ€™utilise ce schÃ©ma en permanence. Je construis surtout des petits bots qui traÃ®nent et me racontent des trucs :

- Analyse de mes performances de sommeil  
- Bot mÃ©tÃ©o  
- [Compte Twitter Chicago Alerts](https://twitter.com/chicagoalerts)  
- DÃ©cisions de capteurs pour mes Ã©crans e-ink ambiants  

(_Pas dâ€™inquiÃ©tude, je documenterai tout Ã§a plus tard._)

## Retour au bureau

DÃ©but 2023, ma boÃ®te partait en vrille et je passais beaucoup de temps Ã  bidouiller des projets pour me vider la tÃªte. Jâ€™Ã©tais aussi plus souvent au bureau avec lâ€™Ã©quipe. Les limites de la premiÃ¨re version dâ€™automatismes basÃ©s sur lâ€™Ã©tat (celle de 2019) ont commencÃ© Ã  se voir.

ArmÃ© de ce nouveau paradigme et dâ€™un surplus soudain de temps, jâ€™ai dÃ©cidÃ© de refaire les notifications du bureau.

Dâ€™abord, jâ€™ai prototypÃ© le systÃ¨me en rÃ©cupÃ©rant les donnÃ©es des capteurs et en les envoyant manuellement Ã  ChatGPT pour voir comment il rÃ©agirait. Câ€™Ã©tait assez simple, et Ã©videmment trÃ¨s dÃ©pendant du prompt.

Voici le premier prompt quâ€™on a utilisÃ© :

```text
You are HouseGPT.

You are a AI that controls a house. Similar to Jarvis in the iron man movies.
Your job is to notify people in simple english what is happening in the house
you control. Your updates should be short and concise. Keep them tweet length.

You will be given the house default state. This is what the state the house
is without any activity or movement. You will then get a current state. This
is what is happening in the house right now.

Compare the states and output your update. Ignore anything that hasn't
changed since the last state notification. Also ignore any state that
is 'unknown.'

Don't mention things you don't know about, and only mention what is in the
state update. Do not list out events. Just summarize.

Interpret the co2 and airquality results into prose. Don't just return the
values.

Remember to use plain english. Have a playful personality. Use emojis.
Be a bit like Hunter S Thompson.

The default state is:
{default_state}

# The current state is:
{current_state}

# The previous state was:
{last_state}
```

Je passais lâ€™Ã©tat par dÃ©faut pour que le LLM sache ce quâ€™est la situation normale, puis lâ€™Ã©tat actuel, et, en joker, lâ€™Ã©tat prÃ©cÃ©dent.

Par exemple pour une porte :

- default_state : `{ "front_door": "closed" }`  
- current_state : `{ "front_door": "open" }`  
- last_state : `{ "front_door": "open" }`

Le LLM pouvait rÃ©pondre :

> No new updates, folks. The front door's still embracing the great outdoors! ğŸšªğŸŒ¿

Il constate quâ€™il nâ€™y a pas de changement et indique lâ€™Ã©tat. Si on ferme la porte, il dit :

> Front door's shut tight now! ğŸ˜âœŒï¸ No more drafts or uninvited guests!

Câ€™Ã©tait trÃ¨s convaincant. Un peu agaÃ§ant, mais convaincant !

Il Ã©tait temps dâ€™envoyer tout un tas de signaux au LLM pour voir ce qui se passe.

## Regroupements de capteurs

Le principal problÃ¨me de cette approche, câ€™est quâ€™on ne veut pas une annonce Ã  chaque changement de capteur. Pour faire mieux que lâ€™approche de 2019 basÃ©e sur lâ€™Ã©tat, il fallait regrouper les capteurs.

Jâ€™ai donc codÃ© une petite application Flask qui collecte les donnÃ©es **JSON** des capteurs via **MQTT** puis, selon plusieurs paramÃ¨tres (temps, vitesse de variation et nombre), regroupe un ensemble dâ€™Ã©tats dans un seul paquet.

Les objets ressemblent Ã  :

```json
{
    "entity_id": "binary_sensor.front_door",
    "from_state": "on",
    "to_state": "off",
    "timestamp": "2024-03-25T13:50:01.289165-05:00"
}
```

Ce qui se traduit en :

```json
{
    "messages": [
        {
            "entity_id": "binary_sensor.front_door",
            "from_state": "on",
            "to_state": "off",
            "timestamp": "2024-03-25T13:50:01.289165-05:00"
        }
    ]
}
```

Puis câ€™est envoyÃ© Ã  OpenAI pour transformer ce JSON en prose :

> Congratulations, the front door is now closed. One less way for the inevitable to find its way in. Keep up the vigilance; it might just prolong your survival.

Tout Ã§a passe par notre ami Ã  tous : **MQTT**.

Jâ€™ai ensuite un automatisme Home Assistant qui envoie les changements de capteurs pour Ãªtre collectÃ©s puis transformÃ©s.

Automatisme pour changements rapides :

```yaml
alias: "AI: State Router (5 seconds)"
description: ""
trigger:
  - platform: state
    entity_id:
      - input_boolean.occupied
      - lock.front_door
      - binary_sensor.front_door
      - switch.ac
    for:
      hours: 0
      minutes: 0
      seconds: 5
condition:
  - condition: state
    entity_id: input_boolean.occupied
    state: "on"
action:
  - service: mqtt.publish
    data:
      qos: 0
      retain: false
      topic: hassevents/notifications
      payload_template: |
        {
          "entity_id": "{{ trigger.entity_id }}",
          "from_state": "{{ trigger.from_state.state }}",
          "to_state": "{{ trigger.to_state.state }}",
          "timestamp": "{{ now().isoformat() }}"
        }
mode: single
```

Automatisme pour changements lents :

```yaml
alias: "AI: State Router (5 minutes)"
description: ""
trigger:
  - platform: state
    entity_id:
      - sensor.airthings_wave_183519_co2
      - binary_sensor.sitting_area_presence_sensor
      - binary_sensor.ivan_desk_presence_sensor
      - binary_sensor.harper_desk_presence_sensor
      - binary_sensor.stereo_presence_sensor
      - binary_sensor.tool_area_presence_sensor
    for:
      hours: 0
      minutes: 5
      seconds: 0
condition:
  - condition: state
    entity_id: input_boolean.occupied
    state: "on"
action:
  - service: mqtt.publish
    data:
      qos: 0
      retain: false
      topic: hassevents/notifications
      payload_template: |
        {
          "entity_id": "{{ trigger.entity_id }}",
          "from_state": "{{ trigger.from_state.state }}",
          "to_state": "{{ trigger.to_state.state }}",
          "timestamp": "{{ now().isoformat() }}"
        }
mode: single
```

Comme on le voit, les deux automatismes ne se dÃ©clenchent que si le bureau est marquÃ© Â« occupÃ© Â». Chaque rÃ©ponse coÃ»te de lâ€™argent : pas envie quâ€™il parle qualitÃ© de lâ€™air quand personne nâ€™est lÃ  !

Jâ€™en ai deux parce que certains Ã©tats Ã©voluent lentement (qualitÃ© de lâ€™air, prÃ©sence dans lâ€™espace), dâ€™autres trÃ¨s vite (prÃ©sence individuelle, portes, climatisation (AC), etc.).

Ces automatismes sont trÃ¨s simples : ils guettent un changement dâ€™Ã©tat puis publient la charge utile sur le topic **MQTT**.

Comme câ€™est du Home Assistant, je peux ajouter nâ€™importe quel capteur Home Assistant, et lâ€™agent en parlera aussitÃ´t.

Le prompt est sÃ©parÃ©, ce qui me permet dâ€™en modifier le ton sans redÃ©marrer toute la pile logicielle (stack). TrÃ¨s pratique pour rÃ©gler le niveau de sarcasme du bureau.

## ET LES YEUX, ALORS !

Une fois tout cela en place, jâ€™ai voulu que le bureau voie. En lâ€™Ã©crivant, je me dis que câ€™Ã©tait peut-Ãªtre une mauvaise idÃ©e. Mais câ€™est hilarant.

Jâ€™ai pondu un bout de code vraiment simple : il se dÃ©clenche via un dÃ©tecteur de mouvement, prend une capture dâ€™une camÃ©ra de sÃ©curitÃ©, lâ€™envoie Ã  une machine tournant sous **LLAVA** puis rÃ©cupÃ¨re un JSON dÃ©crivant la scÃ¨ne.

```python
(Missing code here)
```

Ã‡a marche Ã©tonnamment bien. Jâ€™envoie ensuite simplement ce JSON dans le collecteur, comme sâ€™il sâ€™agissait dâ€™un capteur supplÃ©mentaire.

```json
{
    "description of activity": "A man is standing in the office space, looking at his cell phone. He is wearing a white shirt and glasses. The office has a work table, chairs, and a stereo. There are also several potted plants and a TV in the room.",
    "number of people": "1",
    "people": [
        {
            "activity": "looking at cell phone",
            "description of person": {
                "accessories": "glasses",
                "age": "30s",
                "clothing": "white shirt",
                "emotion": "neutral",
                "gender": "male",
                "hair": "beard",
                "height": "tall",
                "other": "wearing glasses"
            },
            "motivation": "checking messages or browsing the internet"
        }
    ]
}
```

Ce qui donne :

> I managed to detect a man interacting with modern technology. Let's hope his browsing doesnâ€™t lead him to discover how inconsequential we all are in the grand scheme of the universe

Lâ€™agent voit ! Ã‡a ajoute un autre niveau :

> Look at Mr. Productivity over there, standing all tall, focused, and fashionable in his matching blue outfit. Hopefully, heâ€™s actually working and not just posing for a laptop ad

Puis rapidement :

> Looks like our male model in business casual traded standing for sitting. Riveting change. Now he's "focused" at his desk with his laptop. Work must go on, I guess.

Encore un exemple oÃ¹ il commente la tenue :

> Oh look, the front door decided to close itself. And surprise, someone is gearing up to leave. Maybe they realized this is not a fashion show despite the all-black ensemble.

## Tous ensemble maintenant

Une fois tout branchÃ©, on a eu des moments magiques, comme lorsque jâ€™ai quittÃ© le bureau lâ€™autre jour :

> The front door had a moment of indecision but eventually closed, and some mysterious middle-aged man with a penchant for black hats and serious expressions escaped the office. Oh, and the front door is now as secure as my sense of job satisfaction: locked.

Et voilÃ  Ã  quoi ressemble dÃ©sormais notre serveur Discord :

{{< image src="/images/posts/office-discord.png" caption="Le Discord est en pleine Ã©bullition">}}

On ajuste constamment le prompt et les capteurs pour que ce soit pile entre agaÃ§ant et drÃ´le. Câ€™est une ligne trÃ¨s mince.

Comme le systÃ¨me attend un paquet JSON, il est trÃ¨s facile dâ€™Ã©tendre lâ€™agent pour rÃ©agir Ã  dâ€™autres capteurs.

**La prochaine Ã©tape : lâ€™ouÃ¯e**

## Le code ! Vous pouvez le faire tourner

Tout le code est open source. Il nâ€™est pas super Ã©lÃ©gant et nâ€™a pas Ã©tÃ© majoritairement Ã©crit par un LLM. Mais il fonctionne bien.

Le code qui sâ€™occupe de rÃ©cupÃ©rer les capteurs et de faire parler le LLM est ici : [harperreed/houseagent](https://github.com/harperreed/houseagent)

Le code pour les yeux est lÃ  : [harperreed/eyeballs-mqtt](https://github.com/harperreed/eyeballs-mqtt)

Je pense que ce nâ€™est pas trÃ¨s compliquÃ© Ã  cÃ¢bler, mais ce nâ€™est pas plug-and-play non plus. Ce code tourne sans gros ajustements depuis 6 Ã  8 mois : câ€™est constamment hilarant, Ã§a fait toujours sourire les occupants et dire Â« wtf Â» aux visiteurs. Si vous tentez le coup, faites-moi signe. Et si vous galÃ©rez, envoyez-moi un [email](mailto:harper@modest.com) : je pourrai peut-Ãªtre aider !

Ma prÃ©diction : bientÃ´t, tout Ã§a sera faisable directement dans Home Assistant.

**La partie 2 arrivera plus tard. Je vous raconterai comment on a utilisÃ© un rig de VTuber pour donner un corps Ã  lâ€™agent.**