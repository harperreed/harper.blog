---
date: 2024-04-12 09:00:00-05:00
description: मैंने siglip/CLIP और वेक्टर एन्कोडिंग इमेजेज का उपयोग करके एक जादुई मीम
  सर्च इंजन बनाया। यह इस शक्तिशाली तकनीक को सीखने का एक मज़ेदार तरीका था। मैं कोड
  साझा कर रहा हूँ ताकि आप अपना खुद का इंजन बना सकें और अपनी फ़ोटो लाइब्रेरी में छिपे
  हुए रत्न खोज सकें। आइए अपनी तस्वीरों पर AI की ताक़त को unleashed करें!
draft: false
generateSocialImage: true
slug: i-accidentally-built-a-meme-search-engine
tags:
- meme-search-engine
- vector-embeddings
- applied-ai
- siglip
- image-search
title: मैंने गलती से एक मीम सर्च इंजन बना दिया
translationKey: I accidentally built a meme search engine
---

## या : CLIP/SigLIP और तस्वीरों को वेक्टर में एन्कोड करना सीखें  

_tl;dr_ : मैंने SigLIP/CLIP और वेक्टर एन्कोडिंग की मदद से एक मीम सर्च-इंजन बनाया। बड़ा मज़ा आया और ढेर सारी नई चीज़ें सीखीं।  

मैं काफी समय से तरह-तरह के applied-AI टूल बना रहा हूँ। इनमें सबसे ज़्यादा जादुई हिस्सा हमेशा वेक्टर एम्बेडिंग्स रहा है। [Word2Vec](https://en.wikipedia.org/wiki/Word2vec) वगैरह ने तो सीधे दिमाग़ उड़ा दिया—मानो जादू हो।  

मैंने [Hacker News पर एक सीधी-सी ऐप](https://news.ycombinator.com/item?id=39392582) देखी जो [बेहद प्रभावशाली](https://mood-amber.vercel.app/) थी। किसी ने Tumblr से ढेरों इमेजें क्रॉल कीं, [SigLIP](https://arxiv.org/abs/2303.15343) से उनकी एम्बेडिंग्स निकालीं और “इमेज पर क्लिक करो, मिलती-जुलती इमेजें देखो” वाला ऐप बना दिया। **BAM**—मानो जादू! मुझे नहीं पता था यह कैसे करूँगा, लेकिन लगा कि इसे आज़माना मुमकिन है।  

तो मैंने सोचा, अचानक आई इस मोटिवेशन को पकड़ कर जान लूँ कि “ये सब चलता कैसे है।”  

## ये क्या बला है (wut)  

अगर आपने पहले कभी वेक्टर एम्बेडिंग्स, CLIP/SigLIP, वेक्टर डेटाबेस वगैरह नहीं देखे—चिंता मत कीजिए।  

HN वाली हैक से पहले तक मैंने वेक्टर एम्बेडिंग्स, मल्टी-मोडल एम्बेडिंग्स या वेक्टर डेटाबेस पर ज़्यादा ध्यान नहीं दिया था। मैंने **FAISS** (Facebook की सिंपल वेक्टर लाइब्रेरी) और Pinecone ($$) को कुछ हैकों में इस्तेमाल किया—बस इतना कि “चल गया, टेस्ट पास।”  

मुझे अब भी वेक्टर्स क्या होते हैं, बस नाम सुना है (LOL)। इस प्रोजेक्ट से पहले मैं समझ नहीं पाता था कि RAG या किसी और LLM प्रोसेस के बाहर इनका क्या करूँगा।  

मैं बनाकर सीखता हूँ। नतीजे जितने ज़्यादा रोमांचक हों, सीखना उतना तेज़ होता है—और यहाँ तो पूरा सेट-अप ही जादू जैसा था।  

### WTF शब्दावली  

कई दोस्तों ने ड्राफ़्ट पढ़ते समय पूछा, “WTF है X?”—तो जिन शब्दों से मैं नया था, उनकी छोटी-सी सूची:  

- **Vector Embeddings** — टेक्स्ट या इमेज को संख्यात्मक वेक्टरों में बदलना, ताकि समान चीज़ें ढूँढ सकें और लाइब्रेरी में तेज़ी से खोज सकें।  
- **Vector Database** — वेक्टरों को स्टोर व सर्च करने का सिस्टम, जो मिलती-जुलती एंट्रियाँ तुरंत लौटाता है।  
- **Word2Vec** — शब्दों को वेक्टरों में बदलने की क्रांतिकारी तकनीक; इससे समान शब्द या उनके रिश्ते मिलते हैं।  
- **CLIP** — OpenAI का मॉडल जो इमेज और टेक्स्ट दोनों को वेक्टरों में एन्कोड करता है।  
- **OpenCLIP** — OpenAI CLIP का ओपन-सोर्स इम्प्लीमेंटेशन; किसी विशेष अनुमति की ज़रूरत नहीं।  
- **FAISS** — बड़े इमेज-वेक्टर कलेक्शन को बिजली-सी तेज़ (fast AF) तरीके से मैनेज व सर्च करने की लाइब्रेरी।  
- **ChromaDB** — एक वेक्टर डेटाबेस जो इमेज/टेक्स्ट वेक्टर स्टोर करता है और समान रिज़ल्ट फटाफट लौटाता है।  

## सिंपल रखो, Harper  

यह एक सीधा-सपाट हैक है। मैं बस मस्ती कर रहा था (*fucking around*), स्केलेबिलिटी की परवाह कम थी। हाँ, इतना ज़रूर चाहता था कि इसे **आप** बिना झंझट चला सकें।  

एक लक्ष्य यह भी था कि सब कुछ मेरे लैपटॉप पर लोकली चले। हमारे पास ये fancy Mac GPUs हैं—आओ उनकी पूरी ताक़त झोंक दें।  

पहला स्टेप था एक सरल क्रॉलर लिखना जो किसी डायरेक्टरी की इमेजें क्रॉल करे। मैं Apple Photos इस्तेमाल करता हूँ, इसलिए सीधा इमेज-फ़ोल्डर नहीं था। पर मेरे बेहद गुप्त मीम-चैट ग्रुप की इमेजें थीं। चैट एक्सपोर्ट की, इमेजें फ़ोल्डर में डालीं और **BAM**—टेस्ट-सेट तैयार।  

### क्रॉलर  

मैंने दुनिया का सबसे बेकार क्रॉलर बनाया। सच कहूँ तो Claude ने मेरी हिदायतों पर वही हरकत की।  

क़दम-दर-क़दम:  

1. टार्गेट डायरेक्टरी की फ़ाइल-लिस्ट लेता है।  
2. उसे एक `msgpack` फ़ाइल में स्टोर करता है।  
3. उस `msgpack` फ़ाइल को रिफ़रेंस करके हर इमेज पर लूप चलाता हूँ और उसे एक `sqlite` DB में स्टोर करता हूँ, साथ में मेटाडेटा:  
   - हैश  
   - फ़ाइल साइज़  
   - लोकेशन (फ़ाइल पथ)  
4. उसी `sqlite` से इमेज उठाकर CLIP से वेक्टर एम्बेडिंग्स बनाता हूँ।  
5. वेक्टर फिर `sqlite` में लिखता हूँ।  
6. फिर `sqlite` से वेक्टर + इमेज-पाथ निकालकर Chroma वेक्टर डेटाबेस में डाल देता हूँ।  
7. और हो गया।  

काफी फ़ालतू काम है; सीधे इमेज लो → एम्बेडिंग निकालो → Chroma में ठेलो—हो जाता। मैंने Chroma चुना क्योंकि यह मुफ़्त है, इस्तेमाल में आसान है और अलग इन्फ्रा नहीं चाहिए।  

मैंने इसे इतना लूप-भरा रखा क्योंकि:  

- मीमों के बाद मैंने 1.4 लाख इमेजें क्रॉल कीं; क्रैश-प्रूफ़ (crash-proof) होना ज़रूरी था।  
- बीच में रुकने पर फिर से शुरू (resume) करना आसान रहे।  
- मुझे लूप्स बहुत पसंद हैं।  

फ़ालतू जटिलता के बावजूद सब बिना रुके चला। अब तक 2 लाख+ इमेजें क्रॉल हो चुकी हैं।  

### एक एम्बेडिंग सिस्टम  

इमेजें एन्कोड करना मज़ेदार था।  

पहले SigLIP के साथ एक [सरल वेब-सर्विस](https://github.com/harperreed/imbedding) बनाई जहाँ इमेज अपलोड करो और वेक्टर ले जाओ। यह हमारे स्टूडियो के GPU बॉक्स पर चली; बहुत तेज़ तो नहीं थी, पर लोकली चल रहे [OpenCLIP](https://github.com/mlfoundations/open_clip) से ज़्यादा फुर्तीली थी।  

फिर भी लोकल चलाना चाहता था। Apple के [ml-explore](https://github.com/ml-explore/) repo में देखा और **BAM**—वहाँ [CLIP का एक इम्प्लीमेंटेशन](https://github.com/ml-explore/mlx-examples/tree/main/clip) था जो बिजली-सा तेज़ (fast AF) था। बड़े मॉडल पर भी RTX 4090 से तेज़—एकदम वाइल्ड-स्टाइल (पूरी तरह अप्रत्याशित)!  

बस इसे अपनी स्क्रिप्ट में जोड़ना था।  

### MLX_CLIP  

Claude और मैंने Apple के उसी example को एक मज़ेदार-सा Python क्लास बना दिया, जो किसी भी मशीन पर लोकली चलता है: मॉडल डाउनलोड, कन्वर्ट, रन—सब ऑटो।  

कोड यहाँ है : <https://github.com/harperreed/mlx_clip>  

मैं नतीजों से काफ़ी खुश (chuffed) हूँ। ज़्यादातर लोग जानते ही होंगे—Apple Silicon सचमुच तेज़ है।  

इस्तेमाल उतना ही आसान:  

```python
import mlx_clip

# मॉडल इनिशियलाइज़ करें
clip = mlx_clip.mlx_clip("openai/clip-vit-base-patch32")

# इमेज एन्कोड करें
image_embeddings = clip.image_encoder("assets/cat.jpeg")
print(image_embeddings)

# टेक्स्ट एन्कोड करें
text_embeddings = clip.text_encoder("a photo of a cat")
print(text_embeddings)
```  

मैं इसे SigLIP पर चलाना चाहूँगा क्योंकि वह CLIP से बेहतर है, मगर यह सिर्फ़ एक प्रूफ़-ऑफ़-कन्सेप्ट (POC) है। अगर किसी के पास SigLIP चलाने का आइडिया हो—[hmu](mailto:harper@modest.com)। OpenCLIP को फिर से बनाना नहीं चाहता—जो सैद्धांतिक रूप से Apple Silicon पर बढ़िया चलेगा और पहले से ही काफ़ी दमदार है।  

### अब क्या  

इमेज वेक्टर Chroma में ठेल चुके हैं, तो इंटरफ़ेस बनाना बाकी था। ChromaDB की बिल्ट-इन क्वेरी से मिलती-जुलती इमेजें दिखाईं।  

1. जिस इमेज से शुरू करना है, उसका वेक्टर उठाओ।  
2. वही वेक्टर Chroma को दो; Chromed [sic] घटती समानता के क्रम में इमेज IDs लौटाता है।  

सब कुछ एक Tailwind/Flask ऐप में लपेट दिया—यह ग़ज़ब था।  

2015 में यही बनाते तो ख़ून-पसीना बह जाता; मैंने शायद कुल दस घंटे लगाए और हो गया।  

रिज़ल्ट literally magic.  

### “मीम” कॉन्सेप्ट-सर्च  

याद रहे, मेरे पास शुरुआती 12 हज़ार मीम थे।  

Start with this:  

{{< image src="images/posts/vector-memes-bowie.png" caption="So true" >}}  

इसे एन्कोड करो, Chroma में दो—मिलती-जुलती रिज़ल्ट:  

{{< image src="images/posts/vector-memes-bowie-results.png" >}}  

एक और example:  

{{< image src="images/posts/vector-memes-star-trek.png" >}}  

रिज़ल्ट:  

{{< image src="images/posts/vector-memes-star-trek-results.png" >}}  

क्लिक-क्लिक खेलते रहो—मज़ा ही मज़ा।  

### Namespaces?  

सिर्फ़ किसी इमेज पर क्लिक कर समान इमेजें मिलना तो बढ़िया है, लेकिन मेरे लिए “holy-shit” मोमेंट यह था कि वही मॉडल सर्च टेक्स्ट को भी वेक्टर में बदलकर वैसी ही इमेजें खोज लेता है।  

किसी एक इमेज से मिलती-जुलती इमेजें देखना एक बात है; मल्टी-मोडल इंटरफ़ेस से टेक्स्ट लिखकर वही जादू देखना सचमुच चकित कर देता है।  

कुछ examples:  

**money** खोजो:  
{{< image src="images/posts/vector-memes-money.png" >}}  

**AI** खोजो:  
{{< image src="images/posts/vector-memes-ai.png" >}}  

**red** खोजो (रंग? लाइफ़-स्टाइल? रूस?):  
{{< image src="images/posts/vector-memes-red.png" >}}  

आदि—अनंत तक! भूले-बिसरे मीम निकल आते हैं।  
ओ शिट, मुझे ब्लॉग-पोस्ट के लिए एक मीम चाहिए:  

{{< image src="images/posts/vector-memes-writing-meme.jpg" >}}  

(मैं self-aware हूँ, पर मुझे परवाह नहीं—LOL)  

### फ़ोटो लाइब्रेरी पर कैसा चलता है?  

बेहद शानदार।  

मैं पूरी तरह सिफ़ारिश करता हूँ कि इसे अपनी फ़ोटो लाइब्रेरी पर चलाएँ। शुरू करने के लिए मैंने Google Photos Takeout डाउनलोड किया, एक्सटर्नल ड्राइव पर निकाला। Google ने डुप्लिकेट्स इतना ठूँस रखा था कि मैंने कुछ स्क्रिप्ट चला कर सफ़ाई की। फिर मीम-फ़ोल्डर की जगह उसी फ़ोल्डर को पॉइंट कर दिया।  

करीब 1.4 लाख फ़ोटो थीं; लगभग 6 घंटे लगे। नतीजे धमाकेदार।  

#### कुछ मज़ेदार examples  

डुप्लीकेट साफ़ दिखते हैं:  
{{< image src="images/posts/vector-memes-harper.png" >}}  

हमने ढेरों पूडल पाले हैं:  
{{< image src="images/posts/vector-memes-poodles.png" >}}  

Landmarks खोजो—पता चला मैंने प्लेन से फ़ूजी-सान की फ़ोटो ली थी!  
{{< image src="images/posts/vector-memes-fuji-results.png" >}}  

और मिलती-जुलती फ़ूजी इमेजें:  
{{< image src="images/posts/vector-memes-fuji-similar.png" >}}  

जगहें ढूँढना आसान:  
{{< image src="images/posts/vector-memes-chicago.png" >}}  

इमोशन्स भी—कहते हैं मैं लोगों को अक्सर चौंका देता हूँ, इसलिए मेरे पास “surprised” फ़ोटो काफ़ी हैं:  
{{< image src="images/posts/vector-memes-surprised.png" >}}  

लो-राइडर्स जैसा niche stuff (ये Shibuya से!):  
{{< image src="images/posts/vector-memes-low-riders.png" >}}  

बोकेह (धुंधली पृष्ठभूमि) जैसी मुश्किल चीज़ें भी:  
{{< image src="images/posts/vector-memes-bokeh.png" >}}  

क्लिक-क्लिक में भूली हुई बेहतरीन फ़ोटो मिल जाती हैं—जैसे 2017 का Baratunde शॉट:  
{{< image src="images/posts/vector-memes-baratunde.png" >}}  

### यह हर जगह होगा  

मुझे यकीन है कि यह टेक्नोलॉजी जल्द ही हर फ़ोटो-ऐप में होगी। Google Photos शायद पहले से करता हो, पर इतना-ज़्यादा ‘गूगल-टच’ दे दिया है कि नोटिस ही नहीं होता।  

अगर मेरा कोई बड़ा इमेज-बेस्ड प्रोडक्ट होता, तो तुरंत वेक्टर-एन्कोडिंग पाइपलाइन लगा देता—कौन-कौन-से नए फीचर खुलें, कौन जाने।  

## आप भी इसे मुफ़्त में इस्तेमाल कर सकते हैं  

सोर्स कोड यहाँ है: [harperreed/photo-similarity-search](https://github.com/harperreed/photo-similarity-search)  

ज़रूर ट्राई करें। थोड़ा हैकी है, पर सीधा-सादा।  

साफ़-सुथरे एनवायरनमेंट के लिए `conda` वगैरह इस्तेमाल करें। इंटरफ़ेस Tailwind, बैकएंड Flask, कोड Python, और आपका मेज़बान—मैं, Harper Reed।  

## आपके लिए एक चैलेंज!  

कृपया एक Mac-नेटिव ऐप बनाइए जो मेरी फ़ोटो लाइब्रेरी को लोकली कैटलॉग करे। कहीं अपलोड नहीं करना चाहता; बस “crawl this” कहूँ। इसमें ये मज़ेदार चीज़ें जोड़ सकते हैं:  

- Llava/Moondream से ऑटो-कैप्शनिंग  
- कीवर्ड / टैग  
- वेक्टर-समानता  
- वगैरह  

सब कुछ लोकली चले, नेटिव हो, सादा और असरदार। Lightroom, Capture One या Apple Photos में प्लग-इन कर दें तो सोने पे सुहागा।  

मैं यह चाहता हूँ—बनाइए। AI के जादू से हम अपनी छिपी हुई बेहतरीन फ़ोटो खोजेंगे।  

## Extra Credit : Lightroom Preview JPEG रिकवरी  

मेरा हैक-बड्डी Ivan यह प्रोजेक्ट देखते ही अपनी फ़ोटो लाइब्रेरी पर चलाना चाहता था। उसकी असली लाइब्रेरी एक्सटर्नल ड्राइव पर थी, पर Lightroom preview फ़ाइल लोकली थी। उसने झटपट एक स्क्रिप्ट लिखी—preview फ़ाइल से थम्बनेल और मेटाडेटा निकालकर एक्सटर्नल डिस्क पर सेव कर लिये।  

हमने वही इमेज-वेक्टर क्रॉलर चलाया और **BAM**—समान इमेजें मिलने लगीं। सब परफेक्ट।  

#### Lightroom फ़ोटो रिकवर करें—कम-से-कम थम्बनेल तो निकालें  

Ivan की यह सिंपल स्क्रिप्ट कमाल की है। अगर कभी आपकी असली लाइब्रेरी उड़ जाये (corrupt HDD वगैरह) और `lrpreview` फ़ाइल बची हो—यह स्क्रिप्ट कम-से-कम लो-रेज़ वर्ज़न निकाल देगी।  

काम की चीज़—संभाल कर रखें।  

देखें : [LR Preview JPEG Extractor](https://github.com/ibips/lrprev-extract)  

## पढ़ने के लिये धन्यवाद  

हमेशा की तरह, मुझसे [hmu](mailto:harper@modest.com) पर बात करें—मिलकर गप करेंगे। इन दिनों मैं AI, ई-कॉमर्स, फ़ोटो, Hi-Fi, हैकिंग वगैरह पर सोच रहा हूँ।  

अगर आप Chicago में हों तो आ मिलें।